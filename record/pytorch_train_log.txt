[2025-08-07 15:06:05 train.log] INFO: Epoch: [0]  [Step 100/14540]  lr: 0.000010  loss: 4.52601  detection_loss: 3.1963 (cls: 1.4221, box: 1.7742)  rpn_loss: 1.3297 (cls: 0.6769, box: 0.6528)
[2025-08-07 15:06:10 train.log] INFO: Epoch: [0]  [Step 200/14540]  lr: 0.000010  loss: 2.90317  detection_loss: 2.2007 (cls: 0.6188, box: 1.5819)  rpn_loss: 0.7025 (cls: 0.6555, box: 0.0470)
[2025-08-07 15:06:15 train.log] INFO: Epoch: [0]  [Step 300/14540]  lr: 0.000010  loss: 3.85390  detection_loss: 3.1785 (cls: 0.6124, box: 2.5661)  rpn_loss: 0.6754 (cls: 0.6295, box: 0.0458)
[2025-08-07 15:06:20 train.log] INFO: Epoch: [0]  [Step 400/14540]  lr: 0.000010  loss: 2.86226  detection_loss: 2.1614 (cls: 0.3718, box: 1.7896)  rpn_loss: 0.7008 (cls: 0.5636, box: 0.1373)
[2025-08-07 15:06:25 train.log] INFO: Epoch: [0]  [Step 500/14540]  lr: 0.000010  loss: 3.01010  detection_loss: 2.4031 (cls: 0.5815, box: 1.8216)  rpn_loss: 0.6070 (cls: 0.4711, box: 0.1360)
[2025-08-07 15:06:30 train.log] INFO: Epoch: [0]  [Step 600/14540]  lr: 0.000010  loss: 2.80564  detection_loss: 2.2710 (cls: 0.4565, box: 1.8144)  rpn_loss: 0.5347 (cls: 0.3169, box: 0.2178)
[2025-08-07 15:06:35 train.log] INFO: Epoch: [0]  [Step 700/14540]  lr: 0.000010  loss: 2.60727  detection_loss: 2.0796 (cls: 0.3261, box: 1.7535)  rpn_loss: 0.5277 (cls: 0.1660, box: 0.3617)
[2025-08-07 15:06:40 train.log] INFO: Epoch: [0]  [Step 800/14540]  lr: 0.000010  loss: 2.86736  detection_loss: 2.4225 (cls: 0.4391, box: 1.9833)  rpn_loss: 0.4449 (cls: 0.3003, box: 0.1445)
[2025-08-07 15:06:45 train.log] INFO: Epoch: [0]  [Step 900/14540]  lr: 0.000010  loss: 2.83619  detection_loss: 2.2826 (cls: 0.5885, box: 1.6941)  rpn_loss: 0.5536 (cls: 0.3118, box: 0.2418)
[2025-08-07 15:06:51 train.log] INFO: Epoch: [0]  [Step 1000/14540]  lr: 0.000010  loss: 2.88056  detection_loss: 2.6036 (cls: 0.4498, box: 2.1537)  rpn_loss: 0.2770 (cls: 0.1445, box: 0.1325)
[2025-08-07 15:06:56 train.log] INFO: Epoch: [0]  [Step 1100/14540]  lr: 0.000010  loss: 2.30415  detection_loss: 2.0099 (cls: 0.3743, box: 1.6356)  rpn_loss: 0.2942 (cls: 0.1611, box: 0.1331)
[2025-08-07 15:07:01 train.log] INFO: Epoch: [0]  [Step 1200/14540]  lr: 0.000010  loss: 2.34311  detection_loss: 2.0387 (cls: 0.2168, box: 1.8219)  rpn_loss: 0.3044 (cls: 0.1040, box: 0.2004)
[2025-08-07 15:07:06 train.log] INFO: Epoch: [0]  [Step 1300/14540]  lr: 0.000010  loss: 2.96884  detection_loss: 2.7005 (cls: 0.5295, box: 2.1710)  rpn_loss: 0.2683 (cls: 0.1953, box: 0.0730)
[2025-08-07 15:07:11 train.log] INFO: Epoch: [0]  [Step 1400/14540]  lr: 0.000010  loss: 3.21836  detection_loss: 2.9240 (cls: 0.6770, box: 2.2470)  rpn_loss: 0.2944 (cls: 0.0959, box: 0.1985)
[2025-08-07 15:07:16 train.log] INFO: Epoch: [0]  [Step 1500/14540]  lr: 0.000010  loss: 2.47110  detection_loss: 2.2406 (cls: 0.3041, box: 1.9365)  rpn_loss: 0.2305 (cls: 0.1332, box: 0.0973)
[2025-08-07 15:07:21 train.log] INFO: Epoch: [0]  [Step 1600/14540]  lr: 0.000010  loss: 2.03819  detection_loss: 1.7815 (cls: 0.2965, box: 1.4850)  rpn_loss: 0.2567 (cls: 0.0950, box: 0.1617)
[2025-08-07 15:07:26 train.log] INFO: Epoch: [0]  [Step 1700/14540]  lr: 0.000010  loss: 2.67501  detection_loss: 2.2957 (cls: 0.3345, box: 1.9612)  rpn_loss: 0.3793 (cls: 0.0876, box: 0.2917)
[2025-08-07 15:07:31 train.log] INFO: Epoch: [0]  [Step 1800/14540]  lr: 0.000010  loss: 2.74110  detection_loss: 2.4409 (cls: 0.4422, box: 1.9987)  rpn_loss: 0.3001 (cls: 0.2449, box: 0.0553)
[2025-08-07 15:07:36 train.log] INFO: Epoch: [0]  [Step 1900/14540]  lr: 0.000010  loss: 2.87798  detection_loss: 2.5709 (cls: 0.4786, box: 2.0923)  rpn_loss: 0.3071 (cls: 0.1691, box: 0.1380)
[2025-08-07 15:07:41 train.log] INFO: Epoch: [0]  [Step 2000/14540]  lr: 0.000010  loss: 2.62892  detection_loss: 2.3852 (cls: 0.4223, box: 1.9629)  rpn_loss: 0.2437 (cls: 0.0977, box: 0.1460)
[2025-08-07 15:07:46 train.log] INFO: Epoch: [0]  [Step 2100/14540]  lr: 0.000010  loss: 2.00211  detection_loss: 1.6794 (cls: 0.2722, box: 1.4071)  rpn_loss: 0.3227 (cls: 0.0880, box: 0.2347)
[2025-08-07 15:07:50 train.log] INFO: Epoch: [0]  [Step 2200/14540]  lr: 0.000010  loss: 2.01434  detection_loss: 1.7386 (cls: 0.2490, box: 1.4895)  rpn_loss: 0.2758 (cls: 0.2158, box: 0.0599)
[2025-08-07 15:07:55 train.log] INFO: Epoch: [0]  [Step 2300/14540]  lr: 0.000010  loss: 2.88313  detection_loss: 2.5784 (cls: 0.5934, box: 1.9850)  rpn_loss: 0.3047 (cls: 0.1358, box: 0.1690)
[2025-08-07 15:08:00 train.log] INFO: Epoch: [0]  [Step 2400/14540]  lr: 0.000010  loss: 2.86617  detection_loss: 2.5810 (cls: 0.5959, box: 1.9851)  rpn_loss: 0.2851 (cls: 0.1122, box: 0.1730)
[2025-08-07 15:08:05 train.log] INFO: Epoch: [0]  [Step 2500/14540]  lr: 0.000010  loss: 2.36330  detection_loss: 2.0564 (cls: 0.3596, box: 1.6968)  rpn_loss: 0.3069 (cls: 0.2440, box: 0.0629)
[2025-08-07 15:08:10 train.log] INFO: Epoch: [0]  [Step 2600/14540]  lr: 0.000010  loss: 1.99285  detection_loss: 1.7559 (cls: 0.3169, box: 1.4390)  rpn_loss: 0.2369 (cls: 0.1466, box: 0.0903)
[2025-08-07 15:08:15 train.log] INFO: Epoch: [0]  [Step 2700/14540]  lr: 0.000010  loss: 2.54385  detection_loss: 2.3499 (cls: 0.4303, box: 1.9197)  rpn_loss: 0.1939 (cls: 0.0831, box: 0.1108)
[2025-08-07 15:08:20 train.log] INFO: Epoch: [0]  [Step 2800/14540]  lr: 0.000010  loss: 2.51975  detection_loss: 1.9471 (cls: 0.4411, box: 1.5060)  rpn_loss: 0.5726 (cls: 0.1169, box: 0.4557)
[2025-08-07 15:08:25 train.log] INFO: Epoch: [0]  [Step 2900/14540]  lr: 0.000010  loss: 2.68883  detection_loss: 2.4266 (cls: 0.3855, box: 2.0411)  rpn_loss: 0.2623 (cls: 0.1622, box: 0.1001)
[2025-08-07 15:08:30 train.log] INFO: Epoch: [0]  [Step 3000/14540]  lr: 0.000010  loss: 2.91427  detection_loss: 2.5536 (cls: 0.6168, box: 1.9368)  rpn_loss: 0.3606 (cls: 0.1441, box: 0.2165)
[2025-08-07 15:08:35 train.log] INFO: Epoch: [0]  [Step 3100/14540]  lr: 0.000010  loss: 2.08946  detection_loss: 1.7372 (cls: 0.3444, box: 1.3928)  rpn_loss: 0.3522 (cls: 0.1286, box: 0.2237)
[2025-08-07 15:08:40 train.log] INFO: Epoch: [0]  [Step 3200/14540]  lr: 0.000010  loss: 2.60917  detection_loss: 2.2949 (cls: 0.4077, box: 1.8872)  rpn_loss: 0.3143 (cls: 0.1929, box: 0.1214)
[2025-08-07 15:08:45 train.log] INFO: Epoch: [0]  [Step 3300/14540]  lr: 0.000010  loss: 2.25929  detection_loss: 1.9654 (cls: 0.3816, box: 1.5838)  rpn_loss: 0.2939 (cls: 0.1799, box: 0.1140)
[2025-08-07 15:08:50 train.log] INFO: Epoch: [0]  [Step 3400/14540]  lr: 0.000010  loss: 2.66127  detection_loss: 2.0907 (cls: 0.3559, box: 1.7348)  rpn_loss: 0.5705 (cls: 0.1449, box: 0.4257)
[2025-08-07 15:08:55 train.log] INFO: Epoch: [0]  [Step 3500/14540]  lr: 0.000010  loss: 2.14848  detection_loss: 1.8781 (cls: 0.3824, box: 1.4958)  rpn_loss: 0.2704 (cls: 0.1485, box: 0.1219)
[2025-08-07 15:09:00 train.log] INFO: Epoch: [0]  [Step 3600/14540]  lr: 0.000010  loss: 2.49835  detection_loss: 2.2034 (cls: 0.5429, box: 1.6605)  rpn_loss: 0.2949 (cls: 0.2213, box: 0.0736)
[2025-08-07 15:09:01 train.log] INFO: Epoch: [0]  [Step 3635/14540]  lr: 0.000010  loss: 2.20205  detection_loss: 1.8430 (cls: 0.3330, box: 1.5100)  rpn_loss: 0.3590 (cls: 0.0679, box: 0.2911)
[2025-08-07 15:09:04 train.log] INFO: Epoch: [0]  [Step 3700/14540]  lr: 0.000010  loss: 2.57535  detection_loss: 2.2847 (cls: 0.3191, box: 1.9657)  rpn_loss: 0.2906 (cls: 0.1469, box: 0.1438)
[2025-08-07 15:09:09 train.log] INFO: Epoch: [0]  [Step 3800/14540]  lr: 0.000010  loss: 2.22276  detection_loss: 1.8745 (cls: 0.2807, box: 1.5938)  rpn_loss: 0.3482 (cls: 0.0832, box: 0.2650)
[2025-08-07 15:09:14 train.log] INFO: Epoch: [0]  [Step 3900/14540]  lr: 0.000010  loss: 2.23729  detection_loss: 1.9500 (cls: 0.4193, box: 1.5306)  rpn_loss: 0.2873 (cls: 0.1786, box: 0.1087)
[2025-08-07 15:09:19 train.log] INFO: Epoch: [0]  [Step 4000/14540]  lr: 0.000010  loss: 2.40830  detection_loss: 2.0678 (cls: 0.4362, box: 1.6316)  rpn_loss: 0.3405 (cls: 0.1290, box: 0.2115)
[2025-08-07 15:09:24 train.log] INFO: Epoch: [0]  [Step 4100/14540]  lr: 0.000010  loss: 2.47804  detection_loss: 2.1893 (cls: 0.3985, box: 1.7908)  rpn_loss: 0.2888 (cls: 0.1499, box: 0.1389)
[2025-08-07 15:09:29 train.log] INFO: Epoch: [0]  [Step 4200/14540]  lr: 0.000010  loss: 2.70627  detection_loss: 2.4932 (cls: 0.5703, box: 1.9229)  rpn_loss: 0.2131 (cls: 0.1216, box: 0.0915)
[2025-08-07 15:09:34 train.log] INFO: Epoch: [0]  [Step 4300/14540]  lr: 0.000010  loss: 2.86698  detection_loss: 2.5101 (cls: 0.3362, box: 2.1739)  rpn_loss: 0.3569 (cls: 0.1463, box: 0.2106)
[2025-08-07 15:09:39 train.log] INFO: Epoch: [0]  [Step 4400/14540]  lr: 0.000010  loss: 2.62931  detection_loss: 2.4221 (cls: 0.6095, box: 1.8125)  rpn_loss: 0.2072 (cls: 0.1394, box: 0.0678)
[2025-08-07 15:09:44 train.log] INFO: Epoch: [0]  [Step 4500/14540]  lr: 0.000010  loss: 2.84086  detection_loss: 2.5462 (cls: 0.3931, box: 2.1531)  rpn_loss: 0.2946 (cls: 0.2328, box: 0.0619)
[2025-08-07 15:09:48 train.log] INFO: Epoch: [0]  [Step 4600/14540]  lr: 0.000010  loss: 2.45487  detection_loss: 2.0272 (cls: 0.4946, box: 1.5326)  rpn_loss: 0.4277 (cls: 0.1160, box: 0.3117)
[2025-08-07 15:09:53 train.log] INFO: Epoch: [0]  [Step 4700/14540]  lr: 0.000010  loss: 2.46955  detection_loss: 2.1689 (cls: 0.4917, box: 1.6772)  rpn_loss: 0.3006 (cls: 0.1820, box: 0.1187)
[2025-08-07 15:09:58 train.log] INFO: Epoch: [0]  [Step 4800/14540]  lr: 0.000010  loss: 1.87509  detection_loss: 1.6211 (cls: 0.4040, box: 1.2171)  rpn_loss: 0.2540 (cls: 0.1081, box: 0.1459)
[2025-08-07 15:10:03 train.log] INFO: Epoch: [0]  [Step 4900/14540]  lr: 0.000010  loss: 2.12825  detection_loss: 1.9077 (cls: 0.4929, box: 1.4148)  rpn_loss: 0.2206 (cls: 0.1082, box: 0.1123)
[2025-08-07 15:10:08 train.log] INFO: Epoch: [0]  [Step 5000/14540]  lr: 0.000010  loss: 2.43755  detection_loss: 2.1703 (cls: 0.6858, box: 1.4845)  rpn_loss: 0.2672 (cls: 0.1379, box: 0.1293)
[2025-08-07 15:10:13 train.log] INFO: Epoch: [0]  [Step 5100/14540]  lr: 0.000010  loss: 2.28776  detection_loss: 1.9694 (cls: 0.4940, box: 1.4754)  rpn_loss: 0.3184 (cls: 0.1955, box: 0.1228)
[2025-08-07 15:10:18 train.log] INFO: Epoch: [0]  [Step 5200/14540]  lr: 0.000010  loss: 2.12426  detection_loss: 1.8940 (cls: 0.4312, box: 1.4627)  rpn_loss: 0.2303 (cls: 0.1840, box: 0.0462)
[2025-08-07 15:10:23 train.log] INFO: Epoch: [0]  [Step 5300/14540]  lr: 0.000010  loss: 2.72133  detection_loss: 2.4904 (cls: 0.5460, box: 1.9443)  rpn_loss: 0.2310 (cls: 0.1534, box: 0.0776)
[2025-08-07 15:10:28 train.log] INFO: Epoch: [0]  [Step 5400/14540]  lr: 0.000010  loss: 1.77781  detection_loss: 1.5425 (cls: 0.3313, box: 1.2112)  rpn_loss: 0.2353 (cls: 0.0816, box: 0.1537)
[2025-08-07 15:10:33 train.log] INFO: Epoch: [0]  [Step 5500/14540]  lr: 0.000010  loss: 2.26252  detection_loss: 2.0732 (cls: 0.4049, box: 1.6684)  rpn_loss: 0.1893 (cls: 0.1021, box: 0.0872)
[2025-08-07 15:10:37 train.log] INFO: Epoch: [0]  [Step 5600/14540]  lr: 0.000010  loss: 2.44720  detection_loss: 2.1477 (cls: 0.4102, box: 1.7375)  rpn_loss: 0.2995 (cls: 0.1099, box: 0.1895)
[2025-08-07 15:10:42 train.log] INFO: Epoch: [0]  [Step 5700/14540]  lr: 0.000010  loss: 2.43591  detection_loss: 2.1826 (cls: 0.4131, box: 1.7695)  rpn_loss: 0.2533 (cls: 0.1867, box: 0.0667)
[2025-08-07 15:10:47 train.log] INFO: Epoch: [0]  [Step 5800/14540]  lr: 0.000010  loss: 2.18333  detection_loss: 1.8034 (cls: 0.3536, box: 1.4498)  rpn_loss: 0.3799 (cls: 0.1865, box: 0.1934)
[2025-08-07 15:10:52 train.log] INFO: Epoch: [0]  [Step 5900/14540]  lr: 0.000010  loss: 2.34418  detection_loss: 2.0303 (cls: 0.3688, box: 1.6615)  rpn_loss: 0.3139 (cls: 0.2725, box: 0.0414)
[2025-08-07 15:10:57 train.log] INFO: Epoch: [0]  [Step 6000/14540]  lr: 0.000010  loss: 2.35112  detection_loss: 2.0795 (cls: 0.4655, box: 1.6140)  rpn_loss: 0.2716 (cls: 0.2062, box: 0.0655)
[2025-08-07 15:11:02 train.log] INFO: Epoch: [0]  [Step 6100/14540]  lr: 0.000010  loss: 2.39936  detection_loss: 2.1852 (cls: 0.4010, box: 1.7842)  rpn_loss: 0.2142 (cls: 0.1213, box: 0.0928)
[2025-08-07 15:11:07 train.log] INFO: Epoch: [0]  [Step 6200/14540]  lr: 0.000010  loss: 2.16316  detection_loss: 1.9444 (cls: 0.5352, box: 1.4092)  rpn_loss: 0.2187 (cls: 0.1772, box: 0.0416)
[2025-08-07 15:11:12 train.log] INFO: Epoch: [0]  [Step 6300/14540]  lr: 0.000010  loss: 2.45734  detection_loss: 2.2099 (cls: 0.4628, box: 1.7470)  rpn_loss: 0.2475 (cls: 0.1785, box: 0.0690)
[2025-08-07 15:11:17 train.log] INFO: Epoch: [0]  [Step 6400/14540]  lr: 0.000010  loss: 2.49217  detection_loss: 2.2922 (cls: 0.4749, box: 1.8173)  rpn_loss: 0.2000 (cls: 0.1003, box: 0.0997)
[2025-08-07 15:11:22 train.log] INFO: Epoch: [0]  [Step 6500/14540]  lr: 0.000010  loss: 2.08439  detection_loss: 1.9106 (cls: 0.3685, box: 1.5421)  rpn_loss: 0.1738 (cls: 0.1063, box: 0.0675)
[2025-08-07 15:11:27 train.log] INFO: Epoch: [0]  [Step 6600/14540]  lr: 0.000010  loss: 1.85593  detection_loss: 1.6219 (cls: 0.5147, box: 1.1072)  rpn_loss: 0.2340 (cls: 0.1478, box: 0.0863)
[2025-08-07 15:11:31 train.log] INFO: Epoch: [0]  [Step 6700/14540]  lr: 0.000010  loss: 1.57692  detection_loss: 1.3862 (cls: 0.3096, box: 1.0766)  rpn_loss: 0.1907 (cls: 0.1564, box: 0.0343)
[2025-08-07 15:11:36 train.log] INFO: Epoch: [0]  [Step 6800/14540]  lr: 0.000010  loss: 2.11770  detection_loss: 1.7654 (cls: 0.4256, box: 1.3397)  rpn_loss: 0.3524 (cls: 0.1229, box: 0.2295)
[2025-08-07 15:11:41 train.log] INFO: Epoch: [0]  [Step 6900/14540]  lr: 0.000010  loss: 2.14617  detection_loss: 1.8470 (cls: 0.5209, box: 1.3261)  rpn_loss: 0.2992 (cls: 0.1308, box: 0.1684)
[2025-08-07 15:11:46 train.log] INFO: Epoch: [0]  [Step 7000/14540]  lr: 0.000010  loss: 2.33612  detection_loss: 2.0521 (cls: 0.4665, box: 1.5856)  rpn_loss: 0.2841 (cls: 0.2444, box: 0.0396)
[2025-08-07 15:11:51 train.log] INFO: Epoch: [0]  [Step 7100/14540]  lr: 0.000010  loss: 2.19772  detection_loss: 1.8170 (cls: 0.4248, box: 1.3922)  rpn_loss: 0.3807 (cls: 0.1178, box: 0.2629)
[2025-08-07 15:11:56 train.log] INFO: Epoch: [0]  [Step 7200/14540]  lr: 0.000010  loss: 2.10013  detection_loss: 1.8503 (cls: 0.2970, box: 1.5533)  rpn_loss: 0.2498 (cls: 0.1792, box: 0.0706)
[2025-08-07 15:12:01 train.log] INFO: Epoch: [0]  [Step 7300/14540]  lr: 0.000010  loss: 2.80624  detection_loss: 2.5645 (cls: 0.3592, box: 2.2052)  rpn_loss: 0.2418 (cls: 0.1794, box: 0.0624)
[2025-08-07 15:12:06 train.log] INFO: Epoch: [0]  [Step 7400/14540]  lr: 0.000010  loss: 2.03181  detection_loss: 1.8342 (cls: 0.2328, box: 1.6014)  rpn_loss: 0.1977 (cls: 0.0934, box: 0.1043)
[2025-08-07 15:12:11 train.log] INFO: Epoch: [0]  [Step 7500/14540]  lr: 0.000010  loss: 1.39508  detection_loss: 1.2101 (cls: 0.2641, box: 0.9460)  rpn_loss: 0.1850 (cls: 0.0777, box: 0.1073)
[2025-08-07 15:12:16 train.log] INFO: Epoch: [0]  [Step 7600/14540]  lr: 0.000010  loss: 2.54842  detection_loss: 2.2557 (cls: 0.5166, box: 1.7390)  rpn_loss: 0.2927 (cls: 0.1384, box: 0.1543)
[2025-08-07 15:12:21 train.log] INFO: Epoch: [0]  [Step 7700/14540]  lr: 0.000010  loss: 2.65440  detection_loss: 2.4053 (cls: 0.6047, box: 1.8007)  rpn_loss: 0.2491 (cls: 0.2048, box: 0.0442)
[2025-08-07 15:12:26 train.log] INFO: Epoch: [0]  [Step 7800/14540]  lr: 0.000010  loss: 2.38330  detection_loss: 2.1470 (cls: 0.4031, box: 1.7439)  rpn_loss: 0.2363 (cls: 0.1821, box: 0.0542)
[2025-08-07 15:12:31 train.log] INFO: Epoch: [0]  [Step 7900/14540]  lr: 0.000010  loss: 1.88233  detection_loss: 1.7352 (cls: 0.5294, box: 1.2058)  rpn_loss: 0.1471 (cls: 0.1164, box: 0.0307)
[2025-08-07 15:12:36 train.log] INFO: Epoch: [0]  [Step 8000/14540]  lr: 0.000010  loss: 1.92118  detection_loss: 1.6369 (cls: 0.3057, box: 1.3312)  rpn_loss: 0.2843 (cls: 0.1371, box: 0.1472)
[2025-08-07 15:12:41 train.log] INFO: Epoch: [0]  [Step 8100/14540]  lr: 0.000010  loss: 2.56442  detection_loss: 2.1239 (cls: 0.6017, box: 1.5222)  rpn_loss: 0.4406 (cls: 0.0781, box: 0.3625)
[2025-08-07 15:12:46 train.log] INFO: Epoch: [0]  [Step 8200/14540]  lr: 0.000010  loss: 1.77011  detection_loss: 1.3628 (cls: 0.2999, box: 1.0630)  rpn_loss: 0.4073 (cls: 0.1150, box: 0.2923)
[2025-08-07 15:12:51 train.log] INFO: Epoch: [0]  [Step 8300/14540]  lr: 0.000010  loss: 1.46258  detection_loss: 1.2962 (cls: 0.2143, box: 1.0819)  rpn_loss: 0.1663 (cls: 0.0982, box: 0.0681)
[2025-08-07 15:12:55 train.log] INFO: Epoch: [0]  [Step 8400/14540]  lr: 0.000010  loss: 1.66968  detection_loss: 1.3966 (cls: 0.2190, box: 1.1776)  rpn_loss: 0.2731 (cls: 0.1182, box: 0.1548)
[2025-08-07 15:13:00 train.log] INFO: Epoch: [0]  [Step 8500/14540]  lr: 0.000010  loss: 1.88665  detection_loss: 1.6604 (cls: 0.2552, box: 1.4053)  rpn_loss: 0.2262 (cls: 0.1191, box: 0.1071)
[2025-08-07 15:13:05 train.log] INFO: Epoch: [0]  [Step 8600/14540]  lr: 0.000010  loss: 1.78935  detection_loss: 1.4951 (cls: 0.2688, box: 1.2263)  rpn_loss: 0.2943 (cls: 0.0783, box: 0.2160)
[2025-08-07 15:13:10 train.log] INFO: Epoch: [0]  [Step 8700/14540]  lr: 0.000010  loss: 1.87655  detection_loss: 1.5449 (cls: 0.2331, box: 1.3118)  rpn_loss: 0.3316 (cls: 0.1340, box: 0.1976)
[2025-08-07 15:13:15 train.log] INFO: Epoch: [0]  [Step 8800/14540]  lr: 0.000010  loss: 2.27238  detection_loss: 2.1342 (cls: 0.4175, box: 1.7167)  rpn_loss: 0.1382 (cls: 0.0852, box: 0.0530)
[2025-08-07 15:13:20 train.log] INFO: Epoch: [0]  [Step 8900/14540]  lr: 0.000010  loss: 2.54251  detection_loss: 2.2690 (cls: 0.5986, box: 1.6704)  rpn_loss: 0.2735 (cls: 0.2219, box: 0.0516)
[2025-08-07 15:13:25 train.log] INFO: Epoch: [0]  [Step 9000/14540]  lr: 0.000010  loss: 1.96826  detection_loss: 1.7737 (cls: 0.1945, box: 1.5791)  rpn_loss: 0.1946 (cls: 0.1450, box: 0.0496)
[2025-08-07 15:13:30 train.log] INFO: Epoch: [0]  [Step 9100/14540]  lr: 0.000010  loss: 1.99775  detection_loss: 1.7438 (cls: 0.3811, box: 1.3628)  rpn_loss: 0.2539 (cls: 0.1158, box: 0.1381)
[2025-08-07 15:13:35 train.log] INFO: Epoch: [0]  [Step 9200/14540]  lr: 0.000010  loss: 1.98454  detection_loss: 1.6009 (cls: 0.2588, box: 1.3421)  rpn_loss: 0.3837 (cls: 0.0841, box: 0.2995)
[2025-08-07 15:13:40 train.log] INFO: Epoch: [0]  [Step 9300/14540]  lr: 0.000010  loss: 1.57712  detection_loss: 1.4167 (cls: 0.1875, box: 1.2292)  rpn_loss: 0.1604 (cls: 0.1109, box: 0.0495)
[2025-08-07 15:13:45 train.log] INFO: Epoch: [0]  [Step 9400/14540]  lr: 0.000010  loss: 1.96391  detection_loss: 1.7633 (cls: 0.3234, box: 1.4399)  rpn_loss: 0.2006 (cls: 0.1173, box: 0.0832)
[2025-08-07 15:13:50 train.log] INFO: Epoch: [0]  [Step 9500/14540]  lr: 0.000010  loss: 1.75282  detection_loss: 1.4290 (cls: 0.3876, box: 1.0414)  rpn_loss: 0.3239 (cls: 0.1065, box: 0.2173)
[2025-08-07 15:13:55 train.log] INFO: Epoch: [0]  [Step 9600/14540]  lr: 0.000010  loss: 1.35210  detection_loss: 1.2150 (cls: 0.3988, box: 0.8162)  rpn_loss: 0.1371 (cls: 0.1116, box: 0.0255)
[2025-08-07 15:14:00 train.log] INFO: Epoch: [0]  [Step 9700/14540]  lr: 0.000010  loss: 2.15930  detection_loss: 1.8961 (cls: 0.4283, box: 1.4678)  rpn_loss: 0.2632 (cls: 0.2233, box: 0.0399)
[2025-08-07 15:14:05 train.log] INFO: Epoch: [0]  [Step 9800/14540]  lr: 0.000010  loss: 1.96604  detection_loss: 1.7880 (cls: 0.3277, box: 1.4603)  rpn_loss: 0.1781 (cls: 0.1362, box: 0.0418)
[2025-08-07 15:14:10 train.log] INFO: Epoch: [0]  [Step 9900/14540]  lr: 0.000010  loss: 2.12225  detection_loss: 1.8592 (cls: 0.3688, box: 1.4904)  rpn_loss: 0.2631 (cls: 0.1730, box: 0.0901)
[2025-08-07 15:14:15 train.log] INFO: Epoch: [0]  [Step 10000/14540]  lr: 0.000010  loss: 1.91023  detection_loss: 1.8076 (cls: 0.2396, box: 1.5680)  rpn_loss: 0.1026 (cls: 0.0568, box: 0.0458)
[2025-08-07 15:14:20 train.log] INFO: Epoch: [0]  [Step 10100/14540]  lr: 0.000010  loss: 1.70420  detection_loss: 1.5728 (cls: 0.2853, box: 1.2875)  rpn_loss: 0.1313 (cls: 0.0748, box: 0.0565)
[2025-08-07 15:14:25 train.log] INFO: Epoch: [0]  [Step 10200/14540]  lr: 0.000010  loss: 1.93219  detection_loss: 1.6648 (cls: 0.3355, box: 1.3294)  rpn_loss: 0.2674 (cls: 0.0670, box: 0.2004)
[2025-08-07 15:14:29 train.log] INFO: Epoch: [0]  [Step 10300/14540]  lr: 0.000010  loss: 2.03680  detection_loss: 1.7428 (cls: 0.4674, box: 1.2754)  rpn_loss: 0.2940 (cls: 0.2256, box: 0.0684)
[2025-08-07 15:14:34 train.log] INFO: Epoch: [0]  [Step 10400/14540]  lr: 0.000010  loss: 1.98452  detection_loss: 1.7735 (cls: 0.3629, box: 1.4106)  rpn_loss: 0.2110 (cls: 0.1295, box: 0.0815)
[2025-08-07 15:14:39 train.log] INFO: Epoch: [0]  [Step 10500/14540]  lr: 0.000010  loss: 2.01077  detection_loss: 1.7844 (cls: 0.4812, box: 1.3032)  rpn_loss: 0.2264 (cls: 0.0541, box: 0.1722)
[2025-08-07 15:14:44 train.log] INFO: Epoch: [0]  [Step 10600/14540]  lr: 0.000010  loss: 2.01610  detection_loss: 1.7451 (cls: 0.4043, box: 1.3409)  rpn_loss: 0.2710 (cls: 0.1205, box: 0.1504)
[2025-08-07 15:14:49 train.log] INFO: Epoch: [0]  [Step 10700/14540]  lr: 0.000010  loss: 1.54221  detection_loss: 1.3469 (cls: 0.2330, box: 1.1139)  rpn_loss: 0.1953 (cls: 0.0911, box: 0.1042)
[2025-08-07 15:14:54 train.log] INFO: Epoch: [0]  [Step 10800/14540]  lr: 0.000010  loss: 2.39795  detection_loss: 2.2150 (cls: 0.5367, box: 1.6783)  rpn_loss: 0.1830 (cls: 0.1131, box: 0.0699)
[2025-08-07 15:14:59 train.log] INFO: Epoch: [0]  [Step 10900/14540]  lr: 0.000010  loss: 2.01949  detection_loss: 1.8383 (cls: 0.3574, box: 1.4809)  rpn_loss: 0.1812 (cls: 0.0758, box: 0.1054)
[2025-08-07 15:15:04 train.log] INFO: Epoch: [0]  [Step 11000/14540]  lr: 0.000010  loss: 1.77733  detection_loss: 1.5783 (cls: 0.3651, box: 1.2132)  rpn_loss: 0.1991 (cls: 0.0965, box: 0.1026)
[2025-08-07 15:15:09 train.log] INFO: Epoch: [0]  [Step 11100/14540]  lr: 0.000010  loss: 1.57134  detection_loss: 1.4316 (cls: 0.4728, box: 0.9588)  rpn_loss: 0.1397 (cls: 0.0880, box: 0.0517)
[2025-08-07 15:15:14 train.log] INFO: Epoch: [0]  [Step 11200/14540]  lr: 0.000010  loss: 1.66070  detection_loss: 1.4631 (cls: 0.3158, box: 1.1473)  rpn_loss: 0.1976 (cls: 0.0858, box: 0.1118)
[2025-08-07 15:15:19 train.log] INFO: Epoch: [0]  [Step 11300/14540]  lr: 0.000010  loss: 1.72910  detection_loss: 1.5611 (cls: 0.2176, box: 1.3435)  rpn_loss: 0.1680 (cls: 0.0768, box: 0.0912)
[2025-08-07 15:15:24 train.log] INFO: Epoch: [0]  [Step 11400/14540]  lr: 0.000010  loss: 1.87646  detection_loss: 1.6291 (cls: 0.2634, box: 1.3657)  rpn_loss: 0.2474 (cls: 0.0956, box: 0.1518)
[2025-08-07 15:15:28 train.log] INFO: Epoch: [0]  [Step 11500/14540]  lr: 0.000010  loss: 1.85370  detection_loss: 1.5127 (cls: 0.3189, box: 1.1937)  rpn_loss: 0.3411 (cls: 0.1162, box: 0.2248)
[2025-08-07 15:15:33 train.log] INFO: Epoch: [0]  [Step 11600/14540]  lr: 0.000010  loss: 1.75352  detection_loss: 1.6000 (cls: 0.3196, box: 1.2804)  rpn_loss: 0.1535 (cls: 0.1019, box: 0.0517)
[2025-08-07 15:15:38 train.log] INFO: Epoch: [0]  [Step 11700/14540]  lr: 0.000010  loss: 1.51293  detection_loss: 1.3221 (cls: 0.2411, box: 1.0810)  rpn_loss: 0.1908 (cls: 0.0826, box: 0.1083)
[2025-08-07 15:15:43 train.log] INFO: Epoch: [0]  [Step 11800/14540]  lr: 0.000010  loss: 1.99581  detection_loss: 1.7735 (cls: 0.3160, box: 1.4574)  rpn_loss: 0.2223 (cls: 0.1336, box: 0.0887)
[2025-08-07 15:15:48 train.log] INFO: Epoch: [0]  [Step 11900/14540]  lr: 0.000010  loss: 2.01066  detection_loss: 1.8126 (cls: 0.3193, box: 1.4933)  rpn_loss: 0.1981 (cls: 0.1014, box: 0.0966)
[2025-08-07 15:15:53 train.log] INFO: Epoch: [0]  [Step 12000/14540]  lr: 0.000010  loss: 1.85019  detection_loss: 1.5904 (cls: 0.3747, box: 1.2158)  rpn_loss: 0.2597 (cls: 0.0830, box: 0.1768)
[2025-08-07 15:15:58 train.log] INFO: Epoch: [0]  [Step 12100/14540]  lr: 0.000010  loss: 1.37129  detection_loss: 1.2505 (cls: 0.1867, box: 1.0638)  rpn_loss: 0.1208 (cls: 0.0667, box: 0.0541)
[2025-08-07 15:16:03 train.log] INFO: Epoch: [0]  [Step 12200/14540]  lr: 0.000010  loss: 1.91717  detection_loss: 1.3817 (cls: 0.4007, box: 0.9810)  rpn_loss: 0.5355 (cls: 0.1364, box: 0.3990)
[2025-08-07 15:16:08 train.log] INFO: Epoch: [0]  [Step 12300/14540]  lr: 0.000010  loss: 2.06330  detection_loss: 1.8740 (cls: 0.4728, box: 1.4012)  rpn_loss: 0.1893 (cls: 0.1303, box: 0.0590)
[2025-08-07 15:16:13 train.log] INFO: Epoch: [0]  [Step 12400/14540]  lr: 0.000010  loss: 1.69206  detection_loss: 1.5508 (cls: 0.2636, box: 1.2871)  rpn_loss: 0.1413 (cls: 0.0601, box: 0.0812)
[2025-08-07 15:16:18 train.log] INFO: Epoch: [0]  [Step 12500/14540]  lr: 0.000010  loss: 1.90048  detection_loss: 1.7294 (cls: 0.3284, box: 1.4010)  rpn_loss: 0.1711 (cls: 0.0935, box: 0.0776)
[2025-08-07 15:16:23 train.log] INFO: Epoch: [0]  [Step 12600/14540]  lr: 0.000010  loss: 2.03739  detection_loss: 1.8428 (cls: 0.5408, box: 1.3020)  rpn_loss: 0.1946 (cls: 0.1537, box: 0.0409)
[2025-08-07 15:16:27 train.log] INFO: Epoch: [0]  [Step 12700/14540]  lr: 0.000010  loss: 1.66264  detection_loss: 1.3951 (cls: 0.1816, box: 1.2135)  rpn_loss: 0.2676 (cls: 0.1478, box: 0.1197)
[2025-08-07 15:16:32 train.log] INFO: Epoch: [0]  [Step 12800/14540]  lr: 0.000010  loss: 2.14839  detection_loss: 1.8314 (cls: 0.3054, box: 1.5260)  rpn_loss: 0.3170 (cls: 0.1015, box: 0.2155)
[2025-08-07 15:16:37 train.log] INFO: Epoch: [0]  [Step 12900/14540]  lr: 0.000010  loss: 2.07224  detection_loss: 1.8243 (cls: 0.4548, box: 1.3695)  rpn_loss: 0.2479 (cls: 0.0936, box: 0.1544)
[2025-08-07 15:16:42 train.log] INFO: Epoch: [0]  [Step 13000/14540]  lr: 0.000010  loss: 1.77671  detection_loss: 1.5641 (cls: 0.3205, box: 1.2437)  rpn_loss: 0.2126 (cls: 0.1562, box: 0.0563)
[2025-08-07 15:16:47 train.log] INFO: Epoch: [0]  [Step 13100/14540]  lr: 0.000010  loss: 1.67559  detection_loss: 1.5154 (cls: 0.2462, box: 1.2692)  rpn_loss: 0.1601 (cls: 0.0780, box: 0.0821)
[2025-08-07 15:16:52 train.log] INFO: Epoch: [0]  [Step 13200/14540]  lr: 0.000010  loss: 2.30831  detection_loss: 2.1267 (cls: 0.3196, box: 1.8071)  rpn_loss: 0.1817 (cls: 0.1083, box: 0.0734)
[2025-08-07 15:16:57 train.log] INFO: Epoch: [0]  [Step 13300/14540]  lr: 0.000010  loss: 1.80352  detection_loss: 1.6461 (cls: 0.3259, box: 1.3202)  rpn_loss: 0.1574 (cls: 0.0977, box: 0.0598)
[2025-08-07 15:17:02 train.log] INFO: Epoch: [0]  [Step 13400/14540]  lr: 0.000010  loss: 2.51150  detection_loss: 2.1582 (cls: 0.4351, box: 1.7231)  rpn_loss: 0.3533 (cls: 0.0701, box: 0.2832)
[2025-08-07 15:17:07 train.log] INFO: Epoch: [0]  [Step 13500/14540]  lr: 0.000010  loss: 1.76823  detection_loss: 1.6570 (cls: 0.4081, box: 1.2488)  rpn_loss: 0.1113 (cls: 0.0537, box: 0.0576)
[2025-08-07 15:17:12 train.log] INFO: Epoch: [0]  [Step 13600/14540]  lr: 0.000010  loss: 1.96472  detection_loss: 1.7441 (cls: 0.3007, box: 1.4433)  rpn_loss: 0.2207 (cls: 0.0827, box: 0.1380)
[2025-08-07 15:17:17 train.log] INFO: Epoch: [0]  [Step 13700/14540]  lr: 0.000010  loss: 1.46617  detection_loss: 1.2862 (cls: 0.2398, box: 1.0464)  rpn_loss: 0.1800 (cls: 0.0921, box: 0.0879)
[2025-08-07 15:17:21 train.log] INFO: Epoch: [0]  [Step 13800/14540]  lr: 0.000010  loss: 1.90019  detection_loss: 1.7329 (cls: 0.3972, box: 1.3357)  rpn_loss: 0.1673 (cls: 0.0792, box: 0.0881)
[2025-08-07 15:17:26 train.log] INFO: Epoch: [0]  [Step 13900/14540]  lr: 0.000010  loss: 1.89927  detection_loss: 1.5911 (cls: 0.4026, box: 1.1885)  rpn_loss: 0.3081 (cls: 0.2028, box: 0.1054)
[2025-08-07 15:17:31 train.log] INFO: Epoch: [0]  [Step 14000/14540]  lr: 0.000010  loss: 1.65217  detection_loss: 1.5223 (cls: 0.3619, box: 1.1605)  rpn_loss: 0.1298 (cls: 0.1030, box: 0.0268)
[2025-08-07 15:17:36 train.log] INFO: Epoch: [0]  [Step 14100/14540]  lr: 0.000010  loss: 2.24430  detection_loss: 2.0518 (cls: 0.4681, box: 1.5836)  rpn_loss: 0.1925 (cls: 0.0845, box: 0.1080)
[2025-08-07 15:17:41 train.log] INFO: Epoch: [0]  [Step 14200/14540]  lr: 0.000010  loss: 1.85548  detection_loss: 1.6698 (cls: 0.4047, box: 1.2651)  rpn_loss: 0.1857 (cls: 0.0940, box: 0.0917)
[2025-08-07 15:17:46 train.log] INFO: Epoch: [0]  [Step 14300/14540]  lr: 0.000010  loss: 1.65870  detection_loss: 1.4652 (cls: 0.3532, box: 1.1120)  rpn_loss: 0.1935 (cls: 0.1410, box: 0.0525)
[2025-08-07 15:17:50 train.log] INFO: Epoch: [0]  [Step 14400/14540]  lr: 0.000010  loss: 1.69483  detection_loss: 1.5922 (cls: 0.4519, box: 1.1403)  rpn_loss: 0.1027 (cls: 0.0430, box: 0.0597)
[2025-08-07 15:17:55 train.log] INFO: Epoch: [0]  [Step 14500/14540]  lr: 0.000010  loss: 2.39292  detection_loss: 1.9395 (cls: 0.5200, box: 1.4195)  rpn_loss: 0.4535 (cls: 0.1918, box: 0.2617)
[2025-08-07 15:21:35 train.log] INFO: Epoch: [1]  [Step 100/14540]  lr: 0.000050  loss: 2.00412  detection_loss: 1.6949 (cls: 0.3512, box: 1.3438)  rpn_loss: 0.3092 (cls: 0.1674, box: 0.1418)
[2025-08-07 15:21:40 train.log] INFO: Epoch: [1]  [Step 200/14540]  lr: 0.000050  loss: 1.97678  detection_loss: 1.7569 (cls: 0.4244, box: 1.3326)  rpn_loss: 0.2198 (cls: 0.0991, box: 0.1207)
[2025-08-07 15:21:45 train.log] INFO: Epoch: [1]  [Step 300/14540]  lr: 0.000050  loss: 2.11696  detection_loss: 1.8689 (cls: 0.3433, box: 1.5256)  rpn_loss: 0.2480 (cls: 0.1717, box: 0.0763)
[2025-08-07 15:21:49 train.log] INFO: Epoch: [1]  [Step 400/14540]  lr: 0.000050  loss: 2.81649  detection_loss: 2.3787 (cls: 0.5609, box: 1.8178)  rpn_loss: 0.4378 (cls: 0.1343, box: 0.3034)
[2025-08-07 15:21:54 train.log] INFO: Epoch: [1]  [Step 500/14540]  lr: 0.000050  loss: 1.89411  detection_loss: 1.7227 (cls: 0.4519, box: 1.2707)  rpn_loss: 0.1714 (cls: 0.1343, box: 0.0372)
[2025-08-07 15:21:59 train.log] INFO: Epoch: [1]  [Step 600/14540]  lr: 0.000050  loss: 2.40648  detection_loss: 2.1647 (cls: 0.5876, box: 1.5771)  rpn_loss: 0.2418 (cls: 0.1456, box: 0.0962)
[2025-08-07 15:22:04 train.log] INFO: Epoch: [1]  [Step 700/14540]  lr: 0.000050  loss: 2.14795  detection_loss: 1.7719 (cls: 0.4164, box: 1.3555)  rpn_loss: 0.3760 (cls: 0.1127, box: 0.2634)
[2025-08-07 15:22:09 train.log] INFO: Epoch: [1]  [Step 800/14540]  lr: 0.000050  loss: 1.84890  detection_loss: 1.6541 (cls: 0.3085, box: 1.3456)  rpn_loss: 0.1948 (cls: 0.0854, box: 0.1094)
[2025-08-07 15:22:14 train.log] INFO: Epoch: [1]  [Step 900/14540]  lr: 0.000050  loss: 2.68230  detection_loss: 2.4541 (cls: 0.3913, box: 2.0628)  rpn_loss: 0.2282 (cls: 0.0786, box: 0.1496)
[2025-08-07 15:22:19 train.log] INFO: Epoch: [1]  [Step 1000/14540]  lr: 0.000050  loss: 2.01576  detection_loss: 1.7929 (cls: 0.2907, box: 1.5023)  rpn_loss: 0.2228 (cls: 0.1703, box: 0.0526)
[2025-08-07 15:22:24 train.log] INFO: Epoch: [1]  [Step 1100/14540]  lr: 0.000050  loss: 2.30141  detection_loss: 1.9573 (cls: 0.3165, box: 1.6408)  rpn_loss: 0.3441 (cls: 0.0372, box: 0.3069)
[2025-08-07 15:22:28 train.log] INFO: Epoch: [1]  [Step 1200/14540]  lr: 0.000050  loss: 2.14081  detection_loss: 1.9598 (cls: 0.4628, box: 1.4970)  rpn_loss: 0.1811 (cls: 0.1163, box: 0.0648)
[2025-08-07 15:22:33 train.log] INFO: Epoch: [1]  [Step 1300/14540]  lr: 0.000050  loss: 2.18357  detection_loss: 1.9544 (cls: 0.4809, box: 1.4736)  rpn_loss: 0.2291 (cls: 0.0931, box: 0.1360)
[2025-08-07 15:22:38 train.log] INFO: Epoch: [1]  [Step 1400/14540]  lr: 0.000050  loss: 2.00340  detection_loss: 1.8264 (cls: 0.2824, box: 1.5440)  rpn_loss: 0.1770 (cls: 0.1264, box: 0.0506)
[2025-08-07 15:22:43 train.log] INFO: Epoch: [1]  [Step 1500/14540]  lr: 0.000050  loss: 2.25663  detection_loss: 1.9079 (cls: 0.3443, box: 1.5636)  rpn_loss: 0.3487 (cls: 0.2632, box: 0.0856)
[2025-08-07 15:22:48 train.log] INFO: Epoch: [1]  [Step 1600/14540]  lr: 0.000050  loss: 2.53681  detection_loss: 2.2713 (cls: 0.5319, box: 1.7395)  rpn_loss: 0.2655 (cls: 0.1274, box: 0.1381)
[2025-08-07 15:22:53 train.log] INFO: Epoch: [1]  [Step 1700/14540]  lr: 0.000050  loss: 2.13587  detection_loss: 1.9518 (cls: 0.4532, box: 1.4985)  rpn_loss: 0.1841 (cls: 0.1018, box: 0.0823)
[2025-08-07 15:22:58 train.log] INFO: Epoch: [1]  [Step 1800/14540]  lr: 0.000050  loss: 2.13741  detection_loss: 1.7821 (cls: 0.3321, box: 1.4500)  rpn_loss: 0.3553 (cls: 0.2701, box: 0.0852)
[2025-08-07 15:23:03 train.log] INFO: Epoch: [1]  [Step 1900/14540]  lr: 0.000050  loss: 1.82053  detection_loss: 1.5300 (cls: 0.3113, box: 1.2188)  rpn_loss: 0.2905 (cls: 0.1158, box: 0.1747)
[2025-08-07 15:23:08 train.log] INFO: Epoch: [1]  [Step 2000/14540]  lr: 0.000050  loss: 1.79041  detection_loss: 1.6088 (cls: 0.3609, box: 1.2480)  rpn_loss: 0.1816 (cls: 0.1398, box: 0.0418)
[2025-08-07 15:23:13 train.log] INFO: Epoch: [1]  [Step 2100/14540]  lr: 0.000050  loss: 2.29995  detection_loss: 2.1378 (cls: 0.4289, box: 1.7089)  rpn_loss: 0.1622 (cls: 0.0881, box: 0.0741)
[2025-08-07 15:23:18 train.log] INFO: Epoch: [1]  [Step 2200/14540]  lr: 0.000050  loss: 1.73731  detection_loss: 1.5973 (cls: 0.3448, box: 1.2524)  rpn_loss: 0.1401 (cls: 0.0965, box: 0.0435)
[2025-08-07 15:23:23 train.log] INFO: Epoch: [1]  [Step 2300/14540]  lr: 0.000050  loss: 2.25383  detection_loss: 1.9338 (cls: 0.4800, box: 1.4538)  rpn_loss: 0.3200 (cls: 0.1306, box: 0.1894)
[2025-08-07 15:23:28 train.log] INFO: Epoch: [1]  [Step 2400/14540]  lr: 0.000050  loss: 2.38372  detection_loss: 2.1200 (cls: 0.6579, box: 1.4621)  rpn_loss: 0.2637 (cls: 0.1910, box: 0.0727)
[2025-08-07 15:23:33 train.log] INFO: Epoch: [1]  [Step 2500/14540]  lr: 0.000050  loss: 2.30423  detection_loss: 2.0474 (cls: 0.4219, box: 1.6255)  rpn_loss: 0.2568 (cls: 0.1320, box: 0.1248)
[2025-08-07 15:23:38 train.log] INFO: Epoch: [1]  [Step 2600/14540]  lr: 0.000050  loss: 1.80887  detection_loss: 1.4737 (cls: 0.3788, box: 1.0950)  rpn_loss: 0.3351 (cls: 0.1090, box: 0.2262)
[2025-08-07 15:23:43 train.log] INFO: Epoch: [1]  [Step 2700/14540]  lr: 0.000050  loss: 2.26963  detection_loss: 1.6446 (cls: 0.2880, box: 1.3566)  rpn_loss: 0.6250 (cls: 0.1415, box: 0.4835)
[2025-08-07 15:23:48 train.log] INFO: Epoch: [1]  [Step 2800/14540]  lr: 0.000050  loss: 2.06637  detection_loss: 1.8806 (cls: 0.2816, box: 1.5990)  rpn_loss: 0.1858 (cls: 0.1029, box: 0.0828)
[2025-08-07 15:23:53 train.log] INFO: Epoch: [1]  [Step 2900/14540]  lr: 0.000050  loss: 1.79214  detection_loss: 1.6841 (cls: 0.2690, box: 1.4150)  rpn_loss: 0.1081 (cls: 0.0465, box: 0.0615)
[2025-08-07 15:23:58 train.log] INFO: Epoch: [1]  [Step 3000/14540]  lr: 0.000050  loss: 2.27970  detection_loss: 2.1193 (cls: 0.5618, box: 1.5575)  rpn_loss: 0.1604 (cls: 0.1208, box: 0.0396)
[2025-08-07 15:24:03 train.log] INFO: Epoch: [1]  [Step 3100/14540]  lr: 0.000050  loss: 2.24597  detection_loss: 2.1041 (cls: 0.3667, box: 1.7375)  rpn_loss: 0.1419 (cls: 0.1024, box: 0.0394)
[2025-08-07 15:24:08 train.log] INFO: Epoch: [1]  [Step 3200/14540]  lr: 0.000050  loss: 2.45935  detection_loss: 2.1923 (cls: 0.4975, box: 1.6948)  rpn_loss: 0.2671 (cls: 0.1807, box: 0.0864)
[2025-08-07 15:24:13 train.log] INFO: Epoch: [1]  [Step 3300/14540]  lr: 0.000050  loss: 2.19981  detection_loss: 1.9207 (cls: 0.5257, box: 1.3950)  rpn_loss: 0.2791 (cls: 0.1182, box: 0.1609)
[2025-08-07 15:24:18 train.log] INFO: Epoch: [1]  [Step 3400/14540]  lr: 0.000050  loss: 2.21858  detection_loss: 2.0792 (cls: 0.4413, box: 1.6379)  rpn_loss: 0.1394 (cls: 0.1154, box: 0.0240)
[2025-08-07 15:24:23 train.log] INFO: Epoch: [1]  [Step 3500/14540]  lr: 0.000050  loss: 2.12903  detection_loss: 1.8266 (cls: 0.3152, box: 1.5114)  rpn_loss: 0.3025 (cls: 0.1605, box: 0.1420)
[2025-08-07 15:24:28 train.log] INFO: Epoch: [1]  [Step 3600/14540]  lr: 0.000050  loss: 2.24611  detection_loss: 2.0092 (cls: 0.5407, box: 1.4685)  rpn_loss: 0.2369 (cls: 0.1704, box: 0.0665)
[2025-08-07 15:24:30 train.log] INFO: Epoch: [1]  [Step 3635/14540]  lr: 0.000050  loss: 1.76888  detection_loss: 1.6285 (cls: 0.2899, box: 1.3385)  rpn_loss: 0.1404 (cls: 0.0408, box: 0.0996)
[2025-08-07 15:24:33 train.log] INFO: Epoch: [1]  [Step 3700/14540]  lr: 0.000050  loss: 2.25442  detection_loss: 2.0659 (cls: 0.4201, box: 1.6458)  rpn_loss: 0.1885 (cls: 0.1548, box: 0.0337)
[2025-08-07 15:24:38 train.log] INFO: Epoch: [1]  [Step 3800/14540]  lr: 0.000050  loss: 1.92910  detection_loss: 1.7070 (cls: 0.3709, box: 1.3361)  rpn_loss: 0.2221 (cls: 0.0746, box: 0.1474)
[2025-08-07 15:24:42 train.log] INFO: Epoch: [1]  [Step 3900/14540]  lr: 0.000050  loss: 2.62167  detection_loss: 2.3444 (cls: 0.9274, box: 1.4170)  rpn_loss: 0.2773 (cls: 0.1434, box: 0.1338)
[2025-08-07 15:24:47 train.log] INFO: Epoch: [1]  [Step 4000/14540]  lr: 0.000050  loss: 2.02516  detection_loss: 1.8496 (cls: 0.3779, box: 1.4717)  rpn_loss: 0.1755 (cls: 0.1211, box: 0.0544)
[2025-08-07 15:24:52 train.log] INFO: Epoch: [1]  [Step 4100/14540]  lr: 0.000050  loss: 2.06210  detection_loss: 1.9064 (cls: 0.4830, box: 1.4234)  rpn_loss: 0.1557 (cls: 0.0974, box: 0.0583)
[2025-08-07 15:24:57 train.log] INFO: Epoch: [1]  [Step 4200/14540]  lr: 0.000050  loss: 1.55030  detection_loss: 1.3710 (cls: 0.3746, box: 0.9963)  rpn_loss: 0.1793 (cls: 0.0899, box: 0.0894)
[2025-08-07 15:25:02 train.log] INFO: Epoch: [1]  [Step 4300/14540]  lr: 0.000050  loss: 2.35526  detection_loss: 1.9434 (cls: 0.6850, box: 1.2585)  rpn_loss: 0.4118 (cls: 0.1009, box: 0.3109)
[2025-08-07 15:25:07 train.log] INFO: Epoch: [1]  [Step 4400/14540]  lr: 0.000050  loss: 1.77142  detection_loss: 1.6196 (cls: 0.3415, box: 1.2782)  rpn_loss: 0.1518 (cls: 0.1163, box: 0.0355)
[2025-08-07 15:25:12 train.log] INFO: Epoch: [1]  [Step 4500/14540]  lr: 0.000050  loss: 2.03993  detection_loss: 1.7059 (cls: 0.2456, box: 1.4603)  rpn_loss: 0.3340 (cls: 0.1120, box: 0.2220)
[2025-08-07 15:25:17 train.log] INFO: Epoch: [1]  [Step 4600/14540]  lr: 0.000050  loss: 1.99000  detection_loss: 1.6594 (cls: 0.2601, box: 1.3993)  rpn_loss: 0.3306 (cls: 0.1128, box: 0.2178)
[2025-08-07 15:25:22 train.log] INFO: Epoch: [1]  [Step 4700/14540]  lr: 0.000050  loss: 1.42876  detection_loss: 1.2333 (cls: 0.2365, box: 0.9968)  rpn_loss: 0.1954 (cls: 0.0785, box: 0.1169)
[2025-08-07 15:25:27 train.log] INFO: Epoch: [1]  [Step 4800/14540]  lr: 0.000050  loss: 2.13850  detection_loss: 1.9721 (cls: 0.4857, box: 1.4864)  rpn_loss: 0.1664 (cls: 0.0976, box: 0.0688)
[2025-08-07 15:25:32 train.log] INFO: Epoch: [1]  [Step 4900/14540]  lr: 0.000050  loss: 1.30437  detection_loss: 1.2121 (cls: 0.4398, box: 0.7723)  rpn_loss: 0.0923 (cls: 0.0697, box: 0.0225)
[2025-08-07 15:25:37 train.log] INFO: Epoch: [1]  [Step 5000/14540]  lr: 0.000050  loss: 2.23824  detection_loss: 2.0584 (cls: 0.4040, box: 1.6544)  rpn_loss: 0.1798 (cls: 0.0996, box: 0.0802)
[2025-08-07 15:25:42 train.log] INFO: Epoch: [1]  [Step 5100/14540]  lr: 0.000050  loss: 3.24413  detection_loss: 2.8462 (cls: 0.9987, box: 1.8475)  rpn_loss: 0.3980 (cls: 0.1309, box: 0.2671)
[2025-08-07 15:25:47 train.log] INFO: Epoch: [1]  [Step 5200/14540]  lr: 0.000050  loss: 1.26350  detection_loss: 1.1972 (cls: 0.2281, box: 0.9692)  rpn_loss: 0.0663 (cls: 0.0280, box: 0.0382)
[2025-08-07 15:25:52 train.log] INFO: Epoch: [1]  [Step 5300/14540]  lr: 0.000050  loss: 1.92730  detection_loss: 1.7819 (cls: 0.4258, box: 1.3561)  rpn_loss: 0.1454 (cls: 0.1159, box: 0.0295)
[2025-08-07 15:25:57 train.log] INFO: Epoch: [1]  [Step 5400/14540]  lr: 0.000050  loss: 2.01065  detection_loss: 1.7290 (cls: 0.4072, box: 1.3218)  rpn_loss: 0.2816 (cls: 0.0899, box: 0.1917)
[2025-08-07 15:26:02 train.log] INFO: Epoch: [1]  [Step 5500/14540]  lr: 0.000050  loss: 2.59305  detection_loss: 2.3519 (cls: 0.4876, box: 1.8643)  rpn_loss: 0.2412 (cls: 0.2039, box: 0.0373)
[2025-08-07 15:26:07 train.log] INFO: Epoch: [1]  [Step 5600/14540]  lr: 0.000050  loss: 1.71408  detection_loss: 1.5043 (cls: 0.5610, box: 0.9434)  rpn_loss: 0.2098 (cls: 0.0699, box: 0.1398)
[2025-08-07 15:26:12 train.log] INFO: Epoch: [1]  [Step 5700/14540]  lr: 0.000050  loss: 1.90130  detection_loss: 1.7417 (cls: 0.4565, box: 1.2852)  rpn_loss: 0.1596 (cls: 0.1023, box: 0.0573)
[2025-08-07 15:26:17 train.log] INFO: Epoch: [1]  [Step 5800/14540]  lr: 0.000050  loss: 2.52939  detection_loss: 2.0976 (cls: 0.4021, box: 1.6955)  rpn_loss: 0.4318 (cls: 0.1785, box: 0.2533)
[2025-08-07 15:26:22 train.log] INFO: Epoch: [1]  [Step 5900/14540]  lr: 0.000050  loss: 1.35025  detection_loss: 1.1878 (cls: 0.1564, box: 1.0314)  rpn_loss: 0.1625 (cls: 0.0819, box: 0.0805)
[2025-08-07 15:26:26 train.log] INFO: Epoch: [1]  [Step 6000/14540]  lr: 0.000050  loss: 1.93508  detection_loss: 1.3358 (cls: 0.3544, box: 0.9814)  rpn_loss: 0.5993 (cls: 0.0925, box: 0.5068)
[2025-08-07 15:26:31 train.log] INFO: Epoch: [1]  [Step 6100/14540]  lr: 0.000050  loss: 1.47601  detection_loss: 1.3563 (cls: 0.2938, box: 1.0625)  rpn_loss: 0.1197 (cls: 0.0673, box: 0.0524)
[2025-08-07 15:26:36 train.log] INFO: Epoch: [1]  [Step 6200/14540]  lr: 0.000050  loss: 2.02059  detection_loss: 1.8838 (cls: 0.4179, box: 1.4659)  rpn_loss: 0.1368 (cls: 0.0861, box: 0.0507)
[2025-08-07 15:26:41 train.log] INFO: Epoch: [1]  [Step 6300/14540]  lr: 0.000050  loss: 2.07757  detection_loss: 1.8064 (cls: 0.3759, box: 1.4305)  rpn_loss: 0.2712 (cls: 0.0878, box: 0.1834)
[2025-08-07 15:26:46 train.log] INFO: Epoch: [1]  [Step 6400/14540]  lr: 0.000050  loss: 1.56955  detection_loss: 1.3895 (cls: 0.2731, box: 1.1164)  rpn_loss: 0.1801 (cls: 0.0867, box: 0.0934)
[2025-08-07 15:26:51 train.log] INFO: Epoch: [1]  [Step 6500/14540]  lr: 0.000050  loss: 1.84494  detection_loss: 1.6639 (cls: 0.4003, box: 1.2637)  rpn_loss: 0.1810 (cls: 0.0841, box: 0.0969)
[2025-08-07 15:26:56 train.log] INFO: Epoch: [1]  [Step 6600/14540]  lr: 0.000050  loss: 2.23710  detection_loss: 1.9255 (cls: 0.6576, box: 1.2679)  rpn_loss: 0.3116 (cls: 0.1760, box: 0.1356)
[2025-08-07 15:27:00 train.log] INFO: Epoch: [1]  [Step 6700/14540]  lr: 0.000050  loss: 1.21999  detection_loss: 1.0890 (cls: 0.2741, box: 0.8149)  rpn_loss: 0.1310 (cls: 0.1013, box: 0.0296)
[2025-08-07 15:27:05 train.log] INFO: Epoch: [1]  [Step 6800/14540]  lr: 0.000050  loss: 2.14614  detection_loss: 1.9128 (cls: 0.4162, box: 1.4966)  rpn_loss: 0.2334 (cls: 0.1879, box: 0.0455)
[2025-08-07 15:27:10 train.log] INFO: Epoch: [1]  [Step 6900/14540]  lr: 0.000050  loss: 2.13942  detection_loss: 2.0096 (cls: 0.3979, box: 1.6117)  rpn_loss: 0.1298 (cls: 0.0750, box: 0.0549)
[2025-08-07 15:27:15 train.log] INFO: Epoch: [1]  [Step 7000/14540]  lr: 0.000050  loss: 1.91075  detection_loss: 1.6514 (cls: 0.3994, box: 1.2519)  rpn_loss: 0.2594 (cls: 0.1165, box: 0.1429)
[2025-08-07 15:27:20 train.log] INFO: Epoch: [1]  [Step 7100/14540]  lr: 0.000050  loss: 1.96405  detection_loss: 1.7949 (cls: 0.4260, box: 1.3689)  rpn_loss: 0.1691 (cls: 0.0728, box: 0.0964)
[2025-08-07 15:27:25 train.log] INFO: Epoch: [1]  [Step 7200/14540]  lr: 0.000050  loss: 1.32943  detection_loss: 1.0020 (cls: 0.2128, box: 0.7892)  rpn_loss: 0.3274 (cls: 0.0697, box: 0.2578)
[2025-08-07 15:27:29 train.log] INFO: Epoch: [1]  [Step 7300/14540]  lr: 0.000050  loss: 1.65099  detection_loss: 1.5193 (cls: 0.2019, box: 1.3175)  rpn_loss: 0.1317 (cls: 0.0574, box: 0.0742)
[2025-08-07 15:27:34 train.log] INFO: Epoch: [1]  [Step 7400/14540]  lr: 0.000050  loss: 2.29788  detection_loss: 2.0346 (cls: 0.6094, box: 1.4252)  rpn_loss: 0.2633 (cls: 0.1029, box: 0.1604)
[2025-08-07 15:27:39 train.log] INFO: Epoch: [1]  [Step 7500/14540]  lr: 0.000050  loss: 2.09786  detection_loss: 1.8452 (cls: 0.3221, box: 1.5231)  rpn_loss: 0.2526 (cls: 0.1111, box: 0.1416)
[2025-08-07 15:27:44 train.log] INFO: Epoch: [1]  [Step 7600/14540]  lr: 0.000050  loss: 1.73861  detection_loss: 1.5964 (cls: 0.3586, box: 1.2379)  rpn_loss: 0.1422 (cls: 0.0956, box: 0.0466)
[2025-08-07 15:27:49 train.log] INFO: Epoch: [1]  [Step 7700/14540]  lr: 0.000050  loss: 1.55950  detection_loss: 1.4446 (cls: 0.2945, box: 1.1501)  rpn_loss: 0.1149 (cls: 0.0782, box: 0.0367)
[2025-08-07 15:27:54 train.log] INFO: Epoch: [1]  [Step 7800/14540]  lr: 0.000050  loss: 1.84443  detection_loss: 1.6664 (cls: 0.4255, box: 1.2410)  rpn_loss: 0.1780 (cls: 0.0850, box: 0.0930)
[2025-08-07 15:27:59 train.log] INFO: Epoch: [1]  [Step 7900/14540]  lr: 0.000050  loss: 2.31778  detection_loss: 2.0259 (cls: 0.4396, box: 1.5864)  rpn_loss: 0.2918 (cls: 0.1139, box: 0.1779)
[2025-08-07 15:28:03 train.log] INFO: Epoch: [1]  [Step 8000/14540]  lr: 0.000050  loss: 2.22631  detection_loss: 1.2540 (cls: 0.3082, box: 0.9458)  rpn_loss: 0.9723 (cls: 0.0645, box: 0.9078)
[2025-08-07 15:28:08 train.log] INFO: Epoch: [1]  [Step 8100/14540]  lr: 0.000050  loss: 1.68901  detection_loss: 1.5325 (cls: 0.3837, box: 1.1487)  rpn_loss: 0.1565 (cls: 0.0866, box: 0.0700)
[2025-08-07 15:28:13 train.log] INFO: Epoch: [1]  [Step 8200/14540]  lr: 0.000050  loss: 1.74857  detection_loss: 1.5850 (cls: 0.2615, box: 1.3236)  rpn_loss: 0.1635 (cls: 0.0992, box: 0.0643)
[2025-08-07 15:28:18 train.log] INFO: Epoch: [1]  [Step 8300/14540]  lr: 0.000050  loss: 1.49197  detection_loss: 1.3392 (cls: 0.4115, box: 0.9277)  rpn_loss: 0.1528 (cls: 0.0964, box: 0.0564)
[2025-08-07 15:28:23 train.log] INFO: Epoch: [1]  [Step 8400/14540]  lr: 0.000050  loss: 2.46040  detection_loss: 2.2391 (cls: 0.4943, box: 1.7449)  rpn_loss: 0.2213 (cls: 0.1102, box: 0.1110)
[2025-08-07 15:28:28 train.log] INFO: Epoch: [1]  [Step 8500/14540]  lr: 0.000050  loss: 1.60787  detection_loss: 1.3795 (cls: 0.3209, box: 1.0587)  rpn_loss: 0.2283 (cls: 0.0679, box: 0.1605)
[2025-08-07 15:28:32 train.log] INFO: Epoch: [1]  [Step 8600/14540]  lr: 0.000050  loss: 2.20993  detection_loss: 1.9633 (cls: 0.2536, box: 1.7097)  rpn_loss: 0.2466 (cls: 0.1585, box: 0.0881)
[2025-08-07 15:28:37 train.log] INFO: Epoch: [1]  [Step 8700/14540]  lr: 0.000050  loss: 2.20051  detection_loss: 1.7039 (cls: 0.4027, box: 1.3012)  rpn_loss: 0.4966 (cls: 0.0952, box: 0.4014)
[2025-08-07 15:28:42 train.log] INFO: Epoch: [1]  [Step 8800/14540]  lr: 0.000050  loss: 1.62136  detection_loss: 1.3900 (cls: 0.3751, box: 1.0148)  rpn_loss: 0.2314 (cls: 0.0962, box: 0.1352)
[2025-08-07 15:28:47 train.log] INFO: Epoch: [1]  [Step 8900/14540]  lr: 0.000050  loss: 1.86281  detection_loss: 1.3949 (cls: 0.3142, box: 1.0807)  rpn_loss: 0.4679 (cls: 0.0831, box: 0.3849)
[2025-08-07 15:28:52 train.log] INFO: Epoch: [1]  [Step 9000/14540]  lr: 0.000050  loss: 1.64433  detection_loss: 1.3982 (cls: 0.2407, box: 1.1575)  rpn_loss: 0.2461 (cls: 0.0741, box: 0.1720)
[2025-08-07 15:28:57 train.log] INFO: Epoch: [1]  [Step 9100/14540]  lr: 0.000050  loss: 1.26404  detection_loss: 1.1743 (cls: 0.2405, box: 0.9339)  rpn_loss: 0.0897 (cls: 0.0513, box: 0.0384)
[2025-08-07 15:29:02 train.log] INFO: Epoch: [1]  [Step 9200/14540]  lr: 0.000050  loss: 1.92923  detection_loss: 1.7753 (cls: 0.2598, box: 1.5155)  rpn_loss: 0.1539 (cls: 0.0656, box: 0.0884)
[2025-08-07 15:29:06 train.log] INFO: Epoch: [1]  [Step 9300/14540]  lr: 0.000050  loss: 1.96525  detection_loss: 1.7856 (cls: 0.4781, box: 1.3075)  rpn_loss: 0.1796 (cls: 0.1044, box: 0.0752)
[2025-08-07 15:29:11 train.log] INFO: Epoch: [1]  [Step 9400/14540]  lr: 0.000050  loss: 2.00426  detection_loss: 1.8113 (cls: 0.3869, box: 1.4244)  rpn_loss: 0.1929 (cls: 0.0900, box: 0.1029)
[2025-08-07 15:29:16 train.log] INFO: Epoch: [1]  [Step 9500/14540]  lr: 0.000050  loss: 1.70343  detection_loss: 1.6177 (cls: 0.2165, box: 1.4012)  rpn_loss: 0.0858 (cls: 0.0454, box: 0.0404)
[2025-08-07 15:29:21 train.log] INFO: Epoch: [1]  [Step 9600/14540]  lr: 0.000050  loss: 1.73829  detection_loss: 1.3713 (cls: 0.3589, box: 1.0124)  rpn_loss: 0.3670 (cls: 0.0926, box: 0.2744)
[2025-08-07 15:29:26 train.log] INFO: Epoch: [1]  [Step 9700/14540]  lr: 0.000050  loss: 1.22732  detection_loss: 1.1017 (cls: 0.3332, box: 0.7685)  rpn_loss: 0.1256 (cls: 0.0964, box: 0.0292)
[2025-08-07 15:29:31 train.log] INFO: Epoch: [1]  [Step 9800/14540]  lr: 0.000050  loss: 1.52083  detection_loss: 1.4093 (cls: 0.3490, box: 1.0603)  rpn_loss: 0.1115 (cls: 0.0573, box: 0.0542)
[2025-08-07 15:29:35 train.log] INFO: Epoch: [1]  [Step 9900/14540]  lr: 0.000050  loss: 2.57897  detection_loss: 2.2927 (cls: 0.4298, box: 1.8629)  rpn_loss: 0.2863 (cls: 0.0986, box: 0.1877)
[2025-08-07 15:29:40 train.log] INFO: Epoch: [1]  [Step 10000/14540]  lr: 0.000050  loss: 2.04866  detection_loss: 1.8239 (cls: 0.3508, box: 1.4731)  rpn_loss: 0.2248 (cls: 0.1142, box: 0.1106)
[2025-08-07 15:29:45 train.log] INFO: Epoch: [1]  [Step 10100/14540]  lr: 0.000050  loss: 2.01652  detection_loss: 1.7858 (cls: 0.4532, box: 1.3325)  rpn_loss: 0.2308 (cls: 0.0901, box: 0.1407)
[2025-08-07 15:29:50 train.log] INFO: Epoch: [1]  [Step 10200/14540]  lr: 0.000050  loss: 1.72354  detection_loss: 1.5424 (cls: 0.4952, box: 1.0472)  rpn_loss: 0.1812 (cls: 0.0736, box: 0.1076)
[2025-08-07 15:29:55 train.log] INFO: Epoch: [1]  [Step 10300/14540]  lr: 0.000050  loss: 2.12530  detection_loss: 1.9633 (cls: 0.5667, box: 1.3966)  rpn_loss: 0.1620 (cls: 0.1263, box: 0.0357)
[2025-08-07 15:30:00 train.log] INFO: Epoch: [1]  [Step 10400/14540]  lr: 0.000050  loss: 1.43062  detection_loss: 1.3292 (cls: 0.2058, box: 1.1234)  rpn_loss: 0.1015 (cls: 0.0338, box: 0.0676)
[2025-08-07 15:30:05 train.log] INFO: Epoch: [1]  [Step 10500/14540]  lr: 0.000050  loss: 1.07560  detection_loss: 0.9599 (cls: 0.1752, box: 0.7847)  rpn_loss: 0.1157 (cls: 0.0943, box: 0.0214)
[2025-08-07 15:30:10 train.log] INFO: Epoch: [1]  [Step 10600/14540]  lr: 0.000050  loss: 1.66335  detection_loss: 1.5341 (cls: 0.1746, box: 1.3595)  rpn_loss: 0.1293 (cls: 0.0242, box: 0.1051)
[2025-08-07 15:30:14 train.log] INFO: Epoch: [1]  [Step 10700/14540]  lr: 0.000050  loss: 2.03763  detection_loss: 1.8227 (cls: 0.4299, box: 1.3928)  rpn_loss: 0.2149 (cls: 0.0717, box: 0.1432)
[2025-08-07 15:30:19 train.log] INFO: Epoch: [1]  [Step 10800/14540]  lr: 0.000050  loss: 1.87559  detection_loss: 1.7718 (cls: 0.2974, box: 1.4744)  rpn_loss: 0.1038 (cls: 0.0831, box: 0.0207)
[2025-08-07 15:30:24 train.log] INFO: Epoch: [1]  [Step 10900/14540]  lr: 0.000050  loss: 1.53892  detection_loss: 1.3250 (cls: 0.4400, box: 0.8851)  rpn_loss: 0.2139 (cls: 0.0965, box: 0.1174)
[2025-08-07 15:30:29 train.log] INFO: Epoch: [1]  [Step 11000/14540]  lr: 0.000050  loss: 2.05903  detection_loss: 1.8976 (cls: 0.3869, box: 1.5107)  rpn_loss: 0.1614 (cls: 0.1019, box: 0.0595)
[2025-08-07 15:30:34 train.log] INFO: Epoch: [1]  [Step 11100/14540]  lr: 0.000050  loss: 1.07821  detection_loss: 0.9817 (cls: 0.1705, box: 0.8112)  rpn_loss: 0.0966 (cls: 0.0444, box: 0.0522)
[2025-08-07 15:30:39 train.log] INFO: Epoch: [1]  [Step 11200/14540]  lr: 0.000050  loss: 1.52194  detection_loss: 1.3891 (cls: 0.2749, box: 1.1142)  rpn_loss: 0.1328 (cls: 0.0855, box: 0.0473)
[2025-08-07 15:30:44 train.log] INFO: Epoch: [1]  [Step 11300/14540]  lr: 0.000050  loss: 1.61613  detection_loss: 1.3931 (cls: 0.2663, box: 1.1268)  rpn_loss: 0.2230 (cls: 0.1534, box: 0.0696)
[2025-08-07 15:30:48 train.log] INFO: Epoch: [1]  [Step 11400/14540]  lr: 0.000050  loss: 1.83934  detection_loss: 1.7436 (cls: 0.2520, box: 1.4917)  rpn_loss: 0.0957 (cls: 0.0731, box: 0.0226)
[2025-08-07 15:30:53 train.log] INFO: Epoch: [1]  [Step 11500/14540]  lr: 0.000050  loss: 1.97538  detection_loss: 1.7716 (cls: 0.4953, box: 1.2763)  rpn_loss: 0.2038 (cls: 0.0908, box: 0.1130)
[2025-08-07 15:30:58 train.log] INFO: Epoch: [1]  [Step 11600/14540]  lr: 0.000050  loss: 1.47530  detection_loss: 1.2525 (cls: 0.3340, box: 0.9185)  rpn_loss: 0.2228 (cls: 0.0688, box: 0.1540)
[2025-08-07 15:31:03 train.log] INFO: Epoch: [1]  [Step 11700/14540]  lr: 0.000050  loss: 1.59195  detection_loss: 1.4279 (cls: 0.2630, box: 1.1648)  rpn_loss: 0.1641 (cls: 0.0620, box: 0.1021)
[2025-08-07 15:31:08 train.log] INFO: Epoch: [1]  [Step 11800/14540]  lr: 0.000050  loss: 1.64979  detection_loss: 1.4847 (cls: 0.2042, box: 1.2806)  rpn_loss: 0.1651 (cls: 0.0714, box: 0.0936)
[2025-08-07 15:31:13 train.log] INFO: Epoch: [1]  [Step 11900/14540]  lr: 0.000050  loss: 1.67886  detection_loss: 1.5389 (cls: 0.3134, box: 1.2255)  rpn_loss: 0.1400 (cls: 0.0696, box: 0.0704)
[2025-08-07 15:31:17 train.log] INFO: Epoch: [1]  [Step 12000/14540]  lr: 0.000050  loss: 1.63811  detection_loss: 1.4807 (cls: 0.4731, box: 1.0076)  rpn_loss: 0.1574 (cls: 0.1242, box: 0.0332)
[2025-08-07 15:31:22 train.log] INFO: Epoch: [1]  [Step 12100/14540]  lr: 0.000050  loss: 1.73487  detection_loss: 1.4268 (cls: 0.3132, box: 1.1137)  rpn_loss: 0.3080 (cls: 0.0709, box: 0.2372)
[2025-08-07 15:31:27 train.log] INFO: Epoch: [1]  [Step 12200/14540]  lr: 0.000050  loss: 1.53139  detection_loss: 1.3362 (cls: 0.2175, box: 1.1188)  rpn_loss: 0.1951 (cls: 0.0821, box: 0.1131)
[2025-08-07 15:31:32 train.log] INFO: Epoch: [1]  [Step 12300/14540]  lr: 0.000050  loss: 1.61629  detection_loss: 1.4485 (cls: 0.4133, box: 1.0351)  rpn_loss: 0.1678 (cls: 0.0823, box: 0.0856)
[2025-08-07 15:31:37 train.log] INFO: Epoch: [1]  [Step 12400/14540]  lr: 0.000050  loss: 2.13510  detection_loss: 1.8247 (cls: 0.2372, box: 1.5876)  rpn_loss: 0.3104 (cls: 0.1513, box: 0.1590)
[2025-08-07 15:31:41 train.log] INFO: Epoch: [1]  [Step 12500/14540]  lr: 0.000050  loss: 1.34884  detection_loss: 1.2016 (cls: 0.2910, box: 0.9106)  rpn_loss: 0.1472 (cls: 0.0427, box: 0.1046)
[2025-08-07 15:31:46 train.log] INFO: Epoch: [1]  [Step 12600/14540]  lr: 0.000050  loss: 1.66944  detection_loss: 1.5291 (cls: 0.2260, box: 1.3030)  rpn_loss: 0.1404 (cls: 0.0835, box: 0.0569)
[2025-08-07 15:31:51 train.log] INFO: Epoch: [1]  [Step 12700/14540]  lr: 0.000050  loss: 1.86449  detection_loss: 1.6931 (cls: 0.3059, box: 1.3871)  rpn_loss: 0.1714 (cls: 0.0587, box: 0.1127)
[2025-08-07 15:31:56 train.log] INFO: Epoch: [1]  [Step 12800/14540]  lr: 0.000050  loss: 1.62991  detection_loss: 1.4037 (cls: 0.3264, box: 1.0773)  rpn_loss: 0.2262 (cls: 0.1721, box: 0.0541)
[2025-08-07 15:32:01 train.log] INFO: Epoch: [1]  [Step 12900/14540]  lr: 0.000050  loss: 1.73797  detection_loss: 1.6092 (cls: 0.3352, box: 1.2740)  rpn_loss: 0.1287 (cls: 0.0720, box: 0.0567)
[2025-08-07 15:32:06 train.log] INFO: Epoch: [1]  [Step 13000/14540]  lr: 0.000050  loss: 1.82147  detection_loss: 1.6302 (cls: 0.2715, box: 1.3587)  rpn_loss: 0.1913 (cls: 0.0677, box: 0.1236)
[2025-08-07 15:32:11 train.log] INFO: Epoch: [1]  [Step 13100/14540]  lr: 0.000050  loss: 1.60851  detection_loss: 1.4675 (cls: 0.2835, box: 1.1840)  rpn_loss: 0.1410 (cls: 0.0514, box: 0.0896)
[2025-08-07 15:32:16 train.log] INFO: Epoch: [1]  [Step 13200/14540]  lr: 0.000050  loss: 1.23415  detection_loss: 1.0857 (cls: 0.2027, box: 0.8831)  rpn_loss: 0.1484 (cls: 0.0471, box: 0.1013)
[2025-08-07 15:32:21 train.log] INFO: Epoch: [1]  [Step 13300/14540]  lr: 0.000050  loss: 1.75574  detection_loss: 1.4284 (cls: 0.5909, box: 0.8376)  rpn_loss: 0.3273 (cls: 0.0860, box: 0.2413)
[2025-08-07 15:32:26 train.log] INFO: Epoch: [1]  [Step 13400/14540]  lr: 0.000050  loss: 1.93657  detection_loss: 1.7260 (cls: 0.4063, box: 1.3198)  rpn_loss: 0.2105 (cls: 0.1220, box: 0.0886)
[2025-08-07 15:32:32 train.log] INFO: Epoch: [1]  [Step 13500/14540]  lr: 0.000050  loss: 1.74765  detection_loss: 1.2452 (cls: 0.2027, box: 1.0425)  rpn_loss: 0.5025 (cls: 0.0481, box: 0.4544)
[2025-08-07 15:32:37 train.log] INFO: Epoch: [1]  [Step 13600/14540]  lr: 0.000050  loss: 2.36066  detection_loss: 2.1208 (cls: 0.5990, box: 1.5219)  rpn_loss: 0.2398 (cls: 0.1777, box: 0.0622)
[2025-08-07 15:32:42 train.log] INFO: Epoch: [1]  [Step 13700/14540]  lr: 0.000050  loss: 1.27376  detection_loss: 1.1282 (cls: 0.3039, box: 0.8243)  rpn_loss: 0.1456 (cls: 0.0709, box: 0.0746)
[2025-08-07 15:32:47 train.log] INFO: Epoch: [1]  [Step 13800/14540]  lr: 0.000050  loss: 1.96190  detection_loss: 1.7480 (cls: 0.5599, box: 1.1882)  rpn_loss: 0.2139 (cls: 0.1294, box: 0.0845)
[2025-08-07 15:32:52 train.log] INFO: Epoch: [1]  [Step 13900/14540]  lr: 0.000050  loss: 1.24409  detection_loss: 1.1025 (cls: 0.3120, box: 0.7905)  rpn_loss: 0.1416 (cls: 0.0541, box: 0.0874)
[2025-08-07 15:32:57 train.log] INFO: Epoch: [1]  [Step 14000/14540]  lr: 0.000050  loss: 1.81678  detection_loss: 1.6876 (cls: 0.3397, box: 1.3480)  rpn_loss: 0.1291 (cls: 0.0547, box: 0.0744)
[2025-08-07 15:33:02 train.log] INFO: Epoch: [1]  [Step 14100/14540]  lr: 0.000050  loss: 1.91039  detection_loss: 1.7512 (cls: 0.2381, box: 1.5131)  rpn_loss: 0.1592 (cls: 0.1249, box: 0.0344)
[2025-08-07 15:33:07 train.log] INFO: Epoch: [1]  [Step 14200/14540]  lr: 0.000050  loss: 1.53615  detection_loss: 1.1685 (cls: 0.3026, box: 0.8659)  rpn_loss: 0.3677 (cls: 0.0401, box: 0.3275)
[2025-08-07 15:33:12 train.log] INFO: Epoch: [1]  [Step 14300/14540]  lr: 0.000050  loss: 1.09843  detection_loss: 0.9956 (cls: 0.2214, box: 0.7741)  rpn_loss: 0.1029 (cls: 0.0560, box: 0.0468)
[2025-08-07 15:33:17 train.log] INFO: Epoch: [1]  [Step 14400/14540]  lr: 0.000050  loss: 1.66752  detection_loss: 1.5811 (cls: 0.3479, box: 1.2332)  rpn_loss: 0.0864 (cls: 0.0472, box: 0.0393)
[2025-08-07 15:33:22 train.log] INFO: Epoch: [1]  [Step 14500/14540]  lr: 0.000050  loss: 1.84757  detection_loss: 1.6991 (cls: 0.3378, box: 1.3613)  rpn_loss: 0.1485 (cls: 0.1034, box: 0.0451)
[2025-08-07 15:36:18 train.log] INFO: Epoch: [2]  [Step 100/14540]  lr: 0.000100  loss: 2.05575  detection_loss: 1.9073 (cls: 0.5616, box: 1.3457)  rpn_loss: 0.1485 (cls: 0.0850, box: 0.0635)
[2025-08-07 15:36:23 train.log] INFO: Epoch: [2]  [Step 200/14540]  lr: 0.000100  loss: 2.20726  detection_loss: 1.6972 (cls: 0.6051, box: 1.0921)  rpn_loss: 0.5101 (cls: 0.0941, box: 0.4159)
[2025-08-07 15:36:28 train.log] INFO: Epoch: [2]  [Step 300/14540]  lr: 0.000100  loss: 2.46008  detection_loss: 2.0417 (cls: 0.3781, box: 1.6636)  rpn_loss: 0.4183 (cls: 0.0968, box: 0.3215)
[2025-08-07 15:36:33 train.log] INFO: Epoch: [2]  [Step 400/14540]  lr: 0.000100  loss: 2.88499  detection_loss: 2.6297 (cls: 0.7464, box: 1.8833)  rpn_loss: 0.2553 (cls: 0.1225, box: 0.1327)
[2025-08-07 15:36:38 train.log] INFO: Epoch: [2]  [Step 500/14540]  lr: 0.000100  loss: 2.03191  detection_loss: 1.8470 (cls: 0.4519, box: 1.3951)  rpn_loss: 0.1849 (cls: 0.1126, box: 0.0723)
[2025-08-07 15:36:43 train.log] INFO: Epoch: [2]  [Step 600/14540]  lr: 0.000100  loss: 2.18035  detection_loss: 1.7832 (cls: 0.5401, box: 1.2431)  rpn_loss: 0.3972 (cls: 0.1075, box: 0.2896)
[2025-08-07 15:36:49 train.log] INFO: Epoch: [2]  [Step 700/14540]  lr: 0.000100  loss: 1.99398  detection_loss: 1.8048 (cls: 0.3804, box: 1.4244)  rpn_loss: 0.1892 (cls: 0.1095, box: 0.0797)
[2025-08-07 15:36:54 train.log] INFO: Epoch: [2]  [Step 800/14540]  lr: 0.000100  loss: 1.81292  detection_loss: 1.5257 (cls: 0.3456, box: 1.1801)  rpn_loss: 0.2872 (cls: 0.1529, box: 0.1343)
[2025-08-07 15:36:59 train.log] INFO: Epoch: [2]  [Step 900/14540]  lr: 0.000100  loss: 1.75813  detection_loss: 1.5923 (cls: 0.4035, box: 1.1888)  rpn_loss: 0.1658 (cls: 0.0809, box: 0.0849)
[2025-08-07 15:37:04 train.log] INFO: Epoch: [2]  [Step 1000/14540]  lr: 0.000100  loss: 2.77964  detection_loss: 2.5465 (cls: 0.8779, box: 1.6686)  rpn_loss: 0.2332 (cls: 0.1636, box: 0.0696)
[2025-08-07 15:37:09 train.log] INFO: Epoch: [2]  [Step 1100/14540]  lr: 0.000100  loss: 2.16081  detection_loss: 1.9880 (cls: 0.6307, box: 1.3573)  rpn_loss: 0.1728 (cls: 0.0975, box: 0.0753)
[2025-08-07 15:37:14 train.log] INFO: Epoch: [2]  [Step 1200/14540]  lr: 0.000100  loss: 1.50269  detection_loss: 1.3625 (cls: 0.2255, box: 1.1370)  rpn_loss: 0.1402 (cls: 0.0298, box: 0.1104)
[2025-08-07 15:37:19 train.log] INFO: Epoch: [2]  [Step 1300/14540]  lr: 0.000100  loss: 2.09142  detection_loss: 1.9201 (cls: 0.5300, box: 1.3901)  rpn_loss: 0.1713 (cls: 0.1085, box: 0.0628)
[2025-08-07 15:37:24 train.log] INFO: Epoch: [2]  [Step 1400/14540]  lr: 0.000100  loss: 2.06134  detection_loss: 1.8318 (cls: 0.6613, box: 1.1705)  rpn_loss: 0.2295 (cls: 0.1938, box: 0.0357)
[2025-08-07 15:37:29 train.log] INFO: Epoch: [2]  [Step 1500/14540]  lr: 0.000100  loss: 1.85329  detection_loss: 1.6070 (cls: 0.3129, box: 1.2940)  rpn_loss: 0.2463 (cls: 0.1008, box: 0.1455)
[2025-08-07 15:37:34 train.log] INFO: Epoch: [2]  [Step 1600/14540]  lr: 0.000100  loss: 1.51582  detection_loss: 1.3166 (cls: 0.3264, box: 0.9902)  rpn_loss: 0.1992 (cls: 0.0589, box: 0.1404)
[2025-08-07 15:37:39 train.log] INFO: Epoch: [2]  [Step 1700/14540]  lr: 0.000100  loss: 1.69116  detection_loss: 1.5643 (cls: 0.2055, box: 1.3588)  rpn_loss: 0.1269 (cls: 0.0501, box: 0.0768)
[2025-08-07 15:37:43 train.log] INFO: Epoch: [2]  [Step 1800/14540]  lr: 0.000100  loss: 2.28327  detection_loss: 2.0600 (cls: 0.4872, box: 1.5729)  rpn_loss: 0.2232 (cls: 0.1129, box: 0.1104)
[2025-08-07 15:37:48 train.log] INFO: Epoch: [2]  [Step 1900/14540]  lr: 0.000100  loss: 2.46658  detection_loss: 2.3131 (cls: 0.5552, box: 1.7579)  rpn_loss: 0.1535 (cls: 0.0803, box: 0.0732)
[2025-08-07 15:37:53 train.log] INFO: Epoch: [2]  [Step 2000/14540]  lr: 0.000100  loss: 1.75814  detection_loss: 1.5710 (cls: 0.3118, box: 1.2592)  rpn_loss: 0.1871 (cls: 0.0569, box: 0.1302)
[2025-08-07 15:37:58 train.log] INFO: Epoch: [2]  [Step 2100/14540]  lr: 0.000100  loss: 1.52350  detection_loss: 1.3640 (cls: 0.2090, box: 1.1550)  rpn_loss: 0.1595 (cls: 0.0578, box: 0.1017)
[2025-08-07 15:38:03 train.log] INFO: Epoch: [2]  [Step 2200/14540]  lr: 0.000100  loss: 1.99242  detection_loss: 1.7956 (cls: 0.4494, box: 1.3463)  rpn_loss: 0.1968 (cls: 0.1329, box: 0.0639)
[2025-08-07 15:38:08 train.log] INFO: Epoch: [2]  [Step 2300/14540]  lr: 0.000100  loss: 2.11086  detection_loss: 1.9543 (cls: 0.4865, box: 1.4677)  rpn_loss: 0.1566 (cls: 0.1101, box: 0.0465)
[2025-08-07 15:38:13 train.log] INFO: Epoch: [2]  [Step 2400/14540]  lr: 0.000100  loss: 1.38986  detection_loss: 1.2866 (cls: 0.2773, box: 1.0093)  rpn_loss: 0.1032 (cls: 0.0479, box: 0.0553)
[2025-08-07 15:38:18 train.log] INFO: Epoch: [2]  [Step 2500/14540]  lr: 0.000100  loss: 1.99498  detection_loss: 1.8794 (cls: 0.5498, box: 1.3295)  rpn_loss: 0.1156 (cls: 0.0599, box: 0.0557)
[2025-08-07 15:38:22 train.log] INFO: Epoch: [2]  [Step 2600/14540]  lr: 0.000100  loss: 1.68485  detection_loss: 1.5706 (cls: 0.2963, box: 1.2743)  rpn_loss: 0.1142 (cls: 0.0421, box: 0.0722)
[2025-08-07 15:38:27 train.log] INFO: Epoch: [2]  [Step 2700/14540]  lr: 0.000100  loss: 1.70094  detection_loss: 1.5926 (cls: 0.4120, box: 1.1805)  rpn_loss: 0.1084 (cls: 0.0852, box: 0.0232)
[2025-08-07 15:38:32 train.log] INFO: Epoch: [2]  [Step 2800/14540]  lr: 0.000100  loss: 1.93068  detection_loss: 1.7401 (cls: 0.4172, box: 1.3229)  rpn_loss: 0.1906 (cls: 0.1229, box: 0.0677)
[2025-08-07 15:38:37 train.log] INFO: Epoch: [2]  [Step 2900/14540]  lr: 0.000100  loss: 2.11523  detection_loss: 1.9289 (cls: 0.4899, box: 1.4390)  rpn_loss: 0.1863 (cls: 0.0756, box: 0.1107)
[2025-08-07 15:38:42 train.log] INFO: Epoch: [2]  [Step 3000/14540]  lr: 0.000100  loss: 2.04636  detection_loss: 1.8735 (cls: 0.3585, box: 1.5150)  rpn_loss: 0.1728 (cls: 0.1274, box: 0.0454)
[2025-08-07 15:38:47 train.log] INFO: Epoch: [2]  [Step 3100/14540]  lr: 0.000100  loss: 2.13466  detection_loss: 1.7354 (cls: 0.4170, box: 1.3185)  rpn_loss: 0.3992 (cls: 0.1225, box: 0.2767)
[2025-08-07 15:38:52 train.log] INFO: Epoch: [2]  [Step 3200/14540]  lr: 0.000100  loss: 2.11942  detection_loss: 1.9779 (cls: 0.3859, box: 1.5919)  rpn_loss: 0.1416 (cls: 0.0542, box: 0.0873)
[2025-08-07 15:38:57 train.log] INFO: Epoch: [2]  [Step 3300/14540]  lr: 0.000100  loss: 2.61721  detection_loss: 2.4195 (cls: 0.7475, box: 1.6720)  rpn_loss: 0.1977 (cls: 0.1031, box: 0.0946)
[2025-08-07 15:39:02 train.log] INFO: Epoch: [2]  [Step 3400/14540]  lr: 0.000100  loss: 1.71805  detection_loss: 1.5668 (cls: 0.3412, box: 1.2256)  rpn_loss: 0.1513 (cls: 0.0819, box: 0.0694)
[2025-08-07 15:39:07 train.log] INFO: Epoch: [2]  [Step 3500/14540]  lr: 0.000100  loss: 1.91246  detection_loss: 1.6778 (cls: 0.3615, box: 1.3163)  rpn_loss: 0.2346 (cls: 0.2059, box: 0.0288)
[2025-08-07 15:39:12 train.log] INFO: Epoch: [2]  [Step 3600/14540]  lr: 0.000100  loss: 2.27368  detection_loss: 2.0897 (cls: 0.6662, box: 1.4236)  rpn_loss: 0.1840 (cls: 0.1052, box: 0.0788)
[2025-08-07 15:39:13 train.log] INFO: Epoch: [2]  [Step 3635/14540]  lr: 0.000100  loss: 1.75712  detection_loss: 1.5923 (cls: 0.5505, box: 1.0418)  rpn_loss: 0.1648 (cls: 0.0742, box: 0.0905)
[2025-08-07 15:39:17 train.log] INFO: Epoch: [2]  [Step 3700/14540]  lr: 0.000100  loss: 1.76557  detection_loss: 1.5577 (cls: 0.3447, box: 1.2130)  rpn_loss: 0.2079 (cls: 0.0997, box: 0.1082)
[2025-08-07 15:39:22 train.log] INFO: Epoch: [2]  [Step 3800/14540]  lr: 0.000100  loss: 1.70525  detection_loss: 1.3935 (cls: 0.2788, box: 1.1147)  rpn_loss: 0.3117 (cls: 0.1090, box: 0.2027)
[2025-08-07 15:39:27 train.log] INFO: Epoch: [2]  [Step 3900/14540]  lr: 0.000100  loss: 2.19111  detection_loss: 2.0791 (cls: 0.5270, box: 1.5521)  rpn_loss: 0.1120 (cls: 0.0716, box: 0.0404)
[2025-08-07 15:39:31 train.log] INFO: Epoch: [2]  [Step 4000/14540]  lr: 0.000100  loss: 2.50410  detection_loss: 2.1981 (cls: 0.7010, box: 1.4971)  rpn_loss: 0.3060 (cls: 0.2618, box: 0.0442)
[2025-08-07 15:39:36 train.log] INFO: Epoch: [2]  [Step 4100/14540]  lr: 0.000100  loss: 1.96628  detection_loss: 1.8731 (cls: 0.3281, box: 1.5450)  rpn_loss: 0.0932 (cls: 0.0440, box: 0.0491)
[2025-08-07 15:39:41 train.log] INFO: Epoch: [2]  [Step 4200/14540]  lr: 0.000100  loss: 2.19008  detection_loss: 2.0274 (cls: 0.4304, box: 1.5969)  rpn_loss: 0.1627 (cls: 0.0992, box: 0.0635)
[2025-08-07 15:39:46 train.log] INFO: Epoch: [2]  [Step 4300/14540]  lr: 0.000100  loss: 1.66287  detection_loss: 1.5133 (cls: 0.2562, box: 1.2571)  rpn_loss: 0.1496 (cls: 0.1086, box: 0.0410)
[2025-08-07 15:39:51 train.log] INFO: Epoch: [2]  [Step 4400/14540]  lr: 0.000100  loss: 2.06618  detection_loss: 1.6841 (cls: 0.4384, box: 1.2458)  rpn_loss: 0.3820 (cls: 0.0730, box: 0.3090)
[2025-08-07 15:39:56 train.log] INFO: Epoch: [2]  [Step 4500/14540]  lr: 0.000100  loss: 2.04931  detection_loss: 1.6190 (cls: 0.2927, box: 1.3264)  rpn_loss: 0.4303 (cls: 0.0763, box: 0.3539)
[2025-08-07 15:40:01 train.log] INFO: Epoch: [2]  [Step 4600/14540]  lr: 0.000100  loss: 1.78046  detection_loss: 1.6494 (cls: 0.4986, box: 1.1508)  rpn_loss: 0.1311 (cls: 0.0712, box: 0.0598)
[2025-08-07 15:40:06 train.log] INFO: Epoch: [2]  [Step 4700/14540]  lr: 0.000100  loss: 1.92008  detection_loss: 1.7931 (cls: 0.5613, box: 1.2317)  rpn_loss: 0.1270 (cls: 0.0919, box: 0.0351)
[2025-08-07 15:40:11 train.log] INFO: Epoch: [2]  [Step 4800/14540]  lr: 0.000100  loss: 1.46698  detection_loss: 1.2892 (cls: 0.3953, box: 0.8939)  rpn_loss: 0.1778 (cls: 0.0601, box: 0.1177)
[2025-08-07 15:40:16 train.log] INFO: Epoch: [2]  [Step 4900/14540]  lr: 0.000100  loss: 1.48005  detection_loss: 1.3841 (cls: 0.2134, box: 1.1707)  rpn_loss: 0.0959 (cls: 0.0284, box: 0.0675)
[2025-08-07 15:40:21 train.log] INFO: Epoch: [2]  [Step 5000/14540]  lr: 0.000100  loss: 1.68993  detection_loss: 1.3659 (cls: 0.2669, box: 1.0991)  rpn_loss: 0.3240 (cls: 0.0723, box: 0.2517)
[2025-08-07 15:40:25 train.log] INFO: Epoch: [2]  [Step 5100/14540]  lr: 0.000100  loss: 1.45341  detection_loss: 1.3446 (cls: 0.1829, box: 1.1617)  rpn_loss: 0.1088 (cls: 0.0537, box: 0.0551)
[2025-08-07 15:40:30 train.log] INFO: Epoch: [2]  [Step 5200/14540]  lr: 0.000100  loss: 1.58882  detection_loss: 1.4847 (cls: 0.3437, box: 1.1409)  rpn_loss: 0.1042 (cls: 0.0815, box: 0.0227)
[2025-08-07 15:40:35 train.log] INFO: Epoch: [2]  [Step 5300/14540]  lr: 0.000100  loss: 2.05727  detection_loss: 1.9192 (cls: 0.2469, box: 1.6723)  rpn_loss: 0.1380 (cls: 0.0695, box: 0.0685)
[2025-08-07 15:40:40 train.log] INFO: Epoch: [2]  [Step 5400/14540]  lr: 0.000100  loss: 1.94358  detection_loss: 1.7605 (cls: 0.4811, box: 1.2794)  rpn_loss: 0.1830 (cls: 0.0800, box: 0.1030)
[2025-08-07 15:40:45 train.log] INFO: Epoch: [2]  [Step 5500/14540]  lr: 0.000100  loss: 1.69235  detection_loss: 1.5151 (cls: 0.3595, box: 1.1557)  rpn_loss: 0.1772 (cls: 0.0948, box: 0.0824)
[2025-08-07 15:40:49 train.log] INFO: Epoch: [2]  [Step 5600/14540]  lr: 0.000100  loss: 1.49230  detection_loss: 1.3704 (cls: 0.2411, box: 1.1293)  rpn_loss: 0.1219 (cls: 0.0815, box: 0.0404)
[2025-08-07 15:40:54 train.log] INFO: Epoch: [2]  [Step 5700/14540]  lr: 0.000100  loss: 1.49957  detection_loss: 1.3261 (cls: 0.2737, box: 1.0524)  rpn_loss: 0.1734 (cls: 0.0996, box: 0.0739)
[2025-08-07 15:40:59 train.log] INFO: Epoch: [2]  [Step 5800/14540]  lr: 0.000100  loss: 1.55677  detection_loss: 1.3068 (cls: 0.4351, box: 0.8717)  rpn_loss: 0.2500 (cls: 0.1132, box: 0.1368)
[2025-08-07 15:41:04 train.log] INFO: Epoch: [2]  [Step 5900/14540]  lr: 0.000100  loss: 1.70532  detection_loss: 1.2910 (cls: 0.3116, box: 0.9794)  rpn_loss: 0.4143 (cls: 0.0843, box: 0.3300)
[2025-08-07 15:41:09 train.log] INFO: Epoch: [2]  [Step 6000/14540]  lr: 0.000100  loss: 0.98965  detection_loss: 0.9024 (cls: 0.1643, box: 0.7381)  rpn_loss: 0.0873 (cls: 0.0448, box: 0.0425)
[2025-08-07 15:41:14 train.log] INFO: Epoch: [2]  [Step 6100/14540]  lr: 0.000100  loss: 1.60923  detection_loss: 1.4810 (cls: 0.3141, box: 1.1669)  rpn_loss: 0.1282 (cls: 0.0593, box: 0.0690)
[2025-08-07 15:41:19 train.log] INFO: Epoch: [2]  [Step 6200/14540]  lr: 0.000100  loss: 2.07138  detection_loss: 1.9481 (cls: 0.3029, box: 1.6452)  rpn_loss: 0.1233 (cls: 0.0434, box: 0.0798)
[2025-08-07 15:41:24 train.log] INFO: Epoch: [2]  [Step 6300/14540]  lr: 0.000100  loss: 1.36090  detection_loss: 1.2292 (cls: 0.2801, box: 0.9491)  rpn_loss: 0.1317 (cls: 0.0652, box: 0.0665)
[2025-08-07 15:41:28 train.log] INFO: Epoch: [2]  [Step 6400/14540]  lr: 0.000100  loss: 1.61727  detection_loss: 1.4627 (cls: 0.3257, box: 1.1370)  rpn_loss: 0.1546 (cls: 0.0522, box: 0.1024)
[2025-08-07 15:41:33 train.log] INFO: Epoch: [2]  [Step 6500/14540]  lr: 0.000100  loss: 1.71651  detection_loss: 1.5995 (cls: 0.4449, box: 1.1546)  rpn_loss: 0.1170 (cls: 0.0706, box: 0.0464)
[2025-08-07 15:41:38 train.log] INFO: Epoch: [2]  [Step 6600/14540]  lr: 0.000100  loss: 1.97750  detection_loss: 1.7700 (cls: 0.4966, box: 1.2734)  rpn_loss: 0.2075 (cls: 0.1895, box: 0.0179)
[2025-08-07 15:41:43 train.log] INFO: Epoch: [2]  [Step 6700/14540]  lr: 0.000100  loss: 2.06874  detection_loss: 1.9673 (cls: 0.3447, box: 1.6226)  rpn_loss: 0.1015 (cls: 0.0494, box: 0.0521)
[2025-08-07 15:41:48 train.log] INFO: Epoch: [2]  [Step 6800/14540]  lr: 0.000100  loss: 1.17970  detection_loss: 1.0613 (cls: 0.2741, box: 0.7872)  rpn_loss: 0.1184 (cls: 0.0692, box: 0.0493)
[2025-08-07 15:41:53 train.log] INFO: Epoch: [2]  [Step 6900/14540]  lr: 0.000100  loss: 1.42820  detection_loss: 1.3000 (cls: 0.2290, box: 1.0711)  rpn_loss: 0.1282 (cls: 0.1006, box: 0.0276)
[2025-08-07 15:41:58 train.log] INFO: Epoch: [2]  [Step 7000/14540]  lr: 0.000100  loss: 1.57205  detection_loss: 1.4407 (cls: 0.3446, box: 1.0962)  rpn_loss: 0.1313 (cls: 0.0889, box: 0.0424)
[2025-08-07 15:42:03 train.log] INFO: Epoch: [2]  [Step 7100/14540]  lr: 0.000100  loss: 1.61481  detection_loss: 1.4164 (cls: 0.4393, box: 0.9771)  rpn_loss: 0.1984 (cls: 0.1075, box: 0.0909)
[2025-08-07 15:42:08 train.log] INFO: Epoch: [2]  [Step 7200/14540]  lr: 0.000100  loss: 1.78333  detection_loss: 1.6581 (cls: 0.5256, box: 1.1325)  rpn_loss: 0.1252 (cls: 0.0756, box: 0.0497)
[2025-08-07 15:42:13 train.log] INFO: Epoch: [2]  [Step 7300/14540]  lr: 0.000100  loss: 2.11831  detection_loss: 1.8623 (cls: 0.6531, box: 1.2091)  rpn_loss: 0.2560 (cls: 0.1589, box: 0.0971)
[2025-08-07 15:42:18 train.log] INFO: Epoch: [2]  [Step 7400/14540]  lr: 0.000100  loss: 1.89163  detection_loss: 1.6584 (cls: 0.5285, box: 1.1299)  rpn_loss: 0.2333 (cls: 0.0771, box: 0.1561)
[2025-08-07 15:42:23 train.log] INFO: Epoch: [2]  [Step 7500/14540]  lr: 0.000100  loss: 1.65416  detection_loss: 1.4911 (cls: 0.3930, box: 1.0980)  rpn_loss: 0.1631 (cls: 0.0636, box: 0.0995)
[2025-08-07 15:42:28 train.log] INFO: Epoch: [2]  [Step 7600/14540]  lr: 0.000100  loss: 2.42206  detection_loss: 2.1411 (cls: 0.6959, box: 1.4452)  rpn_loss: 0.2809 (cls: 0.1765, box: 0.1044)
[2025-08-07 15:42:33 train.log] INFO: Epoch: [2]  [Step 7700/14540]  lr: 0.000100  loss: 1.89873  detection_loss: 1.7452 (cls: 0.4401, box: 1.3052)  rpn_loss: 0.1535 (cls: 0.1112, box: 0.0423)
[2025-08-07 15:42:38 train.log] INFO: Epoch: [2]  [Step 7800/14540]  lr: 0.000100  loss: 1.87893  detection_loss: 1.7606 (cls: 0.3977, box: 1.3629)  rpn_loss: 0.1183 (cls: 0.0841, box: 0.0342)
[2025-08-07 15:42:43 train.log] INFO: Epoch: [2]  [Step 7900/14540]  lr: 0.000100  loss: 2.29188  detection_loss: 2.1211 (cls: 0.5400, box: 1.5812)  rpn_loss: 0.1707 (cls: 0.0614, box: 0.1093)
[2025-08-07 15:42:48 train.log] INFO: Epoch: [2]  [Step 8000/14540]  lr: 0.000100  loss: 1.97503  detection_loss: 1.7408 (cls: 0.4109, box: 1.3299)  rpn_loss: 0.2342 (cls: 0.0774, box: 0.1568)
[2025-08-07 15:42:52 train.log] INFO: Epoch: [2]  [Step 8100/14540]  lr: 0.000100  loss: 1.34598  detection_loss: 1.2724 (cls: 0.2969, box: 0.9755)  rpn_loss: 0.0735 (cls: 0.0438, box: 0.0297)
[2025-08-07 15:42:57 train.log] INFO: Epoch: [2]  [Step 8200/14540]  lr: 0.000100  loss: 1.62014  detection_loss: 1.4178 (cls: 0.3595, box: 1.0583)  rpn_loss: 0.2024 (cls: 0.0653, box: 0.1370)
[2025-08-07 15:43:02 train.log] INFO: Epoch: [2]  [Step 8300/14540]  lr: 0.000100  loss: 1.76010  detection_loss: 1.5987 (cls: 0.3941, box: 1.2046)  rpn_loss: 0.1614 (cls: 0.1033, box: 0.0581)
[2025-08-07 15:43:07 train.log] INFO: Epoch: [2]  [Step 8400/14540]  lr: 0.000100  loss: 1.77380  detection_loss: 1.5177 (cls: 0.4106, box: 1.1072)  rpn_loss: 0.2561 (cls: 0.1158, box: 0.1402)
[2025-08-07 15:43:12 train.log] INFO: Epoch: [2]  [Step 8500/14540]  lr: 0.000100  loss: 1.85754  detection_loss: 1.7057 (cls: 0.4319, box: 1.2738)  rpn_loss: 0.1518 (cls: 0.1191, box: 0.0327)
[2025-08-07 15:43:17 train.log] INFO: Epoch: [2]  [Step 8600/14540]  lr: 0.000100  loss: 2.39813  detection_loss: 1.9838 (cls: 0.5492, box: 1.4347)  rpn_loss: 0.4143 (cls: 0.1787, box: 0.2355)
[2025-08-07 15:43:22 train.log] INFO: Epoch: [2]  [Step 8700/14540]  lr: 0.000100  loss: 2.37683  detection_loss: 2.1898 (cls: 0.4162, box: 1.7737)  rpn_loss: 0.1870 (cls: 0.1057, box: 0.0813)
[2025-08-07 15:43:26 train.log] INFO: Epoch: [2]  [Step 8800/14540]  lr: 0.000100  loss: 2.31331  detection_loss: 1.8263 (cls: 0.3226, box: 1.5037)  rpn_loss: 0.4870 (cls: 0.1099, box: 0.3771)
[2025-08-07 15:43:31 train.log] INFO: Epoch: [2]  [Step 8900/14540]  lr: 0.000100  loss: 1.65642  detection_loss: 1.4297 (cls: 0.3773, box: 1.0524)  rpn_loss: 0.2268 (cls: 0.0851, box: 0.1416)
[2025-08-07 15:43:36 train.log] INFO: Epoch: [2]  [Step 9000/14540]  lr: 0.000100  loss: 2.08247  detection_loss: 1.9146 (cls: 0.3190, box: 1.5956)  rpn_loss: 0.1679 (cls: 0.1178, box: 0.0501)
[2025-08-07 15:43:41 train.log] INFO: Epoch: [2]  [Step 9100/14540]  lr: 0.000100  loss: 1.75604  detection_loss: 1.5498 (cls: 0.3752, box: 1.1746)  rpn_loss: 0.2063 (cls: 0.0967, box: 0.1096)
[2025-08-07 15:43:46 train.log] INFO: Epoch: [2]  [Step 9200/14540]  lr: 0.000100  loss: 2.27265  detection_loss: 1.9370 (cls: 0.4924, box: 1.4446)  rpn_loss: 0.3357 (cls: 0.1185, box: 0.2172)
[2025-08-07 15:43:51 train.log] INFO: Epoch: [2]  [Step 9300/14540]  lr: 0.000100  loss: 2.05456  detection_loss: 1.8955 (cls: 0.4522, box: 1.4433)  rpn_loss: 0.1590 (cls: 0.0779, box: 0.0811)
[2025-08-07 15:43:56 train.log] INFO: Epoch: [2]  [Step 9400/14540]  lr: 0.000100  loss: 1.18023  detection_loss: 1.0301 (cls: 0.2827, box: 0.7475)  rpn_loss: 0.1501 (cls: 0.0326, box: 0.1175)
[2025-08-07 15:44:01 train.log] INFO: Epoch: [2]  [Step 9500/14540]  lr: 0.000100  loss: 1.52382  detection_loss: 1.4281 (cls: 0.3204, box: 1.1077)  rpn_loss: 0.0957 (cls: 0.0538, box: 0.0419)
[2025-08-07 15:44:05 train.log] INFO: Epoch: [2]  [Step 9600/14540]  lr: 0.000100  loss: 1.47710  detection_loss: 1.3301 (cls: 0.3256, box: 1.0045)  rpn_loss: 0.1470 (cls: 0.0639, box: 0.0831)
[2025-08-07 15:44:10 train.log] INFO: Epoch: [2]  [Step 9700/14540]  lr: 0.000100  loss: 2.28883  detection_loss: 2.0350 (cls: 0.5533, box: 1.4816)  rpn_loss: 0.2539 (cls: 0.0884, box: 0.1655)
[2025-08-07 15:44:15 train.log] INFO: Epoch: [2]  [Step 9800/14540]  lr: 0.000100  loss: 1.54311  detection_loss: 1.2739 (cls: 0.2591, box: 1.0148)  rpn_loss: 0.2692 (cls: 0.0679, box: 0.2013)
[2025-08-07 15:44:20 train.log] INFO: Epoch: [2]  [Step 9900/14540]  lr: 0.000100  loss: 1.76743  detection_loss: 1.6989 (cls: 0.3214, box: 1.3775)  rpn_loss: 0.0685 (cls: 0.0477, box: 0.0209)
[2025-08-07 15:44:25 train.log] INFO: Epoch: [2]  [Step 10000/14540]  lr: 0.000100  loss: 1.39922  detection_loss: 1.3144 (cls: 0.2461, box: 1.0683)  rpn_loss: 0.0848 (cls: 0.0496, box: 0.0352)
[2025-08-07 15:44:30 train.log] INFO: Epoch: [2]  [Step 10100/14540]  lr: 0.000100  loss: 1.72315  detection_loss: 1.4723 (cls: 0.3219, box: 1.1503)  rpn_loss: 0.2509 (cls: 0.0483, box: 0.2026)
[2025-08-07 15:44:35 train.log] INFO: Epoch: [2]  [Step 10200/14540]  lr: 0.000100  loss: 2.37714  detection_loss: 2.2436 (cls: 0.4888, box: 1.7548)  rpn_loss: 0.1336 (cls: 0.0890, box: 0.0446)
[2025-08-07 15:44:39 train.log] INFO: Epoch: [2]  [Step 10300/14540]  lr: 0.000100  loss: 2.66097  detection_loss: 2.5060 (cls: 0.6623, box: 1.8437)  rpn_loss: 0.1549 (cls: 0.1119, box: 0.0430)
[2025-08-07 15:44:44 train.log] INFO: Epoch: [2]  [Step 10400/14540]  lr: 0.000100  loss: 2.33770  detection_loss: 2.1593 (cls: 0.4992, box: 1.6601)  rpn_loss: 0.1784 (cls: 0.1035, box: 0.0749)
[2025-08-07 15:44:49 train.log] INFO: Epoch: [2]  [Step 10500/14540]  lr: 0.000100  loss: 2.18315  detection_loss: 1.8751 (cls: 0.4121, box: 1.4631)  rpn_loss: 0.3080 (cls: 0.1016, box: 0.2064)
[2025-08-07 15:44:54 train.log] INFO: Epoch: [2]  [Step 10600/14540]  lr: 0.000100  loss: 1.33046  detection_loss: 1.2362 (cls: 0.1648, box: 1.0714)  rpn_loss: 0.0942 (cls: 0.0261, box: 0.0682)
[2025-08-07 15:44:59 train.log] INFO: Epoch: [2]  [Step 10700/14540]  lr: 0.000100  loss: 1.49909  detection_loss: 1.2336 (cls: 0.2741, box: 0.9595)  rpn_loss: 0.2655 (cls: 0.0817, box: 0.1838)
[2025-08-07 15:45:04 train.log] INFO: Epoch: [2]  [Step 10800/14540]  lr: 0.000100  loss: 1.64729  detection_loss: 1.4847 (cls: 0.5083, box: 0.9763)  rpn_loss: 0.1626 (cls: 0.0788, box: 0.0839)
[2025-08-07 15:45:08 train.log] INFO: Epoch: [2]  [Step 10900/14540]  lr: 0.000100  loss: 1.66709  detection_loss: 1.5858 (cls: 0.3084, box: 1.2774)  rpn_loss: 0.0812 (cls: 0.0281, box: 0.0531)
[2025-08-07 15:45:13 train.log] INFO: Epoch: [2]  [Step 11000/14540]  lr: 0.000100  loss: 1.87945  detection_loss: 1.7330 (cls: 0.2735, box: 1.4595)  rpn_loss: 0.1464 (cls: 0.0363, box: 0.1101)
[2025-08-07 15:45:18 train.log] INFO: Epoch: [2]  [Step 11100/14540]  lr: 0.000100  loss: 1.84303  detection_loss: 1.6131 (cls: 0.3367, box: 1.2764)  rpn_loss: 0.2299 (cls: 0.1143, box: 0.1156)
[2025-08-07 15:45:23 train.log] INFO: Epoch: [2]  [Step 11200/14540]  lr: 0.000100  loss: 2.08438  detection_loss: 1.9650 (cls: 0.6704, box: 1.2946)  rpn_loss: 0.1194 (cls: 0.0656, box: 0.0539)
[2025-08-07 15:45:28 train.log] INFO: Epoch: [2]  [Step 11300/14540]  lr: 0.000100  loss: 2.39299  detection_loss: 2.1550 (cls: 0.4510, box: 1.7040)  rpn_loss: 0.2380 (cls: 0.1954, box: 0.0426)
[2025-08-07 15:45:33 train.log] INFO: Epoch: [2]  [Step 11400/14540]  lr: 0.000100  loss: 2.02388  detection_loss: 1.9107 (cls: 0.3441, box: 1.5666)  rpn_loss: 0.1132 (cls: 0.0693, box: 0.0439)
[2025-08-07 15:45:37 train.log] INFO: Epoch: [2]  [Step 11500/14540]  lr: 0.000100  loss: 1.58123  detection_loss: 1.4763 (cls: 0.3290, box: 1.1474)  rpn_loss: 0.1049 (cls: 0.0763, box: 0.0286)
[2025-08-07 15:45:42 train.log] INFO: Epoch: [2]  [Step 11600/14540]  lr: 0.000100  loss: 1.35737  detection_loss: 1.1886 (cls: 0.1619, box: 1.0267)  rpn_loss: 0.1688 (cls: 0.0260, box: 0.1428)
[2025-08-07 15:45:47 train.log] INFO: Epoch: [2]  [Step 11700/14540]  lr: 0.000100  loss: 1.65111  detection_loss: 1.5451 (cls: 0.3609, box: 1.1843)  rpn_loss: 0.1060 (cls: 0.0574, box: 0.0486)
[2025-08-07 15:45:52 train.log] INFO: Epoch: [2]  [Step 11800/14540]  lr: 0.000100  loss: 1.56553  detection_loss: 1.3941 (cls: 0.3366, box: 1.0576)  rpn_loss: 0.1714 (cls: 0.0802, box: 0.0912)
[2025-08-07 15:45:57 train.log] INFO: Epoch: [2]  [Step 11900/14540]  lr: 0.000100  loss: 2.06383  detection_loss: 1.9143 (cls: 0.6988, box: 1.2155)  rpn_loss: 0.1496 (cls: 0.0576, box: 0.0920)
[2025-08-07 15:46:02 train.log] INFO: Epoch: [2]  [Step 12000/14540]  lr: 0.000100  loss: 1.89792  detection_loss: 1.7273 (cls: 0.3510, box: 1.3763)  rpn_loss: 0.1706 (cls: 0.1093, box: 0.0613)
[2025-08-07 15:46:07 train.log] INFO: Epoch: [2]  [Step 12100/14540]  lr: 0.000100  loss: 1.77061  detection_loss: 1.5411 (cls: 0.2825, box: 1.2586)  rpn_loss: 0.2295 (cls: 0.0968, box: 0.1327)
[2025-08-07 15:46:12 train.log] INFO: Epoch: [2]  [Step 12200/14540]  lr: 0.000100  loss: 1.65463  detection_loss: 1.4845 (cls: 0.3107, box: 1.1738)  rpn_loss: 0.1701 (cls: 0.0822, box: 0.0879)
[2025-08-07 15:46:16 train.log] INFO: Epoch: [2]  [Step 12300/14540]  lr: 0.000100  loss: 1.86829  detection_loss: 1.6723 (cls: 0.4511, box: 1.2212)  rpn_loss: 0.1960 (cls: 0.1394, box: 0.0566)
[2025-08-07 15:46:21 train.log] INFO: Epoch: [2]  [Step 12400/14540]  lr: 0.000100  loss: 1.39975  detection_loss: 1.2565 (cls: 0.2229, box: 1.0336)  rpn_loss: 0.1433 (cls: 0.1034, box: 0.0398)
[2025-08-07 15:46:26 train.log] INFO: Epoch: [2]  [Step 12500/14540]  lr: 0.000100  loss: 1.93928  detection_loss: 1.8145 (cls: 0.5577, box: 1.2568)  rpn_loss: 0.1247 (cls: 0.0683, box: 0.0565)
[2025-08-07 15:46:31 train.log] INFO: Epoch: [2]  [Step 12600/14540]  lr: 0.000100  loss: 1.74300  detection_loss: 1.6161 (cls: 0.3578, box: 1.2582)  rpn_loss: 0.1269 (cls: 0.0556, box: 0.0713)
[2025-08-07 15:46:36 train.log] INFO: Epoch: [2]  [Step 12700/14540]  lr: 0.000100  loss: 1.61084  detection_loss: 1.4477 (cls: 0.1814, box: 1.2662)  rpn_loss: 0.1632 (cls: 0.0768, box: 0.0864)
[2025-08-07 15:46:41 train.log] INFO: Epoch: [2]  [Step 12800/14540]  lr: 0.000100  loss: 1.55951  detection_loss: 1.4387 (cls: 0.2784, box: 1.1603)  rpn_loss: 0.1208 (cls: 0.0722, box: 0.0486)
[2025-08-07 15:46:46 train.log] INFO: Epoch: [2]  [Step 12900/14540]  lr: 0.000100  loss: 1.72951  detection_loss: 1.5621 (cls: 0.3425, box: 1.2196)  rpn_loss: 0.1674 (cls: 0.1241, box: 0.0432)
[2025-08-07 15:46:50 train.log] INFO: Epoch: [2]  [Step 13000/14540]  lr: 0.000100  loss: 2.03578  detection_loss: 1.9088 (cls: 0.3841, box: 1.5247)  rpn_loss: 0.1270 (cls: 0.0772, box: 0.0498)
[2025-08-07 15:46:55 train.log] INFO: Epoch: [2]  [Step 13100/14540]  lr: 0.000100  loss: 1.69665  detection_loss: 1.5865 (cls: 0.4310, box: 1.1556)  rpn_loss: 0.1101 (cls: 0.0586, box: 0.0516)
[2025-08-07 15:47:00 train.log] INFO: Epoch: [2]  [Step 13200/14540]  lr: 0.000100  loss: 1.49663  detection_loss: 1.3681 (cls: 0.3565, box: 1.0116)  rpn_loss: 0.1285 (cls: 0.0758, box: 0.0528)
[2025-08-07 15:47:05 train.log] INFO: Epoch: [2]  [Step 13300/14540]  lr: 0.000100  loss: 1.90739  detection_loss: 1.7996 (cls: 0.4225, box: 1.3771)  rpn_loss: 0.1078 (cls: 0.0471, box: 0.0607)
[2025-08-07 15:47:10 train.log] INFO: Epoch: [2]  [Step 13400/14540]  lr: 0.000100  loss: 0.94319  detection_loss: 0.8992 (cls: 0.3195, box: 0.5796)  rpn_loss: 0.0440 (cls: 0.0275, box: 0.0165)
[2025-08-07 15:47:15 train.log] INFO: Epoch: [2]  [Step 13500/14540]  lr: 0.000100  loss: 1.68951  detection_loss: 1.5310 (cls: 0.4642, box: 1.0668)  rpn_loss: 0.1586 (cls: 0.0797, box: 0.0789)
[2025-08-07 15:47:19 train.log] INFO: Epoch: [2]  [Step 13600/14540]  lr: 0.000100  loss: 1.72910  detection_loss: 1.6021 (cls: 0.4324, box: 1.1697)  rpn_loss: 0.1270 (cls: 0.0573, box: 0.0697)
[2025-08-07 15:47:24 train.log] INFO: Epoch: [2]  [Step 13700/14540]  lr: 0.000100  loss: 2.25770  detection_loss: 2.1094 (cls: 0.4830, box: 1.6264)  rpn_loss: 0.1483 (cls: 0.0481, box: 0.1002)
[2025-08-07 15:47:29 train.log] INFO: Epoch: [2]  [Step 13800/14540]  lr: 0.000100  loss: 2.02140  detection_loss: 1.7805 (cls: 0.6901, box: 1.0904)  rpn_loss: 0.2409 (cls: 0.1322, box: 0.1087)
[2025-08-07 15:47:34 train.log] INFO: Epoch: [2]  [Step 13900/14540]  lr: 0.000100  loss: 1.30443  detection_loss: 1.1085 (cls: 0.2012, box: 0.9073)  rpn_loss: 0.1960 (cls: 0.0388, box: 0.1571)
[2025-08-07 15:47:39 train.log] INFO: Epoch: [2]  [Step 14000/14540]  lr: 0.000100  loss: 2.27268  detection_loss: 2.1345 (cls: 0.6285, box: 1.5060)  rpn_loss: 0.1382 (cls: 0.0815, box: 0.0567)
[2025-08-07 15:47:44 train.log] INFO: Epoch: [2]  [Step 14100/14540]  lr: 0.000100  loss: 1.72533  detection_loss: 1.5704 (cls: 0.3553, box: 1.2151)  rpn_loss: 0.1550 (cls: 0.0554, box: 0.0996)
[2025-08-07 15:47:49 train.log] INFO: Epoch: [2]  [Step 14200/14540]  lr: 0.000100  loss: 1.72603  detection_loss: 1.5848 (cls: 0.4210, box: 1.1638)  rpn_loss: 0.1412 (cls: 0.0549, box: 0.0863)
[2025-08-07 15:47:54 train.log] INFO: Epoch: [2]  [Step 14300/14540]  lr: 0.000100  loss: 2.18399  detection_loss: 1.9323 (cls: 0.3654, box: 1.5668)  rpn_loss: 0.2517 (cls: 0.1879, box: 0.0638)
[2025-08-07 15:47:59 train.log] INFO: Epoch: [2]  [Step 14400/14540]  lr: 0.000100  loss: 1.11180  detection_loss: 1.0097 (cls: 0.3146, box: 0.6951)  rpn_loss: 0.1021 (cls: 0.0756, box: 0.0264)
[2025-08-07 15:48:04 train.log] INFO: Epoch: [2]  [Step 14500/14540]  lr: 0.000100  loss: 1.72662  detection_loss: 1.2659 (cls: 0.2666, box: 0.9993)  rpn_loss: 0.4607 (cls: 0.0736, box: 0.3871)
[2025-08-07 15:51:01 train.log] INFO: Epoch: [3]  [Step 100/14540]  lr: 0.000099  loss: 1.72612  detection_loss: 1.5821 (cls: 0.2576, box: 1.3245)  rpn_loss: 0.1441 (cls: 0.0766, box: 0.0675)
[2025-08-07 15:51:06 train.log] INFO: Epoch: [3]  [Step 200/14540]  lr: 0.000099  loss: 2.62288  detection_loss: 2.4967 (cls: 0.3010, box: 2.1956)  rpn_loss: 0.1262 (cls: 0.0826, box: 0.0436)
[2025-08-07 15:51:10 train.log] INFO: Epoch: [3]  [Step 300/14540]  lr: 0.000099  loss: 1.27156  detection_loss: 1.1632 (cls: 0.3627, box: 0.8004)  rpn_loss: 0.1084 (cls: 0.0672, box: 0.0412)
[2025-08-07 15:51:15 train.log] INFO: Epoch: [3]  [Step 400/14540]  lr: 0.000099  loss: 2.17937  detection_loss: 2.0521 (cls: 0.5885, box: 1.4636)  rpn_loss: 0.1273 (cls: 0.0746, box: 0.0528)
[2025-08-07 15:51:20 train.log] INFO: Epoch: [3]  [Step 500/14540]  lr: 0.000099  loss: 1.62876  detection_loss: 1.5296 (cls: 0.3094, box: 1.2202)  rpn_loss: 0.0991 (cls: 0.0641, box: 0.0351)
[2025-08-07 15:51:25 train.log] INFO: Epoch: [3]  [Step 600/14540]  lr: 0.000099  loss: 2.28152  detection_loss: 2.0312 (cls: 0.5902, box: 1.4410)  rpn_loss: 0.2503 (cls: 0.1501, box: 0.1002)
[2025-08-07 15:51:30 train.log] INFO: Epoch: [3]  [Step 700/14540]  lr: 0.000099  loss: 1.52948  detection_loss: 1.4346 (cls: 0.2345, box: 1.2001)  rpn_loss: 0.0949 (cls: 0.0470, box: 0.0479)
[2025-08-07 15:51:35 train.log] INFO: Epoch: [3]  [Step 800/14540]  lr: 0.000099  loss: 1.53502  detection_loss: 1.3973 (cls: 0.4139, box: 0.9834)  rpn_loss: 0.1377 (cls: 0.0778, box: 0.0599)
[2025-08-07 15:51:40 train.log] INFO: Epoch: [3]  [Step 900/14540]  lr: 0.000099  loss: 1.61877  detection_loss: 1.5161 (cls: 0.5533, box: 0.9628)  rpn_loss: 0.1027 (cls: 0.0571, box: 0.0456)
[2025-08-07 15:51:45 train.log] INFO: Epoch: [3]  [Step 1000/14540]  lr: 0.000099  loss: 1.51770  detection_loss: 1.4419 (cls: 0.3257, box: 1.1163)  rpn_loss: 0.0758 (cls: 0.0345, box: 0.0413)
[2025-08-07 15:51:49 train.log] INFO: Epoch: [3]  [Step 1100/14540]  lr: 0.000099  loss: 1.91351  detection_loss: 1.7426 (cls: 0.4953, box: 1.2472)  rpn_loss: 0.1709 (cls: 0.1072, box: 0.0638)
[2025-08-07 15:51:54 train.log] INFO: Epoch: [3]  [Step 1200/14540]  lr: 0.000099  loss: 2.05956  detection_loss: 1.6723 (cls: 0.2613, box: 1.4109)  rpn_loss: 0.3873 (cls: 0.0375, box: 0.3498)
[2025-08-07 15:51:59 train.log] INFO: Epoch: [3]  [Step 1300/14540]  lr: 0.000099  loss: 1.32135  detection_loss: 1.1188 (cls: 0.3576, box: 0.7613)  rpn_loss: 0.2025 (cls: 0.0771, box: 0.1254)
[2025-08-07 15:52:04 train.log] INFO: Epoch: [3]  [Step 1400/14540]  lr: 0.000099  loss: 1.57832  detection_loss: 1.4249 (cls: 0.3551, box: 1.0698)  rpn_loss: 0.1534 (cls: 0.1204, box: 0.0331)
[2025-08-07 15:52:09 train.log] INFO: Epoch: [3]  [Step 1500/14540]  lr: 0.000099  loss: 2.06263  detection_loss: 1.7239 (cls: 0.4522, box: 1.2717)  rpn_loss: 0.3387 (cls: 0.0996, box: 0.2391)
[2025-08-07 15:52:14 train.log] INFO: Epoch: [3]  [Step 1600/14540]  lr: 0.000099  loss: 1.86811  detection_loss: 1.5636 (cls: 0.4104, box: 1.1532)  rpn_loss: 0.3046 (cls: 0.0536, box: 0.2510)
[2025-08-07 15:52:19 train.log] INFO: Epoch: [3]  [Step 1700/14540]  lr: 0.000099  loss: 1.47113  detection_loss: 1.3657 (cls: 0.3847, box: 0.9810)  rpn_loss: 0.1055 (cls: 0.0810, box: 0.0245)
[2025-08-07 15:52:23 train.log] INFO: Epoch: [3]  [Step 1800/14540]  lr: 0.000099  loss: 2.74511  detection_loss: 2.4811 (cls: 0.5303, box: 1.9508)  rpn_loss: 0.2640 (cls: 0.1919, box: 0.0721)
[2025-08-07 15:52:28 train.log] INFO: Epoch: [3]  [Step 1900/14540]  lr: 0.000099  loss: 1.66229  detection_loss: 1.6007 (cls: 0.3175, box: 1.2831)  rpn_loss: 0.0616 (cls: 0.0336, box: 0.0281)
[2025-08-07 15:52:33 train.log] INFO: Epoch: [3]  [Step 2000/14540]  lr: 0.000099  loss: 1.33690  detection_loss: 1.2262 (cls: 0.2141, box: 1.0121)  rpn_loss: 0.1107 (cls: 0.0360, box: 0.0747)
[2025-08-07 15:52:38 train.log] INFO: Epoch: [3]  [Step 2100/14540]  lr: 0.000099  loss: 1.68770  detection_loss: 1.5563 (cls: 0.1940, box: 1.3623)  rpn_loss: 0.1314 (cls: 0.0454, box: 0.0861)
[2025-08-07 15:52:43 train.log] INFO: Epoch: [3]  [Step 2200/14540]  lr: 0.000099  loss: 0.86011  detection_loss: 0.7953 (cls: 0.2175, box: 0.5778)  rpn_loss: 0.0648 (cls: 0.0176, box: 0.0472)
[2025-08-07 15:52:47 train.log] INFO: Epoch: [3]  [Step 2300/14540]  lr: 0.000099  loss: 1.35570  detection_loss: 1.2643 (cls: 0.2992, box: 0.9651)  rpn_loss: 0.0914 (cls: 0.0620, box: 0.0295)
[2025-08-07 15:52:52 train.log] INFO: Epoch: [3]  [Step 2400/14540]  lr: 0.000099  loss: 1.71741  detection_loss: 1.5487 (cls: 0.3647, box: 1.1839)  rpn_loss: 0.1687 (cls: 0.0221, box: 0.1467)
[2025-08-07 15:52:57 train.log] INFO: Epoch: [3]  [Step 2500/14540]  lr: 0.000099  loss: 1.98449  detection_loss: 1.8883 (cls: 0.4771, box: 1.4112)  rpn_loss: 0.0962 (cls: 0.0394, box: 0.0568)
[2025-08-07 15:53:02 train.log] INFO: Epoch: [3]  [Step 2600/14540]  lr: 0.000099  loss: 1.60463  detection_loss: 1.4508 (cls: 0.2853, box: 1.1655)  rpn_loss: 0.1538 (cls: 0.1356, box: 0.0182)
[2025-08-07 15:53:07 train.log] INFO: Epoch: [3]  [Step 2700/14540]  lr: 0.000099  loss: 1.95867  detection_loss: 1.8334 (cls: 0.1259, box: 1.7075)  rpn_loss: 0.1252 (cls: 0.0600, box: 0.0653)
[2025-08-07 15:53:11 train.log] INFO: Epoch: [3]  [Step 2800/14540]  lr: 0.000099  loss: 1.33665  detection_loss: 1.2649 (cls: 0.3758, box: 0.8891)  rpn_loss: 0.0718 (cls: 0.0399, box: 0.0319)
[2025-08-07 15:53:16 train.log] INFO: Epoch: [3]  [Step 2900/14540]  lr: 0.000099  loss: 1.05824  detection_loss: 1.0013 (cls: 0.2145, box: 0.7868)  rpn_loss: 0.0570 (cls: 0.0254, box: 0.0315)
[2025-08-07 15:53:21 train.log] INFO: Epoch: [3]  [Step 3000/14540]  lr: 0.000099  loss: 2.40107  detection_loss: 2.1427 (cls: 0.5172, box: 1.6255)  rpn_loss: 0.2584 (cls: 0.1895, box: 0.0689)
[2025-08-07 15:53:26 train.log] INFO: Epoch: [3]  [Step 3100/14540]  lr: 0.000099  loss: 1.43723  detection_loss: 1.3165 (cls: 0.2954, box: 1.0210)  rpn_loss: 0.1207 (cls: 0.0924, box: 0.0283)
[2025-08-07 15:53:31 train.log] INFO: Epoch: [3]  [Step 3200/14540]  lr: 0.000099  loss: 1.29851  detection_loss: 1.1383 (cls: 0.2340, box: 0.9042)  rpn_loss: 0.1602 (cls: 0.0542, box: 0.1060)
[2025-08-07 15:53:36 train.log] INFO: Epoch: [3]  [Step 3300/14540]  lr: 0.000099  loss: 1.82098  detection_loss: 1.7009 (cls: 0.4335, box: 1.2674)  rpn_loss: 0.1201 (cls: 0.0468, box: 0.0733)
[2025-08-07 15:53:40 train.log] INFO: Epoch: [3]  [Step 3400/14540]  lr: 0.000099  loss: 2.25641  detection_loss: 2.0833 (cls: 0.4748, box: 1.6085)  rpn_loss: 0.1731 (cls: 0.0650, box: 0.1081)
[2025-08-07 15:53:45 train.log] INFO: Epoch: [3]  [Step 3500/14540]  lr: 0.000099  loss: 1.44047  detection_loss: 1.3648 (cls: 0.5346, box: 0.8302)  rpn_loss: 0.0757 (cls: 0.0441, box: 0.0315)
[2025-08-07 15:53:50 train.log] INFO: Epoch: [3]  [Step 3600/14540]  lr: 0.000099  loss: 1.77646  detection_loss: 1.5819 (cls: 0.4466, box: 1.1353)  rpn_loss: 0.1945 (cls: 0.1345, box: 0.0600)
[2025-08-07 15:53:52 train.log] INFO: Epoch: [3]  [Step 3635/14540]  lr: 0.000099  loss: 1.47369  detection_loss: 1.3817 (cls: 0.1881, box: 1.1936)  rpn_loss: 0.0920 (cls: 0.0541, box: 0.0379)
[2025-08-07 15:53:55 train.log] INFO: Epoch: [3]  [Step 3700/14540]  lr: 0.000099  loss: 1.92744  detection_loss: 1.7491 (cls: 0.4539, box: 1.2952)  rpn_loss: 0.1783 (cls: 0.1255, box: 0.0528)
[2025-08-07 15:54:00 train.log] INFO: Epoch: [3]  [Step 3800/14540]  lr: 0.000099  loss: 1.78776  detection_loss: 1.6088 (cls: 0.4663, box: 1.1425)  rpn_loss: 0.1790 (cls: 0.1036, box: 0.0754)
[2025-08-07 15:54:04 train.log] INFO: Epoch: [3]  [Step 3900/14540]  lr: 0.000099  loss: 2.25132  detection_loss: 2.0838 (cls: 0.7931, box: 1.2907)  rpn_loss: 0.1675 (cls: 0.1259, box: 0.0416)
[2025-08-07 15:54:09 train.log] INFO: Epoch: [3]  [Step 4000/14540]  lr: 0.000099  loss: 1.74794  detection_loss: 1.6199 (cls: 0.3829, box: 1.2370)  rpn_loss: 0.1280 (cls: 0.0780, box: 0.0500)
[2025-08-07 15:54:14 train.log] INFO: Epoch: [3]  [Step 4100/14540]  lr: 0.000099  loss: 1.71296  detection_loss: 1.4706 (cls: 0.2377, box: 1.2329)  rpn_loss: 0.2424 (cls: 0.0445, box: 0.1978)
[2025-08-07 15:54:19 train.log] INFO: Epoch: [3]  [Step 4200/14540]  lr: 0.000099  loss: 1.54362  detection_loss: 1.3888 (cls: 0.3414, box: 1.0474)  rpn_loss: 0.1548 (cls: 0.0714, box: 0.0834)
[2025-08-07 15:54:24 train.log] INFO: Epoch: [3]  [Step 4300/14540]  lr: 0.000099  loss: 1.73433  detection_loss: 1.4507 (cls: 0.2790, box: 1.1717)  rpn_loss: 0.2836 (cls: 0.0693, box: 0.2143)
[2025-08-07 15:54:29 train.log] INFO: Epoch: [3]  [Step 4400/14540]  lr: 0.000099  loss: 2.09630  detection_loss: 1.9344 (cls: 0.5855, box: 1.3489)  rpn_loss: 0.1618 (cls: 0.1320, box: 0.0299)
[2025-08-07 15:54:33 train.log] INFO: Epoch: [3]  [Step 4500/14540]  lr: 0.000099  loss: 1.60287  detection_loss: 1.4206 (cls: 0.5066, box: 0.9140)  rpn_loss: 0.1823 (cls: 0.0639, box: 0.1184)
[2025-08-07 15:54:38 train.log] INFO: Epoch: [3]  [Step 4600/14540]  lr: 0.000099  loss: 1.37142  detection_loss: 1.0430 (cls: 0.2301, box: 0.8129)  rpn_loss: 0.3284 (cls: 0.0682, box: 0.2602)
[2025-08-07 15:54:43 train.log] INFO: Epoch: [3]  [Step 4700/14540]  lr: 0.000099  loss: 1.24964  detection_loss: 1.1515 (cls: 0.2212, box: 0.9302)  rpn_loss: 0.0982 (cls: 0.0517, box: 0.0465)
[2025-08-07 15:54:48 train.log] INFO: Epoch: [3]  [Step 4800/14540]  lr: 0.000099  loss: 1.54138  detection_loss: 1.2838 (cls: 0.1694, box: 1.1145)  rpn_loss: 0.2576 (cls: 0.2128, box: 0.0448)
[2025-08-07 15:54:53 train.log] INFO: Epoch: [3]  [Step 4900/14540]  lr: 0.000099  loss: 1.17921  detection_loss: 0.8965 (cls: 0.2344, box: 0.6621)  rpn_loss: 0.2827 (cls: 0.1184, box: 0.1644)
[2025-08-07 15:54:58 train.log] INFO: Epoch: [3]  [Step 5000/14540]  lr: 0.000099  loss: 1.18126  detection_loss: 1.0507 (cls: 0.1816, box: 0.8691)  rpn_loss: 0.1305 (cls: 0.0608, box: 0.0698)
[2025-08-07 15:55:02 train.log] INFO: Epoch: [3]  [Step 5100/14540]  lr: 0.000099  loss: 1.79225  detection_loss: 1.4629 (cls: 0.3212, box: 1.1416)  rpn_loss: 0.3293 (cls: 0.1840, box: 0.1453)
[2025-08-07 15:55:07 train.log] INFO: Epoch: [3]  [Step 5200/14540]  lr: 0.000099  loss: 1.96906  detection_loss: 1.8245 (cls: 0.4821, box: 1.3425)  rpn_loss: 0.1445 (cls: 0.0932, box: 0.0513)
[2025-08-07 15:55:12 train.log] INFO: Epoch: [3]  [Step 5300/14540]  lr: 0.000099  loss: 2.37251  detection_loss: 2.2896 (cls: 0.5118, box: 1.7777)  rpn_loss: 0.0829 (cls: 0.0512, box: 0.0317)
[2025-08-07 15:55:17 train.log] INFO: Epoch: [3]  [Step 5400/14540]  lr: 0.000099  loss: 1.44772  detection_loss: 1.1645 (cls: 0.2241, box: 0.9405)  rpn_loss: 0.2832 (cls: 0.0505, box: 0.2327)
[2025-08-07 15:55:22 train.log] INFO: Epoch: [3]  [Step 5500/14540]  lr: 0.000099  loss: 1.77204  detection_loss: 1.5934 (cls: 0.4069, box: 1.1864)  rpn_loss: 0.1787 (cls: 0.0584, box: 0.1203)
[2025-08-07 15:55:27 train.log] INFO: Epoch: [3]  [Step 5600/14540]  lr: 0.000099  loss: 2.37142  detection_loss: 2.1808 (cls: 0.4870, box: 1.6939)  rpn_loss: 0.1906 (cls: 0.0609, box: 0.1297)
[2025-08-07 15:55:31 train.log] INFO: Epoch: [3]  [Step 5700/14540]  lr: 0.000099  loss: 1.42178  detection_loss: 1.2860 (cls: 0.2474, box: 1.0386)  rpn_loss: 0.1358 (cls: 0.1132, box: 0.0226)
[2025-08-07 15:55:36 train.log] INFO: Epoch: [3]  [Step 5800/14540]  lr: 0.000099  loss: 1.54378  detection_loss: 1.4602 (cls: 0.2854, box: 1.1748)  rpn_loss: 0.0835 (cls: 0.0489, box: 0.0346)
[2025-08-07 15:55:41 train.log] INFO: Epoch: [3]  [Step 5900/14540]  lr: 0.000099  loss: 2.33931  detection_loss: 2.1675 (cls: 0.6950, box: 1.4725)  rpn_loss: 0.1718 (cls: 0.1166, box: 0.0552)
[2025-08-07 15:55:46 train.log] INFO: Epoch: [3]  [Step 6000/14540]  lr: 0.000099  loss: 1.57112  detection_loss: 1.4476 (cls: 0.1874, box: 1.2602)  rpn_loss: 0.1235 (cls: 0.0567, box: 0.0668)
[2025-08-07 15:55:51 train.log] INFO: Epoch: [3]  [Step 6100/14540]  lr: 0.000099  loss: 1.53999  detection_loss: 1.3386 (cls: 0.2880, box: 1.0505)  rpn_loss: 0.2014 (cls: 0.0755, box: 0.1260)
[2025-08-07 15:55:56 train.log] INFO: Epoch: [3]  [Step 6200/14540]  lr: 0.000099  loss: 1.87735  detection_loss: 1.7590 (cls: 0.2862, box: 1.4728)  rpn_loss: 0.1183 (cls: 0.0533, box: 0.0651)
[2025-08-07 15:56:00 train.log] INFO: Epoch: [3]  [Step 6300/14540]  lr: 0.000099  loss: 1.97964  detection_loss: 1.8040 (cls: 0.4836, box: 1.3204)  rpn_loss: 0.1757 (cls: 0.0920, box: 0.0837)
[2025-08-07 15:56:05 train.log] INFO: Epoch: [3]  [Step 6400/14540]  lr: 0.000099  loss: 1.78503  detection_loss: 1.6486 (cls: 0.4585, box: 1.1901)  rpn_loss: 0.1364 (cls: 0.1086, box: 0.0278)
[2025-08-07 15:56:10 train.log] INFO: Epoch: [3]  [Step 6500/14540]  lr: 0.000099  loss: 1.42143  detection_loss: 1.3546 (cls: 0.2595, box: 1.0950)  rpn_loss: 0.0669 (cls: 0.0389, box: 0.0279)
[2025-08-07 15:56:15 train.log] INFO: Epoch: [3]  [Step 6600/14540]  lr: 0.000099  loss: 1.26710  detection_loss: 1.1837 (cls: 0.2603, box: 0.9235)  rpn_loss: 0.0834 (cls: 0.0522, box: 0.0312)
[2025-08-07 15:56:20 train.log] INFO: Epoch: [3]  [Step 6700/14540]  lr: 0.000099  loss: 2.42099  detection_loss: 2.1328 (cls: 0.3846, box: 1.7482)  rpn_loss: 0.2882 (cls: 0.1175, box: 0.1707)
[2025-08-07 15:56:24 train.log] INFO: Epoch: [3]  [Step 6800/14540]  lr: 0.000099  loss: 1.64748  detection_loss: 1.5265 (cls: 0.3973, box: 1.1292)  rpn_loss: 0.1210 (cls: 0.0464, box: 0.0745)
[2025-08-07 15:56:29 train.log] INFO: Epoch: [3]  [Step 6900/14540]  lr: 0.000099  loss: 1.55685  detection_loss: 1.1686 (cls: 0.3206, box: 0.8479)  rpn_loss: 0.3883 (cls: 0.0770, box: 0.3113)
[2025-08-07 15:56:34 train.log] INFO: Epoch: [3]  [Step 7000/14540]  lr: 0.000099  loss: 1.42699  detection_loss: 1.2850 (cls: 0.2281, box: 1.0569)  rpn_loss: 0.1420 (cls: 0.1077, box: 0.0343)
[2025-08-07 15:56:39 train.log] INFO: Epoch: [3]  [Step 7100/14540]  lr: 0.000099  loss: 1.61820  detection_loss: 1.3772 (cls: 0.4089, box: 0.9683)  rpn_loss: 0.2410 (cls: 0.0715, box: 0.1695)
[2025-08-07 15:56:44 train.log] INFO: Epoch: [3]  [Step 7200/14540]  lr: 0.000099  loss: 1.77889  detection_loss: 1.6211 (cls: 0.3005, box: 1.3206)  rpn_loss: 0.1578 (cls: 0.0865, box: 0.0713)
[2025-08-07 15:56:49 train.log] INFO: Epoch: [3]  [Step 7300/14540]  lr: 0.000099  loss: 1.59792  detection_loss: 1.2084 (cls: 0.3331, box: 0.8752)  rpn_loss: 0.3895 (cls: 0.0861, box: 0.3034)
[2025-08-07 15:56:54 train.log] INFO: Epoch: [3]  [Step 7400/14540]  lr: 0.000099  loss: 1.82317  detection_loss: 1.7030 (cls: 0.3271, box: 1.3759)  rpn_loss: 0.1201 (cls: 0.0854, box: 0.0347)
[2025-08-07 15:56:59 train.log] INFO: Epoch: [3]  [Step 7500/14540]  lr: 0.000099  loss: 1.56007  detection_loss: 1.4330 (cls: 0.3328, box: 1.1002)  rpn_loss: 0.1271 (cls: 0.0562, box: 0.0709)
[2025-08-07 15:57:04 train.log] INFO: Epoch: [3]  [Step 7600/14540]  lr: 0.000099  loss: 1.67871  detection_loss: 1.5504 (cls: 0.3423, box: 1.2081)  rpn_loss: 0.1283 (cls: 0.0673, box: 0.0609)
[2025-08-07 15:57:09 train.log] INFO: Epoch: [3]  [Step 7700/14540]  lr: 0.000099  loss: 1.33838  detection_loss: 1.2756 (cls: 0.3757, box: 0.8999)  rpn_loss: 0.0628 (cls: 0.0227, box: 0.0400)
[2025-08-07 15:57:14 train.log] INFO: Epoch: [3]  [Step 7800/14540]  lr: 0.000099  loss: 1.92548  detection_loss: 1.7779 (cls: 0.3954, box: 1.3826)  rpn_loss: 0.1475 (cls: 0.0482, box: 0.0994)
[2025-08-07 15:57:19 train.log] INFO: Epoch: [3]  [Step 7900/14540]  lr: 0.000099  loss: 1.93501  detection_loss: 1.7280 (cls: 0.4198, box: 1.3082)  rpn_loss: 0.2070 (cls: 0.0995, box: 0.1075)
[2025-08-07 15:57:24 train.log] INFO: Epoch: [3]  [Step 8000/14540]  lr: 0.000099  loss: 1.48508  detection_loss: 1.3646 (cls: 0.2841, box: 1.0806)  rpn_loss: 0.1205 (cls: 0.0530, box: 0.0674)
[2025-08-07 15:57:29 train.log] INFO: Epoch: [3]  [Step 8100/14540]  lr: 0.000099  loss: 1.21771  detection_loss: 1.0741 (cls: 0.1928, box: 0.8813)  rpn_loss: 0.1437 (cls: 0.1171, box: 0.0265)
[2025-08-07 15:57:34 train.log] INFO: Epoch: [3]  [Step 8200/14540]  lr: 0.000099  loss: 2.01039  detection_loss: 1.7732 (cls: 0.3993, box: 1.3739)  rpn_loss: 0.2372 (cls: 0.0602, box: 0.1770)
[2025-08-07 15:57:38 train.log] INFO: Epoch: [3]  [Step 8300/14540]  lr: 0.000099  loss: 1.86310  detection_loss: 1.6967 (cls: 0.4789, box: 1.2178)  rpn_loss: 0.1664 (cls: 0.0875, box: 0.0789)
[2025-08-07 15:57:43 train.log] INFO: Epoch: [3]  [Step 8400/14540]  lr: 0.000099  loss: 1.66811  detection_loss: 1.4290 (cls: 0.3820, box: 1.0470)  rpn_loss: 0.2391 (cls: 0.0593, box: 0.1798)
[2025-08-07 15:57:48 train.log] INFO: Epoch: [3]  [Step 8500/14540]  lr: 0.000099  loss: 1.29607  detection_loss: 1.0179 (cls: 0.2837, box: 0.7342)  rpn_loss: 0.2782 (cls: 0.0952, box: 0.1831)
[2025-08-07 15:57:53 train.log] INFO: Epoch: [3]  [Step 8600/14540]  lr: 0.000099  loss: 1.30471  detection_loss: 1.1617 (cls: 0.3195, box: 0.8422)  rpn_loss: 0.1430 (cls: 0.1224, box: 0.0206)
[2025-08-07 15:57:58 train.log] INFO: Epoch: [3]  [Step 8700/14540]  lr: 0.000099  loss: 1.53583  detection_loss: 1.4217 (cls: 0.2481, box: 1.1735)  rpn_loss: 0.1141 (cls: 0.0332, box: 0.0809)
[2025-08-07 15:58:03 train.log] INFO: Epoch: [3]  [Step 8800/14540]  lr: 0.000099  loss: 1.25397  detection_loss: 1.1515 (cls: 0.2573, box: 0.8942)  rpn_loss: 0.1025 (cls: 0.0673, box: 0.0351)
[2025-08-07 15:58:07 train.log] INFO: Epoch: [3]  [Step 8900/14540]  lr: 0.000099  loss: 1.74728  detection_loss: 1.5963 (cls: 0.4284, box: 1.1678)  rpn_loss: 0.1510 (cls: 0.0914, box: 0.0596)
[2025-08-07 15:58:12 train.log] INFO: Epoch: [3]  [Step 9000/14540]  lr: 0.000099  loss: 1.33670  detection_loss: 1.2615 (cls: 0.2091, box: 1.0523)  rpn_loss: 0.0753 (cls: 0.0159, box: 0.0594)
[2025-08-07 15:58:17 train.log] INFO: Epoch: [3]  [Step 9100/14540]  lr: 0.000099  loss: 1.46599  detection_loss: 1.2450 (cls: 0.2611, box: 0.9838)  rpn_loss: 0.2210 (cls: 0.0476, box: 0.1734)
[2025-08-07 15:58:22 train.log] INFO: Epoch: [3]  [Step 9200/14540]  lr: 0.000099  loss: 1.36219  detection_loss: 1.2784 (cls: 0.3449, box: 0.9335)  rpn_loss: 0.0838 (cls: 0.0610, box: 0.0228)
[2025-08-07 15:58:27 train.log] INFO: Epoch: [3]  [Step 9300/14540]  lr: 0.000099  loss: 1.45154  detection_loss: 1.3541 (cls: 0.4323, box: 0.9218)  rpn_loss: 0.0974 (cls: 0.0624, box: 0.0350)
[2025-08-07 15:58:32 train.log] INFO: Epoch: [3]  [Step 9400/14540]  lr: 0.000099  loss: 2.14215  detection_loss: 1.9828 (cls: 0.5063, box: 1.4765)  rpn_loss: 0.1594 (cls: 0.1125, box: 0.0469)
[2025-08-07 15:58:37 train.log] INFO: Epoch: [3]  [Step 9500/14540]  lr: 0.000099  loss: 1.53731  detection_loss: 1.4221 (cls: 0.1822, box: 1.2399)  rpn_loss: 0.1152 (cls: 0.0729, box: 0.0423)
[2025-08-07 15:58:41 train.log] INFO: Epoch: [3]  [Step 9600/14540]  lr: 0.000099  loss: 1.90079  detection_loss: 1.7161 (cls: 0.4721, box: 1.2441)  rpn_loss: 0.1846 (cls: 0.0788, box: 0.1059)
[2025-08-07 15:58:46 train.log] INFO: Epoch: [3]  [Step 9700/14540]  lr: 0.000099  loss: 2.42076  detection_loss: 2.2425 (cls: 0.5024, box: 1.7401)  rpn_loss: 0.1783 (cls: 0.0795, box: 0.0988)
[2025-08-07 15:58:51 train.log] INFO: Epoch: [3]  [Step 9800/14540]  lr: 0.000099  loss: 1.45578  detection_loss: 1.2935 (cls: 0.2661, box: 1.0274)  rpn_loss: 0.1623 (cls: 0.0570, box: 0.1053)
[2025-08-07 15:58:56 train.log] INFO: Epoch: [3]  [Step 9900/14540]  lr: 0.000099  loss: 1.05294  detection_loss: 0.9792 (cls: 0.1868, box: 0.7923)  rpn_loss: 0.0738 (cls: 0.0420, box: 0.0318)
[2025-08-07 15:59:01 train.log] INFO: Epoch: [3]  [Step 10000/14540]  lr: 0.000099  loss: 1.38094  detection_loss: 1.2593 (cls: 0.3020, box: 0.9573)  rpn_loss: 0.1216 (cls: 0.0808, box: 0.0408)
[2025-08-07 15:59:05 train.log] INFO: Epoch: [3]  [Step 10100/14540]  lr: 0.000099  loss: 2.03360  detection_loss: 1.6928 (cls: 0.2360, box: 1.4568)  rpn_loss: 0.3408 (cls: 0.0574, box: 0.2835)
[2025-08-07 15:59:10 train.log] INFO: Epoch: [3]  [Step 10200/14540]  lr: 0.000099  loss: 1.05411  detection_loss: 0.9641 (cls: 0.2139, box: 0.7502)  rpn_loss: 0.0900 (cls: 0.0639, box: 0.0261)
[2025-08-07 15:59:15 train.log] INFO: Epoch: [3]  [Step 10300/14540]  lr: 0.000099  loss: 2.23407  detection_loss: 2.0868 (cls: 0.3812, box: 1.7056)  rpn_loss: 0.1472 (cls: 0.1227, box: 0.0245)
[2025-08-07 15:59:20 train.log] INFO: Epoch: [3]  [Step 10400/14540]  lr: 0.000099  loss: 1.73876  detection_loss: 1.6009 (cls: 0.1845, box: 1.4164)  rpn_loss: 0.1378 (cls: 0.0462, box: 0.0916)
[2025-08-07 15:59:25 train.log] INFO: Epoch: [3]  [Step 10500/14540]  lr: 0.000099  loss: 1.78921  detection_loss: 1.5249 (cls: 0.3779, box: 1.1470)  rpn_loss: 0.2643 (cls: 0.1103, box: 0.1540)
[2025-08-07 15:59:30 train.log] INFO: Epoch: [3]  [Step 10600/14540]  lr: 0.000099  loss: 1.47711  detection_loss: 1.3435 (cls: 0.4828, box: 0.8607)  rpn_loss: 0.1336 (cls: 0.0679, box: 0.0657)
[2025-08-07 15:59:34 train.log] INFO: Epoch: [3]  [Step 10700/14540]  lr: 0.000099  loss: 2.38248  detection_loss: 1.7004 (cls: 0.5908, box: 1.1096)  rpn_loss: 0.6821 (cls: 0.0948, box: 0.5873)
[2025-08-07 15:59:39 train.log] INFO: Epoch: [3]  [Step 10800/14540]  lr: 0.000099  loss: 1.68067  detection_loss: 1.5762 (cls: 0.3470, box: 1.2293)  rpn_loss: 0.1044 (cls: 0.0492, box: 0.0552)
[2025-08-07 15:59:44 train.log] INFO: Epoch: [3]  [Step 10900/14540]  lr: 0.000099  loss: 1.25331  detection_loss: 1.1641 (cls: 0.2699, box: 0.8943)  rpn_loss: 0.0892 (cls: 0.0409, box: 0.0483)
[2025-08-07 15:59:49 train.log] INFO: Epoch: [3]  [Step 11000/14540]  lr: 0.000099  loss: 1.44125  detection_loss: 1.3483 (cls: 0.3104, box: 1.0379)  rpn_loss: 0.0929 (cls: 0.0490, box: 0.0440)
[2025-08-07 15:59:54 train.log] INFO: Epoch: [3]  [Step 11100/14540]  lr: 0.000099  loss: 1.46453  detection_loss: 1.2887 (cls: 0.1787, box: 1.1100)  rpn_loss: 0.1758 (cls: 0.0458, box: 0.1300)
[2025-08-07 15:59:59 train.log] INFO: Epoch: [3]  [Step 11200/14540]  lr: 0.000099  loss: 1.27230  detection_loss: 1.2066 (cls: 0.2296, box: 0.9771)  rpn_loss: 0.0657 (cls: 0.0295, box: 0.0362)
[2025-08-07 16:00:03 train.log] INFO: Epoch: [3]  [Step 11300/14540]  lr: 0.000099  loss: 2.03883  detection_loss: 1.7859 (cls: 0.5643, box: 1.2215)  rpn_loss: 0.2530 (cls: 0.0894, box: 0.1635)
[2025-08-07 16:00:08 train.log] INFO: Epoch: [3]  [Step 11400/14540]  lr: 0.000099  loss: 1.18610  detection_loss: 1.0581 (cls: 0.2428, box: 0.8153)  rpn_loss: 0.1280 (cls: 0.0814, box: 0.0465)
[2025-08-07 16:00:13 train.log] INFO: Epoch: [3]  [Step 11500/14540]  lr: 0.000099  loss: 1.83264  detection_loss: 1.7232 (cls: 0.4374, box: 1.2858)  rpn_loss: 0.1094 (cls: 0.0597, box: 0.0497)
[2025-08-07 16:00:18 train.log] INFO: Epoch: [3]  [Step 11600/14540]  lr: 0.000099  loss: 1.20081  detection_loss: 1.0318 (cls: 0.2216, box: 0.8102)  rpn_loss: 0.1690 (cls: 0.1161, box: 0.0528)
[2025-08-07 16:00:23 train.log] INFO: Epoch: [3]  [Step 11700/14540]  lr: 0.000099  loss: 1.57084  detection_loss: 1.2802 (cls: 0.2650, box: 1.0152)  rpn_loss: 0.2907 (cls: 0.1104, box: 0.1803)
[2025-08-07 16:00:28 train.log] INFO: Epoch: [3]  [Step 11800/14540]  lr: 0.000099  loss: 2.20898  detection_loss: 2.0395 (cls: 0.5189, box: 1.5205)  rpn_loss: 0.1695 (cls: 0.1464, box: 0.0232)
[2025-08-07 16:00:32 train.log] INFO: Epoch: [3]  [Step 11900/14540]  lr: 0.000099  loss: 1.27243  detection_loss: 1.1726 (cls: 0.2302, box: 0.9424)  rpn_loss: 0.0999 (cls: 0.0759, box: 0.0240)
[2025-08-07 16:00:37 train.log] INFO: Epoch: [3]  [Step 12000/14540]  lr: 0.000099  loss: 1.65498  detection_loss: 1.5005 (cls: 0.3893, box: 1.1112)  rpn_loss: 0.1545 (cls: 0.1078, box: 0.0468)
[2025-08-07 16:00:42 train.log] INFO: Epoch: [3]  [Step 12100/14540]  lr: 0.000099  loss: 2.02580  detection_loss: 1.8767 (cls: 0.4032, box: 1.4735)  rpn_loss: 0.1491 (cls: 0.0876, box: 0.0616)
[2025-08-07 16:00:47 train.log] INFO: Epoch: [3]  [Step 12200/14540]  lr: 0.000099  loss: 1.95522  detection_loss: 1.5737 (cls: 0.5061, box: 1.0676)  rpn_loss: 0.3815 (cls: 0.2008, box: 0.1807)
[2025-08-07 16:00:52 train.log] INFO: Epoch: [3]  [Step 12300/14540]  lr: 0.000099  loss: 1.39033  detection_loss: 1.1467 (cls: 0.3191, box: 0.8276)  rpn_loss: 0.2436 (cls: 0.1209, box: 0.1227)
[2025-08-07 16:00:57 train.log] INFO: Epoch: [3]  [Step 12400/14540]  lr: 0.000099  loss: 1.80272  detection_loss: 1.6338 (cls: 0.4053, box: 1.2285)  rpn_loss: 0.1689 (cls: 0.0979, box: 0.0710)
[2025-08-07 16:01:01 train.log] INFO: Epoch: [3]  [Step 12500/14540]  lr: 0.000099  loss: 1.96600  detection_loss: 1.7616 (cls: 0.3470, box: 1.4146)  rpn_loss: 0.2044 (cls: 0.1658, box: 0.0386)
[2025-08-07 16:01:06 train.log] INFO: Epoch: [3]  [Step 12600/14540]  lr: 0.000099  loss: 1.36138  detection_loss: 1.2643 (cls: 0.2779, box: 0.9864)  rpn_loss: 0.0971 (cls: 0.0577, box: 0.0394)
[2025-08-07 16:01:11 train.log] INFO: Epoch: [3]  [Step 12700/14540]  lr: 0.000099  loss: 1.34608  detection_loss: 1.2489 (cls: 0.2251, box: 1.0238)  rpn_loss: 0.0972 (cls: 0.0322, box: 0.0650)
[2025-08-07 16:01:16 train.log] INFO: Epoch: [3]  [Step 12800/14540]  lr: 0.000099  loss: 1.37039  detection_loss: 1.2322 (cls: 0.3124, box: 0.9198)  rpn_loss: 0.1382 (cls: 0.0707, box: 0.0675)
[2025-08-07 16:01:21 train.log] INFO: Epoch: [3]  [Step 12900/14540]  lr: 0.000099  loss: 1.22209  detection_loss: 1.0791 (cls: 0.2291, box: 0.8500)  rpn_loss: 0.1430 (cls: 0.0537, box: 0.0892)
[2025-08-07 16:01:26 train.log] INFO: Epoch: [3]  [Step 13000/14540]  lr: 0.000099  loss: 1.79745  detection_loss: 1.6362 (cls: 0.2623, box: 1.3739)  rpn_loss: 0.1613 (cls: 0.0563, box: 0.1050)
[2025-08-07 16:01:30 train.log] INFO: Epoch: [3]  [Step 13100/14540]  lr: 0.000099  loss: 1.46935  detection_loss: 1.3371 (cls: 0.2405, box: 1.0966)  rpn_loss: 0.1323 (cls: 0.0689, box: 0.0634)
[2025-08-07 16:01:35 train.log] INFO: Epoch: [3]  [Step 13200/14540]  lr: 0.000099  loss: 1.97252  detection_loss: 1.8673 (cls: 0.4781, box: 1.3893)  rpn_loss: 0.1052 (cls: 0.0819, box: 0.0232)
[2025-08-07 16:01:40 train.log] INFO: Epoch: [3]  [Step 13300/14540]  lr: 0.000099  loss: 1.66163  detection_loss: 1.5221 (cls: 0.3638, box: 1.1582)  rpn_loss: 0.1396 (cls: 0.0426, box: 0.0970)
[2025-08-07 16:01:45 train.log] INFO: Epoch: [3]  [Step 13400/14540]  lr: 0.000099  loss: 1.61266  detection_loss: 1.2958 (cls: 0.2814, box: 1.0145)  rpn_loss: 0.3168 (cls: 0.0627, box: 0.2541)
[2025-08-07 16:01:50 train.log] INFO: Epoch: [3]  [Step 13500/14540]  lr: 0.000099  loss: 0.84142  detection_loss: 0.7620 (cls: 0.1392, box: 0.6228)  rpn_loss: 0.0794 (cls: 0.0279, box: 0.0515)
[2025-08-07 16:01:55 train.log] INFO: Epoch: [3]  [Step 13600/14540]  lr: 0.000099  loss: 1.65287  detection_loss: 1.5521 (cls: 0.5836, box: 0.9685)  rpn_loss: 0.1008 (cls: 0.0607, box: 0.0401)
[2025-08-07 16:02:00 train.log] INFO: Epoch: [3]  [Step 13700/14540]  lr: 0.000099  loss: 1.54838  detection_loss: 1.3104 (cls: 0.4106, box: 0.8998)  rpn_loss: 0.2380 (cls: 0.2110, box: 0.0269)
[2025-08-07 16:02:05 train.log] INFO: Epoch: [3]  [Step 13800/14540]  lr: 0.000099  loss: 2.27054  detection_loss: 2.0495 (cls: 0.4977, box: 1.5518)  rpn_loss: 0.2210 (cls: 0.1382, box: 0.0828)
[2025-08-07 16:02:10 train.log] INFO: Epoch: [3]  [Step 13900/14540]  lr: 0.000099  loss: 1.59235  detection_loss: 1.3963 (cls: 0.3860, box: 1.0103)  rpn_loss: 0.1961 (cls: 0.0765, box: 0.1196)
[2025-08-07 16:02:15 train.log] INFO: Epoch: [3]  [Step 14000/14540]  lr: 0.000099  loss: 1.40497  detection_loss: 1.2982 (cls: 0.3160, box: 0.9822)  rpn_loss: 0.1068 (cls: 0.0699, box: 0.0368)
[2025-08-07 16:02:19 train.log] INFO: Epoch: [3]  [Step 14100/14540]  lr: 0.000099  loss: 1.30876  detection_loss: 1.1835 (cls: 0.3584, box: 0.8251)  rpn_loss: 0.1252 (cls: 0.0685, box: 0.0567)
[2025-08-07 16:02:24 train.log] INFO: Epoch: [3]  [Step 14200/14540]  lr: 0.000099  loss: 1.17173  detection_loss: 1.0654 (cls: 0.2883, box: 0.7771)  rpn_loss: 0.1064 (cls: 0.0646, box: 0.0417)
[2025-08-07 16:02:29 train.log] INFO: Epoch: [3]  [Step 14300/14540]  lr: 0.000099  loss: 1.84761  detection_loss: 1.5998 (cls: 0.3166, box: 1.2832)  rpn_loss: 0.2478 (cls: 0.0210, box: 0.2268)
[2025-08-07 16:02:34 train.log] INFO: Epoch: [3]  [Step 14400/14540]  lr: 0.000099  loss: 1.53499  detection_loss: 1.2827 (cls: 0.3474, box: 0.9352)  rpn_loss: 0.2523 (cls: 0.0609, box: 0.1914)
[2025-08-07 16:02:39 train.log] INFO: Epoch: [3]  [Step 14500/14540]  lr: 0.000099  loss: 2.21805  detection_loss: 1.9900 (cls: 0.6739, box: 1.3161)  rpn_loss: 0.2281 (cls: 0.1818, box: 0.0463)
[2025-08-07 16:05:37 train.log] INFO: Epoch: [4]  [Step 100/14540]  lr: 0.000098  loss: 1.44212  detection_loss: 1.2345 (cls: 0.2655, box: 0.9690)  rpn_loss: 0.2076 (cls: 0.0428, box: 0.1648)
[2025-08-07 16:05:42 train.log] INFO: Epoch: [4]  [Step 200/14540]  lr: 0.000098  loss: 1.19989  detection_loss: 1.0477 (cls: 0.2957, box: 0.7521)  rpn_loss: 0.1522 (cls: 0.0405, box: 0.1116)
[2025-08-07 16:05:47 train.log] INFO: Epoch: [4]  [Step 300/14540]  lr: 0.000098  loss: 1.79523  detection_loss: 1.6344 (cls: 0.2795, box: 1.3550)  rpn_loss: 0.1608 (cls: 0.0928, box: 0.0680)
[2025-08-07 16:05:52 train.log] INFO: Epoch: [4]  [Step 400/14540]  lr: 0.000098  loss: 1.68938  detection_loss: 1.5672 (cls: 0.3994, box: 1.1678)  rpn_loss: 0.1222 (cls: 0.0802, box: 0.0419)
[2025-08-07 16:05:57 train.log] INFO: Epoch: [4]  [Step 500/14540]  lr: 0.000098  loss: 2.82812  detection_loss: 2.5680 (cls: 0.8118, box: 1.7562)  rpn_loss: 0.2601 (cls: 0.0368, box: 0.2234)
[2025-08-07 16:06:03 train.log] INFO: Epoch: [4]  [Step 600/14540]  lr: 0.000098  loss: 1.80312  detection_loss: 1.6790 (cls: 0.3319, box: 1.3471)  rpn_loss: 0.1241 (cls: 0.1018, box: 0.0223)
[2025-08-07 16:06:08 train.log] INFO: Epoch: [4]  [Step 700/14540]  lr: 0.000098  loss: 1.22877  detection_loss: 0.9596 (cls: 0.2919, box: 0.6678)  rpn_loss: 0.2691 (cls: 0.0691, box: 0.2000)
[2025-08-07 16:06:13 train.log] INFO: Epoch: [4]  [Step 800/14540]  lr: 0.000098  loss: 1.97780  detection_loss: 1.5441 (cls: 0.5216, box: 1.0225)  rpn_loss: 0.4337 (cls: 0.0903, box: 0.3434)
[2025-08-07 16:06:18 train.log] INFO: Epoch: [4]  [Step 900/14540]  lr: 0.000098  loss: 1.06323  detection_loss: 0.8975 (cls: 0.1625, box: 0.7350)  rpn_loss: 0.1657 (cls: 0.0363, box: 0.1294)
[2025-08-07 16:06:23 train.log] INFO: Epoch: [4]  [Step 1000/14540]  lr: 0.000098  loss: 1.74977  detection_loss: 1.5593 (cls: 0.4508, box: 1.1085)  rpn_loss: 0.1905 (cls: 0.0971, box: 0.0934)
[2025-08-07 16:06:28 train.log] INFO: Epoch: [4]  [Step 1100/14540]  lr: 0.000098  loss: 0.96822  detection_loss: 0.8731 (cls: 0.1879, box: 0.6852)  rpn_loss: 0.0952 (cls: 0.0656, box: 0.0295)
[2025-08-07 16:06:33 train.log] INFO: Epoch: [4]  [Step 1200/14540]  lr: 0.000098  loss: 1.55349  detection_loss: 1.2991 (cls: 0.2619, box: 1.0372)  rpn_loss: 0.2544 (cls: 0.0429, box: 0.2114)
[2025-08-07 16:06:39 train.log] INFO: Epoch: [4]  [Step 1300/14540]  lr: 0.000098  loss: 1.46838  detection_loss: 1.3013 (cls: 0.2804, box: 1.0209)  rpn_loss: 0.1671 (cls: 0.0839, box: 0.0832)
[2025-08-07 16:06:44 train.log] INFO: Epoch: [4]  [Step 1400/14540]  lr: 0.000098  loss: 1.52028  detection_loss: 1.3978 (cls: 0.3134, box: 1.0844)  rpn_loss: 0.1225 (cls: 0.0799, box: 0.0426)
[2025-08-07 16:06:49 train.log] INFO: Epoch: [4]  [Step 1500/14540]  lr: 0.000098  loss: 2.12732  detection_loss: 1.8765 (cls: 0.3697, box: 1.5068)  rpn_loss: 0.2508 (cls: 0.1806, box: 0.0702)
[2025-08-07 16:06:54 train.log] INFO: Epoch: [4]  [Step 1600/14540]  lr: 0.000098  loss: 1.62704  detection_loss: 1.5027 (cls: 0.3002, box: 1.2026)  rpn_loss: 0.1243 (cls: 0.0836, box: 0.0407)
[2025-08-07 16:07:00 train.log] INFO: Epoch: [4]  [Step 1700/14540]  lr: 0.000098  loss: 1.37655  detection_loss: 1.1996 (cls: 0.4013, box: 0.7983)  rpn_loss: 0.1769 (cls: 0.0258, box: 0.1512)
[2025-08-07 16:07:05 train.log] INFO: Epoch: [4]  [Step 1800/14540]  lr: 0.000098  loss: 1.86752  detection_loss: 1.7566 (cls: 0.4023, box: 1.3543)  rpn_loss: 0.1109 (cls: 0.0519, box: 0.0590)
[2025-08-07 16:07:10 train.log] INFO: Epoch: [4]  [Step 1900/14540]  lr: 0.000098  loss: 1.97255  detection_loss: 1.8577 (cls: 0.4323, box: 1.4254)  rpn_loss: 0.1148 (cls: 0.0853, box: 0.0295)
[2025-08-07 16:07:15 train.log] INFO: Epoch: [4]  [Step 2000/14540]  lr: 0.000098  loss: 1.50884  detection_loss: 1.3656 (cls: 0.3164, box: 1.0492)  rpn_loss: 0.1432 (cls: 0.1068, box: 0.0364)
[2025-08-07 16:07:20 train.log] INFO: Epoch: [4]  [Step 2100/14540]  lr: 0.000098  loss: 1.95221  detection_loss: 1.8098 (cls: 0.3311, box: 1.4787)  rpn_loss: 0.1424 (cls: 0.0409, box: 0.1015)
[2025-08-07 16:07:25 train.log] INFO: Epoch: [4]  [Step 2200/14540]  lr: 0.000098  loss: 1.94322  detection_loss: 1.7907 (cls: 0.4255, box: 1.3652)  rpn_loss: 0.1525 (cls: 0.1229, box: 0.0296)
[2025-08-07 16:07:30 train.log] INFO: Epoch: [4]  [Step 2300/14540]  lr: 0.000098  loss: 1.79225  detection_loss: 1.6044 (cls: 0.4300, box: 1.1745)  rpn_loss: 0.1878 (cls: 0.1455, box: 0.0423)
[2025-08-07 16:07:35 train.log] INFO: Epoch: [4]  [Step 2400/14540]  lr: 0.000098  loss: 2.01561  detection_loss: 1.8373 (cls: 0.5679, box: 1.2694)  rpn_loss: 0.1783 (cls: 0.0694, box: 0.1089)
[2025-08-07 16:07:40 train.log] INFO: Epoch: [4]  [Step 2500/14540]  lr: 0.000098  loss: 1.85819  detection_loss: 1.7493 (cls: 0.5288, box: 1.2204)  rpn_loss: 0.1089 (cls: 0.0543, box: 0.0546)
[2025-08-07 16:07:45 train.log] INFO: Epoch: [4]  [Step 2600/14540]  lr: 0.000098  loss: 1.49944  detection_loss: 1.3841 (cls: 0.3241, box: 1.0600)  rpn_loss: 0.1153 (cls: 0.0555, box: 0.0598)
[2025-08-07 16:07:50 train.log] INFO: Epoch: [4]  [Step 2700/14540]  lr: 0.000098  loss: 1.38318  detection_loss: 1.2619 (cls: 0.4385, box: 0.8234)  rpn_loss: 0.1212 (cls: 0.0961, box: 0.0252)
[2025-08-07 16:07:55 train.log] INFO: Epoch: [4]  [Step 2800/14540]  lr: 0.000098  loss: 1.51780  detection_loss: 1.3541 (cls: 0.4224, box: 0.9316)  rpn_loss: 0.1637 (cls: 0.1380, box: 0.0258)
[2025-08-07 16:08:00 train.log] INFO: Epoch: [4]  [Step 2900/14540]  lr: 0.000098  loss: 1.59188  detection_loss: 1.4758 (cls: 0.2350, box: 1.2408)  rpn_loss: 0.1161 (cls: 0.0765, box: 0.0396)
[2025-08-07 16:08:05 train.log] INFO: Epoch: [4]  [Step 3000/14540]  lr: 0.000098  loss: 1.32129  detection_loss: 1.1919 (cls: 0.3330, box: 0.8589)  rpn_loss: 0.1294 (cls: 0.0578, box: 0.0715)
[2025-08-07 16:08:10 train.log] INFO: Epoch: [4]  [Step 3100/14540]  lr: 0.000098  loss: 1.24451  detection_loss: 1.1387 (cls: 0.2762, box: 0.8625)  rpn_loss: 0.1058 (cls: 0.0543, box: 0.0515)
[2025-08-07 16:08:15 train.log] INFO: Epoch: [4]  [Step 3200/14540]  lr: 0.000098  loss: 1.68148  detection_loss: 1.5305 (cls: 0.3542, box: 1.1763)  rpn_loss: 0.1510 (cls: 0.1175, box: 0.0334)
[2025-08-07 16:08:20 train.log] INFO: Epoch: [4]  [Step 3300/14540]  lr: 0.000098  loss: 1.61278  detection_loss: 1.5190 (cls: 0.2416, box: 1.2773)  rpn_loss: 0.0938 (cls: 0.0437, box: 0.0501)
[2025-08-07 16:08:25 train.log] INFO: Epoch: [4]  [Step 3400/14540]  lr: 0.000098  loss: 2.22480  detection_loss: 1.9341 (cls: 0.4804, box: 1.4537)  rpn_loss: 0.2907 (cls: 0.1018, box: 0.1888)
[2025-08-07 16:08:30 train.log] INFO: Epoch: [4]  [Step 3500/14540]  lr: 0.000098  loss: 1.73523  detection_loss: 1.4777 (cls: 0.3419, box: 1.1358)  rpn_loss: 0.2575 (cls: 0.1406, box: 0.1170)
[2025-08-07 16:08:35 train.log] INFO: Epoch: [4]  [Step 3600/14540]  lr: 0.000098  loss: 1.08810  detection_loss: 0.9477 (cls: 0.2802, box: 0.6675)  rpn_loss: 0.1404 (cls: 0.1010, box: 0.0394)
[2025-08-07 16:08:37 train.log] INFO: Epoch: [4]  [Step 3635/14540]  lr: 0.000098  loss: 1.89616  detection_loss: 1.7375 (cls: 0.3057, box: 1.4318)  rpn_loss: 0.1587 (cls: 0.1231, box: 0.0355)
[2025-08-07 16:08:40 train.log] INFO: Epoch: [4]  [Step 3700/14540]  lr: 0.000098  loss: 1.59754  detection_loss: 1.3321 (cls: 0.2105, box: 1.1216)  rpn_loss: 0.2655 (cls: 0.0911, box: 0.1743)
[2025-08-07 16:08:45 train.log] INFO: Epoch: [4]  [Step 3800/14540]  lr: 0.000098  loss: 1.88850  detection_loss: 1.7536 (cls: 0.3898, box: 1.3638)  rpn_loss: 0.1349 (cls: 0.0595, box: 0.0754)
[2025-08-07 16:08:50 train.log] INFO: Epoch: [4]  [Step 3900/14540]  lr: 0.000098  loss: 1.95770  detection_loss: 1.7077 (cls: 0.3541, box: 1.3536)  rpn_loss: 0.2500 (cls: 0.0553, box: 0.1947)
[2025-08-07 16:08:55 train.log] INFO: Epoch: [4]  [Step 4000/14540]  lr: 0.000098  loss: 1.37776  detection_loss: 1.2956 (cls: 0.2186, box: 1.0770)  rpn_loss: 0.0822 (cls: 0.0491, box: 0.0331)
[2025-08-07 16:09:00 train.log] INFO: Epoch: [4]  [Step 4100/14540]  lr: 0.000098  loss: 1.52844  detection_loss: 1.3146 (cls: 0.3766, box: 0.9380)  rpn_loss: 0.2139 (cls: 0.0487, box: 0.1652)
[2025-08-07 16:09:05 train.log] INFO: Epoch: [4]  [Step 4200/14540]  lr: 0.000098  loss: 1.67104  detection_loss: 1.5462 (cls: 0.2023, box: 1.3439)  rpn_loss: 0.1248 (cls: 0.0779, box: 0.0469)
[2025-08-07 16:09:10 train.log] INFO: Epoch: [4]  [Step 4300/14540]  lr: 0.000098  loss: 1.32866  detection_loss: 1.2067 (cls: 0.4223, box: 0.7844)  rpn_loss: 0.1219 (cls: 0.0463, box: 0.0757)
[2025-08-07 16:09:15 train.log] INFO: Epoch: [4]  [Step 4400/14540]  lr: 0.000098  loss: 1.14627  detection_loss: 1.0286 (cls: 0.2579, box: 0.7707)  rpn_loss: 0.1176 (cls: 0.0793, box: 0.0384)
[2025-08-07 16:09:20 train.log] INFO: Epoch: [4]  [Step 4500/14540]  lr: 0.000098  loss: 1.60325  detection_loss: 1.4171 (cls: 0.3717, box: 1.0453)  rpn_loss: 0.1862 (cls: 0.0962, box: 0.0900)
[2025-08-07 16:09:25 train.log] INFO: Epoch: [4]  [Step 4600/14540]  lr: 0.000098  loss: 1.66415  detection_loss: 1.5236 (cls: 0.2848, box: 1.2388)  rpn_loss: 0.1406 (cls: 0.1127, box: 0.0279)
[2025-08-07 16:09:30 train.log] INFO: Epoch: [4]  [Step 4700/14540]  lr: 0.000098  loss: 1.66588  detection_loss: 1.4794 (cls: 0.3774, box: 1.1019)  rpn_loss: 0.1865 (cls: 0.0973, box: 0.0892)
[2025-08-07 16:09:35 train.log] INFO: Epoch: [4]  [Step 4800/14540]  lr: 0.000098  loss: 1.61912  detection_loss: 1.5646 (cls: 0.4258, box: 1.1388)  rpn_loss: 0.0545 (cls: 0.0339, box: 0.0206)
[2025-08-07 16:09:40 train.log] INFO: Epoch: [4]  [Step 4900/14540]  lr: 0.000098  loss: 1.73523  detection_loss: 1.5959 (cls: 0.3373, box: 1.2585)  rpn_loss: 0.1393 (cls: 0.0373, box: 0.1020)
[2025-08-07 16:09:45 train.log] INFO: Epoch: [4]  [Step 5000/14540]  lr: 0.000098  loss: 1.12527  detection_loss: 1.0541 (cls: 0.3352, box: 0.7190)  rpn_loss: 0.0711 (cls: 0.0493, box: 0.0219)
[2025-08-07 16:09:51 train.log] INFO: Epoch: [4]  [Step 5100/14540]  lr: 0.000098  loss: 1.51628  detection_loss: 1.3665 (cls: 0.2830, box: 1.0835)  rpn_loss: 0.1498 (cls: 0.0718, box: 0.0780)
[2025-08-07 16:09:56 train.log] INFO: Epoch: [4]  [Step 5200/14540]  lr: 0.000098  loss: 1.24740  detection_loss: 1.1265 (cls: 0.1522, box: 0.9743)  rpn_loss: 0.1209 (cls: 0.0722, box: 0.0487)
[2025-08-07 16:10:01 train.log] INFO: Epoch: [4]  [Step 5300/14540]  lr: 0.000098  loss: 1.80236  detection_loss: 1.5647 (cls: 0.2403, box: 1.3243)  rpn_loss: 0.2377 (cls: 0.2124, box: 0.0253)
[2025-08-07 16:10:06 train.log] INFO: Epoch: [4]  [Step 5400/14540]  lr: 0.000098  loss: 1.32043  detection_loss: 1.2253 (cls: 0.2066, box: 1.0187)  rpn_loss: 0.0951 (cls: 0.0319, box: 0.0632)
[2025-08-07 16:10:11 train.log] INFO: Epoch: [4]  [Step 5500/14540]  lr: 0.000098  loss: 1.06904  detection_loss: 0.9599 (cls: 0.1912, box: 0.7687)  rpn_loss: 0.1092 (cls: 0.0401, box: 0.0691)
[2025-08-07 16:10:16 train.log] INFO: Epoch: [4]  [Step 5600/14540]  lr: 0.000098  loss: 1.78671  detection_loss: 1.5596 (cls: 0.2673, box: 1.2923)  rpn_loss: 0.2271 (cls: 0.0345, box: 0.1926)
[2025-08-07 16:10:21 train.log] INFO: Epoch: [4]  [Step 5700/14540]  lr: 0.000098  loss: 0.83272  detection_loss: 0.7310 (cls: 0.1785, box: 0.5525)  rpn_loss: 0.1017 (cls: 0.0366, box: 0.0651)
[2025-08-07 16:10:26 train.log] INFO: Epoch: [4]  [Step 5800/14540]  lr: 0.000098  loss: 1.82360  detection_loss: 1.6808 (cls: 0.3900, box: 1.2908)  rpn_loss: 0.1428 (cls: 0.0744, box: 0.0684)
[2025-08-07 16:10:31 train.log] INFO: Epoch: [4]  [Step 5900/14540]  lr: 0.000098  loss: 1.20067  detection_loss: 1.1002 (cls: 0.1960, box: 0.9043)  rpn_loss: 0.1004 (cls: 0.0310, box: 0.0695)
[2025-08-07 16:10:36 train.log] INFO: Epoch: [4]  [Step 6000/14540]  lr: 0.000098  loss: 1.23752  detection_loss: 1.0066 (cls: 0.2129, box: 0.7938)  rpn_loss: 0.2309 (cls: 0.0422, box: 0.1887)
[2025-08-07 16:10:41 train.log] INFO: Epoch: [4]  [Step 6100/14540]  lr: 0.000098  loss: 0.97723  detection_loss: 0.9078 (cls: 0.3388, box: 0.5690)  rpn_loss: 0.0694 (cls: 0.0555, box: 0.0139)
[2025-08-07 16:10:46 train.log] INFO: Epoch: [4]  [Step 6200/14540]  lr: 0.000098  loss: 1.56336  detection_loss: 1.4171 (cls: 0.2102, box: 1.2070)  rpn_loss: 0.1462 (cls: 0.0685, box: 0.0777)
[2025-08-07 16:10:51 train.log] INFO: Epoch: [4]  [Step 6300/14540]  lr: 0.000098  loss: 2.32699  detection_loss: 2.0750 (cls: 0.6744, box: 1.4007)  rpn_loss: 0.2519 (cls: 0.2161, box: 0.0359)
[2025-08-07 16:10:56 train.log] INFO: Epoch: [4]  [Step 6400/14540]  lr: 0.000098  loss: 1.71962  detection_loss: 1.5371 (cls: 0.3419, box: 1.1953)  rpn_loss: 0.1825 (cls: 0.0964, box: 0.0861)
[2025-08-07 16:11:01 train.log] INFO: Epoch: [4]  [Step 6500/14540]  lr: 0.000098  loss: 1.54564  detection_loss: 1.3466 (cls: 0.3421, box: 1.0045)  rpn_loss: 0.1991 (cls: 0.0689, box: 0.1302)
[2025-08-07 16:11:06 train.log] INFO: Epoch: [4]  [Step 6600/14540]  lr: 0.000098  loss: 1.89112  detection_loss: 1.5852 (cls: 0.5242, box: 1.0610)  rpn_loss: 0.3059 (cls: 0.1327, box: 0.1732)
[2025-08-07 16:11:11 train.log] INFO: Epoch: [4]  [Step 6700/14540]  lr: 0.000098  loss: 1.94801  detection_loss: 1.8422 (cls: 0.3646, box: 1.4776)  rpn_loss: 0.1058 (cls: 0.0379, box: 0.0679)
[2025-08-07 16:11:16 train.log] INFO: Epoch: [4]  [Step 6800/14540]  lr: 0.000098  loss: 1.33284  detection_loss: 1.1806 (cls: 0.1792, box: 1.0014)  rpn_loss: 0.1523 (cls: 0.0577, box: 0.0945)
[2025-08-07 16:11:21 train.log] INFO: Epoch: [4]  [Step 6900/14540]  lr: 0.000098  loss: 1.16175  detection_loss: 1.0586 (cls: 0.3204, box: 0.7382)  rpn_loss: 0.1032 (cls: 0.0524, box: 0.0508)
[2025-08-07 16:11:26 train.log] INFO: Epoch: [4]  [Step 7000/14540]  lr: 0.000098  loss: 2.00860  detection_loss: 1.7830 (cls: 0.4224, box: 1.3606)  rpn_loss: 0.2256 (cls: 0.0814, box: 0.1442)
[2025-08-07 16:11:31 train.log] INFO: Epoch: [4]  [Step 7100/14540]  lr: 0.000098  loss: 1.76257  detection_loss: 1.4243 (cls: 0.3014, box: 1.1229)  rpn_loss: 0.3383 (cls: 0.0381, box: 0.3002)
[2025-08-07 16:11:37 train.log] INFO: Epoch: [4]  [Step 7200/14540]  lr: 0.000098  loss: 1.48828  detection_loss: 1.4264 (cls: 0.3589, box: 1.0675)  rpn_loss: 0.0619 (cls: 0.0316, box: 0.0303)
[2025-08-07 16:11:42 train.log] INFO: Epoch: [4]  [Step 7300/14540]  lr: 0.000098  loss: 1.49964  detection_loss: 1.4162 (cls: 0.2901, box: 1.1261)  rpn_loss: 0.0834 (cls: 0.0329, box: 0.0505)
[2025-08-07 16:11:47 train.log] INFO: Epoch: [4]  [Step 7400/14540]  lr: 0.000098  loss: 1.48733  detection_loss: 1.3871 (cls: 0.3424, box: 1.0447)  rpn_loss: 0.1002 (cls: 0.0609, box: 0.0393)
[2025-08-07 16:11:52 train.log] INFO: Epoch: [4]  [Step 7500/14540]  lr: 0.000098  loss: 1.95257  detection_loss: 1.7851 (cls: 0.3929, box: 1.3922)  rpn_loss: 0.1675 (cls: 0.0971, box: 0.0704)
[2025-08-07 16:11:57 train.log] INFO: Epoch: [4]  [Step 7600/14540]  lr: 0.000098  loss: 1.33726  detection_loss: 1.1866 (cls: 0.1883, box: 0.9984)  rpn_loss: 0.1506 (cls: 0.0933, box: 0.0573)
[2025-08-07 16:12:02 train.log] INFO: Epoch: [4]  [Step 7700/14540]  lr: 0.000098  loss: 1.39855  detection_loss: 1.2620 (cls: 0.2223, box: 1.0397)  rpn_loss: 0.1365 (cls: 0.0871, box: 0.0494)
[2025-08-07 16:12:07 train.log] INFO: Epoch: [4]  [Step 7800/14540]  lr: 0.000098  loss: 0.78053  detection_loss: 0.6640 (cls: 0.1610, box: 0.5029)  rpn_loss: 0.1166 (cls: 0.0825, box: 0.0340)
[2025-08-07 16:12:12 train.log] INFO: Epoch: [4]  [Step 7900/14540]  lr: 0.000098  loss: 1.82455  detection_loss: 1.6987 (cls: 0.3548, box: 1.3439)  rpn_loss: 0.1258 (cls: 0.0771, box: 0.0488)
[2025-08-07 16:12:17 train.log] INFO: Epoch: [4]  [Step 8000/14540]  lr: 0.000098  loss: 1.48662  detection_loss: 1.3199 (cls: 0.2960, box: 1.0239)  rpn_loss: 0.1668 (cls: 0.0954, box: 0.0713)
[2025-08-07 16:12:22 train.log] INFO: Epoch: [4]  [Step 8100/14540]  lr: 0.000098  loss: 1.46912  detection_loss: 1.2111 (cls: 0.1658, box: 1.0453)  rpn_loss: 0.2580 (cls: 0.0184, box: 0.2396)
[2025-08-07 16:12:27 train.log] INFO: Epoch: [4]  [Step 8200/14540]  lr: 0.000098  loss: 1.08474  detection_loss: 1.0037 (cls: 0.1678, box: 0.8359)  rpn_loss: 0.0811 (cls: 0.0334, box: 0.0477)
[2025-08-07 16:12:32 train.log] INFO: Epoch: [4]  [Step 8300/14540]  lr: 0.000098  loss: 1.07408  detection_loss: 0.9505 (cls: 0.2272, box: 0.7233)  rpn_loss: 0.1236 (cls: 0.0204, box: 0.1032)
[2025-08-07 16:12:37 train.log] INFO: Epoch: [4]  [Step 8400/14540]  lr: 0.000098  loss: 2.32729  detection_loss: 2.1888 (cls: 0.6271, box: 1.5617)  rpn_loss: 0.1385 (cls: 0.1079, box: 0.0305)
[2025-08-07 16:12:42 train.log] INFO: Epoch: [4]  [Step 8500/14540]  lr: 0.000098  loss: 1.09294  detection_loss: 1.0282 (cls: 0.1994, box: 0.8287)  rpn_loss: 0.0648 (cls: 0.0387, box: 0.0261)
[2025-08-07 16:12:47 train.log] INFO: Epoch: [4]  [Step 8600/14540]  lr: 0.000098  loss: 2.33916  detection_loss: 2.1626 (cls: 0.4560, box: 1.7065)  rpn_loss: 0.1766 (cls: 0.1111, box: 0.0655)
[2025-08-07 16:12:52 train.log] INFO: Epoch: [4]  [Step 8700/14540]  lr: 0.000098  loss: 1.45985  detection_loss: 1.2672 (cls: 0.1901, box: 1.0771)  rpn_loss: 0.1926 (cls: 0.0600, box: 0.1326)
[2025-08-07 16:12:57 train.log] INFO: Epoch: [4]  [Step 8800/14540]  lr: 0.000098  loss: 1.40958  detection_loss: 1.0608 (cls: 0.2275, box: 0.8333)  rpn_loss: 0.3488 (cls: 0.0471, box: 0.3017)
[2025-08-07 16:13:02 train.log] INFO: Epoch: [4]  [Step 8900/14540]  lr: 0.000098  loss: 1.31872  detection_loss: 1.2514 (cls: 0.4134, box: 0.8381)  rpn_loss: 0.0673 (cls: 0.0429, box: 0.0244)
[2025-08-07 16:13:07 train.log] INFO: Epoch: [4]  [Step 9000/14540]  lr: 0.000098  loss: 1.75926  detection_loss: 1.6682 (cls: 0.4453, box: 1.2229)  rpn_loss: 0.0911 (cls: 0.0652, box: 0.0259)
[2025-08-07 16:13:12 train.log] INFO: Epoch: [4]  [Step 9100/14540]  lr: 0.000098  loss: 1.60404  detection_loss: 1.4620 (cls: 0.4819, box: 0.9802)  rpn_loss: 0.1420 (cls: 0.0709, box: 0.0711)
[2025-08-07 16:13:17 train.log] INFO: Epoch: [4]  [Step 9200/14540]  lr: 0.000098  loss: 0.83869  detection_loss: 0.7824 (cls: 0.2014, box: 0.5810)  rpn_loss: 0.0563 (cls: 0.0395, box: 0.0168)
[2025-08-07 16:13:22 train.log] INFO: Epoch: [4]  [Step 9300/14540]  lr: 0.000098  loss: 1.41115  detection_loss: 1.2939 (cls: 0.3199, box: 0.9740)  rpn_loss: 0.1172 (cls: 0.0720, box: 0.0452)
[2025-08-07 16:13:27 train.log] INFO: Epoch: [4]  [Step 9400/14540]  lr: 0.000098  loss: 1.64695  detection_loss: 1.5105 (cls: 0.4525, box: 1.0580)  rpn_loss: 0.1364 (cls: 0.1083, box: 0.0281)
[2025-08-07 16:13:32 train.log] INFO: Epoch: [4]  [Step 9500/14540]  lr: 0.000098  loss: 1.84495  detection_loss: 1.6221 (cls: 0.3231, box: 1.2990)  rpn_loss: 0.2228 (cls: 0.0750, box: 0.1478)
[2025-08-07 16:13:37 train.log] INFO: Epoch: [4]  [Step 9600/14540]  lr: 0.000098  loss: 1.38650  detection_loss: 1.2597 (cls: 0.3964, box: 0.8633)  rpn_loss: 0.1268 (cls: 0.0929, box: 0.0338)
[2025-08-07 16:13:42 train.log] INFO: Epoch: [4]  [Step 9700/14540]  lr: 0.000098  loss: 1.06119  detection_loss: 0.9519 (cls: 0.2215, box: 0.7304)  rpn_loss: 0.1093 (cls: 0.0673, box: 0.0420)
[2025-08-07 16:13:47 train.log] INFO: Epoch: [4]  [Step 9800/14540]  lr: 0.000098  loss: 1.69008  detection_loss: 1.5860 (cls: 0.5290, box: 1.0570)  rpn_loss: 0.1041 (cls: 0.0639, box: 0.0402)
[2025-08-07 16:13:52 train.log] INFO: Epoch: [4]  [Step 9900/14540]  lr: 0.000098  loss: 1.72969  detection_loss: 1.5881 (cls: 0.2308, box: 1.3573)  rpn_loss: 0.1416 (cls: 0.0824, box: 0.0592)
[2025-08-07 16:13:57 train.log] INFO: Epoch: [4]  [Step 10000/14540]  lr: 0.000098  loss: 1.34873  detection_loss: 1.2268 (cls: 0.2657, box: 0.9610)  rpn_loss: 0.1220 (cls: 0.0719, box: 0.0500)
[2025-08-07 16:14:01 train.log] INFO: Epoch: [4]  [Step 10100/14540]  lr: 0.000098  loss: 2.22346  detection_loss: 1.9643 (cls: 0.4020, box: 1.5623)  rpn_loss: 0.2591 (cls: 0.1288, box: 0.1303)
[2025-08-07 16:14:06 train.log] INFO: Epoch: [4]  [Step 10200/14540]  lr: 0.000098  loss: 1.67317  detection_loss: 1.4982 (cls: 0.3723, box: 1.1260)  rpn_loss: 0.1749 (cls: 0.1394, box: 0.0356)
[2025-08-07 16:14:11 train.log] INFO: Epoch: [4]  [Step 10300/14540]  lr: 0.000098  loss: 1.78222  detection_loss: 1.6370 (cls: 0.2795, box: 1.3575)  rpn_loss: 0.1452 (cls: 0.1097, box: 0.0355)
[2025-08-07 16:14:16 train.log] INFO: Epoch: [4]  [Step 10400/14540]  lr: 0.000098  loss: 1.34481  detection_loss: 1.0409 (cls: 0.1887, box: 0.8522)  rpn_loss: 0.3039 (cls: 0.1120, box: 0.1919)
[2025-08-07 16:14:21 train.log] INFO: Epoch: [4]  [Step 10500/14540]  lr: 0.000098  loss: 2.19217  detection_loss: 2.0715 (cls: 0.5781, box: 1.4934)  rpn_loss: 0.1206 (cls: 0.0884, box: 0.0322)
[2025-08-07 16:14:26 train.log] INFO: Epoch: [4]  [Step 10600/14540]  lr: 0.000098  loss: 1.19265  detection_loss: 1.0769 (cls: 0.2660, box: 0.8110)  rpn_loss: 0.1157 (cls: 0.0647, box: 0.0510)
[2025-08-07 16:14:31 train.log] INFO: Epoch: [4]  [Step 10700/14540]  lr: 0.000098  loss: 1.34722  detection_loss: 1.2202 (cls: 0.3745, box: 0.8457)  rpn_loss: 0.1270 (cls: 0.0969, box: 0.0301)
[2025-08-07 16:14:36 train.log] INFO: Epoch: [4]  [Step 10800/14540]  lr: 0.000098  loss: 1.79630  detection_loss: 1.6315 (cls: 0.5692, box: 1.0623)  rpn_loss: 0.1648 (cls: 0.1371, box: 0.0278)
[2025-08-07 16:14:41 train.log] INFO: Epoch: [4]  [Step 10900/14540]  lr: 0.000098  loss: 2.10037  detection_loss: 1.8701 (cls: 0.6189, box: 1.2511)  rpn_loss: 0.2303 (cls: 0.0759, box: 0.1544)
[2025-08-07 16:14:46 train.log] INFO: Epoch: [4]  [Step 11000/14540]  lr: 0.000098  loss: 0.94570  detection_loss: 0.8780 (cls: 0.1993, box: 0.6787)  rpn_loss: 0.0677 (cls: 0.0471, box: 0.0206)
[2025-08-07 16:14:51 train.log] INFO: Epoch: [4]  [Step 11100/14540]  lr: 0.000098  loss: 1.51170  detection_loss: 1.3521 (cls: 0.2660, box: 1.0861)  rpn_loss: 0.1596 (cls: 0.1209, box: 0.0386)
[2025-08-07 16:14:56 train.log] INFO: Epoch: [4]  [Step 11200/14540]  lr: 0.000098  loss: 1.68651  detection_loss: 1.5509 (cls: 0.4016, box: 1.1492)  rpn_loss: 0.1356 (cls: 0.0929, box: 0.0428)
[2025-08-07 16:15:01 train.log] INFO: Epoch: [4]  [Step 11300/14540]  lr: 0.000098  loss: 1.96030  detection_loss: 1.7886 (cls: 0.2790, box: 1.5096)  rpn_loss: 0.1717 (cls: 0.0744, box: 0.0973)
[2025-08-07 16:15:06 train.log] INFO: Epoch: [4]  [Step 11400/14540]  lr: 0.000098  loss: 1.12999  detection_loss: 1.0119 (cls: 0.2702, box: 0.7417)  rpn_loss: 0.1181 (cls: 0.0855, box: 0.0326)
[2025-08-07 16:15:11 train.log] INFO: Epoch: [4]  [Step 11500/14540]  lr: 0.000098  loss: 1.62297  detection_loss: 1.4592 (cls: 0.3260, box: 1.1332)  rpn_loss: 0.1637 (cls: 0.1386, box: 0.0251)
[2025-08-07 16:15:16 train.log] INFO: Epoch: [4]  [Step 11600/14540]  lr: 0.000098  loss: 1.60132  detection_loss: 1.4754 (cls: 0.3475, box: 1.1279)  rpn_loss: 0.1259 (cls: 0.0718, box: 0.0540)
[2025-08-07 16:15:21 train.log] INFO: Epoch: [4]  [Step 11700/14540]  lr: 0.000098  loss: 2.14892  detection_loss: 1.9974 (cls: 0.4059, box: 1.5915)  rpn_loss: 0.1515 (cls: 0.0839, box: 0.0677)
[2025-08-07 16:15:26 train.log] INFO: Epoch: [4]  [Step 11800/14540]  lr: 0.000098  loss: 1.17139  detection_loss: 1.0644 (cls: 0.3337, box: 0.7307)  rpn_loss: 0.1070 (cls: 0.0727, box: 0.0343)
[2025-08-07 16:15:31 train.log] INFO: Epoch: [4]  [Step 11900/14540]  lr: 0.000098  loss: 1.40428  detection_loss: 1.2755 (cls: 0.3556, box: 0.9199)  rpn_loss: 0.1288 (cls: 0.0796, box: 0.0492)
[2025-08-07 16:15:36 train.log] INFO: Epoch: [4]  [Step 12000/14540]  lr: 0.000098  loss: 2.13352  detection_loss: 1.9684 (cls: 0.5231, box: 1.4453)  rpn_loss: 0.1651 (cls: 0.1178, box: 0.0473)
[2025-08-07 16:15:42 train.log] INFO: Epoch: [4]  [Step 12100/14540]  lr: 0.000098  loss: 1.93069  detection_loss: 1.7692 (cls: 0.3903, box: 1.3789)  rpn_loss: 0.1615 (cls: 0.1113, box: 0.0502)
[2025-08-07 16:15:47 train.log] INFO: Epoch: [4]  [Step 12200/14540]  lr: 0.000098  loss: 2.14487  detection_loss: 2.0119 (cls: 0.3593, box: 1.6526)  rpn_loss: 0.1330 (cls: 0.0754, box: 0.0576)
[2025-08-07 16:15:52 train.log] INFO: Epoch: [4]  [Step 12300/14540]  lr: 0.000098  loss: 1.28032  detection_loss: 1.0682 (cls: 0.3125, box: 0.7558)  rpn_loss: 0.2121 (cls: 0.0815, box: 0.1305)
[2025-08-07 16:15:58 train.log] INFO: Epoch: [4]  [Step 12400/14540]  lr: 0.000098  loss: 1.52089  detection_loss: 1.3012 (cls: 0.3112, box: 0.9900)  rpn_loss: 0.2197 (cls: 0.0400, box: 0.1797)
[2025-08-07 16:16:03 train.log] INFO: Epoch: [4]  [Step 12500/14540]  lr: 0.000098  loss: 1.88546  detection_loss: 1.6690 (cls: 0.5274, box: 1.1416)  rpn_loss: 0.2165 (cls: 0.1758, box: 0.0407)
[2025-08-07 16:16:08 train.log] INFO: Epoch: [4]  [Step 12600/14540]  lr: 0.000098  loss: 1.85251  detection_loss: 1.5386 (cls: 0.5059, box: 1.0327)  rpn_loss: 0.3139 (cls: 0.1305, box: 0.1834)
[2025-08-07 16:16:13 train.log] INFO: Epoch: [4]  [Step 12700/14540]  lr: 0.000098  loss: 1.55220  detection_loss: 1.4003 (cls: 0.3445, box: 1.0558)  rpn_loss: 0.1519 (cls: 0.0208, box: 0.1310)
[2025-08-07 16:16:18 train.log] INFO: Epoch: [4]  [Step 12800/14540]  lr: 0.000098  loss: 1.77165  detection_loss: 1.5652 (cls: 0.2295, box: 1.3358)  rpn_loss: 0.2064 (cls: 0.0603, box: 0.1461)
[2025-08-07 16:16:23 train.log] INFO: Epoch: [4]  [Step 12900/14540]  lr: 0.000098  loss: 1.26085  detection_loss: 1.0312 (cls: 0.3075, box: 0.7237)  rpn_loss: 0.2297 (cls: 0.0617, box: 0.1679)
[2025-08-07 16:16:28 train.log] INFO: Epoch: [4]  [Step 13000/14540]  lr: 0.000098  loss: 1.13539  detection_loss: 1.0191 (cls: 0.3190, box: 0.7002)  rpn_loss: 0.1163 (cls: 0.0798, box: 0.0364)
[2025-08-07 16:16:33 train.log] INFO: Epoch: [4]  [Step 13100/14540]  lr: 0.000098  loss: 1.36673  detection_loss: 1.2004 (cls: 0.3124, box: 0.8880)  rpn_loss: 0.1664 (cls: 0.0924, box: 0.0740)
[2025-08-07 16:16:38 train.log] INFO: Epoch: [4]  [Step 13200/14540]  lr: 0.000098  loss: 2.05970  detection_loss: 1.9421 (cls: 0.3506, box: 1.5915)  rpn_loss: 0.1176 (cls: 0.0368, box: 0.0807)
[2025-08-07 16:16:43 train.log] INFO: Epoch: [4]  [Step 13300/14540]  lr: 0.000098  loss: 1.61845  detection_loss: 1.4249 (cls: 0.4266, box: 0.9983)  rpn_loss: 0.1936 (cls: 0.1001, box: 0.0935)
[2025-08-07 16:16:48 train.log] INFO: Epoch: [4]  [Step 13400/14540]  lr: 0.000098  loss: 2.16542  detection_loss: 1.9194 (cls: 0.4980, box: 1.4214)  rpn_loss: 0.2460 (cls: 0.0995, box: 0.1465)
[2025-08-07 16:16:53 train.log] INFO: Epoch: [4]  [Step 13500/14540]  lr: 0.000098  loss: 1.30996  detection_loss: 1.2212 (cls: 0.3421, box: 0.8791)  rpn_loss: 0.0888 (cls: 0.0576, box: 0.0312)
[2025-08-07 16:16:58 train.log] INFO: Epoch: [4]  [Step 13600/14540]  lr: 0.000098  loss: 1.29705  detection_loss: 1.1746 (cls: 0.2391, box: 0.9355)  rpn_loss: 0.1225 (cls: 0.0840, box: 0.0385)
[2025-08-07 16:17:03 train.log] INFO: Epoch: [4]  [Step 13700/14540]  lr: 0.000098  loss: 1.58300  detection_loss: 1.4971 (cls: 0.4636, box: 1.0335)  rpn_loss: 0.0859 (cls: 0.0570, box: 0.0289)
[2025-08-07 16:17:08 train.log] INFO: Epoch: [4]  [Step 13800/14540]  lr: 0.000098  loss: 1.15251  detection_loss: 1.0407 (cls: 0.3019, box: 0.7387)  rpn_loss: 0.1119 (cls: 0.0542, box: 0.0576)
[2025-08-07 16:17:13 train.log] INFO: Epoch: [4]  [Step 13900/14540]  lr: 0.000098  loss: 0.97309  detection_loss: 0.9105 (cls: 0.3226, box: 0.5880)  rpn_loss: 0.0625 (cls: 0.0386, box: 0.0239)
[2025-08-07 16:17:18 train.log] INFO: Epoch: [4]  [Step 14000/14540]  lr: 0.000098  loss: 1.51615  detection_loss: 1.3328 (cls: 0.3947, box: 0.9380)  rpn_loss: 0.1834 (cls: 0.1498, box: 0.0336)
[2025-08-07 16:17:23 train.log] INFO: Epoch: [4]  [Step 14100/14540]  lr: 0.000098  loss: 1.18887  detection_loss: 0.9068 (cls: 0.2273, box: 0.6795)  rpn_loss: 0.2821 (cls: 0.0985, box: 0.1836)
[2025-08-07 16:17:28 train.log] INFO: Epoch: [4]  [Step 14200/14540]  lr: 0.000098  loss: 1.42550  detection_loss: 1.2666 (cls: 0.3975, box: 0.8691)  rpn_loss: 0.1589 (cls: 0.0905, box: 0.0685)
[2025-08-07 16:17:34 train.log] INFO: Epoch: [4]  [Step 14300/14540]  lr: 0.000098  loss: 1.46898  detection_loss: 1.2689 (cls: 0.4175, box: 0.8514)  rpn_loss: 0.2000 (cls: 0.0413, box: 0.1588)
[2025-08-07 16:17:39 train.log] INFO: Epoch: [4]  [Step 14400/14540]  lr: 0.000098  loss: 1.98094  detection_loss: 1.8297 (cls: 0.4489, box: 1.3809)  rpn_loss: 0.1512 (cls: 0.0817, box: 0.0695)
[2025-08-07 16:17:45 train.log] INFO: Epoch: [4]  [Step 14500/14540]  lr: 0.000098  loss: 1.17788  detection_loss: 1.0573 (cls: 0.2833, box: 0.7740)  rpn_loss: 0.1206 (cls: 0.0711, box: 0.0495)
[2025-08-07 16:20:52 train.log] INFO: Epoch: [5]  [Step 100/14540]  lr: 0.000096  loss: 1.16027  detection_loss: 1.0513 (cls: 0.2003, box: 0.8510)  rpn_loss: 0.1089 (cls: 0.0607, box: 0.0483)
[2025-08-07 16:20:57 train.log] INFO: Epoch: [5]  [Step 200/14540]  lr: 0.000096  loss: 1.15256  detection_loss: 1.0059 (cls: 0.2113, box: 0.7946)  rpn_loss: 0.1467 (cls: 0.1144, box: 0.0322)
[2025-08-07 16:21:02 train.log] INFO: Epoch: [5]  [Step 300/14540]  lr: 0.000096  loss: 1.47988  detection_loss: 1.1945 (cls: 0.3410, box: 0.8535)  rpn_loss: 0.2854 (cls: 0.1838, box: 0.1015)
[2025-08-07 16:21:07 train.log] INFO: Epoch: [5]  [Step 400/14540]  lr: 0.000096  loss: 1.13059  detection_loss: 0.9418 (cls: 0.2255, box: 0.7163)  rpn_loss: 0.1888 (cls: 0.0676, box: 0.1212)
[2025-08-07 16:21:12 train.log] INFO: Epoch: [5]  [Step 500/14540]  lr: 0.000096  loss: 1.60474  detection_loss: 1.4317 (cls: 0.4082, box: 1.0234)  rpn_loss: 0.1731 (cls: 0.0550, box: 0.1180)
[2025-08-07 16:21:17 train.log] INFO: Epoch: [5]  [Step 600/14540]  lr: 0.000096  loss: 0.76760  detection_loss: 0.6006 (cls: 0.1433, box: 0.4572)  rpn_loss: 0.1670 (cls: 0.1421, box: 0.0249)
[2025-08-07 16:21:22 train.log] INFO: Epoch: [5]  [Step 700/14540]  lr: 0.000096  loss: 1.78590  detection_loss: 1.4735 (cls: 0.3800, box: 1.0935)  rpn_loss: 0.3124 (cls: 0.0584, box: 0.2541)
[2025-08-07 16:21:26 train.log] INFO: Epoch: [5]  [Step 800/14540]  lr: 0.000096  loss: 0.86674  detection_loss: 0.7834 (cls: 0.2099, box: 0.5735)  rpn_loss: 0.0833 (cls: 0.0374, box: 0.0459)
[2025-08-07 16:21:31 train.log] INFO: Epoch: [5]  [Step 900/14540]  lr: 0.000096  loss: 1.38658  detection_loss: 1.2854 (cls: 0.2880, box: 0.9974)  rpn_loss: 0.1012 (cls: 0.0812, box: 0.0201)
[2025-08-07 16:21:36 train.log] INFO: Epoch: [5]  [Step 1000/14540]  lr: 0.000096  loss: 2.10944  detection_loss: 1.9757 (cls: 0.6339, box: 1.3418)  rpn_loss: 0.1337 (cls: 0.0865, box: 0.0472)
[2025-08-07 16:21:41 train.log] INFO: Epoch: [5]  [Step 1100/14540]  lr: 0.000096  loss: 1.35124  detection_loss: 1.1823 (cls: 0.2847, box: 0.8976)  rpn_loss: 0.1690 (cls: 0.1421, box: 0.0269)
[2025-08-07 16:21:46 train.log] INFO: Epoch: [5]  [Step 1200/14540]  lr: 0.000096  loss: 1.33062  detection_loss: 1.2005 (cls: 0.2962, box: 0.9042)  rpn_loss: 0.1302 (cls: 0.0469, box: 0.0833)
[2025-08-07 16:21:51 train.log] INFO: Epoch: [5]  [Step 1300/14540]  lr: 0.000096  loss: 1.45082  detection_loss: 1.2623 (cls: 0.1566, box: 1.1058)  rpn_loss: 0.1885 (cls: 0.0908, box: 0.0977)
[2025-08-07 16:21:55 train.log] INFO: Epoch: [5]  [Step 1400/14540]  lr: 0.000096  loss: 1.12350  detection_loss: 0.9890 (cls: 0.1167, box: 0.8724)  rpn_loss: 0.1345 (cls: 0.0122, box: 0.1223)
[2025-08-07 16:22:00 train.log] INFO: Epoch: [5]  [Step 1500/14540]  lr: 0.000096  loss: 1.30865  detection_loss: 1.2030 (cls: 0.3245, box: 0.8785)  rpn_loss: 0.1057 (cls: 0.0317, box: 0.0740)
[2025-08-07 16:22:05 train.log] INFO: Epoch: [5]  [Step 1600/14540]  lr: 0.000096  loss: 1.56442  detection_loss: 1.4584 (cls: 0.3027, box: 1.1557)  rpn_loss: 0.1061 (cls: 0.0783, box: 0.0277)
[2025-08-07 16:22:10 train.log] INFO: Epoch: [5]  [Step 1700/14540]  lr: 0.000096  loss: 2.14496  detection_loss: 1.9610 (cls: 0.6271, box: 1.3339)  rpn_loss: 0.1839 (cls: 0.1495, box: 0.0345)
[2025-08-07 16:22:15 train.log] INFO: Epoch: [5]  [Step 1800/14540]  lr: 0.000096  loss: 1.29539  detection_loss: 1.0316 (cls: 0.2187, box: 0.8129)  rpn_loss: 0.2638 (cls: 0.0448, box: 0.2191)
[2025-08-07 16:22:20 train.log] INFO: Epoch: [5]  [Step 1900/14540]  lr: 0.000096  loss: 1.83015  detection_loss: 1.6515 (cls: 0.4769, box: 1.1746)  rpn_loss: 0.1786 (cls: 0.0807, box: 0.0980)
[2025-08-07 16:22:25 train.log] INFO: Epoch: [5]  [Step 2000/14540]  lr: 0.000096  loss: 0.93367  detection_loss: 0.8930 (cls: 0.1394, box: 0.7536)  rpn_loss: 0.0406 (cls: 0.0299, box: 0.0107)
[2025-08-07 16:22:30 train.log] INFO: Epoch: [5]  [Step 2100/14540]  lr: 0.000096  loss: 1.65605  detection_loss: 1.5753 (cls: 0.4090, box: 1.1663)  rpn_loss: 0.0807 (cls: 0.0285, box: 0.0522)
[2025-08-07 16:22:35 train.log] INFO: Epoch: [5]  [Step 2200/14540]  lr: 0.000096  loss: 1.01263  detection_loss: 0.8937 (cls: 0.1814, box: 0.7124)  rpn_loss: 0.1189 (cls: 0.0980, box: 0.0209)
[2025-08-07 16:22:39 train.log] INFO: Epoch: [5]  [Step 2300/14540]  lr: 0.000096  loss: 1.95295  detection_loss: 1.8476 (cls: 0.5635, box: 1.2841)  rpn_loss: 0.1053 (cls: 0.0393, box: 0.0661)
[2025-08-07 16:22:44 train.log] INFO: Epoch: [5]  [Step 2400/14540]  lr: 0.000096  loss: 2.04170  detection_loss: 1.8868 (cls: 0.6451, box: 1.2417)  rpn_loss: 0.1549 (cls: 0.1120, box: 0.0430)
[2025-08-07 16:22:49 train.log] INFO: Epoch: [5]  [Step 2500/14540]  lr: 0.000096  loss: 1.38684  detection_loss: 1.2643 (cls: 0.2253, box: 1.0390)  rpn_loss: 0.1225 (cls: 0.0663, box: 0.0562)
[2025-08-07 16:22:54 train.log] INFO: Epoch: [5]  [Step 2600/14540]  lr: 0.000096  loss: 1.39041  detection_loss: 1.2743 (cls: 0.2376, box: 1.0367)  rpn_loss: 0.1161 (cls: 0.0664, box: 0.0497)
[2025-08-07 16:22:59 train.log] INFO: Epoch: [5]  [Step 2700/14540]  lr: 0.000096  loss: 1.27446  detection_loss: 1.0852 (cls: 0.2640, box: 0.8212)  rpn_loss: 0.1892 (cls: 0.0724, box: 0.1169)
[2025-08-07 16:23:04 train.log] INFO: Epoch: [5]  [Step 2800/14540]  lr: 0.000096  loss: 1.77670  detection_loss: 1.6573 (cls: 0.4126, box: 1.2447)  rpn_loss: 0.1194 (cls: 0.0912, box: 0.0282)
[2025-08-07 16:23:09 train.log] INFO: Epoch: [5]  [Step 2900/14540]  lr: 0.000096  loss: 1.47837  detection_loss: 1.3666 (cls: 0.5034, box: 0.8632)  rpn_loss: 0.1117 (cls: 0.0734, box: 0.0384)
[2025-08-07 16:23:13 train.log] INFO: Epoch: [5]  [Step 3000/14540]  lr: 0.000096  loss: 1.62577  detection_loss: 1.4768 (cls: 0.3113, box: 1.1655)  rpn_loss: 0.1490 (cls: 0.0653, box: 0.0837)
[2025-08-07 16:23:18 train.log] INFO: Epoch: [5]  [Step 3100/14540]  lr: 0.000096  loss: 2.75163  detection_loss: 2.5374 (cls: 0.4534, box: 2.0840)  rpn_loss: 0.2143 (cls: 0.0984, box: 0.1159)
[2025-08-07 16:23:23 train.log] INFO: Epoch: [5]  [Step 3200/14540]  lr: 0.000096  loss: 1.44949  detection_loss: 1.3317 (cls: 0.3629, box: 0.9688)  rpn_loss: 0.1178 (cls: 0.0385, box: 0.0793)
[2025-08-07 16:23:28 train.log] INFO: Epoch: [5]  [Step 3300/14540]  lr: 0.000096  loss: 1.64534  detection_loss: 1.3781 (cls: 0.2246, box: 1.1536)  rpn_loss: 0.2672 (cls: 0.0290, box: 0.2382)
[2025-08-07 16:23:33 train.log] INFO: Epoch: [5]  [Step 3400/14540]  lr: 0.000096  loss: 1.76188  detection_loss: 1.5225 (cls: 0.4461, box: 1.0764)  rpn_loss: 0.2394 (cls: 0.0696, box: 0.1698)
[2025-08-07 16:23:38 train.log] INFO: Epoch: [5]  [Step 3500/14540]  lr: 0.000096  loss: 1.87669  detection_loss: 1.7352 (cls: 0.5974, box: 1.1379)  rpn_loss: 0.1414 (cls: 0.1038, box: 0.0377)
[2025-08-07 16:23:43 train.log] INFO: Epoch: [5]  [Step 3600/14540]  lr: 0.000096  loss: 1.43569  detection_loss: 1.2972 (cls: 0.2745, box: 1.0228)  rpn_loss: 0.1385 (cls: 0.1081, box: 0.0304)
[2025-08-07 16:23:44 train.log] INFO: Epoch: [5]  [Step 3635/14540]  lr: 0.000096  loss: 1.06660  detection_loss: 0.9850 (cls: 0.1356, box: 0.8494)  rpn_loss: 0.0816 (cls: 0.0573, box: 0.0243)
[2025-08-07 16:23:48 train.log] INFO: Epoch: [5]  [Step 3700/14540]  lr: 0.000096  loss: 1.56810  detection_loss: 1.3525 (cls: 0.3726, box: 0.9799)  rpn_loss: 0.2156 (cls: 0.0683, box: 0.1473)
[2025-08-07 16:23:52 train.log] INFO: Epoch: [5]  [Step 3800/14540]  lr: 0.000096  loss: 1.18356  detection_loss: 1.0412 (cls: 0.2471, box: 0.7940)  rpn_loss: 0.1424 (cls: 0.0518, box: 0.0906)
[2025-08-07 16:23:57 train.log] INFO: Epoch: [5]  [Step 3900/14540]  lr: 0.000096  loss: 1.53863  detection_loss: 1.3356 (cls: 0.3217, box: 1.0139)  rpn_loss: 0.2030 (cls: 0.0741, box: 0.1289)
[2025-08-07 16:24:02 train.log] INFO: Epoch: [5]  [Step 4000/14540]  lr: 0.000096  loss: 1.36450  detection_loss: 1.2783 (cls: 0.3577, box: 0.9206)  rpn_loss: 0.0862 (cls: 0.0639, box: 0.0223)
[2025-08-07 16:24:07 train.log] INFO: Epoch: [5]  [Step 4100/14540]  lr: 0.000096  loss: 1.33280  detection_loss: 1.2106 (cls: 0.3497, box: 0.8609)  rpn_loss: 0.1222 (cls: 0.0916, box: 0.0306)
[2025-08-07 16:24:12 train.log] INFO: Epoch: [5]  [Step 4200/14540]  lr: 0.000096  loss: 1.47431  detection_loss: 1.3515 (cls: 0.3528, box: 0.9988)  rpn_loss: 0.1228 (cls: 0.0809, box: 0.0419)
[2025-08-07 16:24:17 train.log] INFO: Epoch: [5]  [Step 4300/14540]  lr: 0.000096  loss: 1.96595  detection_loss: 1.8174 (cls: 0.5172, box: 1.3002)  rpn_loss: 0.1486 (cls: 0.1111, box: 0.0374)
[2025-08-07 16:24:22 train.log] INFO: Epoch: [5]  [Step 4400/14540]  lr: 0.000096  loss: 0.95071  detection_loss: 0.7499 (cls: 0.1430, box: 0.6069)  rpn_loss: 0.2008 (cls: 0.0545, box: 0.1463)
[2025-08-07 16:24:27 train.log] INFO: Epoch: [5]  [Step 4500/14540]  lr: 0.000096  loss: 1.43060  detection_loss: 1.2695 (cls: 0.3902, box: 0.8793)  rpn_loss: 0.1611 (cls: 0.0673, box: 0.0938)
[2025-08-07 16:24:32 train.log] INFO: Epoch: [5]  [Step 4600/14540]  lr: 0.000096  loss: 0.77956  detection_loss: 0.7209 (cls: 0.0658, box: 0.6551)  rpn_loss: 0.0587 (cls: 0.0294, box: 0.0293)
[2025-08-07 16:24:37 train.log] INFO: Epoch: [5]  [Step 4700/14540]  lr: 0.000096  loss: 1.52195  detection_loss: 1.2711 (cls: 0.2589, box: 1.0122)  rpn_loss: 0.2509 (cls: 0.0482, box: 0.2026)
[2025-08-07 16:24:42 train.log] INFO: Epoch: [5]  [Step 4800/14540]  lr: 0.000096  loss: 1.24350  detection_loss: 1.1184 (cls: 0.2772, box: 0.8412)  rpn_loss: 0.1251 (cls: 0.0263, box: 0.0989)
[2025-08-07 16:24:46 train.log] INFO: Epoch: [5]  [Step 4900/14540]  lr: 0.000096  loss: 1.17870  detection_loss: 1.0876 (cls: 0.1499, box: 0.9378)  rpn_loss: 0.0910 (cls: 0.0380, box: 0.0530)
[2025-08-07 16:24:51 train.log] INFO: Epoch: [5]  [Step 5000/14540]  lr: 0.000096  loss: 1.07049  detection_loss: 0.9797 (cls: 0.2068, box: 0.7729)  rpn_loss: 0.0908 (cls: 0.0510, box: 0.0397)
[2025-08-07 16:24:56 train.log] INFO: Epoch: [5]  [Step 5100/14540]  lr: 0.000096  loss: 1.73136  detection_loss: 1.5663 (cls: 0.5734, box: 0.9929)  rpn_loss: 0.1650 (cls: 0.1017, box: 0.0634)
[2025-08-07 16:25:01 train.log] INFO: Epoch: [5]  [Step 5200/14540]  lr: 0.000096  loss: 1.39445  detection_loss: 1.2526 (cls: 0.2566, box: 0.9960)  rpn_loss: 0.1418 (cls: 0.0753, box: 0.0666)
[2025-08-07 16:25:06 train.log] INFO: Epoch: [5]  [Step 5300/14540]  lr: 0.000096  loss: 0.90190  detection_loss: 0.8540 (cls: 0.1920, box: 0.6620)  rpn_loss: 0.0480 (cls: 0.0268, box: 0.0212)
[2025-08-07 16:25:11 train.log] INFO: Epoch: [5]  [Step 5400/14540]  lr: 0.000096  loss: 1.22847  detection_loss: 1.1101 (cls: 0.2025, box: 0.9076)  rpn_loss: 0.1183 (cls: 0.0508, box: 0.0675)
[2025-08-07 16:25:16 train.log] INFO: Epoch: [5]  [Step 5500/14540]  lr: 0.000096  loss: 1.40133  detection_loss: 1.2679 (cls: 0.2952, box: 0.9727)  rpn_loss: 0.1334 (cls: 0.0999, box: 0.0335)
[2025-08-07 16:25:20 train.log] INFO: Epoch: [5]  [Step 5600/14540]  lr: 0.000096  loss: 1.34149  detection_loss: 1.2182 (cls: 0.3538, box: 0.8644)  rpn_loss: 0.1233 (cls: 0.0590, box: 0.0643)
[2025-08-07 16:25:25 train.log] INFO: Epoch: [5]  [Step 5700/14540]  lr: 0.000096  loss: 1.65061  detection_loss: 1.4255 (cls: 0.4585, box: 0.9670)  rpn_loss: 0.2251 (cls: 0.0820, box: 0.1431)
[2025-08-07 16:25:30 train.log] INFO: Epoch: [5]  [Step 5800/14540]  lr: 0.000096  loss: 1.05466  detection_loss: 0.8964 (cls: 0.2706, box: 0.6258)  rpn_loss: 0.1583 (cls: 0.0928, box: 0.0655)
[2025-08-07 16:25:35 train.log] INFO: Epoch: [5]  [Step 5900/14540]  lr: 0.000096  loss: 1.64355  detection_loss: 1.4741 (cls: 0.3520, box: 1.1221)  rpn_loss: 0.1694 (cls: 0.1335, box: 0.0359)
[2025-08-07 16:25:40 train.log] INFO: Epoch: [5]  [Step 6000/14540]  lr: 0.000096  loss: 1.25940  detection_loss: 1.1415 (cls: 0.3078, box: 0.8338)  rpn_loss: 0.1179 (cls: 0.0757, box: 0.0422)
[2025-08-07 16:25:44 train.log] INFO: Epoch: [5]  [Step 6100/14540]  lr: 0.000096  loss: 1.63414  detection_loss: 1.5214 (cls: 0.4497, box: 1.0717)  rpn_loss: 0.1127 (cls: 0.0900, box: 0.0227)
[2025-08-07 16:25:49 train.log] INFO: Epoch: [5]  [Step 6200/14540]  lr: 0.000096  loss: 1.18252  detection_loss: 1.0956 (cls: 0.2603, box: 0.8353)  rpn_loss: 0.0869 (cls: 0.0451, box: 0.0418)
[2025-08-07 16:25:54 train.log] INFO: Epoch: [5]  [Step 6300/14540]  lr: 0.000096  loss: 0.85383  detection_loss: 0.7873 (cls: 0.1732, box: 0.6141)  rpn_loss: 0.0665 (cls: 0.0373, box: 0.0292)
[2025-08-07 16:25:59 train.log] INFO: Epoch: [5]  [Step 6400/14540]  lr: 0.000096  loss: 1.59264  detection_loss: 1.4965 (cls: 0.4249, box: 1.0717)  rpn_loss: 0.0961 (cls: 0.0534, box: 0.0427)
[2025-08-07 16:26:04 train.log] INFO: Epoch: [5]  [Step 6500/14540]  lr: 0.000096  loss: 1.28381  detection_loss: 1.1943 (cls: 0.2728, box: 0.9215)  rpn_loss: 0.0895 (cls: 0.0386, box: 0.0509)
[2025-08-07 16:26:09 train.log] INFO: Epoch: [5]  [Step 6600/14540]  lr: 0.000096  loss: 1.41311  detection_loss: 1.3493 (cls: 0.2592, box: 1.0901)  rpn_loss: 0.0638 (cls: 0.0397, box: 0.0241)
[2025-08-07 16:26:14 train.log] INFO: Epoch: [5]  [Step 6700/14540]  lr: 0.000096  loss: 2.06181  detection_loss: 1.9205 (cls: 0.4155, box: 1.5050)  rpn_loss: 0.1413 (cls: 0.0334, box: 0.1079)
[2025-08-07 16:26:18 train.log] INFO: Epoch: [5]  [Step 6800/14540]  lr: 0.000096  loss: 1.64741  detection_loss: 1.4346 (cls: 0.3228, box: 1.1118)  rpn_loss: 0.2128 (cls: 0.0689, box: 0.1439)
[2025-08-07 16:26:23 train.log] INFO: Epoch: [5]  [Step 6900/14540]  lr: 0.000096  loss: 2.24817  detection_loss: 2.0960 (cls: 0.3399, box: 1.7561)  rpn_loss: 0.1522 (cls: 0.0693, box: 0.0829)
[2025-08-07 16:26:28 train.log] INFO: Epoch: [5]  [Step 7000/14540]  lr: 0.000096  loss: 1.15474  detection_loss: 1.0529 (cls: 0.3097, box: 0.7432)  rpn_loss: 0.1018 (cls: 0.0496, box: 0.0522)
[2025-08-07 16:26:33 train.log] INFO: Epoch: [5]  [Step 7100/14540]  lr: 0.000096  loss: 1.50274  detection_loss: 1.4128 (cls: 0.4755, box: 0.9373)  rpn_loss: 0.0900 (cls: 0.0525, box: 0.0375)
[2025-08-07 16:26:38 train.log] INFO: Epoch: [5]  [Step 7200/14540]  lr: 0.000096  loss: 1.42554  detection_loss: 1.2867 (cls: 0.2129, box: 1.0738)  rpn_loss: 0.1389 (cls: 0.0834, box: 0.0555)
[2025-08-07 16:26:43 train.log] INFO: Epoch: [5]  [Step 7300/14540]  lr: 0.000096  loss: 1.65827  detection_loss: 1.4330 (cls: 0.2121, box: 1.2209)  rpn_loss: 0.2253 (cls: 0.0445, box: 0.1807)
[2025-08-07 16:26:48 train.log] INFO: Epoch: [5]  [Step 7400/14540]  lr: 0.000096  loss: 1.95678  detection_loss: 1.5866 (cls: 0.3244, box: 1.2622)  rpn_loss: 0.3702 (cls: 0.1243, box: 0.2459)
[2025-08-07 16:26:53 train.log] INFO: Epoch: [5]  [Step 7500/14540]  lr: 0.000096  loss: 1.93171  detection_loss: 1.8264 (cls: 0.2715, box: 1.5549)  rpn_loss: 0.1054 (cls: 0.0852, box: 0.0202)
[2025-08-07 16:26:58 train.log] INFO: Epoch: [5]  [Step 7600/14540]  lr: 0.000096  loss: 1.21502  detection_loss: 1.1333 (cls: 0.2704, box: 0.8629)  rpn_loss: 0.0817 (cls: 0.0378, box: 0.0439)
[2025-08-07 16:27:03 train.log] INFO: Epoch: [5]  [Step 7700/14540]  lr: 0.000096  loss: 1.63598  detection_loss: 1.5346 (cls: 0.3845, box: 1.1501)  rpn_loss: 0.1013 (cls: 0.0520, box: 0.0493)
[2025-08-07 16:27:08 train.log] INFO: Epoch: [5]  [Step 7800/14540]  lr: 0.000096  loss: 1.63713  detection_loss: 1.5156 (cls: 0.3915, box: 1.1240)  rpn_loss: 0.1216 (cls: 0.0648, box: 0.0568)
[2025-08-07 16:27:13 train.log] INFO: Epoch: [5]  [Step 7900/14540]  lr: 0.000096  loss: 0.99255  detection_loss: 0.8924 (cls: 0.1800, box: 0.7124)  rpn_loss: 0.1002 (cls: 0.0549, box: 0.0453)
[2025-08-07 16:27:18 train.log] INFO: Epoch: [5]  [Step 8000/14540]  lr: 0.000096  loss: 0.86702  detection_loss: 0.7479 (cls: 0.0985, box: 0.6494)  rpn_loss: 0.1192 (cls: 0.0371, box: 0.0821)
[2025-08-07 16:27:23 train.log] INFO: Epoch: [5]  [Step 8100/14540]  lr: 0.000096  loss: 1.54306  detection_loss: 1.4377 (cls: 0.4020, box: 1.0357)  rpn_loss: 0.1054 (cls: 0.0542, box: 0.0511)
[2025-08-07 16:27:28 train.log] INFO: Epoch: [5]  [Step 8200/14540]  lr: 0.000096  loss: 0.75345  detection_loss: 0.5445 (cls: 0.1438, box: 0.4007)  rpn_loss: 0.2089 (cls: 0.0547, box: 0.1542)
[2025-08-07 16:27:33 train.log] INFO: Epoch: [5]  [Step 8300/14540]  lr: 0.000096  loss: 1.59336  detection_loss: 1.4102 (cls: 0.3587, box: 1.0515)  rpn_loss: 0.1831 (cls: 0.0854, box: 0.0977)
[2025-08-07 16:27:38 train.log] INFO: Epoch: [5]  [Step 8400/14540]  lr: 0.000096  loss: 1.89271  detection_loss: 1.7777 (cls: 0.5366, box: 1.2411)  rpn_loss: 0.1150 (cls: 0.0829, box: 0.0321)
[2025-08-07 16:27:43 train.log] INFO: Epoch: [5]  [Step 8500/14540]  lr: 0.000096  loss: 1.57685  detection_loss: 1.3305 (cls: 0.3913, box: 0.9392)  rpn_loss: 0.2463 (cls: 0.0512, box: 0.1952)
[2025-08-07 16:27:48 train.log] INFO: Epoch: [5]  [Step 8600/14540]  lr: 0.000096  loss: 1.61167  detection_loss: 1.5463 (cls: 0.4759, box: 1.0704)  rpn_loss: 0.0654 (cls: 0.0397, box: 0.0257)
[2025-08-07 16:27:53 train.log] INFO: Epoch: [5]  [Step 8700/14540]  lr: 0.000096  loss: 1.89974  detection_loss: 1.7459 (cls: 0.4446, box: 1.3013)  rpn_loss: 0.1538 (cls: 0.0646, box: 0.0892)
[2025-08-07 16:27:58 train.log] INFO: Epoch: [5]  [Step 8800/14540]  lr: 0.000096  loss: 1.27234  detection_loss: 1.1353 (cls: 0.2350, box: 0.9003)  rpn_loss: 0.1370 (cls: 0.0481, box: 0.0889)
[2025-08-07 16:28:03 train.log] INFO: Epoch: [5]  [Step 8900/14540]  lr: 0.000096  loss: 1.75035  detection_loss: 1.6656 (cls: 0.4347, box: 1.2310)  rpn_loss: 0.0847 (cls: 0.0490, box: 0.0357)
[2025-08-07 16:28:08 train.log] INFO: Epoch: [5]  [Step 9000/14540]  lr: 0.000096  loss: 2.30159  detection_loss: 2.2135 (cls: 0.2383, box: 1.9752)  rpn_loss: 0.0881 (cls: 0.0351, box: 0.0530)
[2025-08-07 16:28:13 train.log] INFO: Epoch: [5]  [Step 9100/14540]  lr: 0.000096  loss: 1.89973  detection_loss: 1.7025 (cls: 0.4258, box: 1.2767)  rpn_loss: 0.1973 (cls: 0.0771, box: 0.1202)
[2025-08-07 16:28:18 train.log] INFO: Epoch: [5]  [Step 9200/14540]  lr: 0.000096  loss: 1.10589  detection_loss: 1.0365 (cls: 0.1826, box: 0.8539)  rpn_loss: 0.0694 (cls: 0.0367, box: 0.0327)
[2025-08-07 16:28:23 train.log] INFO: Epoch: [5]  [Step 9300/14540]  lr: 0.000096  loss: 1.39050  detection_loss: 1.1684 (cls: 0.3305, box: 0.8379)  rpn_loss: 0.2221 (cls: 0.0790, box: 0.1431)
[2025-08-07 16:28:28 train.log] INFO: Epoch: [5]  [Step 9400/14540]  lr: 0.000096  loss: 1.27513  detection_loss: 1.1941 (cls: 0.3283, box: 0.8658)  rpn_loss: 0.0810 (cls: 0.0319, box: 0.0491)
[2025-08-07 16:28:33 train.log] INFO: Epoch: [5]  [Step 9500/14540]  lr: 0.000096  loss: 1.40252  detection_loss: 1.2670 (cls: 0.3609, box: 0.9062)  rpn_loss: 0.1355 (cls: 0.0956, box: 0.0399)
[2025-08-07 16:28:38 train.log] INFO: Epoch: [5]  [Step 9600/14540]  lr: 0.000096  loss: 2.77301  detection_loss: 2.5089 (cls: 0.6187, box: 1.8902)  rpn_loss: 0.2641 (cls: 0.2124, box: 0.0517)
[2025-08-07 16:28:43 train.log] INFO: Epoch: [5]  [Step 9700/14540]  lr: 0.000096  loss: 1.15780  detection_loss: 1.0635 (cls: 0.2655, box: 0.7980)  rpn_loss: 0.0943 (cls: 0.0588, box: 0.0355)
[2025-08-07 16:28:48 train.log] INFO: Epoch: [5]  [Step 9800/14540]  lr: 0.000096  loss: 1.62839  detection_loss: 1.4872 (cls: 0.3292, box: 1.1579)  rpn_loss: 0.1412 (cls: 0.0624, box: 0.0788)
[2025-08-07 16:28:53 train.log] INFO: Epoch: [5]  [Step 9900/14540]  lr: 0.000096  loss: 1.33710  detection_loss: 1.2183 (cls: 0.2643, box: 0.9540)  rpn_loss: 0.1188 (cls: 0.0763, box: 0.0425)
[2025-08-07 16:28:58 train.log] INFO: Epoch: [5]  [Step 10000/14540]  lr: 0.000096  loss: 1.35697  detection_loss: 1.1386 (cls: 0.2562, box: 0.8824)  rpn_loss: 0.2183 (cls: 0.1214, box: 0.0969)
[2025-08-07 16:29:03 train.log] INFO: Epoch: [5]  [Step 10100/14540]  lr: 0.000096  loss: 1.07410  detection_loss: 1.0168 (cls: 0.2287, box: 0.7881)  rpn_loss: 0.0573 (cls: 0.0332, box: 0.0241)
[2025-08-07 16:29:08 train.log] INFO: Epoch: [5]  [Step 10200/14540]  lr: 0.000096  loss: 1.88543  detection_loss: 1.6472 (cls: 0.5082, box: 1.1390)  rpn_loss: 0.2382 (cls: 0.1251, box: 0.1132)
[2025-08-07 16:29:13 train.log] INFO: Epoch: [5]  [Step 10300/14540]  lr: 0.000096  loss: 1.25169  detection_loss: 1.1032 (cls: 0.2509, box: 0.8522)  rpn_loss: 0.1485 (cls: 0.1250, box: 0.0235)
[2025-08-07 16:29:18 train.log] INFO: Epoch: [5]  [Step 10400/14540]  lr: 0.000096  loss: 1.74781  detection_loss: 1.6547 (cls: 0.3689, box: 1.2858)  rpn_loss: 0.0931 (cls: 0.0596, box: 0.0335)
[2025-08-07 16:29:23 train.log] INFO: Epoch: [5]  [Step 10500/14540]  lr: 0.000096  loss: 1.81963  detection_loss: 1.6645 (cls: 0.6447, box: 1.0198)  rpn_loss: 0.1551 (cls: 0.1294, box: 0.0257)
[2025-08-07 16:29:28 train.log] INFO: Epoch: [5]  [Step 10600/14540]  lr: 0.000096  loss: 1.63541  detection_loss: 1.5688 (cls: 0.3261, box: 1.2427)  rpn_loss: 0.0666 (cls: 0.0199, box: 0.0467)
[2025-08-07 16:29:33 train.log] INFO: Epoch: [5]  [Step 10700/14540]  lr: 0.000096  loss: 1.27084  detection_loss: 0.9339 (cls: 0.1781, box: 0.7558)  rpn_loss: 0.3369 (cls: 0.0406, box: 0.2963)
[2025-08-07 16:29:38 train.log] INFO: Epoch: [5]  [Step 10800/14540]  lr: 0.000096  loss: 1.34354  detection_loss: 1.1950 (cls: 0.2585, box: 0.9365)  rpn_loss: 0.1486 (cls: 0.0681, box: 0.0805)
[2025-08-07 16:29:43 train.log] INFO: Epoch: [5]  [Step 10900/14540]  lr: 0.000096  loss: 1.28037  detection_loss: 1.1995 (cls: 0.2928, box: 0.9067)  rpn_loss: 0.0809 (cls: 0.0500, box: 0.0309)
[2025-08-07 16:29:48 train.log] INFO: Epoch: [5]  [Step 11000/14540]  lr: 0.000096  loss: 1.34165  detection_loss: 1.1935 (cls: 0.3792, box: 0.8143)  rpn_loss: 0.1482 (cls: 0.0994, box: 0.0488)
[2025-08-07 16:29:53 train.log] INFO: Epoch: [5]  [Step 11100/14540]  lr: 0.000096  loss: 2.33698  detection_loss: 2.1650 (cls: 0.7298, box: 1.4352)  rpn_loss: 0.1719 (cls: 0.1266, box: 0.0453)
[2025-08-07 16:29:58 train.log] INFO: Epoch: [5]  [Step 11200/14540]  lr: 0.000096  loss: 1.70018  detection_loss: 1.5763 (cls: 0.4155, box: 1.1608)  rpn_loss: 0.1239 (cls: 0.0583, box: 0.0656)
[2025-08-07 16:30:03 train.log] INFO: Epoch: [5]  [Step 11300/14540]  lr: 0.000096  loss: 1.18524  detection_loss: 1.0000 (cls: 0.2146, box: 0.7853)  rpn_loss: 0.1853 (cls: 0.0366, box: 0.1487)
[2025-08-07 16:30:08 train.log] INFO: Epoch: [5]  [Step 11400/14540]  lr: 0.000096  loss: 1.35481  detection_loss: 1.1521 (cls: 0.1629, box: 0.9892)  rpn_loss: 0.2027 (cls: 0.0467, box: 0.1560)
[2025-08-07 16:30:13 train.log] INFO: Epoch: [5]  [Step 11500/14540]  lr: 0.000096  loss: 1.38473  detection_loss: 1.2505 (cls: 0.3489, box: 0.9016)  rpn_loss: 0.1342 (cls: 0.1059, box: 0.0284)
[2025-08-07 16:30:18 train.log] INFO: Epoch: [5]  [Step 11600/14540]  lr: 0.000096  loss: 1.34154  detection_loss: 1.2259 (cls: 0.2805, box: 0.9453)  rpn_loss: 0.1157 (cls: 0.0527, box: 0.0630)
[2025-08-07 16:30:23 train.log] INFO: Epoch: [5]  [Step 11700/14540]  lr: 0.000096  loss: 1.78588  detection_loss: 1.5991 (cls: 0.4591, box: 1.1400)  rpn_loss: 0.1868 (cls: 0.1080, box: 0.0788)
[2025-08-07 16:30:28 train.log] INFO: Epoch: [5]  [Step 11800/14540]  lr: 0.000096  loss: 1.28431  detection_loss: 0.9074 (cls: 0.2544, box: 0.6530)  rpn_loss: 0.3769 (cls: 0.0341, box: 0.3428)
[2025-08-07 16:30:34 train.log] INFO: Epoch: [5]  [Step 11900/14540]  lr: 0.000096  loss: 1.46944  detection_loss: 1.3756 (cls: 0.4436, box: 0.9320)  rpn_loss: 0.0939 (cls: 0.0551, box: 0.0388)
[2025-08-07 16:30:39 train.log] INFO: Epoch: [5]  [Step 12000/14540]  lr: 0.000096  loss: 1.30363  detection_loss: 1.2305 (cls: 0.2265, box: 1.0040)  rpn_loss: 0.0732 (cls: 0.0305, box: 0.0427)
[2025-08-07 16:30:44 train.log] INFO: Epoch: [5]  [Step 12100/14540]  lr: 0.000096  loss: 2.06718  detection_loss: 1.9547 (cls: 0.4707, box: 1.4840)  rpn_loss: 0.1125 (cls: 0.0736, box: 0.0388)
[2025-08-07 16:30:49 train.log] INFO: Epoch: [5]  [Step 12200/14540]  lr: 0.000096  loss: 1.76082  detection_loss: 1.5240 (cls: 0.5169, box: 1.0070)  rpn_loss: 0.2368 (cls: 0.1977, box: 0.0392)
[2025-08-07 16:30:54 train.log] INFO: Epoch: [5]  [Step 12300/14540]  lr: 0.000096  loss: 1.74079  detection_loss: 1.5504 (cls: 0.3616, box: 1.1888)  rpn_loss: 0.1904 (cls: 0.1584, box: 0.0320)
[2025-08-07 16:30:59 train.log] INFO: Epoch: [5]  [Step 12400/14540]  lr: 0.000096  loss: 1.95311  detection_loss: 1.6670 (cls: 0.4426, box: 1.2243)  rpn_loss: 0.2861 (cls: 0.2577, box: 0.0284)
[2025-08-07 16:31:04 train.log] INFO: Epoch: [5]  [Step 12500/14540]  lr: 0.000096  loss: 1.41103  detection_loss: 1.2788 (cls: 0.1525, box: 1.1263)  rpn_loss: 0.1323 (cls: 0.0827, box: 0.0496)
[2025-08-07 16:31:09 train.log] INFO: Epoch: [5]  [Step 12600/14540]  lr: 0.000096  loss: 2.05107  detection_loss: 1.8293 (cls: 0.6855, box: 1.1438)  rpn_loss: 0.2218 (cls: 0.1837, box: 0.0381)
[2025-08-07 16:31:14 train.log] INFO: Epoch: [5]  [Step 12700/14540]  lr: 0.000096  loss: 0.97024  detection_loss: 0.9323 (cls: 0.1924, box: 0.7399)  rpn_loss: 0.0379 (cls: 0.0141, box: 0.0238)
[2025-08-07 16:31:19 train.log] INFO: Epoch: [5]  [Step 12800/14540]  lr: 0.000096  loss: 1.12455  detection_loss: 0.9920 (cls: 0.2312, box: 0.7608)  rpn_loss: 0.1325 (cls: 0.1120, box: 0.0205)
[2025-08-07 16:31:24 train.log] INFO: Epoch: [5]  [Step 12900/14540]  lr: 0.000096  loss: 1.45931  detection_loss: 1.3540 (cls: 0.3923, box: 0.9617)  rpn_loss: 0.1053 (cls: 0.0731, box: 0.0322)
[2025-08-07 16:31:29 train.log] INFO: Epoch: [5]  [Step 13000/14540]  lr: 0.000096  loss: 1.54921  detection_loss: 1.4929 (cls: 0.2841, box: 1.2088)  rpn_loss: 0.0563 (cls: 0.0384, box: 0.0179)
[2025-08-07 16:31:34 train.log] INFO: Epoch: [5]  [Step 13100/14540]  lr: 0.000096  loss: 1.52522  detection_loss: 1.2733 (cls: 0.4582, box: 0.8151)  rpn_loss: 0.2520 (cls: 0.0777, box: 0.1742)
[2025-08-07 16:31:39 train.log] INFO: Epoch: [5]  [Step 13200/14540]  lr: 0.000096  loss: 1.26679  detection_loss: 1.0551 (cls: 0.1847, box: 0.8704)  rpn_loss: 0.2116 (cls: 0.0393, box: 0.1723)
[2025-08-07 16:31:44 train.log] INFO: Epoch: [5]  [Step 13300/14540]  lr: 0.000096  loss: 1.52510  detection_loss: 1.1575 (cls: 0.3020, box: 0.8555)  rpn_loss: 0.3676 (cls: 0.0444, box: 0.3232)
[2025-08-07 16:31:49 train.log] INFO: Epoch: [5]  [Step 13400/14540]  lr: 0.000096  loss: 1.13550  detection_loss: 1.0522 (cls: 0.1832, box: 0.8690)  rpn_loss: 0.0833 (cls: 0.0366, box: 0.0467)
[2025-08-07 16:31:54 train.log] INFO: Epoch: [5]  [Step 13500/14540]  lr: 0.000096  loss: 1.51228  detection_loss: 1.4065 (cls: 0.5933, box: 0.8132)  rpn_loss: 0.1058 (cls: 0.0874, box: 0.0184)
[2025-08-07 16:31:59 train.log] INFO: Epoch: [5]  [Step 13600/14540]  lr: 0.000096  loss: 1.29138  detection_loss: 1.1615 (cls: 0.3348, box: 0.8266)  rpn_loss: 0.1299 (cls: 0.0916, box: 0.0383)
[2025-08-07 16:32:04 train.log] INFO: Epoch: [5]  [Step 13700/14540]  lr: 0.000096  loss: 1.17349  detection_loss: 1.0168 (cls: 0.2668, box: 0.7499)  rpn_loss: 0.1567 (cls: 0.0813, box: 0.0755)
[2025-08-07 16:32:09 train.log] INFO: Epoch: [5]  [Step 13800/14540]  lr: 0.000096  loss: 1.65105  detection_loss: 1.4632 (cls: 0.3164, box: 1.1468)  rpn_loss: 0.1879 (cls: 0.0536, box: 0.1342)
[2025-08-07 16:32:14 train.log] INFO: Epoch: [5]  [Step 13900/14540]  lr: 0.000096  loss: 0.89496  detection_loss: 0.6683 (cls: 0.2354, box: 0.4330)  rpn_loss: 0.2266 (cls: 0.0713, box: 0.1553)
[2025-08-07 16:32:19 train.log] INFO: Epoch: [5]  [Step 14000/14540]  lr: 0.000096  loss: 1.51026  detection_loss: 1.3257 (cls: 0.1756, box: 1.1501)  rpn_loss: 0.1846 (cls: 0.0524, box: 0.1322)
[2025-08-07 16:32:24 train.log] INFO: Epoch: [5]  [Step 14100/14540]  lr: 0.000096  loss: 1.57933  detection_loss: 1.4596 (cls: 0.3020, box: 1.1575)  rpn_loss: 0.1198 (cls: 0.0595, box: 0.0603)
[2025-08-07 16:32:28 train.log] INFO: Epoch: [5]  [Step 14200/14540]  lr: 0.000096  loss: 1.16594  detection_loss: 1.0564 (cls: 0.2936, box: 0.7628)  rpn_loss: 0.1096 (cls: 0.0439, box: 0.0656)
[2025-08-07 16:32:33 train.log] INFO: Epoch: [5]  [Step 14300/14540]  lr: 0.000096  loss: 1.82298  detection_loss: 1.6830 (cls: 0.4307, box: 1.2523)  rpn_loss: 0.1400 (cls: 0.0562, box: 0.0838)
[2025-08-07 16:32:38 train.log] INFO: Epoch: [5]  [Step 14400/14540]  lr: 0.000096  loss: 1.33825  detection_loss: 1.1321 (cls: 0.4511, box: 0.6810)  rpn_loss: 0.2062 (cls: 0.0912, box: 0.1149)
[2025-08-07 16:32:43 train.log] INFO: Epoch: [5]  [Step 14500/14540]  lr: 0.000096  loss: 1.31415  detection_loss: 1.2116 (cls: 0.2747, box: 0.9369)  rpn_loss: 0.1026 (cls: 0.0565, box: 0.0461)
[2025-08-07 16:35:44 train.log] INFO: Epoch: [6]  [Step 100/14540]  lr: 0.000093  loss: 1.31334  detection_loss: 1.0789 (cls: 0.2613, box: 0.8176)  rpn_loss: 0.2344 (cls: 0.1895, box: 0.0449)
[2025-08-07 16:35:49 train.log] INFO: Epoch: [6]  [Step 200/14540]  lr: 0.000093  loss: 1.39447  detection_loss: 1.2886 (cls: 0.2375, box: 1.0511)  rpn_loss: 0.1059 (cls: 0.0645, box: 0.0414)
[2025-08-07 16:35:54 train.log] INFO: Epoch: [6]  [Step 300/14540]  lr: 0.000093  loss: 1.43223  detection_loss: 1.2926 (cls: 0.3458, box: 0.9468)  rpn_loss: 0.1396 (cls: 0.1089, box: 0.0307)
[2025-08-07 16:35:59 train.log] INFO: Epoch: [6]  [Step 400/14540]  lr: 0.000093  loss: 1.81366  detection_loss: 1.5762 (cls: 0.2844, box: 1.2918)  rpn_loss: 0.2375 (cls: 0.1668, box: 0.0706)
[2025-08-07 16:36:04 train.log] INFO: Epoch: [6]  [Step 500/14540]  lr: 0.000093  loss: 1.54258  detection_loss: 1.2658 (cls: 0.4778, box: 0.7880)  rpn_loss: 0.2768 (cls: 0.0494, box: 0.2274)
[2025-08-07 16:36:09 train.log] INFO: Epoch: [6]  [Step 600/14540]  lr: 0.000093  loss: 1.13100  detection_loss: 1.0400 (cls: 0.2075, box: 0.8325)  rpn_loss: 0.0910 (cls: 0.0648, box: 0.0261)
[2025-08-07 16:36:14 train.log] INFO: Epoch: [6]  [Step 700/14540]  lr: 0.000093  loss: 1.69049  detection_loss: 1.5135 (cls: 0.4318, box: 1.0816)  rpn_loss: 0.1770 (cls: 0.1319, box: 0.0452)
[2025-08-07 16:36:19 train.log] INFO: Epoch: [6]  [Step 800/14540]  lr: 0.000093  loss: 1.00487  detection_loss: 0.9146 (cls: 0.2821, box: 0.6325)  rpn_loss: 0.0902 (cls: 0.0651, box: 0.0251)
[2025-08-07 16:36:24 train.log] INFO: Epoch: [6]  [Step 900/14540]  lr: 0.000093  loss: 1.75285  detection_loss: 1.4671 (cls: 0.2736, box: 1.1935)  rpn_loss: 0.2857 (cls: 0.0809, box: 0.2048)
[2025-08-07 16:36:29 train.log] INFO: Epoch: [6]  [Step 1000/14540]  lr: 0.000093  loss: 1.87305  detection_loss: 1.5751 (cls: 0.2711, box: 1.3040)  rpn_loss: 0.2979 (cls: 0.0593, box: 0.2386)
[2025-08-07 16:36:33 train.log] INFO: Epoch: [6]  [Step 1100/14540]  lr: 0.000093  loss: 1.40789  detection_loss: 1.3417 (cls: 0.2679, box: 1.0738)  rpn_loss: 0.0662 (cls: 0.0425, box: 0.0237)
[2025-08-07 16:36:38 train.log] INFO: Epoch: [6]  [Step 1200/14540]  lr: 0.000093  loss: 1.28014  detection_loss: 1.1686 (cls: 0.4130, box: 0.7555)  rpn_loss: 0.1116 (cls: 0.0839, box: 0.0277)
[2025-08-07 16:36:43 train.log] INFO: Epoch: [6]  [Step 1300/14540]  lr: 0.000093  loss: 1.38890  detection_loss: 1.3227 (cls: 0.1656, box: 1.1571)  rpn_loss: 0.0662 (cls: 0.0420, box: 0.0242)
[2025-08-07 16:36:48 train.log] INFO: Epoch: [6]  [Step 1400/14540]  lr: 0.000093  loss: 1.19931  detection_loss: 1.0733 (cls: 0.2846, box: 0.7887)  rpn_loss: 0.1260 (cls: 0.0398, box: 0.0862)
[2025-08-07 16:36:53 train.log] INFO: Epoch: [6]  [Step 1500/14540]  lr: 0.000093  loss: 1.49692  detection_loss: 1.3389 (cls: 0.3080, box: 1.0309)  rpn_loss: 0.1580 (cls: 0.0930, box: 0.0650)
[2025-08-07 16:36:57 train.log] INFO: Epoch: [6]  [Step 1600/14540]  lr: 0.000093  loss: 1.16569  detection_loss: 1.0676 (cls: 0.3403, box: 0.7274)  rpn_loss: 0.0980 (cls: 0.0330, box: 0.0650)
[2025-08-07 16:37:02 train.log] INFO: Epoch: [6]  [Step 1700/14540]  lr: 0.000093  loss: 1.41606  detection_loss: 1.3169 (cls: 0.2694, box: 1.0475)  rpn_loss: 0.0991 (cls: 0.0495, box: 0.0496)
[2025-08-07 16:37:07 train.log] INFO: Epoch: [6]  [Step 1800/14540]  lr: 0.000093  loss: 1.57196  detection_loss: 1.3721 (cls: 0.3536, box: 1.0185)  rpn_loss: 0.1999 (cls: 0.0517, box: 0.1482)
[2025-08-07 16:37:12 train.log] INFO: Epoch: [6]  [Step 1900/14540]  lr: 0.000093  loss: 1.06406  detection_loss: 0.9129 (cls: 0.1912, box: 0.7217)  rpn_loss: 0.1511 (cls: 0.0385, box: 0.1126)
[2025-08-07 16:37:17 train.log] INFO: Epoch: [6]  [Step 2000/14540]  lr: 0.000093  loss: 0.90130  detection_loss: 0.8195 (cls: 0.1543, box: 0.6652)  rpn_loss: 0.0818 (cls: 0.0322, box: 0.0496)
[2025-08-07 16:37:22 train.log] INFO: Epoch: [6]  [Step 2100/14540]  lr: 0.000093  loss: 1.30149  detection_loss: 1.1205 (cls: 0.2498, box: 0.8707)  rpn_loss: 0.1810 (cls: 0.0933, box: 0.0877)
[2025-08-07 16:37:27 train.log] INFO: Epoch: [6]  [Step 2200/14540]  lr: 0.000093  loss: 1.30687  detection_loss: 1.1682 (cls: 0.2464, box: 0.9217)  rpn_loss: 0.1387 (cls: 0.0482, box: 0.0905)
[2025-08-07 16:37:32 train.log] INFO: Epoch: [6]  [Step 2300/14540]  lr: 0.000093  loss: 1.23924  detection_loss: 1.0392 (cls: 0.3698, box: 0.6694)  rpn_loss: 0.2000 (cls: 0.0781, box: 0.1220)
[2025-08-07 16:37:37 train.log] INFO: Epoch: [6]  [Step 2400/14540]  lr: 0.000093  loss: 1.49806  detection_loss: 1.2185 (cls: 0.3014, box: 0.9171)  rpn_loss: 0.2796 (cls: 0.0773, box: 0.2023)
[2025-08-07 16:37:42 train.log] INFO: Epoch: [6]  [Step 2500/14540]  lr: 0.000093  loss: 1.64350  detection_loss: 1.5420 (cls: 0.4354, box: 1.1066)  rpn_loss: 0.1015 (cls: 0.0390, box: 0.0626)
[2025-08-07 16:37:47 train.log] INFO: Epoch: [6]  [Step 2600/14540]  lr: 0.000093  loss: 1.01048  detection_loss: 0.8834 (cls: 0.2216, box: 0.6617)  rpn_loss: 0.1271 (cls: 0.0556, box: 0.0715)
[2025-08-07 16:37:52 train.log] INFO: Epoch: [6]  [Step 2700/14540]  lr: 0.000093  loss: 1.77779  detection_loss: 1.5978 (cls: 0.2969, box: 1.3009)  rpn_loss: 0.1800 (cls: 0.0522, box: 0.1278)
[2025-08-07 16:37:57 train.log] INFO: Epoch: [6]  [Step 2800/14540]  lr: 0.000093  loss: 1.20543  detection_loss: 1.1191 (cls: 0.2613, box: 0.8577)  rpn_loss: 0.0864 (cls: 0.0614, box: 0.0250)
[2025-08-07 16:38:02 train.log] INFO: Epoch: [6]  [Step 2900/14540]  lr: 0.000093  loss: 1.18218  detection_loss: 1.0743 (cls: 0.1505, box: 0.9238)  rpn_loss: 0.1079 (cls: 0.0186, box: 0.0893)
[2025-08-07 16:38:07 train.log] INFO: Epoch: [6]  [Step 3000/14540]  lr: 0.000093  loss: 1.68276  detection_loss: 1.5559 (cls: 0.3316, box: 1.2242)  rpn_loss: 0.1269 (cls: 0.0625, box: 0.0644)
[2025-08-07 16:38:12 train.log] INFO: Epoch: [6]  [Step 3100/14540]  lr: 0.000093  loss: 1.34180  detection_loss: 1.2063 (cls: 0.2470, box: 0.9593)  rpn_loss: 0.1355 (cls: 0.1085, box: 0.0270)
[2025-08-07 16:38:17 train.log] INFO: Epoch: [6]  [Step 3200/14540]  lr: 0.000093  loss: 2.05817  detection_loss: 1.8009 (cls: 0.7033, box: 1.0976)  rpn_loss: 0.2573 (cls: 0.1988, box: 0.0585)
[2025-08-07 16:38:22 train.log] INFO: Epoch: [6]  [Step 3300/14540]  lr: 0.000093  loss: 1.62016  detection_loss: 1.4628 (cls: 0.4366, box: 1.0263)  rpn_loss: 0.1574 (cls: 0.0766, box: 0.0808)
[2025-08-07 16:38:27 train.log] INFO: Epoch: [6]  [Step 3400/14540]  lr: 0.000093  loss: 1.50073  detection_loss: 1.3343 (cls: 0.3912, box: 0.9431)  rpn_loss: 0.1664 (cls: 0.1222, box: 0.0442)
[2025-08-07 16:38:32 train.log] INFO: Epoch: [6]  [Step 3500/14540]  lr: 0.000093  loss: 0.88045  detection_loss: 0.7846 (cls: 0.1879, box: 0.5967)  rpn_loss: 0.0959 (cls: 0.0483, box: 0.0476)
[2025-08-07 16:38:37 train.log] INFO: Epoch: [6]  [Step 3600/14540]  lr: 0.000093  loss: 1.91974  detection_loss: 1.7628 (cls: 0.5687, box: 1.1941)  rpn_loss: 0.1570 (cls: 0.1364, box: 0.0206)
[2025-08-07 16:38:39 train.log] INFO: Epoch: [6]  [Step 3635/14540]  lr: 0.000093  loss: 1.28895  detection_loss: 1.1862 (cls: 0.2882, box: 0.8980)  rpn_loss: 0.1027 (cls: 0.0685, box: 0.0342)
[2025-08-07 16:38:42 train.log] INFO: Epoch: [6]  [Step 3700/14540]  lr: 0.000093  loss: 1.72586  detection_loss: 1.5395 (cls: 0.3609, box: 1.1786)  rpn_loss: 0.1864 (cls: 0.1539, box: 0.0325)
[2025-08-07 16:38:47 train.log] INFO: Epoch: [6]  [Step 3800/14540]  lr: 0.000093  loss: 0.94924  detection_loss: 0.8482 (cls: 0.2698, box: 0.5785)  rpn_loss: 0.1010 (cls: 0.0689, box: 0.0321)
[2025-08-07 16:38:52 train.log] INFO: Epoch: [6]  [Step 3900/14540]  lr: 0.000093  loss: 1.08239  detection_loss: 0.9698 (cls: 0.2564, box: 0.7134)  rpn_loss: 0.1126 (cls: 0.0846, box: 0.0280)
[2025-08-07 16:38:57 train.log] INFO: Epoch: [6]  [Step 4000/14540]  lr: 0.000093  loss: 1.16499  detection_loss: 1.0845 (cls: 0.2062, box: 0.8783)  rpn_loss: 0.0805 (cls: 0.0312, box: 0.0492)
[2025-08-07 16:39:02 train.log] INFO: Epoch: [6]  [Step 4100/14540]  lr: 0.000093  loss: 1.83212  detection_loss: 1.6639 (cls: 0.4374, box: 1.2265)  rpn_loss: 0.1682 (cls: 0.1422, box: 0.0260)
[2025-08-07 16:39:06 train.log] INFO: Epoch: [6]  [Step 4200/14540]  lr: 0.000093  loss: 0.69514  detection_loss: 0.5835 (cls: 0.1264, box: 0.4570)  rpn_loss: 0.1117 (cls: 0.0533, box: 0.0584)
[2025-08-07 16:39:12 train.log] INFO: Epoch: [6]  [Step 4300/14540]  lr: 0.000093  loss: 1.23060  detection_loss: 1.1222 (cls: 0.1766, box: 0.9455)  rpn_loss: 0.1084 (cls: 0.0724, box: 0.0360)
[2025-08-07 16:39:17 train.log] INFO: Epoch: [6]  [Step 4400/14540]  lr: 0.000093  loss: 1.92536  detection_loss: 1.7806 (cls: 0.5077, box: 1.2729)  rpn_loss: 0.1448 (cls: 0.0555, box: 0.0893)
[2025-08-07 16:39:22 train.log] INFO: Epoch: [6]  [Step 4500/14540]  lr: 0.000093  loss: 1.01966  detection_loss: 0.9226 (cls: 0.1489, box: 0.7737)  rpn_loss: 0.0971 (cls: 0.0503, box: 0.0468)
[2025-08-07 16:39:26 train.log] INFO: Epoch: [6]  [Step 4600/14540]  lr: 0.000093  loss: 0.72709  detection_loss: 0.6564 (cls: 0.2287, box: 0.4277)  rpn_loss: 0.0707 (cls: 0.0508, box: 0.0200)
[2025-08-07 16:39:32 train.log] INFO: Epoch: [6]  [Step 4700/14540]  lr: 0.000093  loss: 1.68011  detection_loss: 1.5934 (cls: 0.1930, box: 1.4004)  rpn_loss: 0.0868 (cls: 0.0437, box: 0.0430)
[2025-08-07 16:39:37 train.log] INFO: Epoch: [6]  [Step 4800/14540]  lr: 0.000093  loss: 1.07909  detection_loss: 0.9974 (cls: 0.2166, box: 0.7807)  rpn_loss: 0.0817 (cls: 0.0565, box: 0.0252)
[2025-08-07 16:39:42 train.log] INFO: Epoch: [6]  [Step 4900/14540]  lr: 0.000093  loss: 2.25792  detection_loss: 2.0425 (cls: 0.6167, box: 1.4258)  rpn_loss: 0.2154 (cls: 0.0699, box: 0.1455)
[2025-08-07 16:39:47 train.log] INFO: Epoch: [6]  [Step 5000/14540]  lr: 0.000093  loss: 1.45852  detection_loss: 1.2747 (cls: 0.2421, box: 1.0326)  rpn_loss: 0.1838 (cls: 0.0698, box: 0.1139)
[2025-08-07 16:39:52 train.log] INFO: Epoch: [6]  [Step 5100/14540]  lr: 0.000093  loss: 1.88426  detection_loss: 1.6959 (cls: 0.3933, box: 1.3027)  rpn_loss: 0.1883 (cls: 0.0609, box: 0.1274)
[2025-08-07 16:39:57 train.log] INFO: Epoch: [6]  [Step 5200/14540]  lr: 0.000093  loss: 0.95390  detection_loss: 0.8836 (cls: 0.2895, box: 0.5941)  rpn_loss: 0.0703 (cls: 0.0488, box: 0.0215)
[2025-08-07 16:40:02 train.log] INFO: Epoch: [6]  [Step 5300/14540]  lr: 0.000093  loss: 0.87386  detection_loss: 0.7903 (cls: 0.1736, box: 0.6167)  rpn_loss: 0.0836 (cls: 0.0419, box: 0.0417)
[2025-08-07 16:40:07 train.log] INFO: Epoch: [6]  [Step 5400/14540]  lr: 0.000093  loss: 1.98944  detection_loss: 1.8255 (cls: 0.6284, box: 1.1971)  rpn_loss: 0.1639 (cls: 0.0974, box: 0.0665)
[2025-08-07 16:40:12 train.log] INFO: Epoch: [6]  [Step 5500/14540]  lr: 0.000093  loss: 0.93215  detection_loss: 0.8474 (cls: 0.2341, box: 0.6133)  rpn_loss: 0.0848 (cls: 0.0460, box: 0.0388)
[2025-08-07 16:40:17 train.log] INFO: Epoch: [6]  [Step 5600/14540]  lr: 0.000093  loss: 1.33729  detection_loss: 1.1334 (cls: 0.2103, box: 0.9231)  rpn_loss: 0.2039 (cls: 0.0190, box: 0.1848)
[2025-08-07 16:40:22 train.log] INFO: Epoch: [6]  [Step 5700/14540]  lr: 0.000093  loss: 1.83685  detection_loss: 1.6365 (cls: 0.3514, box: 1.2850)  rpn_loss: 0.2004 (cls: 0.0454, box: 0.1550)
[2025-08-07 16:40:27 train.log] INFO: Epoch: [6]  [Step 5800/14540]  lr: 0.000093  loss: 1.51970  detection_loss: 1.3100 (cls: 0.1967, box: 1.1133)  rpn_loss: 0.2097 (cls: 0.0494, box: 0.1604)
[2025-08-07 16:40:32 train.log] INFO: Epoch: [6]  [Step 5900/14540]  lr: 0.000093  loss: 1.38048  detection_loss: 1.2252 (cls: 0.2910, box: 0.9342)  rpn_loss: 0.1553 (cls: 0.0561, box: 0.0992)
[2025-08-07 16:40:37 train.log] INFO: Epoch: [6]  [Step 6000/14540]  lr: 0.000093  loss: 1.84455  detection_loss: 1.7413 (cls: 0.4771, box: 1.2642)  rpn_loss: 0.1033 (cls: 0.0641, box: 0.0391)
[2025-08-07 16:40:42 train.log] INFO: Epoch: [6]  [Step 6100/14540]  lr: 0.000093  loss: 1.35397  detection_loss: 1.1819 (cls: 0.2498, box: 0.9321)  rpn_loss: 0.1721 (cls: 0.0969, box: 0.0752)
[2025-08-07 16:40:47 train.log] INFO: Epoch: [6]  [Step 6200/14540]  lr: 0.000093  loss: 1.74382  detection_loss: 1.5644 (cls: 0.4042, box: 1.1602)  rpn_loss: 0.1794 (cls: 0.1338, box: 0.0456)
[2025-08-07 16:40:52 train.log] INFO: Epoch: [6]  [Step 6300/14540]  lr: 0.000093  loss: 1.63007  detection_loss: 1.3028 (cls: 0.2646, box: 1.0382)  rpn_loss: 0.3273 (cls: 0.0437, box: 0.2836)
[2025-08-07 16:40:56 train.log] INFO: Epoch: [6]  [Step 6400/14540]  lr: 0.000093  loss: 1.39366  detection_loss: 1.2842 (cls: 0.2249, box: 1.0593)  rpn_loss: 0.1095 (cls: 0.0642, box: 0.0453)
[2025-08-07 16:41:01 train.log] INFO: Epoch: [6]  [Step 6500/14540]  lr: 0.000093  loss: 0.99164  detection_loss: 0.9178 (cls: 0.1820, box: 0.7358)  rpn_loss: 0.0738 (cls: 0.0408, box: 0.0331)
[2025-08-07 16:41:06 train.log] INFO: Epoch: [6]  [Step 6600/14540]  lr: 0.000093  loss: 1.29010  detection_loss: 1.1551 (cls: 0.2626, box: 0.8925)  rpn_loss: 0.1350 (cls: 0.0797, box: 0.0553)
[2025-08-07 16:41:11 train.log] INFO: Epoch: [6]  [Step 6700/14540]  lr: 0.000093  loss: 1.16280  detection_loss: 1.0881 (cls: 0.1558, box: 0.9323)  rpn_loss: 0.0747 (cls: 0.0294, box: 0.0454)
[2025-08-07 16:41:16 train.log] INFO: Epoch: [6]  [Step 6800/14540]  lr: 0.000093  loss: 1.48898  detection_loss: 1.4113 (cls: 0.3892, box: 1.0221)  rpn_loss: 0.0777 (cls: 0.0410, box: 0.0367)
[2025-08-07 16:41:21 train.log] INFO: Epoch: [6]  [Step 6900/14540]  lr: 0.000093  loss: 2.07601  detection_loss: 1.9661 (cls: 0.4629, box: 1.5032)  rpn_loss: 0.1099 (cls: 0.0614, box: 0.0484)
[2025-08-07 16:41:26 train.log] INFO: Epoch: [6]  [Step 7000/14540]  lr: 0.000093  loss: 1.75996  detection_loss: 1.6266 (cls: 0.4418, box: 1.1847)  rpn_loss: 0.1334 (cls: 0.0686, box: 0.0648)
[2025-08-07 16:41:31 train.log] INFO: Epoch: [6]  [Step 7100/14540]  lr: 0.000093  loss: 1.26660  detection_loss: 1.2161 (cls: 0.3844, box: 0.8317)  rpn_loss: 0.0505 (cls: 0.0348, box: 0.0157)
[2025-08-07 16:41:36 train.log] INFO: Epoch: [6]  [Step 7200/14540]  lr: 0.000093  loss: 1.50124  detection_loss: 1.3231 (cls: 0.4250, box: 0.8981)  rpn_loss: 0.1782 (cls: 0.0849, box: 0.0933)
[2025-08-07 16:41:41 train.log] INFO: Epoch: [6]  [Step 7300/14540]  lr: 0.000093  loss: 1.65672  detection_loss: 1.5697 (cls: 0.2882, box: 1.2815)  rpn_loss: 0.0870 (cls: 0.0547, box: 0.0323)
[2025-08-07 16:41:46 train.log] INFO: Epoch: [6]  [Step 7400/14540]  lr: 0.000093  loss: 1.59933  detection_loss: 1.4715 (cls: 0.3700, box: 1.1015)  rpn_loss: 0.1278 (cls: 0.0748, box: 0.0531)
[2025-08-07 16:41:51 train.log] INFO: Epoch: [6]  [Step 7500/14540]  lr: 0.000093  loss: 1.59791  detection_loss: 1.4439 (cls: 0.4270, box: 1.0169)  rpn_loss: 0.1540 (cls: 0.1110, box: 0.0430)
[2025-08-07 16:41:56 train.log] INFO: Epoch: [6]  [Step 7600/14540]  lr: 0.000093  loss: 1.92199  detection_loss: 1.7697 (cls: 0.4689, box: 1.3008)  rpn_loss: 0.1523 (cls: 0.0817, box: 0.0706)
[2025-08-07 16:42:01 train.log] INFO: Epoch: [6]  [Step 7700/14540]  lr: 0.000093  loss: 1.40645  detection_loss: 1.2703 (cls: 0.2313, box: 1.0390)  rpn_loss: 0.1362 (cls: 0.1095, box: 0.0267)
[2025-08-07 16:42:06 train.log] INFO: Epoch: [6]  [Step 7800/14540]  lr: 0.000093  loss: 2.06787  detection_loss: 1.8846 (cls: 0.3457, box: 1.5389)  rpn_loss: 0.1833 (cls: 0.0439, box: 0.1393)
[2025-08-07 16:42:11 train.log] INFO: Epoch: [6]  [Step 7900/14540]  lr: 0.000093  loss: 1.28079  detection_loss: 1.1765 (cls: 0.2252, box: 0.9513)  rpn_loss: 0.1042 (cls: 0.0499, box: 0.0544)
[2025-08-07 16:42:16 train.log] INFO: Epoch: [6]  [Step 8000/14540]  lr: 0.000093  loss: 1.47135  detection_loss: 1.1073 (cls: 0.4485, box: 0.6588)  rpn_loss: 0.3641 (cls: 0.0930, box: 0.2711)
[2025-08-07 16:42:21 train.log] INFO: Epoch: [6]  [Step 8100/14540]  lr: 0.000093  loss: 1.03893  detection_loss: 0.9052 (cls: 0.2729, box: 0.6323)  rpn_loss: 0.1338 (cls: 0.0413, box: 0.0925)
[2025-08-07 16:42:26 train.log] INFO: Epoch: [6]  [Step 8200/14540]  lr: 0.000093  loss: 1.54103  detection_loss: 1.2979 (cls: 0.3027, box: 0.9952)  rpn_loss: 0.2431 (cls: 0.1686, box: 0.0745)
[2025-08-07 16:42:31 train.log] INFO: Epoch: [6]  [Step 8300/14540]  lr: 0.000093  loss: 1.65812  detection_loss: 1.4613 (cls: 0.4639, box: 0.9975)  rpn_loss: 0.1968 (cls: 0.1505, box: 0.0463)
[2025-08-07 16:42:36 train.log] INFO: Epoch: [6]  [Step 8400/14540]  lr: 0.000093  loss: 1.77239  detection_loss: 1.6484 (cls: 0.2720, box: 1.3765)  rpn_loss: 0.1239 (cls: 0.0325, box: 0.0914)
[2025-08-07 16:42:41 train.log] INFO: Epoch: [6]  [Step 8500/14540]  lr: 0.000093  loss: 1.13650  detection_loss: 0.9968 (cls: 0.2284, box: 0.7685)  rpn_loss: 0.1397 (cls: 0.0788, box: 0.0609)
[2025-08-07 16:42:46 train.log] INFO: Epoch: [6]  [Step 8600/14540]  lr: 0.000093  loss: 1.65121  detection_loss: 1.5123 (cls: 0.2217, box: 1.2906)  rpn_loss: 0.1389 (cls: 0.0354, box: 0.1035)
[2025-08-07 16:42:51 train.log] INFO: Epoch: [6]  [Step 8700/14540]  lr: 0.000093  loss: 1.60410  detection_loss: 1.5152 (cls: 0.3140, box: 1.2012)  rpn_loss: 0.0889 (cls: 0.0661, box: 0.0228)
[2025-08-07 16:42:56 train.log] INFO: Epoch: [6]  [Step 8800/14540]  lr: 0.000093  loss: 1.59799  detection_loss: 1.4792 (cls: 0.3123, box: 1.1668)  rpn_loss: 0.1188 (cls: 0.0576, box: 0.0612)
[2025-08-07 16:43:00 train.log] INFO: Epoch: [6]  [Step 8900/14540]  lr: 0.000093  loss: 1.54695  detection_loss: 1.4005 (cls: 0.3120, box: 1.0885)  rpn_loss: 0.1464 (cls: 0.0591, box: 0.0873)
[2025-08-07 16:43:05 train.log] INFO: Epoch: [6]  [Step 9000/14540]  lr: 0.000093  loss: 1.25172  detection_loss: 1.1281 (cls: 0.2051, box: 0.9230)  rpn_loss: 0.1236 (cls: 0.0270, box: 0.0966)
[2025-08-07 16:43:10 train.log] INFO: Epoch: [6]  [Step 9100/14540]  lr: 0.000093  loss: 1.58661  detection_loss: 1.4707 (cls: 0.4824, box: 0.9883)  rpn_loss: 0.1159 (cls: 0.0841, box: 0.0318)
[2025-08-07 16:43:15 train.log] INFO: Epoch: [6]  [Step 9200/14540]  lr: 0.000093  loss: 1.21775  detection_loss: 1.1208 (cls: 0.3109, box: 0.8099)  rpn_loss: 0.0970 (cls: 0.0682, box: 0.0287)
[2025-08-07 16:43:20 train.log] INFO: Epoch: [6]  [Step 9300/14540]  lr: 0.000093  loss: 1.54513  detection_loss: 1.4034 (cls: 0.3052, box: 1.0982)  rpn_loss: 0.1417 (cls: 0.0519, box: 0.0898)
[2025-08-07 16:43:25 train.log] INFO: Epoch: [6]  [Step 9400/14540]  lr: 0.000093  loss: 1.44147  detection_loss: 1.2661 (cls: 0.2477, box: 1.0185)  rpn_loss: 0.1753 (cls: 0.0338, box: 0.1416)
[2025-08-07 16:43:29 train.log] INFO: Epoch: [6]  [Step 9500/14540]  lr: 0.000093  loss: 1.51559  detection_loss: 1.3917 (cls: 0.4281, box: 0.9636)  rpn_loss: 0.1239 (cls: 0.0751, box: 0.0488)
[2025-08-07 16:43:34 train.log] INFO: Epoch: [6]  [Step 9600/14540]  lr: 0.000093  loss: 1.18673  detection_loss: 1.1099 (cls: 0.1860, box: 0.9239)  rpn_loss: 0.0768 (cls: 0.0316, box: 0.0453)
[2025-08-07 16:43:39 train.log] INFO: Epoch: [6]  [Step 9700/14540]  lr: 0.000093  loss: 1.13990  detection_loss: 1.0230 (cls: 0.3404, box: 0.6826)  rpn_loss: 0.1169 (cls: 0.0726, box: 0.0443)
[2025-08-07 16:43:44 train.log] INFO: Epoch: [6]  [Step 9800/14540]  lr: 0.000093  loss: 1.03923  detection_loss: 0.8714 (cls: 0.2299, box: 0.6415)  rpn_loss: 0.1678 (cls: 0.1041, box: 0.0638)
[2025-08-07 16:43:49 train.log] INFO: Epoch: [6]  [Step 9900/14540]  lr: 0.000093  loss: 1.04135  detection_loss: 0.9130 (cls: 0.2459, box: 0.6671)  rpn_loss: 0.1283 (cls: 0.0652, box: 0.0631)
[2025-08-07 16:43:54 train.log] INFO: Epoch: [6]  [Step 10000/14540]  lr: 0.000093  loss: 1.42678  detection_loss: 1.2547 (cls: 0.2105, box: 1.0442)  rpn_loss: 0.1721 (cls: 0.0366, box: 0.1354)
[2025-08-07 16:43:59 train.log] INFO: Epoch: [6]  [Step 10100/14540]  lr: 0.000093  loss: 0.91117  detection_loss: 0.8495 (cls: 0.1834, box: 0.6661)  rpn_loss: 0.0617 (cls: 0.0319, box: 0.0298)
[2025-08-07 16:44:04 train.log] INFO: Epoch: [6]  [Step 10200/14540]  lr: 0.000093  loss: 0.91155  detection_loss: 0.8340 (cls: 0.1527, box: 0.6814)  rpn_loss: 0.0775 (cls: 0.0335, box: 0.0440)
[2025-08-07 16:44:09 train.log] INFO: Epoch: [6]  [Step 10300/14540]  lr: 0.000093  loss: 1.45215  detection_loss: 1.2129 (cls: 0.4150, box: 0.7979)  rpn_loss: 0.2393 (cls: 0.1319, box: 0.1074)
[2025-08-07 16:44:14 train.log] INFO: Epoch: [6]  [Step 10400/14540]  lr: 0.000093  loss: 1.58456  detection_loss: 1.4914 (cls: 0.4224, box: 1.0690)  rpn_loss: 0.0932 (cls: 0.0676, box: 0.0255)
[2025-08-07 16:44:19 train.log] INFO: Epoch: [6]  [Step 10500/14540]  lr: 0.000093  loss: 1.36910  detection_loss: 1.2133 (cls: 0.1648, box: 1.0486)  rpn_loss: 0.1558 (cls: 0.0551, box: 0.1007)
[2025-08-07 16:44:24 train.log] INFO: Epoch: [6]  [Step 10600/14540]  lr: 0.000093  loss: 1.44262  detection_loss: 1.2910 (cls: 0.3517, box: 0.9393)  rpn_loss: 0.1516 (cls: 0.1228, box: 0.0288)
[2025-08-07 16:44:29 train.log] INFO: Epoch: [6]  [Step 10700/14540]  lr: 0.000093  loss: 1.54554  detection_loss: 1.4519 (cls: 0.3273, box: 1.1246)  rpn_loss: 0.0937 (cls: 0.0507, box: 0.0430)
[2025-08-07 16:44:34 train.log] INFO: Epoch: [6]  [Step 10800/14540]  lr: 0.000093  loss: 1.60936  detection_loss: 1.4965 (cls: 0.3553, box: 1.1411)  rpn_loss: 0.1129 (cls: 0.0659, box: 0.0470)
[2025-08-07 16:44:39 train.log] INFO: Epoch: [6]  [Step 10900/14540]  lr: 0.000093  loss: 1.37753  detection_loss: 1.2148 (cls: 0.2988, box: 0.9160)  rpn_loss: 0.1627 (cls: 0.0430, box: 0.1198)
[2025-08-07 16:44:44 train.log] INFO: Epoch: [6]  [Step 11000/14540]  lr: 0.000093  loss: 0.89440  detection_loss: 0.8391 (cls: 0.1259, box: 0.7133)  rpn_loss: 0.0552 (cls: 0.0302, box: 0.0250)
[2025-08-07 16:44:49 train.log] INFO: Epoch: [6]  [Step 11100/14540]  lr: 0.000093  loss: 1.07121  detection_loss: 0.9800 (cls: 0.1788, box: 0.8013)  rpn_loss: 0.0912 (cls: 0.0279, box: 0.0633)
[2025-08-07 16:44:54 train.log] INFO: Epoch: [6]  [Step 11200/14540]  lr: 0.000093  loss: 1.00350  detection_loss: 0.9198 (cls: 0.2340, box: 0.6858)  rpn_loss: 0.0837 (cls: 0.0495, box: 0.0342)
[2025-08-07 16:44:59 train.log] INFO: Epoch: [6]  [Step 11300/14540]  lr: 0.000093  loss: 1.27292  detection_loss: 1.1247 (cls: 0.1959, box: 0.9288)  rpn_loss: 0.1482 (cls: 0.0524, box: 0.0958)
[2025-08-07 16:45:04 train.log] INFO: Epoch: [6]  [Step 11400/14540]  lr: 0.000093  loss: 1.86505  detection_loss: 1.6836 (cls: 0.4814, box: 1.2022)  rpn_loss: 0.1815 (cls: 0.0542, box: 0.1273)
[2025-08-07 16:45:09 train.log] INFO: Epoch: [6]  [Step 11500/14540]  lr: 0.000093  loss: 1.87936  detection_loss: 1.7330 (cls: 0.3200, box: 1.4130)  rpn_loss: 0.1463 (cls: 0.0761, box: 0.0702)
[2025-08-07 16:45:14 train.log] INFO: Epoch: [6]  [Step 11600/14540]  lr: 0.000093  loss: 0.99348  detection_loss: 0.8870 (cls: 0.2536, box: 0.6333)  rpn_loss: 0.1065 (cls: 0.0722, box: 0.0343)
[2025-08-07 16:45:19 train.log] INFO: Epoch: [6]  [Step 11700/14540]  lr: 0.000093  loss: 1.09742  detection_loss: 0.9114 (cls: 0.2611, box: 0.6503)  rpn_loss: 0.1860 (cls: 0.0684, box: 0.1177)
[2025-08-07 16:45:24 train.log] INFO: Epoch: [6]  [Step 11800/14540]  lr: 0.000093  loss: 1.05836  detection_loss: 0.9730 (cls: 0.2348, box: 0.7382)  rpn_loss: 0.0853 (cls: 0.0353, box: 0.0500)
[2025-08-07 16:45:29 train.log] INFO: Epoch: [6]  [Step 11900/14540]  lr: 0.000093  loss: 1.18262  detection_loss: 1.0476 (cls: 0.2562, box: 0.7914)  rpn_loss: 0.1350 (cls: 0.1052, box: 0.0298)
[2025-08-07 16:45:34 train.log] INFO: Epoch: [6]  [Step 12000/14540]  lr: 0.000093  loss: 1.81122  detection_loss: 1.6751 (cls: 0.4344, box: 1.2408)  rpn_loss: 0.1361 (cls: 0.0979, box: 0.0382)
[2025-08-07 16:45:39 train.log] INFO: Epoch: [6]  [Step 12100/14540]  lr: 0.000093  loss: 1.49825  detection_loss: 1.3219 (cls: 0.4106, box: 0.9114)  rpn_loss: 0.1763 (cls: 0.1034, box: 0.0729)
[2025-08-07 16:45:44 train.log] INFO: Epoch: [6]  [Step 12200/14540]  lr: 0.000093  loss: 2.49590  detection_loss: 1.9504 (cls: 0.4303, box: 1.5201)  rpn_loss: 0.5455 (cls: 0.0775, box: 0.4680)
[2025-08-07 16:45:49 train.log] INFO: Epoch: [6]  [Step 12300/14540]  lr: 0.000093  loss: 2.10788  detection_loss: 1.9693 (cls: 0.2287, box: 1.7405)  rpn_loss: 0.1386 (cls: 0.0862, box: 0.0525)
[2025-08-07 16:45:54 train.log] INFO: Epoch: [6]  [Step 12400/14540]  lr: 0.000093  loss: 1.21037  detection_loss: 1.1383 (cls: 0.1583, box: 0.9800)  rpn_loss: 0.0720 (cls: 0.0180, box: 0.0541)
[2025-08-07 16:45:59 train.log] INFO: Epoch: [6]  [Step 12500/14540]  lr: 0.000093  loss: 1.25740  detection_loss: 1.0953 (cls: 0.3502, box: 0.7451)  rpn_loss: 0.1621 (cls: 0.0602, box: 0.1019)
[2025-08-07 16:46:04 train.log] INFO: Epoch: [6]  [Step 12600/14540]  lr: 0.000093  loss: 1.03680  detection_loss: 0.9346 (cls: 0.2166, box: 0.7180)  rpn_loss: 0.1022 (cls: 0.0519, box: 0.0502)
[2025-08-07 16:46:09 train.log] INFO: Epoch: [6]  [Step 12700/14540]  lr: 0.000093  loss: 1.31885  detection_loss: 1.2136 (cls: 0.3665, box: 0.8471)  rpn_loss: 0.1052 (cls: 0.0410, box: 0.0642)
[2025-08-07 16:46:14 train.log] INFO: Epoch: [6]  [Step 12800/14540]  lr: 0.000093  loss: 1.99177  detection_loss: 1.8938 (cls: 0.6058, box: 1.2880)  rpn_loss: 0.0980 (cls: 0.0682, box: 0.0297)
[2025-08-07 16:46:19 train.log] INFO: Epoch: [6]  [Step 12900/14540]  lr: 0.000093  loss: 1.11051  detection_loss: 0.9441 (cls: 0.2443, box: 0.6999)  rpn_loss: 0.1664 (cls: 0.0278, box: 0.1386)
[2025-08-07 16:46:24 train.log] INFO: Epoch: [6]  [Step 13000/14540]  lr: 0.000093  loss: 0.87399  detection_loss: 0.7429 (cls: 0.1888, box: 0.5540)  rpn_loss: 0.1311 (cls: 0.0564, box: 0.0747)
[2025-08-07 16:46:29 train.log] INFO: Epoch: [6]  [Step 13100/14540]  lr: 0.000093  loss: 1.47144  detection_loss: 1.3521 (cls: 0.3712, box: 0.9809)  rpn_loss: 0.1193 (cls: 0.0561, box: 0.0632)
[2025-08-07 16:46:34 train.log] INFO: Epoch: [6]  [Step 13200/14540]  lr: 0.000093  loss: 1.13895  detection_loss: 1.0222 (cls: 0.1620, box: 0.8602)  rpn_loss: 0.1168 (cls: 0.0463, box: 0.0705)
[2025-08-07 16:46:39 train.log] INFO: Epoch: [6]  [Step 13300/14540]  lr: 0.000093  loss: 1.74355  detection_loss: 1.6094 (cls: 0.3056, box: 1.3038)  rpn_loss: 0.1341 (cls: 0.0584, box: 0.0757)
[2025-08-07 16:46:44 train.log] INFO: Epoch: [6]  [Step 13400/14540]  lr: 0.000093  loss: 1.76109  detection_loss: 1.6152 (cls: 0.4706, box: 1.1446)  rpn_loss: 0.1459 (cls: 0.1251, box: 0.0208)
[2025-08-07 16:46:49 train.log] INFO: Epoch: [6]  [Step 13500/14540]  lr: 0.000093  loss: 1.21201  detection_loss: 1.1225 (cls: 0.3353, box: 0.7872)  rpn_loss: 0.0895 (cls: 0.0714, box: 0.0181)
[2025-08-07 16:46:54 train.log] INFO: Epoch: [6]  [Step 13600/14540]  lr: 0.000093  loss: 1.32020  detection_loss: 1.2196 (cls: 0.2207, box: 0.9989)  rpn_loss: 0.1006 (cls: 0.0704, box: 0.0303)
[2025-08-07 16:46:59 train.log] INFO: Epoch: [6]  [Step 13700/14540]  lr: 0.000093  loss: 1.86317  detection_loss: 1.5921 (cls: 0.2314, box: 1.3607)  rpn_loss: 0.2711 (cls: 0.1315, box: 0.1396)
[2025-08-07 16:47:04 train.log] INFO: Epoch: [6]  [Step 13800/14540]  lr: 0.000093  loss: 1.42999  detection_loss: 1.3141 (cls: 0.3662, box: 0.9479)  rpn_loss: 0.1159 (cls: 0.0848, box: 0.0311)
[2025-08-07 16:47:09 train.log] INFO: Epoch: [6]  [Step 13900/14540]  lr: 0.000093  loss: 1.63523  detection_loss: 1.4022 (cls: 0.3216, box: 1.0806)  rpn_loss: 0.2330 (cls: 0.1153, box: 0.1177)
[2025-08-07 16:47:14 train.log] INFO: Epoch: [6]  [Step 14000/14540]  lr: 0.000093  loss: 1.46387  detection_loss: 1.2283 (cls: 0.2431, box: 0.9851)  rpn_loss: 0.2356 (cls: 0.0718, box: 0.1638)
[2025-08-07 16:47:19 train.log] INFO: Epoch: [6]  [Step 14100/14540]  lr: 0.000093  loss: 1.36723  detection_loss: 1.2817 (cls: 0.3650, box: 0.9167)  rpn_loss: 0.0855 (cls: 0.0455, box: 0.0400)
[2025-08-07 16:47:24 train.log] INFO: Epoch: [6]  [Step 14200/14540]  lr: 0.000093  loss: 2.03121  detection_loss: 1.8076 (cls: 0.5476, box: 1.2600)  rpn_loss: 0.2236 (cls: 0.1162, box: 0.1074)
[2025-08-07 16:47:29 train.log] INFO: Epoch: [6]  [Step 14300/14540]  lr: 0.000093  loss: 1.95251  detection_loss: 1.6449 (cls: 0.4696, box: 1.1753)  rpn_loss: 0.3076 (cls: 0.2674, box: 0.0402)
[2025-08-07 16:47:34 train.log] INFO: Epoch: [6]  [Step 14400/14540]  lr: 0.000093  loss: 1.31438  detection_loss: 1.1624 (cls: 0.3164, box: 0.8460)  rpn_loss: 0.1519 (cls: 0.0806, box: 0.0713)
[2025-08-07 16:47:39 train.log] INFO: Epoch: [6]  [Step 14500/14540]  lr: 0.000093  loss: 1.52574  detection_loss: 1.2628 (cls: 0.3308, box: 0.9320)  rpn_loss: 0.2629 (cls: 0.0649, box: 0.1980)
[2025-08-07 16:50:41 train.log] INFO: Epoch: [7]  [Step 100/14540]  lr: 0.000090  loss: 1.39900  detection_loss: 1.2168 (cls: 0.3120, box: 0.9047)  rpn_loss: 0.1822 (cls: 0.1301, box: 0.0521)
[2025-08-07 16:50:46 train.log] INFO: Epoch: [7]  [Step 200/14540]  lr: 0.000090  loss: 1.85615  detection_loss: 1.6295 (cls: 0.2352, box: 1.3943)  rpn_loss: 0.2266 (cls: 0.1274, box: 0.0992)
[2025-08-07 16:50:51 train.log] INFO: Epoch: [7]  [Step 300/14540]  lr: 0.000090  loss: 1.00267  detection_loss: 0.8888 (cls: 0.1210, box: 0.7678)  rpn_loss: 0.1139 (cls: 0.0633, box: 0.0506)
[2025-08-07 16:50:56 train.log] INFO: Epoch: [7]  [Step 400/14540]  lr: 0.000090  loss: 1.23652  detection_loss: 1.1417 (cls: 0.3012, box: 0.8405)  rpn_loss: 0.0948 (cls: 0.0360, box: 0.0588)
[2025-08-07 16:51:01 train.log] INFO: Epoch: [7]  [Step 500/14540]  lr: 0.000090  loss: 0.88778  detection_loss: 0.8230 (cls: 0.2064, box: 0.6166)  rpn_loss: 0.0647 (cls: 0.0329, box: 0.0319)
[2025-08-07 16:51:06 train.log] INFO: Epoch: [7]  [Step 600/14540]  lr: 0.000090  loss: 1.22912  detection_loss: 1.1296 (cls: 0.1945, box: 0.9350)  rpn_loss: 0.0995 (cls: 0.0677, box: 0.0318)
[2025-08-07 16:51:11 train.log] INFO: Epoch: [7]  [Step 700/14540]  lr: 0.000090  loss: 1.32289  detection_loss: 1.2265 (cls: 0.2271, box: 0.9994)  rpn_loss: 0.0964 (cls: 0.0565, box: 0.0398)
[2025-08-07 16:51:16 train.log] INFO: Epoch: [7]  [Step 800/14540]  lr: 0.000090  loss: 1.64039  detection_loss: 1.4482 (cls: 0.2652, box: 1.1831)  rpn_loss: 0.1922 (cls: 0.1376, box: 0.0546)
[2025-08-07 16:51:21 train.log] INFO: Epoch: [7]  [Step 900/14540]  lr: 0.000090  loss: 1.38412  detection_loss: 1.2934 (cls: 0.4251, box: 0.8682)  rpn_loss: 0.0907 (cls: 0.0475, box: 0.0432)
[2025-08-07 16:51:26 train.log] INFO: Epoch: [7]  [Step 1000/14540]  lr: 0.000090  loss: 1.35849  detection_loss: 1.2091 (cls: 0.2590, box: 0.9501)  rpn_loss: 0.1493 (cls: 0.1227, box: 0.0266)
[2025-08-07 16:51:31 train.log] INFO: Epoch: [7]  [Step 1100/14540]  lr: 0.000090  loss: 1.00534  detection_loss: 0.8318 (cls: 0.2333, box: 0.5984)  rpn_loss: 0.1736 (cls: 0.0410, box: 0.1326)
[2025-08-07 16:51:36 train.log] INFO: Epoch: [7]  [Step 1200/14540]  lr: 0.000090  loss: 1.07018  detection_loss: 0.9222 (cls: 0.3621, box: 0.5601)  rpn_loss: 0.1480 (cls: 0.1152, box: 0.0328)
[2025-08-07 16:51:41 train.log] INFO: Epoch: [7]  [Step 1300/14540]  lr: 0.000090  loss: 1.06616  detection_loss: 0.9885 (cls: 0.2364, box: 0.7521)  rpn_loss: 0.0777 (cls: 0.0462, box: 0.0315)
[2025-08-07 16:51:46 train.log] INFO: Epoch: [7]  [Step 1400/14540]  lr: 0.000090  loss: 1.16329  detection_loss: 1.0632 (cls: 0.2866, box: 0.7765)  rpn_loss: 0.1001 (cls: 0.0283, box: 0.0718)
[2025-08-07 16:51:51 train.log] INFO: Epoch: [7]  [Step 1500/14540]  lr: 0.000090  loss: 1.03092  detection_loss: 0.9266 (cls: 0.1922, box: 0.7344)  rpn_loss: 0.1043 (cls: 0.0545, box: 0.0498)
[2025-08-07 16:51:56 train.log] INFO: Epoch: [7]  [Step 1600/14540]  lr: 0.000090  loss: 1.64577  detection_loss: 1.5363 (cls: 0.4780, box: 1.0582)  rpn_loss: 0.1095 (cls: 0.0902, box: 0.0193)
[2025-08-07 16:52:01 train.log] INFO: Epoch: [7]  [Step 1700/14540]  lr: 0.000090  loss: 1.14674  detection_loss: 1.0189 (cls: 0.1588, box: 0.8601)  rpn_loss: 0.1278 (cls: 0.0274, box: 0.1004)
[2025-08-07 16:52:06 train.log] INFO: Epoch: [7]  [Step 1800/14540]  lr: 0.000090  loss: 1.39244  detection_loss: 1.1818 (cls: 0.2768, box: 0.9050)  rpn_loss: 0.2107 (cls: 0.1281, box: 0.0825)
[2025-08-07 16:52:11 train.log] INFO: Epoch: [7]  [Step 1900/14540]  lr: 0.000090  loss: 1.85820  detection_loss: 1.5448 (cls: 0.2884, box: 1.2564)  rpn_loss: 0.3134 (cls: 0.1205, box: 0.1929)
[2025-08-07 16:52:16 train.log] INFO: Epoch: [7]  [Step 2000/14540]  lr: 0.000090  loss: 1.31173  detection_loss: 1.1120 (cls: 0.2701, box: 0.8418)  rpn_loss: 0.1998 (cls: 0.0784, box: 0.1214)
[2025-08-07 16:52:20 train.log] INFO: Epoch: [7]  [Step 2100/14540]  lr: 0.000090  loss: 1.18904  detection_loss: 1.1165 (cls: 0.3865, box: 0.7300)  rpn_loss: 0.0726 (cls: 0.0286, box: 0.0440)
[2025-08-07 16:52:25 train.log] INFO: Epoch: [7]  [Step 2200/14540]  lr: 0.000090  loss: 1.57153  detection_loss: 0.9786 (cls: 0.2430, box: 0.7356)  rpn_loss: 0.5929 (cls: 0.0297, box: 0.5632)
[2025-08-07 16:52:30 train.log] INFO: Epoch: [7]  [Step 2300/14540]  lr: 0.000090  loss: 1.50287  detection_loss: 1.3613 (cls: 0.3978, box: 0.9635)  rpn_loss: 0.1416 (cls: 0.0338, box: 0.1078)
[2025-08-07 16:52:35 train.log] INFO: Epoch: [7]  [Step 2400/14540]  lr: 0.000090  loss: 1.80197  detection_loss: 1.6199 (cls: 0.5282, box: 1.0917)  rpn_loss: 0.1820 (cls: 0.1137, box: 0.0683)
[2025-08-07 16:52:40 train.log] INFO: Epoch: [7]  [Step 2500/14540]  lr: 0.000090  loss: 1.97377  detection_loss: 1.7517 (cls: 0.5552, box: 1.1965)  rpn_loss: 0.2221 (cls: 0.0586, box: 0.1635)
[2025-08-07 16:52:45 train.log] INFO: Epoch: [7]  [Step 2600/14540]  lr: 0.000090  loss: 1.08335  detection_loss: 0.8971 (cls: 0.1868, box: 0.7103)  rpn_loss: 0.1863 (cls: 0.1280, box: 0.0583)
[2025-08-07 16:52:50 train.log] INFO: Epoch: [7]  [Step 2700/14540]  lr: 0.000090  loss: 1.26372  detection_loss: 1.0500 (cls: 0.2670, box: 0.7830)  rpn_loss: 0.2137 (cls: 0.0661, box: 0.1477)
[2025-08-07 16:52:55 train.log] INFO: Epoch: [7]  [Step 2800/14540]  lr: 0.000090  loss: 1.52014  detection_loss: 1.4083 (cls: 0.2988, box: 1.1095)  rpn_loss: 0.1118 (cls: 0.0487, box: 0.0632)
[2025-08-07 16:52:59 train.log] INFO: Epoch: [7]  [Step 2900/14540]  lr: 0.000090  loss: 1.18881  detection_loss: 1.0522 (cls: 0.1961, box: 0.8561)  rpn_loss: 0.1366 (cls: 0.1008, box: 0.0357)
[2025-08-07 16:53:04 train.log] INFO: Epoch: [7]  [Step 3000/14540]  lr: 0.000090  loss: 1.11229  detection_loss: 0.9682 (cls: 0.2687, box: 0.6995)  rpn_loss: 0.1441 (cls: 0.0706, box: 0.0735)
[2025-08-07 16:53:09 train.log] INFO: Epoch: [7]  [Step 3100/14540]  lr: 0.000090  loss: 1.61048  detection_loss: 1.2793 (cls: 0.2355, box: 1.0438)  rpn_loss: 0.3312 (cls: 0.0730, box: 0.2582)
[2025-08-07 16:53:14 train.log] INFO: Epoch: [7]  [Step 3200/14540]  lr: 0.000090  loss: 2.02862  detection_loss: 1.9338 (cls: 0.5718, box: 1.3620)  rpn_loss: 0.0948 (cls: 0.0515, box: 0.0433)
[2025-08-07 16:53:19 train.log] INFO: Epoch: [7]  [Step 3300/14540]  lr: 0.000090  loss: 2.48302  detection_loss: 2.3131 (cls: 0.5076, box: 1.8055)  rpn_loss: 0.1700 (cls: 0.1154, box: 0.0546)
[2025-08-07 16:53:24 train.log] INFO: Epoch: [7]  [Step 3400/14540]  lr: 0.000090  loss: 0.70374  detection_loss: 0.6421 (cls: 0.2100, box: 0.4320)  rpn_loss: 0.0617 (cls: 0.0278, box: 0.0339)
[2025-08-07 16:53:29 train.log] INFO: Epoch: [7]  [Step 3500/14540]  lr: 0.000090  loss: 1.72832  detection_loss: 1.4371 (cls: 0.5712, box: 0.8658)  rpn_loss: 0.2913 (cls: 0.0424, box: 0.2488)
[2025-08-07 16:53:34 train.log] INFO: Epoch: [7]  [Step 3600/14540]  lr: 0.000090  loss: 1.63776  detection_loss: 1.4309 (cls: 0.3103, box: 1.1207)  rpn_loss: 0.2068 (cls: 0.0738, box: 0.1330)
[2025-08-07 16:53:35 train.log] INFO: Epoch: [7]  [Step 3635/14540]  lr: 0.000090  loss: 1.44821  detection_loss: 1.3114 (cls: 0.4218, box: 0.8896)  rpn_loss: 0.1368 (cls: 0.0923, box: 0.0445)
[2025-08-07 16:53:38 train.log] INFO: Epoch: [7]  [Step 3700/14540]  lr: 0.000090  loss: 2.06400  detection_loss: 1.9221 (cls: 0.4888, box: 1.4333)  rpn_loss: 0.1419 (cls: 0.0792, box: 0.0628)
[2025-08-07 16:53:43 train.log] INFO: Epoch: [7]  [Step 3800/14540]  lr: 0.000090  loss: 1.18212  detection_loss: 1.0558 (cls: 0.3023, box: 0.7534)  rpn_loss: 0.1263 (cls: 0.0879, box: 0.0385)
[2025-08-07 16:53:48 train.log] INFO: Epoch: [7]  [Step 3900/14540]  lr: 0.000090  loss: 1.22105  detection_loss: 0.9897 (cls: 0.2742, box: 0.7154)  rpn_loss: 0.2314 (cls: 0.1533, box: 0.0781)
[2025-08-07 16:53:53 train.log] INFO: Epoch: [7]  [Step 4000/14540]  lr: 0.000090  loss: 1.04839  detection_loss: 0.7878 (cls: 0.2653, box: 0.5225)  rpn_loss: 0.2606 (cls: 0.0399, box: 0.2206)
[2025-08-07 16:53:58 train.log] INFO: Epoch: [7]  [Step 4100/14540]  lr: 0.000090  loss: 1.13289  detection_loss: 1.0025 (cls: 0.2035, box: 0.7990)  rpn_loss: 0.1304 (cls: 0.0429, box: 0.0875)
[2025-08-07 16:54:03 train.log] INFO: Epoch: [7]  [Step 4200/14540]  lr: 0.000090  loss: 1.27080  detection_loss: 1.0350 (cls: 0.2962, box: 0.7388)  rpn_loss: 0.2358 (cls: 0.1126, box: 0.1232)
[2025-08-07 16:54:08 train.log] INFO: Epoch: [7]  [Step 4300/14540]  lr: 0.000090  loss: 1.37295  detection_loss: 1.2751 (cls: 0.3897, box: 0.8854)  rpn_loss: 0.0979 (cls: 0.0524, box: 0.0455)
[2025-08-07 16:54:13 train.log] INFO: Epoch: [7]  [Step 4400/14540]  lr: 0.000090  loss: 1.53523  detection_loss: 1.3675 (cls: 0.2830, box: 1.0845)  rpn_loss: 0.1678 (cls: 0.0358, box: 0.1320)
[2025-08-07 16:54:18 train.log] INFO: Epoch: [7]  [Step 4500/14540]  lr: 0.000090  loss: 1.34800  detection_loss: 1.0857 (cls: 0.1646, box: 0.9211)  rpn_loss: 0.2623 (cls: 0.0592, box: 0.2032)
[2025-08-07 16:54:23 train.log] INFO: Epoch: [7]  [Step 4600/14540]  lr: 0.000090  loss: 1.24589  detection_loss: 1.1467 (cls: 0.1981, box: 0.9486)  rpn_loss: 0.0992 (cls: 0.0556, box: 0.0436)
[2025-08-07 16:54:27 train.log] INFO: Epoch: [7]  [Step 4700/14540]  lr: 0.000090  loss: 0.92628  detection_loss: 0.8484 (cls: 0.2370, box: 0.6114)  rpn_loss: 0.0779 (cls: 0.0449, box: 0.0330)
[2025-08-07 16:54:33 train.log] INFO: Epoch: [7]  [Step 4800/14540]  lr: 0.000090  loss: 0.75899  detection_loss: 0.6921 (cls: 0.2456, box: 0.4464)  rpn_loss: 0.0669 (cls: 0.0336, box: 0.0333)
[2025-08-07 16:54:38 train.log] INFO: Epoch: [7]  [Step 4900/14540]  lr: 0.000090  loss: 1.57691  detection_loss: 1.2627 (cls: 0.1733, box: 1.0894)  rpn_loss: 0.3142 (cls: 0.0634, box: 0.2508)
[2025-08-07 16:54:43 train.log] INFO: Epoch: [7]  [Step 5000/14540]  lr: 0.000090  loss: 1.70609  detection_loss: 1.5612 (cls: 0.3183, box: 1.2429)  rpn_loss: 0.1449 (cls: 0.0556, box: 0.0893)
[2025-08-07 16:54:48 train.log] INFO: Epoch: [7]  [Step 5100/14540]  lr: 0.000090  loss: 0.97657  detection_loss: 0.8239 (cls: 0.1203, box: 0.7037)  rpn_loss: 0.1527 (cls: 0.0277, box: 0.1250)
[2025-08-07 16:54:52 train.log] INFO: Epoch: [7]  [Step 5200/14540]  lr: 0.000090  loss: 1.19609  detection_loss: 1.0813 (cls: 0.3073, box: 0.7739)  rpn_loss: 0.1148 (cls: 0.0895, box: 0.0254)
[2025-08-07 16:54:57 train.log] INFO: Epoch: [7]  [Step 5300/14540]  lr: 0.000090  loss: 1.39557  detection_loss: 1.2940 (cls: 0.2817, box: 1.0123)  rpn_loss: 0.1016 (cls: 0.0401, box: 0.0615)
[2025-08-07 16:55:02 train.log] INFO: Epoch: [7]  [Step 5400/14540]  lr: 0.000090  loss: 1.33084  detection_loss: 1.2079 (cls: 0.2896, box: 0.9183)  rpn_loss: 0.1229 (cls: 0.0880, box: 0.0349)
[2025-08-07 16:55:07 train.log] INFO: Epoch: [7]  [Step 5500/14540]  lr: 0.000090  loss: 0.85437  detection_loss: 0.7473 (cls: 0.1411, box: 0.6062)  rpn_loss: 0.1070 (cls: 0.0305, box: 0.0765)
[2025-08-07 16:55:12 train.log] INFO: Epoch: [7]  [Step 5600/14540]  lr: 0.000090  loss: 1.37941  detection_loss: 1.2818 (cls: 0.2737, box: 1.0080)  rpn_loss: 0.0976 (cls: 0.0594, box: 0.0382)
[2025-08-07 16:55:16 train.log] INFO: Epoch: [7]  [Step 5700/14540]  lr: 0.000090  loss: 1.10258  detection_loss: 0.9554 (cls: 0.2674, box: 0.6880)  rpn_loss: 0.1471 (cls: 0.0840, box: 0.0632)
[2025-08-07 16:55:21 train.log] INFO: Epoch: [7]  [Step 5800/14540]  lr: 0.000090  loss: 1.42539  detection_loss: 1.2948 (cls: 0.3276, box: 0.9672)  rpn_loss: 0.1306 (cls: 0.0947, box: 0.0359)
[2025-08-07 16:55:26 train.log] INFO: Epoch: [7]  [Step 5900/14540]  lr: 0.000090  loss: 1.02635  detection_loss: 0.9498 (cls: 0.1974, box: 0.7524)  rpn_loss: 0.0765 (cls: 0.0358, box: 0.0407)
[2025-08-07 16:55:31 train.log] INFO: Epoch: [7]  [Step 6000/14540]  lr: 0.000090  loss: 1.32884  detection_loss: 1.2295 (cls: 0.3246, box: 0.9049)  rpn_loss: 0.0993 (cls: 0.0427, box: 0.0566)
[2025-08-07 16:55:36 train.log] INFO: Epoch: [7]  [Step 6100/14540]  lr: 0.000090  loss: 1.59123  detection_loss: 1.4768 (cls: 0.2942, box: 1.1827)  rpn_loss: 0.1144 (cls: 0.0484, box: 0.0660)
[2025-08-07 16:55:41 train.log] INFO: Epoch: [7]  [Step 6200/14540]  lr: 0.000090  loss: 1.24715  detection_loss: 1.1358 (cls: 0.1243, box: 1.0115)  rpn_loss: 0.1113 (cls: 0.0458, box: 0.0655)
[2025-08-07 16:55:46 train.log] INFO: Epoch: [7]  [Step 6300/14540]  lr: 0.000090  loss: 1.60781  detection_loss: 1.4306 (cls: 0.3362, box: 1.0944)  rpn_loss: 0.1773 (cls: 0.1184, box: 0.0588)
[2025-08-07 16:55:51 train.log] INFO: Epoch: [7]  [Step 6400/14540]  lr: 0.000090  loss: 1.12128  detection_loss: 0.9943 (cls: 0.3941, box: 0.6002)  rpn_loss: 0.1270 (cls: 0.1009, box: 0.0261)
[2025-08-07 16:55:56 train.log] INFO: Epoch: [7]  [Step 6500/14540]  lr: 0.000090  loss: 1.50811  detection_loss: 1.3119 (cls: 0.3369, box: 0.9750)  rpn_loss: 0.1962 (cls: 0.1276, box: 0.0686)
[2025-08-07 16:56:01 train.log] INFO: Epoch: [7]  [Step 6600/14540]  lr: 0.000090  loss: 2.03038  detection_loss: 1.8463 (cls: 0.5730, box: 1.2732)  rpn_loss: 0.1841 (cls: 0.1447, box: 0.0394)
[2025-08-07 16:56:05 train.log] INFO: Epoch: [7]  [Step 6700/14540]  lr: 0.000090  loss: 1.15607  detection_loss: 1.0851 (cls: 0.2295, box: 0.8556)  rpn_loss: 0.0710 (cls: 0.0109, box: 0.0601)
[2025-08-07 16:56:10 train.log] INFO: Epoch: [7]  [Step 6800/14540]  lr: 0.000090  loss: 1.13798  detection_loss: 1.0483 (cls: 0.3796, box: 0.6688)  rpn_loss: 0.0896 (cls: 0.0535, box: 0.0361)
[2025-08-07 16:56:15 train.log] INFO: Epoch: [7]  [Step 6900/14540]  lr: 0.000090  loss: 1.62717  detection_loss: 1.3745 (cls: 0.3897, box: 0.9847)  rpn_loss: 0.2527 (cls: 0.1323, box: 0.1204)
[2025-08-07 16:56:20 train.log] INFO: Epoch: [7]  [Step 7000/14540]  lr: 0.000090  loss: 1.63836  detection_loss: 1.4553 (cls: 0.4478, box: 1.0074)  rpn_loss: 0.1831 (cls: 0.1269, box: 0.0562)
[2025-08-07 16:56:25 train.log] INFO: Epoch: [7]  [Step 7100/14540]  lr: 0.000090  loss: 1.40173  detection_loss: 1.0763 (cls: 0.3102, box: 0.7661)  rpn_loss: 0.3255 (cls: 0.0339, box: 0.2915)
[2025-08-07 16:56:30 train.log] INFO: Epoch: [7]  [Step 7200/14540]  lr: 0.000090  loss: 1.85730  detection_loss: 1.7917 (cls: 0.4664, box: 1.3253)  rpn_loss: 0.0656 (cls: 0.0413, box: 0.0244)
[2025-08-07 16:56:35 train.log] INFO: Epoch: [7]  [Step 7300/14540]  lr: 0.000090  loss: 1.40508  detection_loss: 0.8000 (cls: 0.2743, box: 0.5257)  rpn_loss: 0.6051 (cls: 0.0438, box: 0.5613)
[2025-08-07 16:56:40 train.log] INFO: Epoch: [7]  [Step 7400/14540]  lr: 0.000090  loss: 1.09605  detection_loss: 1.0349 (cls: 0.2639, box: 0.7709)  rpn_loss: 0.0612 (cls: 0.0332, box: 0.0280)
[2025-08-07 16:56:45 train.log] INFO: Epoch: [7]  [Step 7500/14540]  lr: 0.000090  loss: 1.24238  detection_loss: 1.0326 (cls: 0.2547, box: 0.7779)  rpn_loss: 0.2098 (cls: 0.1788, box: 0.0310)
[2025-08-07 16:56:50 train.log] INFO: Epoch: [7]  [Step 7600/14540]  lr: 0.000090  loss: 1.55070  detection_loss: 1.4020 (cls: 0.3110, box: 1.0910)  rpn_loss: 0.1487 (cls: 0.1156, box: 0.0331)
[2025-08-07 16:56:55 train.log] INFO: Epoch: [7]  [Step 7700/14540]  lr: 0.000090  loss: 1.12151  detection_loss: 0.9944 (cls: 0.3431, box: 0.6513)  rpn_loss: 0.1271 (cls: 0.0439, box: 0.0832)
[2025-08-07 16:57:00 train.log] INFO: Epoch: [7]  [Step 7800/14540]  lr: 0.000090  loss: 1.26816  detection_loss: 1.2027 (cls: 0.3563, box: 0.8465)  rpn_loss: 0.0654 (cls: 0.0308, box: 0.0347)
[2025-08-07 16:57:05 train.log] INFO: Epoch: [7]  [Step 7900/14540]  lr: 0.000090  loss: 1.39837  detection_loss: 1.2357 (cls: 0.2421, box: 0.9936)  rpn_loss: 0.1627 (cls: 0.0327, box: 0.1300)
[2025-08-07 16:57:10 train.log] INFO: Epoch: [7]  [Step 8000/14540]  lr: 0.000090  loss: 1.60716  detection_loss: 1.4965 (cls: 0.3264, box: 1.1701)  rpn_loss: 0.1106 (cls: 0.0697, box: 0.0410)
[2025-08-07 16:57:15 train.log] INFO: Epoch: [7]  [Step 8100/14540]  lr: 0.000090  loss: 1.39613  detection_loss: 1.2859 (cls: 0.4619, box: 0.8239)  rpn_loss: 0.1103 (cls: 0.0731, box: 0.0372)
[2025-08-07 16:57:19 train.log] INFO: Epoch: [7]  [Step 8200/14540]  lr: 0.000090  loss: 1.80611  detection_loss: 1.6614 (cls: 0.3608, box: 1.3006)  rpn_loss: 0.1447 (cls: 0.0958, box: 0.0489)
[2025-08-07 16:57:24 train.log] INFO: Epoch: [7]  [Step 8300/14540]  lr: 0.000090  loss: 1.61539  detection_loss: 1.4353 (cls: 0.4900, box: 0.9453)  rpn_loss: 0.1801 (cls: 0.0811, box: 0.0990)
[2025-08-07 16:57:29 train.log] INFO: Epoch: [7]  [Step 8400/14540]  lr: 0.000090  loss: 1.52331  detection_loss: 1.3695 (cls: 0.2938, box: 1.0757)  rpn_loss: 0.1538 (cls: 0.1284, box: 0.0254)
[2025-08-07 16:57:34 train.log] INFO: Epoch: [7]  [Step 8500/14540]  lr: 0.000090  loss: 1.04352  detection_loss: 0.9560 (cls: 0.3739, box: 0.5820)  rpn_loss: 0.0876 (cls: 0.0463, box: 0.0413)
[2025-08-07 16:57:39 train.log] INFO: Epoch: [7]  [Step 8600/14540]  lr: 0.000090  loss: 0.89525  detection_loss: 0.8319 (cls: 0.2289, box: 0.6030)  rpn_loss: 0.0634 (cls: 0.0280, box: 0.0354)
[2025-08-07 16:57:44 train.log] INFO: Epoch: [7]  [Step 8700/14540]  lr: 0.000090  loss: 1.47514  detection_loss: 1.3378 (cls: 0.2410, box: 1.0967)  rpn_loss: 0.1374 (cls: 0.0496, box: 0.0877)
[2025-08-07 16:57:49 train.log] INFO: Epoch: [7]  [Step 8800/14540]  lr: 0.000090  loss: 1.60825  detection_loss: 1.4717 (cls: 0.4373, box: 1.0344)  rpn_loss: 0.1366 (cls: 0.0772, box: 0.0594)
[2025-08-07 16:57:54 train.log] INFO: Epoch: [7]  [Step 8900/14540]  lr: 0.000090  loss: 1.17963  detection_loss: 1.0846 (cls: 0.2350, box: 0.8497)  rpn_loss: 0.0950 (cls: 0.0316, box: 0.0633)
[2025-08-07 16:57:59 train.log] INFO: Epoch: [7]  [Step 9000/14540]  lr: 0.000090  loss: 1.02572  detection_loss: 0.8199 (cls: 0.2351, box: 0.5847)  rpn_loss: 0.2059 (cls: 0.1323, box: 0.0736)
[2025-08-07 16:58:04 train.log] INFO: Epoch: [7]  [Step 9100/14540]  lr: 0.000090  loss: 0.98611  detection_loss: 0.9244 (cls: 0.2676, box: 0.6569)  rpn_loss: 0.0617 (cls: 0.0138, box: 0.0479)
[2025-08-07 16:58:09 train.log] INFO: Epoch: [7]  [Step 9200/14540]  lr: 0.000090  loss: 1.37872  detection_loss: 1.2902 (cls: 0.2655, box: 1.0247)  rpn_loss: 0.0885 (cls: 0.0688, box: 0.0197)
[2025-08-07 16:58:13 train.log] INFO: Epoch: [7]  [Step 9300/14540]  lr: 0.000090  loss: 1.43951  detection_loss: 1.3332 (cls: 0.3109, box: 1.0223)  rpn_loss: 0.1063 (cls: 0.0588, box: 0.0475)
[2025-08-07 16:58:18 train.log] INFO: Epoch: [7]  [Step 9400/14540]  lr: 0.000090  loss: 1.85217  detection_loss: 1.6017 (cls: 0.2931, box: 1.3087)  rpn_loss: 0.2504 (cls: 0.0343, box: 0.2161)
[2025-08-07 16:58:23 train.log] INFO: Epoch: [7]  [Step 9500/14540]  lr: 0.000090  loss: 1.44024  detection_loss: 1.3419 (cls: 0.4123, box: 0.9295)  rpn_loss: 0.0984 (cls: 0.0620, box: 0.0364)
[2025-08-07 16:58:28 train.log] INFO: Epoch: [7]  [Step 9600/14540]  lr: 0.000090  loss: 0.98097  detection_loss: 0.9121 (cls: 0.2166, box: 0.6955)  rpn_loss: 0.0688 (cls: 0.0508, box: 0.0181)
[2025-08-07 16:58:33 train.log] INFO: Epoch: [7]  [Step 9700/14540]  lr: 0.000090  loss: 1.24850  detection_loss: 1.0333 (cls: 0.3369, box: 0.6963)  rpn_loss: 0.2152 (cls: 0.1589, box: 0.0563)
[2025-08-07 16:58:38 train.log] INFO: Epoch: [7]  [Step 9800/14540]  lr: 0.000090  loss: 0.79305  detection_loss: 0.7459 (cls: 0.1424, box: 0.6035)  rpn_loss: 0.0471 (cls: 0.0159, box: 0.0312)
[2025-08-07 16:58:43 train.log] INFO: Epoch: [7]  [Step 9900/14540]  lr: 0.000090  loss: 1.68458  detection_loss: 1.5556 (cls: 0.3499, box: 1.2057)  rpn_loss: 0.1290 (cls: 0.0770, box: 0.0520)
[2025-08-07 16:58:48 train.log] INFO: Epoch: [7]  [Step 10000/14540]  lr: 0.000090  loss: 1.57995  detection_loss: 1.4047 (cls: 0.3587, box: 1.0460)  rpn_loss: 0.1752 (cls: 0.1411, box: 0.0341)
[2025-08-07 16:58:53 train.log] INFO: Epoch: [7]  [Step 10100/14540]  lr: 0.000090  loss: 0.81223  detection_loss: 0.7324 (cls: 0.2334, box: 0.4990)  rpn_loss: 0.0799 (cls: 0.0481, box: 0.0317)
[2025-08-07 16:58:58 train.log] INFO: Epoch: [7]  [Step 10200/14540]  lr: 0.000090  loss: 1.18556  detection_loss: 1.0928 (cls: 0.2593, box: 0.8336)  rpn_loss: 0.0927 (cls: 0.0343, box: 0.0584)
[2025-08-07 16:59:02 train.log] INFO: Epoch: [7]  [Step 10300/14540]  lr: 0.000090  loss: 1.45787  detection_loss: 1.3353 (cls: 0.2351, box: 1.1002)  rpn_loss: 0.1226 (cls: 0.0502, box: 0.0723)
[2025-08-07 16:59:07 train.log] INFO: Epoch: [7]  [Step 10400/14540]  lr: 0.000090  loss: 1.26308  detection_loss: 1.1433 (cls: 0.1780, box: 0.9653)  rpn_loss: 0.1198 (cls: 0.0338, box: 0.0860)
[2025-08-07 16:59:12 train.log] INFO: Epoch: [7]  [Step 10500/14540]  lr: 0.000090  loss: 1.73695  detection_loss: 1.6215 (cls: 0.3474, box: 1.2741)  rpn_loss: 0.1154 (cls: 0.0545, box: 0.0610)
[2025-08-07 16:59:17 train.log] INFO: Epoch: [7]  [Step 10600/14540]  lr: 0.000090  loss: 2.21444  detection_loss: 1.5940 (cls: 0.3364, box: 1.2576)  rpn_loss: 0.6205 (cls: 0.0540, box: 0.5664)
[2025-08-07 16:59:22 train.log] INFO: Epoch: [7]  [Step 10700/14540]  lr: 0.000090  loss: 1.62085  detection_loss: 1.5369 (cls: 0.3419, box: 1.1950)  rpn_loss: 0.0840 (cls: 0.0656, box: 0.0183)
[2025-08-07 16:59:27 train.log] INFO: Epoch: [7]  [Step 10800/14540]  lr: 0.000090  loss: 1.65399  detection_loss: 1.3991 (cls: 0.2694, box: 1.1297)  rpn_loss: 0.2549 (cls: 0.0429, box: 0.2120)
[2025-08-07 16:59:32 train.log] INFO: Epoch: [7]  [Step 10900/14540]  lr: 0.000090  loss: 0.60050  detection_loss: 0.5364 (cls: 0.0938, box: 0.4426)  rpn_loss: 0.0641 (cls: 0.0252, box: 0.0389)
[2025-08-07 16:59:37 train.log] INFO: Epoch: [7]  [Step 11000/14540]  lr: 0.000090  loss: 1.44501  detection_loss: 1.3881 (cls: 0.2286, box: 1.1596)  rpn_loss: 0.0569 (cls: 0.0177, box: 0.0392)
[2025-08-07 16:59:41 train.log] INFO: Epoch: [7]  [Step 11100/14540]  lr: 0.000090  loss: 1.61688  detection_loss: 1.5319 (cls: 0.4196, box: 1.1123)  rpn_loss: 0.0849 (cls: 0.0619, box: 0.0230)
[2025-08-07 16:59:46 train.log] INFO: Epoch: [7]  [Step 11200/14540]  lr: 0.000090  loss: 1.33540  detection_loss: 1.2717 (cls: 0.4446, box: 0.8271)  rpn_loss: 0.0637 (cls: 0.0432, box: 0.0205)
[2025-08-07 16:59:51 train.log] INFO: Epoch: [7]  [Step 11300/14540]  lr: 0.000090  loss: 0.97222  detection_loss: 0.8854 (cls: 0.2291, box: 0.6564)  rpn_loss: 0.0868 (cls: 0.0413, box: 0.0455)
[2025-08-07 16:59:56 train.log] INFO: Epoch: [7]  [Step 11400/14540]  lr: 0.000090  loss: 1.00564  detection_loss: 0.8697 (cls: 0.2070, box: 0.6627)  rpn_loss: 0.1360 (cls: 0.0947, box: 0.0413)
[2025-08-07 17:00:00 train.log] INFO: Epoch: [7]  [Step 11500/14540]  lr: 0.000090  loss: 1.26977  detection_loss: 0.9384 (cls: 0.3219, box: 0.6166)  rpn_loss: 0.3313 (cls: 0.2837, box: 0.0477)
[2025-08-07 17:00:05 train.log] INFO: Epoch: [7]  [Step 11600/14540]  lr: 0.000090  loss: 1.35187  detection_loss: 1.0472 (cls: 0.2226, box: 0.8246)  rpn_loss: 0.3047 (cls: 0.0671, box: 0.2377)
[2025-08-07 17:00:10 train.log] INFO: Epoch: [7]  [Step 11700/14540]  lr: 0.000090  loss: 1.33128  detection_loss: 1.1743 (cls: 0.2777, box: 0.8966)  rpn_loss: 0.1569 (cls: 0.0879, box: 0.0691)
[2025-08-07 17:00:15 train.log] INFO: Epoch: [7]  [Step 11800/14540]  lr: 0.000090  loss: 1.60629  detection_loss: 1.5188 (cls: 0.3712, box: 1.1476)  rpn_loss: 0.0875 (cls: 0.0630, box: 0.0245)
[2025-08-07 17:00:20 train.log] INFO: Epoch: [7]  [Step 11900/14540]  lr: 0.000090  loss: 1.10748  detection_loss: 1.0080 (cls: 0.2192, box: 0.7888)  rpn_loss: 0.0995 (cls: 0.0429, box: 0.0566)
[2025-08-07 17:00:24 train.log] INFO: Epoch: [7]  [Step 12000/14540]  lr: 0.000090  loss: 1.91589  detection_loss: 1.6803 (cls: 0.4357, box: 1.2446)  rpn_loss: 0.2356 (cls: 0.2079, box: 0.0278)
[2025-08-07 17:00:29 train.log] INFO: Epoch: [7]  [Step 12100/14540]  lr: 0.000090  loss: 1.05967  detection_loss: 0.9726 (cls: 0.1112, box: 0.8614)  rpn_loss: 0.0871 (cls: 0.0569, box: 0.0301)
[2025-08-07 17:00:34 train.log] INFO: Epoch: [7]  [Step 12200/14540]  lr: 0.000090  loss: 1.48639  detection_loss: 1.3297 (cls: 0.2970, box: 1.0327)  rpn_loss: 0.1567 (cls: 0.1127, box: 0.0440)
[2025-08-07 17:00:39 train.log] INFO: Epoch: [7]  [Step 12300/14540]  lr: 0.000090  loss: 2.30899  detection_loss: 1.9580 (cls: 0.3321, box: 1.6260)  rpn_loss: 0.3510 (cls: 0.1232, box: 0.2278)
[2025-08-07 17:00:44 train.log] INFO: Epoch: [7]  [Step 12400/14540]  lr: 0.000090  loss: 1.52252  detection_loss: 1.3747 (cls: 0.4175, box: 0.9572)  rpn_loss: 0.1479 (cls: 0.1025, box: 0.0453)
[2025-08-07 17:00:49 train.log] INFO: Epoch: [7]  [Step 12500/14540]  lr: 0.000090  loss: 1.14368  detection_loss: 1.0601 (cls: 0.2069, box: 0.8532)  rpn_loss: 0.0836 (cls: 0.0617, box: 0.0219)
[2025-08-07 17:00:54 train.log] INFO: Epoch: [7]  [Step 12600/14540]  lr: 0.000090  loss: 1.48021  detection_loss: 1.2846 (cls: 0.3019, box: 0.9827)  rpn_loss: 0.1956 (cls: 0.1544, box: 0.0412)
[2025-08-07 17:00:58 train.log] INFO: Epoch: [7]  [Step 12700/14540]  lr: 0.000090  loss: 1.38209  detection_loss: 1.2995 (cls: 0.2997, box: 0.9998)  rpn_loss: 0.0825 (cls: 0.0361, box: 0.0465)
[2025-08-07 17:01:03 train.log] INFO: Epoch: [7]  [Step 12800/14540]  lr: 0.000090  loss: 1.25281  detection_loss: 1.1242 (cls: 0.3021, box: 0.8220)  rpn_loss: 0.1286 (cls: 0.1014, box: 0.0273)
[2025-08-07 17:01:08 train.log] INFO: Epoch: [7]  [Step 12900/14540]  lr: 0.000090  loss: 0.88135  detection_loss: 0.8258 (cls: 0.1844, box: 0.6414)  rpn_loss: 0.0555 (cls: 0.0344, box: 0.0211)
[2025-08-07 17:01:13 train.log] INFO: Epoch: [7]  [Step 13000/14540]  lr: 0.000090  loss: 1.16846  detection_loss: 1.0781 (cls: 0.2181, box: 0.8600)  rpn_loss: 0.0903 (cls: 0.0603, box: 0.0300)
[2025-08-07 17:01:18 train.log] INFO: Epoch: [7]  [Step 13100/14540]  lr: 0.000090  loss: 1.79123  detection_loss: 1.6011 (cls: 0.2536, box: 1.3474)  rpn_loss: 0.1902 (cls: 0.0875, box: 0.1026)
[2025-08-07 17:01:23 train.log] INFO: Epoch: [7]  [Step 13200/14540]  lr: 0.000090  loss: 0.65426  detection_loss: 0.6010 (cls: 0.1395, box: 0.4616)  rpn_loss: 0.0532 (cls: 0.0296, box: 0.0237)
[2025-08-07 17:01:28 train.log] INFO: Epoch: [7]  [Step 13300/14540]  lr: 0.000090  loss: 1.33662  detection_loss: 1.1480 (cls: 0.2058, box: 0.9422)  rpn_loss: 0.1886 (cls: 0.1118, box: 0.0768)
[2025-08-07 17:01:33 train.log] INFO: Epoch: [7]  [Step 13400/14540]  lr: 0.000090  loss: 1.36894  detection_loss: 1.2223 (cls: 0.3528, box: 0.8696)  rpn_loss: 0.1466 (cls: 0.0914, box: 0.0552)
[2025-08-07 17:01:38 train.log] INFO: Epoch: [7]  [Step 13500/14540]  lr: 0.000090  loss: 1.14905  detection_loss: 0.9522 (cls: 0.3130, box: 0.6391)  rpn_loss: 0.1969 (cls: 0.0970, box: 0.0999)
[2025-08-07 17:01:42 train.log] INFO: Epoch: [7]  [Step 13600/14540]  lr: 0.000090  loss: 1.00800  detection_loss: 0.6154 (cls: 0.1916, box: 0.4238)  rpn_loss: 0.3926 (cls: 0.0399, box: 0.3527)
[2025-08-07 17:01:47 train.log] INFO: Epoch: [7]  [Step 13700/14540]  lr: 0.000090  loss: 1.42076  detection_loss: 1.2714 (cls: 0.2132, box: 1.0582)  rpn_loss: 0.1494 (cls: 0.0671, box: 0.0823)
[2025-08-07 17:01:52 train.log] INFO: Epoch: [7]  [Step 13800/14540]  lr: 0.000090  loss: 1.67445  detection_loss: 1.5015 (cls: 0.3253, box: 1.1761)  rpn_loss: 0.1730 (cls: 0.0707, box: 0.1023)
[2025-08-07 17:01:57 train.log] INFO: Epoch: [7]  [Step 13900/14540]  lr: 0.000090  loss: 1.69934  detection_loss: 1.3955 (cls: 0.3073, box: 1.0882)  rpn_loss: 0.3038 (cls: 0.0665, box: 0.2373)
[2025-08-07 17:02:02 train.log] INFO: Epoch: [7]  [Step 14000/14540]  lr: 0.000090  loss: 1.24506  detection_loss: 1.1778 (cls: 0.1282, box: 1.0496)  rpn_loss: 0.0673 (cls: 0.0225, box: 0.0447)
[2025-08-07 17:02:07 train.log] INFO: Epoch: [7]  [Step 14100/14540]  lr: 0.000090  loss: 1.32769  detection_loss: 1.2018 (cls: 0.2837, box: 0.9181)  rpn_loss: 0.1259 (cls: 0.0606, box: 0.0653)
[2025-08-07 17:02:12 train.log] INFO: Epoch: [7]  [Step 14200/14540]  lr: 0.000090  loss: 1.27691  detection_loss: 1.0787 (cls: 0.2611, box: 0.8176)  rpn_loss: 0.1982 (cls: 0.1080, box: 0.0902)
[2025-08-07 17:02:16 train.log] INFO: Epoch: [7]  [Step 14300/14540]  lr: 0.000090  loss: 1.05002  detection_loss: 0.8496 (cls: 0.1983, box: 0.6514)  rpn_loss: 0.2004 (cls: 0.0495, box: 0.1509)
[2025-08-07 17:02:21 train.log] INFO: Epoch: [7]  [Step 14400/14540]  lr: 0.000090  loss: 1.14942  detection_loss: 1.0360 (cls: 0.2165, box: 0.8195)  rpn_loss: 0.1135 (cls: 0.0611, box: 0.0524)
[2025-08-07 17:02:26 train.log] INFO: Epoch: [7]  [Step 14500/14540]  lr: 0.000090  loss: 1.23801  detection_loss: 1.1325 (cls: 0.2337, box: 0.8987)  rpn_loss: 0.1056 (cls: 0.0235, box: 0.0821)
[2025-08-07 17:05:24 train.log] INFO: Epoch: [8]  [Step 100/14540]  lr: 0.000087  loss: 1.19398  detection_loss: 1.0064 (cls: 0.2776, box: 0.7288)  rpn_loss: 0.1876 (cls: 0.0487, box: 0.1389)
[2025-08-07 17:05:29 train.log] INFO: Epoch: [8]  [Step 200/14540]  lr: 0.000087  loss: 1.51103  detection_loss: 1.2977 (cls: 0.2886, box: 1.0091)  rpn_loss: 0.2133 (cls: 0.1265, box: 0.0868)
[2025-08-07 17:05:34 train.log] INFO: Epoch: [8]  [Step 300/14540]  lr: 0.000087  loss: 1.24764  detection_loss: 1.1240 (cls: 0.2668, box: 0.8572)  rpn_loss: 0.1237 (cls: 0.0603, box: 0.0634)
[2025-08-07 17:05:39 train.log] INFO: Epoch: [8]  [Step 400/14540]  lr: 0.000087  loss: 1.55245  detection_loss: 1.3762 (cls: 0.3086, box: 1.0675)  rpn_loss: 0.1763 (cls: 0.0832, box: 0.0931)
[2025-08-07 17:05:44 train.log] INFO: Epoch: [8]  [Step 500/14540]  lr: 0.000087  loss: 1.51652  detection_loss: 1.3753 (cls: 0.4179, box: 0.9574)  rpn_loss: 0.1412 (cls: 0.0383, box: 0.1029)
[2025-08-07 17:05:49 train.log] INFO: Epoch: [8]  [Step 600/14540]  lr: 0.000087  loss: 1.44117  detection_loss: 1.3398 (cls: 0.3440, box: 0.9958)  rpn_loss: 0.1014 (cls: 0.0642, box: 0.0372)
[2025-08-07 17:05:54 train.log] INFO: Epoch: [8]  [Step 700/14540]  lr: 0.000087  loss: 1.41000  detection_loss: 1.0758 (cls: 0.3300, box: 0.7457)  rpn_loss: 0.3342 (cls: 0.0512, box: 0.2830)
[2025-08-07 17:05:59 train.log] INFO: Epoch: [8]  [Step 800/14540]  lr: 0.000087  loss: 1.25123  detection_loss: 1.1394 (cls: 0.2614, box: 0.8781)  rpn_loss: 0.1118 (cls: 0.0267, box: 0.0851)
[2025-08-07 17:06:04 train.log] INFO: Epoch: [8]  [Step 900/14540]  lr: 0.000087  loss: 1.38468  detection_loss: 1.2364 (cls: 0.4797, box: 0.7567)  rpn_loss: 0.1482 (cls: 0.0981, box: 0.0502)
[2025-08-07 17:06:09 train.log] INFO: Epoch: [8]  [Step 1000/14540]  lr: 0.000087  loss: 1.09523  detection_loss: 0.9471 (cls: 0.2518, box: 0.6954)  rpn_loss: 0.1481 (cls: 0.0704, box: 0.0777)
[2025-08-07 17:06:13 train.log] INFO: Epoch: [8]  [Step 1100/14540]  lr: 0.000087  loss: 0.81596  detection_loss: 0.7273 (cls: 0.1998, box: 0.5275)  rpn_loss: 0.0886 (cls: 0.0453, box: 0.0433)
[2025-08-07 17:06:18 train.log] INFO: Epoch: [8]  [Step 1200/14540]  lr: 0.000087  loss: 0.80673  detection_loss: 0.7262 (cls: 0.1201, box: 0.6062)  rpn_loss: 0.0805 (cls: 0.0579, box: 0.0227)
[2025-08-07 17:06:23 train.log] INFO: Epoch: [8]  [Step 1300/14540]  lr: 0.000087  loss: 0.96351  detection_loss: 0.8572 (cls: 0.2346, box: 0.6227)  rpn_loss: 0.1063 (cls: 0.0952, box: 0.0111)
[2025-08-07 17:06:28 train.log] INFO: Epoch: [8]  [Step 1400/14540]  lr: 0.000087  loss: 1.87409  detection_loss: 1.7077 (cls: 0.2893, box: 1.4184)  rpn_loss: 0.1664 (cls: 0.0417, box: 0.1247)
[2025-08-07 17:06:33 train.log] INFO: Epoch: [8]  [Step 1500/14540]  lr: 0.000087  loss: 1.10881  detection_loss: 0.9778 (cls: 0.1906, box: 0.7872)  rpn_loss: 0.1310 (cls: 0.0387, box: 0.0922)
[2025-08-07 17:06:38 train.log] INFO: Epoch: [8]  [Step 1600/14540]  lr: 0.000087  loss: 1.49852  detection_loss: 1.4231 (cls: 0.2216, box: 1.2015)  rpn_loss: 0.0754 (cls: 0.0462, box: 0.0293)
[2025-08-07 17:06:43 train.log] INFO: Epoch: [8]  [Step 1700/14540]  lr: 0.000087  loss: 1.33460  detection_loss: 1.1935 (cls: 0.3377, box: 0.8558)  rpn_loss: 0.1411 (cls: 0.0978, box: 0.0433)
[2025-08-07 17:06:48 train.log] INFO: Epoch: [8]  [Step 1800/14540]  lr: 0.000087  loss: 1.96474  detection_loss: 1.5910 (cls: 0.4086, box: 1.1824)  rpn_loss: 0.3737 (cls: 0.0774, box: 0.2963)
[2025-08-07 17:06:53 train.log] INFO: Epoch: [8]  [Step 1900/14540]  lr: 0.000087  loss: 1.71825  detection_loss: 1.6133 (cls: 0.5188, box: 1.0945)  rpn_loss: 0.1050 (cls: 0.0503, box: 0.0547)
[2025-08-07 17:06:58 train.log] INFO: Epoch: [8]  [Step 2000/14540]  lr: 0.000087  loss: 1.28159  detection_loss: 1.2052 (cls: 0.4127, box: 0.7925)  rpn_loss: 0.0764 (cls: 0.0213, box: 0.0551)
[2025-08-07 17:07:02 train.log] INFO: Epoch: [8]  [Step 2100/14540]  lr: 0.000087  loss: 1.16623  detection_loss: 1.0369 (cls: 0.3015, box: 0.7354)  rpn_loss: 0.1293 (cls: 0.0310, box: 0.0983)
[2025-08-07 17:07:07 train.log] INFO: Epoch: [8]  [Step 2200/14540]  lr: 0.000087  loss: 1.83147  detection_loss: 1.6520 (cls: 0.5197, box: 1.1323)  rpn_loss: 0.1795 (cls: 0.1394, box: 0.0400)
[2025-08-07 17:07:12 train.log] INFO: Epoch: [8]  [Step 2300/14540]  lr: 0.000087  loss: 1.27509  detection_loss: 1.0196 (cls: 0.3835, box: 0.6361)  rpn_loss: 0.2555 (cls: 0.0504, box: 0.2051)
[2025-08-07 17:07:17 train.log] INFO: Epoch: [8]  [Step 2400/14540]  lr: 0.000087  loss: 1.15052  detection_loss: 1.0159 (cls: 0.3394, box: 0.6765)  rpn_loss: 0.1346 (cls: 0.0726, box: 0.0621)
[2025-08-07 17:07:22 train.log] INFO: Epoch: [8]  [Step 2500/14540]  lr: 0.000087  loss: 1.80528  detection_loss: 1.6392 (cls: 0.3352, box: 1.3041)  rpn_loss: 0.1660 (cls: 0.1063, box: 0.0598)
[2025-08-07 17:07:27 train.log] INFO: Epoch: [8]  [Step 2600/14540]  lr: 0.000087  loss: 1.64531  detection_loss: 1.5322 (cls: 0.4283, box: 1.1039)  rpn_loss: 0.1131 (cls: 0.0509, box: 0.0622)
[2025-08-07 17:07:32 train.log] INFO: Epoch: [8]  [Step 2700/14540]  lr: 0.000087  loss: 0.99649  detection_loss: 0.8812 (cls: 0.1794, box: 0.7018)  rpn_loss: 0.1153 (cls: 0.0358, box: 0.0794)
[2025-08-07 17:07:36 train.log] INFO: Epoch: [8]  [Step 2800/14540]  lr: 0.000087  loss: 1.25280  detection_loss: 1.1917 (cls: 0.1507, box: 1.0410)  rpn_loss: 0.0611 (cls: 0.0261, box: 0.0350)
[2025-08-07 17:07:41 train.log] INFO: Epoch: [8]  [Step 2900/14540]  lr: 0.000087  loss: 1.47959  detection_loss: 1.3022 (cls: 0.4422, box: 0.8601)  rpn_loss: 0.1774 (cls: 0.0890, box: 0.0883)
[2025-08-07 17:07:46 train.log] INFO: Epoch: [8]  [Step 3000/14540]  lr: 0.000087  loss: 1.30447  detection_loss: 1.2259 (cls: 0.2794, box: 0.9465)  rpn_loss: 0.0786 (cls: 0.0591, box: 0.0194)
[2025-08-07 17:07:51 train.log] INFO: Epoch: [8]  [Step 3100/14540]  lr: 0.000087  loss: 1.17465  detection_loss: 1.0352 (cls: 0.2114, box: 0.8238)  rpn_loss: 0.1395 (cls: 0.0523, box: 0.0872)
[2025-08-07 17:07:56 train.log] INFO: Epoch: [8]  [Step 3200/14540]  lr: 0.000087  loss: 1.07673  detection_loss: 1.0013 (cls: 0.2029, box: 0.7983)  rpn_loss: 0.0754 (cls: 0.0327, box: 0.0428)
[2025-08-07 17:08:00 train.log] INFO: Epoch: [8]  [Step 3300/14540]  lr: 0.000087  loss: 1.62982  detection_loss: 1.5021 (cls: 0.5153, box: 0.9868)  rpn_loss: 0.1277 (cls: 0.0739, box: 0.0538)
[2025-08-07 17:08:05 train.log] INFO: Epoch: [8]  [Step 3400/14540]  lr: 0.000087  loss: 1.39046  detection_loss: 1.2792 (cls: 0.2865, box: 0.9927)  rpn_loss: 0.1113 (cls: 0.0731, box: 0.0381)
[2025-08-07 17:08:10 train.log] INFO: Epoch: [8]  [Step 3500/14540]  lr: 0.000087  loss: 1.05304  detection_loss: 0.9554 (cls: 0.2252, box: 0.7301)  rpn_loss: 0.0977 (cls: 0.0370, box: 0.0606)
[2025-08-07 17:08:15 train.log] INFO: Epoch: [8]  [Step 3600/14540]  lr: 0.000087  loss: 1.01710  detection_loss: 0.9567 (cls: 0.2696, box: 0.6871)  rpn_loss: 0.0604 (cls: 0.0345, box: 0.0259)
[2025-08-07 17:08:17 train.log] INFO: Epoch: [8]  [Step 3635/14540]  lr: 0.000087  loss: 1.32252  detection_loss: 1.2038 (cls: 0.3426, box: 0.8611)  rpn_loss: 0.1188 (cls: 0.0917, box: 0.0271)
[2025-08-07 17:08:20 train.log] INFO: Epoch: [8]  [Step 3700/14540]  lr: 0.000087  loss: 1.64241  detection_loss: 1.4024 (cls: 0.4492, box: 0.9532)  rpn_loss: 0.2400 (cls: 0.2104, box: 0.0296)
[2025-08-07 17:08:25 train.log] INFO: Epoch: [8]  [Step 3800/14540]  lr: 0.000087  loss: 1.02073  detection_loss: 0.9241 (cls: 0.2289, box: 0.6952)  rpn_loss: 0.0967 (cls: 0.0252, box: 0.0715)
[2025-08-07 17:08:29 train.log] INFO: Epoch: [8]  [Step 3900/14540]  lr: 0.000087  loss: 1.10375  detection_loss: 0.9257 (cls: 0.2408, box: 0.6848)  rpn_loss: 0.1781 (cls: 0.0734, box: 0.1047)
[2025-08-07 17:08:34 train.log] INFO: Epoch: [8]  [Step 4000/14540]  lr: 0.000087  loss: 1.83419  detection_loss: 1.6026 (cls: 0.2767, box: 1.3259)  rpn_loss: 0.2316 (cls: 0.1244, box: 0.1072)
[2025-08-07 17:08:39 train.log] INFO: Epoch: [8]  [Step 4100/14540]  lr: 0.000087  loss: 1.86413  detection_loss: 1.6882 (cls: 0.3952, box: 1.2930)  rpn_loss: 0.1759 (cls: 0.1119, box: 0.0640)
[2025-08-07 17:08:44 train.log] INFO: Epoch: [8]  [Step 4200/14540]  lr: 0.000087  loss: 1.60332  detection_loss: 1.4588 (cls: 0.3144, box: 1.1444)  rpn_loss: 0.1445 (cls: 0.0821, box: 0.0624)
[2025-08-07 17:08:48 train.log] INFO: Epoch: [8]  [Step 4300/14540]  lr: 0.000087  loss: 1.37446  detection_loss: 1.2242 (cls: 0.2484, box: 0.9757)  rpn_loss: 0.1503 (cls: 0.0930, box: 0.0573)
[2025-08-07 17:08:53 train.log] INFO: Epoch: [8]  [Step 4400/14540]  lr: 0.000087  loss: 0.72540  detection_loss: 0.6698 (cls: 0.1533, box: 0.5164)  rpn_loss: 0.0556 (cls: 0.0383, box: 0.0173)
[2025-08-07 17:08:58 train.log] INFO: Epoch: [8]  [Step 4500/14540]  lr: 0.000087  loss: 1.08754  detection_loss: 0.9508 (cls: 0.3178, box: 0.6330)  rpn_loss: 0.1368 (cls: 0.0529, box: 0.0839)
[2025-08-07 17:09:03 train.log] INFO: Epoch: [8]  [Step 4600/14540]  lr: 0.000087  loss: 1.24312  detection_loss: 1.0015 (cls: 0.2108, box: 0.7908)  rpn_loss: 0.2416 (cls: 0.1458, box: 0.0958)
[2025-08-07 17:09:08 train.log] INFO: Epoch: [8]  [Step 4700/14540]  lr: 0.000087  loss: 0.96877  detection_loss: 0.8331 (cls: 0.1540, box: 0.6791)  rpn_loss: 0.1357 (cls: 0.0564, box: 0.0793)
[2025-08-07 17:09:12 train.log] INFO: Epoch: [8]  [Step 4800/14540]  lr: 0.000087  loss: 0.86279  detection_loss: 0.8342 (cls: 0.1319, box: 0.7024)  rpn_loss: 0.0286 (cls: 0.0169, box: 0.0116)
[2025-08-07 17:09:17 train.log] INFO: Epoch: [8]  [Step 4900/14540]  lr: 0.000087  loss: 1.33302  detection_loss: 1.1010 (cls: 0.2615, box: 0.8395)  rpn_loss: 0.2320 (cls: 0.1778, box: 0.0542)
[2025-08-07 17:09:22 train.log] INFO: Epoch: [8]  [Step 5000/14540]  lr: 0.000087  loss: 1.64367  detection_loss: 1.4998 (cls: 0.2212, box: 1.2786)  rpn_loss: 0.1438 (cls: 0.0832, box: 0.0606)
[2025-08-07 17:09:27 train.log] INFO: Epoch: [8]  [Step 5100/14540]  lr: 0.000087  loss: 1.72332  detection_loss: 1.6001 (cls: 0.2999, box: 1.3003)  rpn_loss: 0.1232 (cls: 0.0811, box: 0.0421)
[2025-08-07 17:09:32 train.log] INFO: Epoch: [8]  [Step 5200/14540]  lr: 0.000087  loss: 1.45859  detection_loss: 1.3472 (cls: 0.2924, box: 1.0548)  rpn_loss: 0.1114 (cls: 0.0483, box: 0.0630)
[2025-08-07 17:09:36 train.log] INFO: Epoch: [8]  [Step 5300/14540]  lr: 0.000087  loss: 0.96423  detection_loss: 0.8862 (cls: 0.1592, box: 0.7270)  rpn_loss: 0.0780 (cls: 0.0251, box: 0.0529)
[2025-08-07 17:09:41 train.log] INFO: Epoch: [8]  [Step 5400/14540]  lr: 0.000087  loss: 1.14395  detection_loss: 0.9888 (cls: 0.1265, box: 0.8623)  rpn_loss: 0.1551 (cls: 0.0311, box: 0.1240)
[2025-08-07 17:09:46 train.log] INFO: Epoch: [8]  [Step 5500/14540]  lr: 0.000087  loss: 1.49408  detection_loss: 1.3880 (cls: 0.3093, box: 1.0787)  rpn_loss: 0.1061 (cls: 0.0640, box: 0.0421)
[2025-08-07 17:09:51 train.log] INFO: Epoch: [8]  [Step 5600/14540]  lr: 0.000087  loss: 1.66479  detection_loss: 1.5625 (cls: 0.3213, box: 1.2412)  rpn_loss: 0.1023 (cls: 0.0495, box: 0.0528)
[2025-08-07 17:09:56 train.log] INFO: Epoch: [8]  [Step 5700/14540]  lr: 0.000087  loss: 1.27149  detection_loss: 1.1906 (cls: 0.1493, box: 1.0413)  rpn_loss: 0.0809 (cls: 0.0452, box: 0.0357)
[2025-08-07 17:10:00 train.log] INFO: Epoch: [8]  [Step 5800/14540]  lr: 0.000087  loss: 1.16305  detection_loss: 0.9910 (cls: 0.1583, box: 0.8327)  rpn_loss: 0.1720 (cls: 0.0786, box: 0.0934)
[2025-08-07 17:10:05 train.log] INFO: Epoch: [8]  [Step 5900/14540]  lr: 0.000087  loss: 1.68388  detection_loss: 1.5216 (cls: 0.6301, box: 0.8915)  rpn_loss: 0.1623 (cls: 0.0670, box: 0.0953)
[2025-08-07 17:10:10 train.log] INFO: Epoch: [8]  [Step 6000/14540]  lr: 0.000087  loss: 1.93748  detection_loss: 1.8191 (cls: 0.3146, box: 1.5045)  rpn_loss: 0.1184 (cls: 0.0592, box: 0.0592)
[2025-08-07 17:10:15 train.log] INFO: Epoch: [8]  [Step 6100/14540]  lr: 0.000087  loss: 1.41684  detection_loss: 1.2503 (cls: 0.4335, box: 0.8168)  rpn_loss: 0.1665 (cls: 0.0996, box: 0.0670)
[2025-08-07 17:10:20 train.log] INFO: Epoch: [8]  [Step 6200/14540]  lr: 0.000087  loss: 1.57727  detection_loss: 1.4646 (cls: 0.3756, box: 1.0890)  rpn_loss: 0.1127 (cls: 0.0699, box: 0.0428)
[2025-08-07 17:10:24 train.log] INFO: Epoch: [8]  [Step 6300/14540]  lr: 0.000087  loss: 1.78737  detection_loss: 1.4931 (cls: 0.5223, box: 0.9708)  rpn_loss: 0.2943 (cls: 0.0767, box: 0.2176)
[2025-08-07 17:10:29 train.log] INFO: Epoch: [8]  [Step 6400/14540]  lr: 0.000087  loss: 1.63383  detection_loss: 1.4676 (cls: 0.5693, box: 0.8983)  rpn_loss: 0.1663 (cls: 0.0506, box: 0.1156)
[2025-08-07 17:10:34 train.log] INFO: Epoch: [8]  [Step 6500/14540]  lr: 0.000087  loss: 1.01534  detection_loss: 0.9071 (cls: 0.1729, box: 0.7342)  rpn_loss: 0.1083 (cls: 0.0683, box: 0.0400)
[2025-08-07 17:10:39 train.log] INFO: Epoch: [8]  [Step 6600/14540]  lr: 0.000087  loss: 1.10470  detection_loss: 0.9474 (cls: 0.2355, box: 0.7119)  rpn_loss: 0.1573 (cls: 0.0712, box: 0.0861)
[2025-08-07 17:10:44 train.log] INFO: Epoch: [8]  [Step 6700/14540]  lr: 0.000087  loss: 1.65034  detection_loss: 1.3378 (cls: 0.3206, box: 1.0171)  rpn_loss: 0.3126 (cls: 0.0998, box: 0.2128)
[2025-08-07 17:10:49 train.log] INFO: Epoch: [8]  [Step 6800/14540]  lr: 0.000087  loss: 1.33766  detection_loss: 1.2109 (cls: 0.3528, box: 0.8581)  rpn_loss: 0.1267 (cls: 0.0997, box: 0.0270)
[2025-08-07 17:10:54 train.log] INFO: Epoch: [8]  [Step 6900/14540]  lr: 0.000087  loss: 1.47552  detection_loss: 1.3541 (cls: 0.2531, box: 1.1009)  rpn_loss: 0.1214 (cls: 0.0789, box: 0.0426)
[2025-08-07 17:10:58 train.log] INFO: Epoch: [8]  [Step 7000/14540]  lr: 0.000087  loss: 1.06874  detection_loss: 1.0041 (cls: 0.2865, box: 0.7176)  rpn_loss: 0.0647 (cls: 0.0494, box: 0.0153)
[2025-08-07 17:11:03 train.log] INFO: Epoch: [8]  [Step 7100/14540]  lr: 0.000087  loss: 1.38392  detection_loss: 1.2813 (cls: 0.4000, box: 0.8813)  rpn_loss: 0.1027 (cls: 0.0671, box: 0.0356)
[2025-08-07 17:11:08 train.log] INFO: Epoch: [8]  [Step 7200/14540]  lr: 0.000087  loss: 1.27160  detection_loss: 1.1901 (cls: 0.2942, box: 0.8959)  rpn_loss: 0.0815 (cls: 0.0324, box: 0.0491)
[2025-08-07 17:11:13 train.log] INFO: Epoch: [8]  [Step 7300/14540]  lr: 0.000087  loss: 1.79635  detection_loss: 1.6373 (cls: 0.4483, box: 1.1891)  rpn_loss: 0.1590 (cls: 0.1292, box: 0.0298)
[2025-08-07 17:11:18 train.log] INFO: Epoch: [8]  [Step 7400/14540]  lr: 0.000087  loss: 1.07115  detection_loss: 0.9728 (cls: 0.2106, box: 0.7622)  rpn_loss: 0.0983 (cls: 0.0247, box: 0.0736)
[2025-08-07 17:11:23 train.log] INFO: Epoch: [8]  [Step 7500/14540]  lr: 0.000087  loss: 1.14241  detection_loss: 0.8904 (cls: 0.1330, box: 0.7574)  rpn_loss: 0.2520 (cls: 0.0669, box: 0.1851)
[2025-08-07 17:11:28 train.log] INFO: Epoch: [8]  [Step 7600/14540]  lr: 0.000087  loss: 0.94188  detection_loss: 0.8703 (cls: 0.1947, box: 0.6756)  rpn_loss: 0.0716 (cls: 0.0533, box: 0.0183)
[2025-08-07 17:11:33 train.log] INFO: Epoch: [8]  [Step 7700/14540]  lr: 0.000087  loss: 1.06089  detection_loss: 0.9395 (cls: 0.1997, box: 0.7398)  rpn_loss: 0.1214 (cls: 0.0931, box: 0.0284)
[2025-08-07 17:11:38 train.log] INFO: Epoch: [8]  [Step 7800/14540]  lr: 0.000087  loss: 0.81343  detection_loss: 0.6521 (cls: 0.1705, box: 0.4816)  rpn_loss: 0.1614 (cls: 0.0432, box: 0.1182)
[2025-08-07 17:11:43 train.log] INFO: Epoch: [8]  [Step 7900/14540]  lr: 0.000087  loss: 0.64536  detection_loss: 0.5774 (cls: 0.1683, box: 0.4091)  rpn_loss: 0.0680 (cls: 0.0285, box: 0.0395)
[2025-08-07 17:11:47 train.log] INFO: Epoch: [8]  [Step 8000/14540]  lr: 0.000087  loss: 1.27998  detection_loss: 1.1592 (cls: 0.2204, box: 0.9387)  rpn_loss: 0.1208 (cls: 0.0772, box: 0.0436)
[2025-08-07 17:11:52 train.log] INFO: Epoch: [8]  [Step 8100/14540]  lr: 0.000087  loss: 1.20531  detection_loss: 1.0744 (cls: 0.3423, box: 0.7321)  rpn_loss: 0.1309 (cls: 0.0449, box: 0.0860)
[2025-08-07 17:11:57 train.log] INFO: Epoch: [8]  [Step 8200/14540]  lr: 0.000087  loss: 1.24864  detection_loss: 1.0711 (cls: 0.2186, box: 0.8525)  rpn_loss: 0.1776 (cls: 0.0683, box: 0.1093)
[2025-08-07 17:12:02 train.log] INFO: Epoch: [8]  [Step 8300/14540]  lr: 0.000087  loss: 1.40182  detection_loss: 1.1743 (cls: 0.2511, box: 0.9231)  rpn_loss: 0.2276 (cls: 0.0454, box: 0.1821)
[2025-08-07 17:12:07 train.log] INFO: Epoch: [8]  [Step 8400/14540]  lr: 0.000087  loss: 1.28292  detection_loss: 1.1982 (cls: 0.4484, box: 0.7497)  rpn_loss: 0.0848 (cls: 0.0466, box: 0.0381)
[2025-08-07 17:12:12 train.log] INFO: Epoch: [8]  [Step 8500/14540]  lr: 0.000087  loss: 1.14433  detection_loss: 1.0464 (cls: 0.3285, box: 0.7179)  rpn_loss: 0.0979 (cls: 0.0388, box: 0.0591)
[2025-08-07 17:12:17 train.log] INFO: Epoch: [8]  [Step 8600/14540]  lr: 0.000087  loss: 1.59128  detection_loss: 1.3421 (cls: 0.3851, box: 0.9570)  rpn_loss: 0.2492 (cls: 0.1111, box: 0.1381)
[2025-08-07 17:12:21 train.log] INFO: Epoch: [8]  [Step 8700/14540]  lr: 0.000087  loss: 1.18566  detection_loss: 1.0558 (cls: 0.3138, box: 0.7420)  rpn_loss: 0.1299 (cls: 0.0742, box: 0.0557)
[2025-08-07 17:12:26 train.log] INFO: Epoch: [8]  [Step 8800/14540]  lr: 0.000087  loss: 1.51527  detection_loss: 1.4427 (cls: 0.3106, box: 1.1321)  rpn_loss: 0.0725 (cls: 0.0379, box: 0.0346)
[2025-08-07 17:12:31 train.log] INFO: Epoch: [8]  [Step 8900/14540]  lr: 0.000087  loss: 1.11582  detection_loss: 0.9825 (cls: 0.1170, box: 0.8656)  rpn_loss: 0.1333 (cls: 0.0611, box: 0.0722)
[2025-08-07 17:12:36 train.log] INFO: Epoch: [8]  [Step 9000/14540]  lr: 0.000087  loss: 0.86031  detection_loss: 0.8117 (cls: 0.3135, box: 0.4982)  rpn_loss: 0.0486 (cls: 0.0337, box: 0.0150)
[2025-08-07 17:12:41 train.log] INFO: Epoch: [8]  [Step 9100/14540]  lr: 0.000087  loss: 1.42279  detection_loss: 1.2013 (cls: 0.2202, box: 0.9811)  rpn_loss: 0.2215 (cls: 0.0780, box: 0.1435)
[2025-08-07 17:12:45 train.log] INFO: Epoch: [8]  [Step 9200/14540]  lr: 0.000087  loss: 1.02034  detection_loss: 0.9438 (cls: 0.1801, box: 0.7636)  rpn_loss: 0.0766 (cls: 0.0402, box: 0.0364)
[2025-08-07 17:12:50 train.log] INFO: Epoch: [8]  [Step 9300/14540]  lr: 0.000087  loss: 1.04430  detection_loss: 0.9586 (cls: 0.2593, box: 0.6992)  rpn_loss: 0.0857 (cls: 0.0538, box: 0.0319)
[2025-08-07 17:12:55 train.log] INFO: Epoch: [8]  [Step 9400/14540]  lr: 0.000087  loss: 1.31834  detection_loss: 1.2244 (cls: 0.1739, box: 1.0505)  rpn_loss: 0.0939 (cls: 0.0314, box: 0.0626)
[2025-08-07 17:13:00 train.log] INFO: Epoch: [8]  [Step 9500/14540]  lr: 0.000087  loss: 1.97520  detection_loss: 1.7357 (cls: 0.5109, box: 1.2248)  rpn_loss: 0.2395 (cls: 0.0339, box: 0.2056)
[2025-08-07 17:13:05 train.log] INFO: Epoch: [8]  [Step 9600/14540]  lr: 0.000087  loss: 1.60296  detection_loss: 1.4065 (cls: 0.3367, box: 1.0698)  rpn_loss: 0.1964 (cls: 0.1258, box: 0.0706)
[2025-08-07 17:13:09 train.log] INFO: Epoch: [8]  [Step 9700/14540]  lr: 0.000087  loss: 1.31578  detection_loss: 1.1337 (cls: 0.2678, box: 0.8658)  rpn_loss: 0.1821 (cls: 0.1289, box: 0.0532)
[2025-08-07 17:13:14 train.log] INFO: Epoch: [8]  [Step 9800/14540]  lr: 0.000087  loss: 1.15627  detection_loss: 1.0713 (cls: 0.1978, box: 0.8735)  rpn_loss: 0.0849 (cls: 0.0449, box: 0.0400)
[2025-08-07 17:13:19 train.log] INFO: Epoch: [8]  [Step 9900/14540]  lr: 0.000087  loss: 1.57734  detection_loss: 1.3898 (cls: 0.4046, box: 0.9852)  rpn_loss: 0.1875 (cls: 0.0280, box: 0.1595)
[2025-08-07 17:13:24 train.log] INFO: Epoch: [8]  [Step 10000/14540]  lr: 0.000087  loss: 1.40287  detection_loss: 1.2733 (cls: 0.4290, box: 0.8443)  rpn_loss: 0.1296 (cls: 0.1061, box: 0.0234)
[2025-08-07 17:13:29 train.log] INFO: Epoch: [8]  [Step 10100/14540]  lr: 0.000087  loss: 1.15938  detection_loss: 1.0668 (cls: 0.3570, box: 0.7097)  rpn_loss: 0.0926 (cls: 0.0613, box: 0.0313)
[2025-08-07 17:13:33 train.log] INFO: Epoch: [8]  [Step 10200/14540]  lr: 0.000087  loss: 1.52360  detection_loss: 1.3504 (cls: 0.3627, box: 0.9877)  rpn_loss: 0.1732 (cls: 0.0900, box: 0.0831)
[2025-08-07 17:13:38 train.log] INFO: Epoch: [8]  [Step 10300/14540]  lr: 0.000087  loss: 1.43556  detection_loss: 1.3397 (cls: 0.4246, box: 0.9150)  rpn_loss: 0.0959 (cls: 0.0545, box: 0.0414)
[2025-08-07 17:13:43 train.log] INFO: Epoch: [8]  [Step 10400/14540]  lr: 0.000087  loss: 1.56307  detection_loss: 1.2586 (cls: 0.3027, box: 0.9559)  rpn_loss: 0.3045 (cls: 0.0393, box: 0.2652)
[2025-08-07 17:13:48 train.log] INFO: Epoch: [8]  [Step 10500/14540]  lr: 0.000087  loss: 1.57430  detection_loss: 1.4337 (cls: 0.3595, box: 1.0741)  rpn_loss: 0.1406 (cls: 0.0711, box: 0.0696)
[2025-08-07 17:13:53 train.log] INFO: Epoch: [8]  [Step 10600/14540]  lr: 0.000087  loss: 1.31756  detection_loss: 1.1983 (cls: 0.3115, box: 0.8868)  rpn_loss: 0.1193 (cls: 0.0913, box: 0.0280)
[2025-08-07 17:13:58 train.log] INFO: Epoch: [8]  [Step 10700/14540]  lr: 0.000087  loss: 1.33889  detection_loss: 1.1935 (cls: 0.2243, box: 0.9692)  rpn_loss: 0.1454 (cls: 0.1065, box: 0.0389)
[2025-08-07 17:14:02 train.log] INFO: Epoch: [8]  [Step 10800/14540]  lr: 0.000087  loss: 0.98304  detection_loss: 0.8501 (cls: 0.1655, box: 0.6845)  rpn_loss: 0.1330 (cls: 0.0438, box: 0.0892)
[2025-08-07 17:14:07 train.log] INFO: Epoch: [8]  [Step 10900/14540]  lr: 0.000087  loss: 1.89535  detection_loss: 1.6746 (cls: 0.4217, box: 1.2529)  rpn_loss: 0.2208 (cls: 0.0857, box: 0.1351)
[2025-08-07 17:14:12 train.log] INFO: Epoch: [8]  [Step 11000/14540]  lr: 0.000087  loss: 0.92979  detection_loss: 0.8905 (cls: 0.1897, box: 0.7008)  rpn_loss: 0.0393 (cls: 0.0192, box: 0.0201)
[2025-08-07 17:14:17 train.log] INFO: Epoch: [8]  [Step 11100/14540]  lr: 0.000087  loss: 1.47948  detection_loss: 1.1194 (cls: 0.3660, box: 0.7533)  rpn_loss: 0.3601 (cls: 0.1300, box: 0.2301)
[2025-08-07 17:14:22 train.log] INFO: Epoch: [8]  [Step 11200/14540]  lr: 0.000087  loss: 1.09043  detection_loss: 0.9421 (cls: 0.2899, box: 0.6522)  rpn_loss: 0.1483 (cls: 0.0587, box: 0.0896)
[2025-08-07 17:14:27 train.log] INFO: Epoch: [8]  [Step 11300/14540]  lr: 0.000087  loss: 1.46847  detection_loss: 1.2129 (cls: 0.3133, box: 0.8996)  rpn_loss: 0.2556 (cls: 0.1786, box: 0.0770)
[2025-08-07 17:14:32 train.log] INFO: Epoch: [8]  [Step 11400/14540]  lr: 0.000087  loss: 1.69621  detection_loss: 1.4806 (cls: 0.2388, box: 1.2419)  rpn_loss: 0.2156 (cls: 0.0338, box: 0.1818)
[2025-08-07 17:14:37 train.log] INFO: Epoch: [8]  [Step 11500/14540]  lr: 0.000087  loss: 1.25676  detection_loss: 1.1527 (cls: 0.2420, box: 0.9107)  rpn_loss: 0.1041 (cls: 0.0567, box: 0.0474)
[2025-08-07 17:14:42 train.log] INFO: Epoch: [8]  [Step 11600/14540]  lr: 0.000087  loss: 1.37097  detection_loss: 1.2624 (cls: 0.2956, box: 0.9668)  rpn_loss: 0.1085 (cls: 0.0560, box: 0.0525)
[2025-08-07 17:14:46 train.log] INFO: Epoch: [8]  [Step 11700/14540]  lr: 0.000087  loss: 1.29396  detection_loss: 1.1315 (cls: 0.2208, box: 0.9107)  rpn_loss: 0.1625 (cls: 0.0861, box: 0.0764)
[2025-08-07 17:14:51 train.log] INFO: Epoch: [8]  [Step 11800/14540]  lr: 0.000087  loss: 2.05237  detection_loss: 1.8875 (cls: 0.4815, box: 1.4059)  rpn_loss: 0.1649 (cls: 0.1270, box: 0.0379)
[2025-08-07 17:14:56 train.log] INFO: Epoch: [8]  [Step 11900/14540]  lr: 0.000087  loss: 1.70517  detection_loss: 1.5598 (cls: 0.3313, box: 1.2286)  rpn_loss: 0.1453 (cls: 0.0459, box: 0.0994)
[2025-08-07 17:15:01 train.log] INFO: Epoch: [8]  [Step 12000/14540]  lr: 0.000087  loss: 1.61129  detection_loss: 1.5059 (cls: 0.3738, box: 1.1321)  rpn_loss: 0.1054 (cls: 0.0564, box: 0.0490)
[2025-08-07 17:15:06 train.log] INFO: Epoch: [8]  [Step 12100/14540]  lr: 0.000087  loss: 1.23533  detection_loss: 1.1005 (cls: 0.2661, box: 0.8344)  rpn_loss: 0.1348 (cls: 0.0897, box: 0.0452)
[2025-08-07 17:15:11 train.log] INFO: Epoch: [8]  [Step 12200/14540]  lr: 0.000087  loss: 0.71901  detection_loss: 0.6438 (cls: 0.1762, box: 0.4676)  rpn_loss: 0.0752 (cls: 0.0190, box: 0.0562)
[2025-08-07 17:15:16 train.log] INFO: Epoch: [8]  [Step 12300/14540]  lr: 0.000087  loss: 1.68906  detection_loss: 1.5089 (cls: 0.2587, box: 1.2501)  rpn_loss: 0.1802 (cls: 0.1111, box: 0.0691)
[2025-08-07 17:15:21 train.log] INFO: Epoch: [8]  [Step 12400/14540]  lr: 0.000087  loss: 1.09109  detection_loss: 0.8993 (cls: 0.2091, box: 0.6902)  rpn_loss: 0.1918 (cls: 0.0618, box: 0.1300)
[2025-08-07 17:15:26 train.log] INFO: Epoch: [8]  [Step 12500/14540]  lr: 0.000087  loss: 1.69683  detection_loss: 1.5458 (cls: 0.2845, box: 1.2613)  rpn_loss: 0.1510 (cls: 0.0994, box: 0.0516)
[2025-08-07 17:15:31 train.log] INFO: Epoch: [8]  [Step 12600/14540]  lr: 0.000087  loss: 1.35091  detection_loss: 1.1985 (cls: 0.2140, box: 0.9845)  rpn_loss: 0.1524 (cls: 0.1057, box: 0.0467)
[2025-08-07 17:15:36 train.log] INFO: Epoch: [8]  [Step 12700/14540]  lr: 0.000087  loss: 0.81439  detection_loss: 0.7367 (cls: 0.1991, box: 0.5376)  rpn_loss: 0.0777 (cls: 0.0233, box: 0.0544)
[2025-08-07 17:15:41 train.log] INFO: Epoch: [8]  [Step 12800/14540]  lr: 0.000087  loss: 1.35788  detection_loss: 1.2386 (cls: 0.3279, box: 0.9107)  rpn_loss: 0.1193 (cls: 0.0814, box: 0.0379)
[2025-08-07 17:15:46 train.log] INFO: Epoch: [8]  [Step 12900/14540]  lr: 0.000087  loss: 1.92550  detection_loss: 1.6763 (cls: 0.4690, box: 1.2073)  rpn_loss: 0.2492 (cls: 0.2099, box: 0.0393)
[2025-08-07 17:15:51 train.log] INFO: Epoch: [8]  [Step 13000/14540]  lr: 0.000087  loss: 1.19076  detection_loss: 0.8005 (cls: 0.1727, box: 0.6279)  rpn_loss: 0.3902 (cls: 0.0552, box: 0.3350)
[2025-08-07 17:15:56 train.log] INFO: Epoch: [8]  [Step 13100/14540]  lr: 0.000087  loss: 1.52594  detection_loss: 1.3776 (cls: 0.3660, box: 1.0115)  rpn_loss: 0.1484 (cls: 0.0972, box: 0.0512)
[2025-08-07 17:16:00 train.log] INFO: Epoch: [8]  [Step 13200/14540]  lr: 0.000087  loss: 0.98487  detection_loss: 0.8913 (cls: 0.1505, box: 0.7408)  rpn_loss: 0.0935 (cls: 0.0697, box: 0.0239)
[2025-08-07 17:16:05 train.log] INFO: Epoch: [8]  [Step 13300/14540]  lr: 0.000087  loss: 1.14991  detection_loss: 1.0423 (cls: 0.2312, box: 0.8111)  rpn_loss: 0.1076 (cls: 0.0597, box: 0.0480)
[2025-08-07 17:16:10 train.log] INFO: Epoch: [8]  [Step 13400/14540]  lr: 0.000087  loss: 1.14735  detection_loss: 1.0080 (cls: 0.2846, box: 0.7234)  rpn_loss: 0.1393 (cls: 0.0948, box: 0.0446)
[2025-08-07 17:16:15 train.log] INFO: Epoch: [8]  [Step 13500/14540]  lr: 0.000087  loss: 1.53883  detection_loss: 1.3985 (cls: 0.2160, box: 1.1824)  rpn_loss: 0.1404 (cls: 0.0436, box: 0.0967)
[2025-08-07 17:16:20 train.log] INFO: Epoch: [8]  [Step 13600/14540]  lr: 0.000087  loss: 1.36380  detection_loss: 1.2306 (cls: 0.3776, box: 0.8530)  rpn_loss: 0.1332 (cls: 0.0737, box: 0.0595)
[2025-08-07 17:16:25 train.log] INFO: Epoch: [8]  [Step 13700/14540]  lr: 0.000087  loss: 1.25061  detection_loss: 1.1100 (cls: 0.2526, box: 0.8574)  rpn_loss: 0.1406 (cls: 0.0650, box: 0.0757)
[2025-08-07 17:16:30 train.log] INFO: Epoch: [8]  [Step 13800/14540]  lr: 0.000087  loss: 1.36315  detection_loss: 1.2057 (cls: 0.2622, box: 0.9435)  rpn_loss: 0.1575 (cls: 0.1284, box: 0.0291)
[2025-08-07 17:16:35 train.log] INFO: Epoch: [8]  [Step 13900/14540]  lr: 0.000087  loss: 1.49451  detection_loss: 1.2961 (cls: 0.2496, box: 1.0465)  rpn_loss: 0.1984 (cls: 0.0629, box: 0.1355)
[2025-08-07 17:16:40 train.log] INFO: Epoch: [8]  [Step 14000/14540]  lr: 0.000087  loss: 0.96877  detection_loss: 0.8640 (cls: 0.1530, box: 0.7110)  rpn_loss: 0.1047 (cls: 0.0221, box: 0.0826)
[2025-08-07 17:16:44 train.log] INFO: Epoch: [8]  [Step 14100/14540]  lr: 0.000087  loss: 1.88103  detection_loss: 1.7662 (cls: 0.4148, box: 1.3514)  rpn_loss: 0.1148 (cls: 0.0530, box: 0.0618)
[2025-08-07 17:16:49 train.log] INFO: Epoch: [8]  [Step 14200/14540]  lr: 0.000087  loss: 0.82467  detection_loss: 0.7310 (cls: 0.1907, box: 0.5403)  rpn_loss: 0.0937 (cls: 0.0563, box: 0.0374)
[2025-08-07 17:16:54 train.log] INFO: Epoch: [8]  [Step 14300/14540]  lr: 0.000087  loss: 1.03724  detection_loss: 0.9069 (cls: 0.2543, box: 0.6526)  rpn_loss: 0.1304 (cls: 0.1084, box: 0.0219)
[2025-08-07 17:16:59 train.log] INFO: Epoch: [8]  [Step 14400/14540]  lr: 0.000087  loss: 1.35259  detection_loss: 1.2300 (cls: 0.3649, box: 0.8651)  rpn_loss: 0.1225 (cls: 0.0502, box: 0.0724)
[2025-08-07 17:17:04 train.log] INFO: Epoch: [8]  [Step 14500/14540]  lr: 0.000087  loss: 0.91345  detection_loss: 0.7839 (cls: 0.1872, box: 0.5967)  rpn_loss: 0.1295 (cls: 0.0379, box: 0.0916)
[2025-08-07 17:19:54 train.log] INFO: Epoch: [9]  [Step 100/14540]  lr: 0.000082  loss: 1.43995  detection_loss: 1.1643 (cls: 0.2692, box: 0.8951)  rpn_loss: 0.2756 (cls: 0.0191, box: 0.2565)
[2025-08-07 17:20:00 train.log] INFO: Epoch: [9]  [Step 200/14540]  lr: 0.000082  loss: 1.21628  detection_loss: 1.1309 (cls: 0.2168, box: 0.9141)  rpn_loss: 0.0854 (cls: 0.0553, box: 0.0301)
[2025-08-07 17:20:05 train.log] INFO: Epoch: [9]  [Step 300/14540]  lr: 0.000082  loss: 0.96603  detection_loss: 0.8928 (cls: 0.2002, box: 0.6926)  rpn_loss: 0.0732 (cls: 0.0513, box: 0.0219)
[2025-08-07 17:20:10 train.log] INFO: Epoch: [9]  [Step 400/14540]  lr: 0.000082  loss: 0.75098  detection_loss: 0.6655 (cls: 0.1724, box: 0.4931)  rpn_loss: 0.0855 (cls: 0.0492, box: 0.0363)
[2025-08-07 17:20:15 train.log] INFO: Epoch: [9]  [Step 500/14540]  lr: 0.000082  loss: 1.15393  detection_loss: 1.0928 (cls: 0.2787, box: 0.8141)  rpn_loss: 0.0612 (cls: 0.0187, box: 0.0424)
[2025-08-07 17:20:20 train.log] INFO: Epoch: [9]  [Step 600/14540]  lr: 0.000082  loss: 1.21700  detection_loss: 1.1352 (cls: 0.3707, box: 0.7644)  rpn_loss: 0.0818 (cls: 0.0492, box: 0.0326)
[2025-08-07 17:20:25 train.log] INFO: Epoch: [9]  [Step 700/14540]  lr: 0.000082  loss: 1.58729  detection_loss: 1.4124 (cls: 0.3241, box: 1.0883)  rpn_loss: 0.1749 (cls: 0.0625, box: 0.1124)
[2025-08-07 17:20:29 train.log] INFO: Epoch: [9]  [Step 800/14540]  lr: 0.000082  loss: 0.95520  detection_loss: 0.9060 (cls: 0.1629, box: 0.7431)  rpn_loss: 0.0492 (cls: 0.0250, box: 0.0242)
[2025-08-07 17:20:34 train.log] INFO: Epoch: [9]  [Step 900/14540]  lr: 0.000082  loss: 1.27342  detection_loss: 1.1889 (cls: 0.3753, box: 0.8136)  rpn_loss: 0.0845 (cls: 0.0607, box: 0.0238)
[2025-08-07 17:20:39 train.log] INFO: Epoch: [9]  [Step 1000/14540]  lr: 0.000082  loss: 1.30746  detection_loss: 0.9915 (cls: 0.2070, box: 0.7845)  rpn_loss: 0.3160 (cls: 0.0348, box: 0.2812)
[2025-08-07 17:20:44 train.log] INFO: Epoch: [9]  [Step 1100/14540]  lr: 0.000082  loss: 0.85886  detection_loss: 0.7674 (cls: 0.1292, box: 0.6382)  rpn_loss: 0.0915 (cls: 0.0327, box: 0.0588)
[2025-08-07 17:20:49 train.log] INFO: Epoch: [9]  [Step 1200/14540]  lr: 0.000082  loss: 1.14382  detection_loss: 0.9395 (cls: 0.3247, box: 0.6147)  rpn_loss: 0.2044 (cls: 0.0789, box: 0.1255)
[2025-08-07 17:20:54 train.log] INFO: Epoch: [9]  [Step 1300/14540]  lr: 0.000082  loss: 0.81128  detection_loss: 0.7414 (cls: 0.1557, box: 0.5856)  rpn_loss: 0.0699 (cls: 0.0326, box: 0.0373)
[2025-08-07 17:20:59 train.log] INFO: Epoch: [9]  [Step 1400/14540]  lr: 0.000082  loss: 0.95963  detection_loss: 0.8947 (cls: 0.2385, box: 0.6562)  rpn_loss: 0.0649 (cls: 0.0363, box: 0.0286)
[2025-08-07 17:21:04 train.log] INFO: Epoch: [9]  [Step 1500/14540]  lr: 0.000082  loss: 1.46718  detection_loss: 1.3746 (cls: 0.3694, box: 1.0052)  rpn_loss: 0.0926 (cls: 0.0607, box: 0.0319)
[2025-08-07 17:21:09 train.log] INFO: Epoch: [9]  [Step 1600/14540]  lr: 0.000082  loss: 0.80088  detection_loss: 0.6755 (cls: 0.2700, box: 0.4055)  rpn_loss: 0.1254 (cls: 0.1042, box: 0.0212)
[2025-08-07 17:21:14 train.log] INFO: Epoch: [9]  [Step 1700/14540]  lr: 0.000082  loss: 1.22843  detection_loss: 1.0902 (cls: 0.2674, box: 0.8228)  rpn_loss: 0.1382 (cls: 0.0911, box: 0.0471)
[2025-08-07 17:21:19 train.log] INFO: Epoch: [9]  [Step 1800/14540]  lr: 0.000082  loss: 1.17286  detection_loss: 1.0260 (cls: 0.1213, box: 0.9048)  rpn_loss: 0.1468 (cls: 0.0710, box: 0.0758)
[2025-08-07 17:21:24 train.log] INFO: Epoch: [9]  [Step 1900/14540]  lr: 0.000082  loss: 1.38013  detection_loss: 1.2271 (cls: 0.3454, box: 0.8817)  rpn_loss: 0.1530 (cls: 0.0595, box: 0.0936)
[2025-08-07 17:21:28 train.log] INFO: Epoch: [9]  [Step 2000/14540]  lr: 0.000082  loss: 0.64759  detection_loss: 0.5700 (cls: 0.1175, box: 0.4524)  rpn_loss: 0.0776 (cls: 0.0695, box: 0.0082)
[2025-08-07 17:21:33 train.log] INFO: Epoch: [9]  [Step 2100/14540]  lr: 0.000082  loss: 1.00258  detection_loss: 0.8678 (cls: 0.2028, box: 0.6650)  rpn_loss: 0.1348 (cls: 0.0321, box: 0.1027)
[2025-08-07 17:21:38 train.log] INFO: Epoch: [9]  [Step 2200/14540]  lr: 0.000082  loss: 1.24733  detection_loss: 1.1339 (cls: 0.2375, box: 0.8965)  rpn_loss: 0.1134 (cls: 0.0351, box: 0.0783)
[2025-08-07 17:21:43 train.log] INFO: Epoch: [9]  [Step 2300/14540]  lr: 0.000082  loss: 0.97529  detection_loss: 0.8600 (cls: 0.2448, box: 0.6152)  rpn_loss: 0.1153 (cls: 0.0497, box: 0.0655)
[2025-08-07 17:21:48 train.log] INFO: Epoch: [9]  [Step 2400/14540]  lr: 0.000082  loss: 1.12476  detection_loss: 1.0351 (cls: 0.2815, box: 0.7536)  rpn_loss: 0.0897 (cls: 0.0583, box: 0.0313)
[2025-08-07 17:21:53 train.log] INFO: Epoch: [9]  [Step 2500/14540]  lr: 0.000082  loss: 1.22382  detection_loss: 1.1309 (cls: 0.2644, box: 0.8665)  rpn_loss: 0.0929 (cls: 0.0427, box: 0.0502)
[2025-08-07 17:21:58 train.log] INFO: Epoch: [9]  [Step 2600/14540]  lr: 0.000082  loss: 0.68511  detection_loss: 0.6128 (cls: 0.1720, box: 0.4408)  rpn_loss: 0.0723 (cls: 0.0444, box: 0.0279)
[2025-08-07 17:22:03 train.log] INFO: Epoch: [9]  [Step 2700/14540]  lr: 0.000082  loss: 1.16723  detection_loss: 1.0108 (cls: 0.2507, box: 0.7601)  rpn_loss: 0.1564 (cls: 0.0515, box: 0.1049)
[2025-08-07 17:22:07 train.log] INFO: Epoch: [9]  [Step 2800/14540]  lr: 0.000082  loss: 1.04852  detection_loss: 0.9565 (cls: 0.2710, box: 0.6855)  rpn_loss: 0.0920 (cls: 0.0652, box: 0.0268)
[2025-08-07 17:22:12 train.log] INFO: Epoch: [9]  [Step 2900/14540]  lr: 0.000082  loss: 1.57167  detection_loss: 1.4244 (cls: 0.1850, box: 1.2394)  rpn_loss: 0.1473 (cls: 0.0855, box: 0.0618)
[2025-08-07 17:22:17 train.log] INFO: Epoch: [9]  [Step 3000/14540]  lr: 0.000082  loss: 1.38250  detection_loss: 1.2399 (cls: 0.4087, box: 0.8312)  rpn_loss: 0.1426 (cls: 0.1027, box: 0.0399)
[2025-08-07 17:22:22 train.log] INFO: Epoch: [9]  [Step 3100/14540]  lr: 0.000082  loss: 0.92961  detection_loss: 0.8285 (cls: 0.2153, box: 0.6131)  rpn_loss: 0.1011 (cls: 0.0369, box: 0.0642)
[2025-08-07 17:22:27 train.log] INFO: Epoch: [9]  [Step 3200/14540]  lr: 0.000082  loss: 1.26829  detection_loss: 1.1819 (cls: 0.3782, box: 0.8037)  rpn_loss: 0.0864 (cls: 0.0517, box: 0.0347)
[2025-08-07 17:22:31 train.log] INFO: Epoch: [9]  [Step 3300/14540]  lr: 0.000082  loss: 1.10490  detection_loss: 0.9942 (cls: 0.3169, box: 0.6774)  rpn_loss: 0.1107 (cls: 0.0650, box: 0.0457)
[2025-08-07 17:22:36 train.log] INFO: Epoch: [9]  [Step 3400/14540]  lr: 0.000082  loss: 1.17639  detection_loss: 0.9043 (cls: 0.2234, box: 0.6809)  rpn_loss: 0.2721 (cls: 0.0744, box: 0.1977)
[2025-08-07 17:22:41 train.log] INFO: Epoch: [9]  [Step 3500/14540]  lr: 0.000082  loss: 1.44625  detection_loss: 1.2477 (cls: 0.3707, box: 0.8771)  rpn_loss: 0.1985 (cls: 0.1386, box: 0.0599)
[2025-08-07 17:22:46 train.log] INFO: Epoch: [9]  [Step 3600/14540]  lr: 0.000082  loss: 1.45039  detection_loss: 1.2541 (cls: 0.2193, box: 1.0347)  rpn_loss: 0.1963 (cls: 0.0475, box: 0.1488)
[2025-08-07 17:22:48 train.log] INFO: Epoch: [9]  [Step 3635/14540]  lr: 0.000082  loss: 1.15787  detection_loss: 1.0350 (cls: 0.1970, box: 0.8379)  rpn_loss: 0.1229 (cls: 0.0416, box: 0.0813)
[2025-08-07 17:22:51 train.log] INFO: Epoch: [9]  [Step 3700/14540]  lr: 0.000082  loss: 1.51390  detection_loss: 1.3039 (cls: 0.1698, box: 1.1341)  rpn_loss: 0.2100 (cls: 0.0441, box: 0.1660)
[2025-08-07 17:22:56 train.log] INFO: Epoch: [9]  [Step 3800/14540]  lr: 0.000082  loss: 1.01775  detection_loss: 0.8783 (cls: 0.2967, box: 0.5815)  rpn_loss: 0.1395 (cls: 0.1119, box: 0.0276)
[2025-08-07 17:23:01 train.log] INFO: Epoch: [9]  [Step 3900/14540]  lr: 0.000082  loss: 1.08459  detection_loss: 0.9746 (cls: 0.2473, box: 0.7274)  rpn_loss: 0.1099 (cls: 0.0851, box: 0.0248)
[2025-08-07 17:23:06 train.log] INFO: Epoch: [9]  [Step 4000/14540]  lr: 0.000082  loss: 1.22989  detection_loss: 1.1502 (cls: 0.2121, box: 0.9381)  rpn_loss: 0.0797 (cls: 0.0571, box: 0.0226)
[2025-08-07 17:23:11 train.log] INFO: Epoch: [9]  [Step 4100/14540]  lr: 0.000082  loss: 1.10303  detection_loss: 0.9811 (cls: 0.1986, box: 0.7825)  rpn_loss: 0.1219 (cls: 0.0527, box: 0.0692)
[2025-08-07 17:23:16 train.log] INFO: Epoch: [9]  [Step 4200/14540]  lr: 0.000082  loss: 1.29809  detection_loss: 1.2232 (cls: 0.2796, box: 0.9435)  rpn_loss: 0.0749 (cls: 0.0294, box: 0.0456)
[2025-08-07 17:23:21 train.log] INFO: Epoch: [9]  [Step 4300/14540]  lr: 0.000082  loss: 1.52229  detection_loss: 1.4049 (cls: 0.2236, box: 1.1813)  rpn_loss: 0.1174 (cls: 0.0806, box: 0.0368)
[2025-08-07 17:23:26 train.log] INFO: Epoch: [9]  [Step 4400/14540]  lr: 0.000082  loss: 1.17898  detection_loss: 1.0621 (cls: 0.1892, box: 0.8728)  rpn_loss: 0.1169 (cls: 0.0446, box: 0.0723)
[2025-08-07 17:23:31 train.log] INFO: Epoch: [9]  [Step 4500/14540]  lr: 0.000082  loss: 0.98192  detection_loss: 0.8869 (cls: 0.2098, box: 0.6770)  rpn_loss: 0.0951 (cls: 0.0765, box: 0.0186)
[2025-08-07 17:23:36 train.log] INFO: Epoch: [9]  [Step 4600/14540]  lr: 0.000082  loss: 0.86804  detection_loss: 0.7745 (cls: 0.2086, box: 0.5659)  rpn_loss: 0.0935 (cls: 0.0565, box: 0.0370)
[2025-08-07 17:23:41 train.log] INFO: Epoch: [9]  [Step 4700/14540]  lr: 0.000082  loss: 1.08931  detection_loss: 0.9366 (cls: 0.2488, box: 0.6878)  rpn_loss: 0.1527 (cls: 0.0312, box: 0.1215)
[2025-08-07 17:23:46 train.log] INFO: Epoch: [9]  [Step 4800/14540]  lr: 0.000082  loss: 1.31310  detection_loss: 1.2205 (cls: 0.1397, box: 1.0809)  rpn_loss: 0.0926 (cls: 0.0197, box: 0.0729)
[2025-08-07 17:23:51 train.log] INFO: Epoch: [9]  [Step 4900/14540]  lr: 0.000082  loss: 1.06845  detection_loss: 0.9878 (cls: 0.2753, box: 0.7124)  rpn_loss: 0.0807 (cls: 0.0643, box: 0.0164)
[2025-08-07 17:23:56 train.log] INFO: Epoch: [9]  [Step 5000/14540]  lr: 0.000082  loss: 0.68537  detection_loss: 0.6372 (cls: 0.1731, box: 0.4642)  rpn_loss: 0.0481 (cls: 0.0194, box: 0.0287)
[2025-08-07 17:24:01 train.log] INFO: Epoch: [9]  [Step 5100/14540]  lr: 0.000082  loss: 1.25026  detection_loss: 1.1527 (cls: 0.3051, box: 0.8476)  rpn_loss: 0.0975 (cls: 0.0604, box: 0.0371)
[2025-08-07 17:24:06 train.log] INFO: Epoch: [9]  [Step 5200/14540]  lr: 0.000082  loss: 0.92334  detection_loss: 0.7872 (cls: 0.2126, box: 0.5746)  rpn_loss: 0.1362 (cls: 0.0466, box: 0.0895)
[2025-08-07 17:24:11 train.log] INFO: Epoch: [9]  [Step 5300/14540]  lr: 0.000082  loss: 1.30324  detection_loss: 1.1742 (cls: 0.3265, box: 0.8477)  rpn_loss: 0.1291 (cls: 0.0884, box: 0.0407)
[2025-08-07 17:24:16 train.log] INFO: Epoch: [9]  [Step 5400/14540]  lr: 0.000082  loss: 1.10163  detection_loss: 0.9858 (cls: 0.2571, box: 0.7287)  rpn_loss: 0.1159 (cls: 0.0723, box: 0.0435)
[2025-08-07 17:24:21 train.log] INFO: Epoch: [9]  [Step 5500/14540]  lr: 0.000082  loss: 1.64738  detection_loss: 1.5023 (cls: 0.3131, box: 1.1892)  rpn_loss: 0.1451 (cls: 0.0463, box: 0.0988)
[2025-08-07 17:24:25 train.log] INFO: Epoch: [9]  [Step 5600/14540]  lr: 0.000082  loss: 0.98969  detection_loss: 0.8772 (cls: 0.2442, box: 0.6330)  rpn_loss: 0.1125 (cls: 0.0806, box: 0.0319)
[2025-08-07 17:24:30 train.log] INFO: Epoch: [9]  [Step 5700/14540]  lr: 0.000082  loss: 1.61643  detection_loss: 1.4798 (cls: 0.3639, box: 1.1159)  rpn_loss: 0.1366 (cls: 0.0912, box: 0.0454)
[2025-08-07 17:24:35 train.log] INFO: Epoch: [9]  [Step 5800/14540]  lr: 0.000082  loss: 1.11268  detection_loss: 0.8502 (cls: 0.1884, box: 0.6618)  rpn_loss: 0.2625 (cls: 0.1534, box: 0.1091)
[2025-08-07 17:24:40 train.log] INFO: Epoch: [9]  [Step 5900/14540]  lr: 0.000082  loss: 1.43200  detection_loss: 1.2018 (cls: 0.2722, box: 0.9296)  rpn_loss: 0.2302 (cls: 0.0333, box: 0.1969)
[2025-08-07 17:24:45 train.log] INFO: Epoch: [9]  [Step 6000/14540]  lr: 0.000082  loss: 1.44035  detection_loss: 1.0461 (cls: 0.1583, box: 0.8878)  rpn_loss: 0.3942 (cls: 0.0262, box: 0.3681)
[2025-08-07 17:24:50 train.log] INFO: Epoch: [9]  [Step 6100/14540]  lr: 0.000082  loss: 1.32025  detection_loss: 1.2512 (cls: 0.2851, box: 0.9660)  rpn_loss: 0.0691 (cls: 0.0219, box: 0.0472)
[2025-08-07 17:24:55 train.log] INFO: Epoch: [9]  [Step 6200/14540]  lr: 0.000082  loss: 1.62861  detection_loss: 1.5614 (cls: 0.3654, box: 1.1959)  rpn_loss: 0.0672 (cls: 0.0440, box: 0.0232)
[2025-08-07 17:25:00 train.log] INFO: Epoch: [9]  [Step 6300/14540]  lr: 0.000082  loss: 1.23619  detection_loss: 1.0979 (cls: 0.3687, box: 0.7292)  rpn_loss: 0.1383 (cls: 0.1019, box: 0.0364)
[2025-08-07 17:25:05 train.log] INFO: Epoch: [9]  [Step 6400/14540]  lr: 0.000082  loss: 1.18766  detection_loss: 1.0596 (cls: 0.2473, box: 0.8123)  rpn_loss: 0.1281 (cls: 0.0341, box: 0.0940)
[2025-08-07 17:25:10 train.log] INFO: Epoch: [9]  [Step 6500/14540]  lr: 0.000082  loss: 1.27681  detection_loss: 1.1850 (cls: 0.3065, box: 0.8785)  rpn_loss: 0.0919 (cls: 0.0275, box: 0.0644)
[2025-08-07 17:25:15 train.log] INFO: Epoch: [9]  [Step 6600/14540]  lr: 0.000082  loss: 0.88918  detection_loss: 0.8107 (cls: 0.1561, box: 0.6546)  rpn_loss: 0.0784 (cls: 0.0264, box: 0.0520)
[2025-08-07 17:25:20 train.log] INFO: Epoch: [9]  [Step 6700/14540]  lr: 0.000082  loss: 1.73645  detection_loss: 1.5500 (cls: 0.3257, box: 1.2242)  rpn_loss: 0.1865 (cls: 0.0929, box: 0.0936)
[2025-08-07 17:25:25 train.log] INFO: Epoch: [9]  [Step 6800/14540]  lr: 0.000082  loss: 1.52481  detection_loss: 1.3647 (cls: 0.5726, box: 0.7921)  rpn_loss: 0.1601 (cls: 0.1299, box: 0.0301)
[2025-08-07 17:25:30 train.log] INFO: Epoch: [9]  [Step 6900/14540]  lr: 0.000082  loss: 1.50438  detection_loss: 1.4060 (cls: 0.3001, box: 1.1060)  rpn_loss: 0.0984 (cls: 0.0509, box: 0.0475)
[2025-08-07 17:25:35 train.log] INFO: Epoch: [9]  [Step 7000/14540]  lr: 0.000082  loss: 0.92222  detection_loss: 0.8249 (cls: 0.1290, box: 0.6960)  rpn_loss: 0.0973 (cls: 0.0677, box: 0.0296)
[2025-08-07 17:25:40 train.log] INFO: Epoch: [9]  [Step 7100/14540]  lr: 0.000082  loss: 1.06528  detection_loss: 0.9734 (cls: 0.2140, box: 0.7593)  rpn_loss: 0.0919 (cls: 0.0578, box: 0.0341)
[2025-08-07 17:25:45 train.log] INFO: Epoch: [9]  [Step 7200/14540]  lr: 0.000082  loss: 1.10768  detection_loss: 0.9924 (cls: 0.1900, box: 0.8024)  rpn_loss: 0.1153 (cls: 0.0763, box: 0.0390)
[2025-08-07 17:25:50 train.log] INFO: Epoch: [9]  [Step 7300/14540]  lr: 0.000082  loss: 0.93963  detection_loss: 0.8137 (cls: 0.1567, box: 0.6570)  rpn_loss: 0.1259 (cls: 0.0421, box: 0.0838)
[2025-08-07 17:25:55 train.log] INFO: Epoch: [9]  [Step 7400/14540]  lr: 0.000082  loss: 1.00385  detection_loss: 0.7993 (cls: 0.1515, box: 0.6478)  rpn_loss: 0.2045 (cls: 0.0846, box: 0.1200)
[2025-08-07 17:26:00 train.log] INFO: Epoch: [9]  [Step 7500/14540]  lr: 0.000082  loss: 0.73854  detection_loss: 0.6213 (cls: 0.1831, box: 0.4382)  rpn_loss: 0.1173 (cls: 0.0849, box: 0.0324)
[2025-08-07 17:26:05 train.log] INFO: Epoch: [9]  [Step 7600/14540]  lr: 0.000082  loss: 1.07488  detection_loss: 0.9678 (cls: 0.2602, box: 0.7075)  rpn_loss: 0.1071 (cls: 0.0259, box: 0.0812)
[2025-08-07 17:26:10 train.log] INFO: Epoch: [9]  [Step 7700/14540]  lr: 0.000082  loss: 0.53206  detection_loss: 0.4819 (cls: 0.1032, box: 0.3787)  rpn_loss: 0.0502 (cls: 0.0332, box: 0.0170)
[2025-08-07 17:26:15 train.log] INFO: Epoch: [9]  [Step 7800/14540]  lr: 0.000082  loss: 1.31646  detection_loss: 1.2175 (cls: 0.2271, box: 0.9903)  rpn_loss: 0.0990 (cls: 0.0808, box: 0.0181)
[2025-08-07 17:26:20 train.log] INFO: Epoch: [9]  [Step 7900/14540]  lr: 0.000082  loss: 1.15942  detection_loss: 1.1005 (cls: 0.1604, box: 0.9402)  rpn_loss: 0.0589 (cls: 0.0287, box: 0.0302)
[2025-08-07 17:26:25 train.log] INFO: Epoch: [9]  [Step 8000/14540]  lr: 0.000082  loss: 1.18570  detection_loss: 1.0838 (cls: 0.3363, box: 0.7475)  rpn_loss: 0.1019 (cls: 0.0555, box: 0.0465)
[2025-08-07 17:26:30 train.log] INFO: Epoch: [9]  [Step 8100/14540]  lr: 0.000082  loss: 1.61022  detection_loss: 1.3078 (cls: 0.3058, box: 1.0020)  rpn_loss: 0.3025 (cls: 0.0564, box: 0.2460)
[2025-08-07 17:26:35 train.log] INFO: Epoch: [9]  [Step 8200/14540]  lr: 0.000082  loss: 1.58130  detection_loss: 1.4687 (cls: 0.4856, box: 0.9832)  rpn_loss: 0.1125 (cls: 0.0635, box: 0.0490)
[2025-08-07 17:26:40 train.log] INFO: Epoch: [9]  [Step 8300/14540]  lr: 0.000082  loss: 1.80094  detection_loss: 1.6676 (cls: 0.3915, box: 1.2762)  rpn_loss: 0.1333 (cls: 0.0544, box: 0.0789)
[2025-08-07 17:26:45 train.log] INFO: Epoch: [9]  [Step 8400/14540]  lr: 0.000082  loss: 1.49304  detection_loss: 1.3634 (cls: 0.1891, box: 1.1743)  rpn_loss: 0.1296 (cls: 0.0617, box: 0.0680)
[2025-08-07 17:26:50 train.log] INFO: Epoch: [9]  [Step 8500/14540]  lr: 0.000082  loss: 1.07572  detection_loss: 0.8686 (cls: 0.2116, box: 0.6570)  rpn_loss: 0.2071 (cls: 0.1627, box: 0.0444)
[2025-08-07 17:26:55 train.log] INFO: Epoch: [9]  [Step 8600/14540]  lr: 0.000082  loss: 1.36308  detection_loss: 1.2660 (cls: 0.3704, box: 0.8956)  rpn_loss: 0.0970 (cls: 0.0589, box: 0.0381)
[2025-08-07 17:27:00 train.log] INFO: Epoch: [9]  [Step 8700/14540]  lr: 0.000082  loss: 1.67011  detection_loss: 1.5394 (cls: 0.3646, box: 1.1748)  rpn_loss: 0.1307 (cls: 0.0866, box: 0.0441)
[2025-08-07 17:27:06 train.log] INFO: Epoch: [9]  [Step 8800/14540]  lr: 0.000082  loss: 1.34593  detection_loss: 1.1603 (cls: 0.3063, box: 0.8540)  rpn_loss: 0.1856 (cls: 0.0830, box: 0.1026)
[2025-08-07 17:27:11 train.log] INFO: Epoch: [9]  [Step 8900/14540]  lr: 0.000082  loss: 1.08286  detection_loss: 1.0250 (cls: 0.2368, box: 0.7881)  rpn_loss: 0.0579 (cls: 0.0315, box: 0.0264)
[2025-08-07 17:27:16 train.log] INFO: Epoch: [9]  [Step 9000/14540]  lr: 0.000082  loss: 1.47251  detection_loss: 1.2277 (cls: 0.3484, box: 0.8793)  rpn_loss: 0.2448 (cls: 0.2015, box: 0.0433)
[2025-08-07 17:27:21 train.log] INFO: Epoch: [9]  [Step 9100/14540]  lr: 0.000082  loss: 0.93067  detection_loss: 0.8131 (cls: 0.1808, box: 0.6324)  rpn_loss: 0.1175 (cls: 0.0647, box: 0.0528)
[2025-08-07 17:27:26 train.log] INFO: Epoch: [9]  [Step 9200/14540]  lr: 0.000082  loss: 0.78395  detection_loss: 0.6944 (cls: 0.1936, box: 0.5007)  rpn_loss: 0.0896 (cls: 0.0393, box: 0.0503)
[2025-08-07 17:27:31 train.log] INFO: Epoch: [9]  [Step 9300/14540]  lr: 0.000082  loss: 1.52184  detection_loss: 1.1767 (cls: 0.3165, box: 0.8601)  rpn_loss: 0.3452 (cls: 0.2266, box: 0.1185)
[2025-08-07 17:27:36 train.log] INFO: Epoch: [9]  [Step 9400/14540]  lr: 0.000082  loss: 1.43130  detection_loss: 1.3580 (cls: 0.2715, box: 1.0865)  rpn_loss: 0.0733 (cls: 0.0151, box: 0.0582)
[2025-08-07 17:27:41 train.log] INFO: Epoch: [9]  [Step 9500/14540]  lr: 0.000082  loss: 1.81191  detection_loss: 1.6003 (cls: 0.4386, box: 1.1617)  rpn_loss: 0.2116 (cls: 0.1199, box: 0.0917)
[2025-08-07 17:27:46 train.log] INFO: Epoch: [9]  [Step 9600/14540]  lr: 0.000082  loss: 1.47791  detection_loss: 1.3487 (cls: 0.3125, box: 1.0362)  rpn_loss: 0.1292 (cls: 0.0560, box: 0.0732)
[2025-08-07 17:27:51 train.log] INFO: Epoch: [9]  [Step 9700/14540]  lr: 0.000082  loss: 1.03658  detection_loss: 0.9410 (cls: 0.2537, box: 0.6873)  rpn_loss: 0.0955 (cls: 0.0481, box: 0.0474)
[2025-08-07 17:27:56 train.log] INFO: Epoch: [9]  [Step 9800/14540]  lr: 0.000082  loss: 1.15067  detection_loss: 1.0451 (cls: 0.2925, box: 0.7526)  rpn_loss: 0.1056 (cls: 0.0373, box: 0.0683)
[2025-08-07 17:28:01 train.log] INFO: Epoch: [9]  [Step 9900/14540]  lr: 0.000082  loss: 1.53477  detection_loss: 1.3821 (cls: 0.4243, box: 0.9579)  rpn_loss: 0.1526 (cls: 0.0700, box: 0.0827)
[2025-08-07 17:28:06 train.log] INFO: Epoch: [9]  [Step 10000/14540]  lr: 0.000082  loss: 1.46665  detection_loss: 1.3485 (cls: 0.2435, box: 1.1050)  rpn_loss: 0.1181 (cls: 0.0482, box: 0.0699)
[2025-08-07 17:28:11 train.log] INFO: Epoch: [9]  [Step 10100/14540]  lr: 0.000082  loss: 1.48940  detection_loss: 1.3351 (cls: 0.4720, box: 0.8631)  rpn_loss: 0.1543 (cls: 0.1164, box: 0.0379)
[2025-08-07 17:28:16 train.log] INFO: Epoch: [9]  [Step 10200/14540]  lr: 0.000082  loss: 1.47145  detection_loss: 1.3263 (cls: 0.4745, box: 0.8518)  rpn_loss: 0.1452 (cls: 0.1183, box: 0.0268)
[2025-08-07 17:28:21 train.log] INFO: Epoch: [9]  [Step 10300/14540]  lr: 0.000082  loss: 1.32256  detection_loss: 1.1846 (cls: 0.3173, box: 0.8673)  rpn_loss: 0.1380 (cls: 0.0713, box: 0.0667)
[2025-08-07 17:28:26 train.log] INFO: Epoch: [9]  [Step 10400/14540]  lr: 0.000082  loss: 2.05028  detection_loss: 1.7407 (cls: 0.4802, box: 1.2606)  rpn_loss: 0.3096 (cls: 0.1264, box: 0.1831)
[2025-08-07 17:28:31 train.log] INFO: Epoch: [9]  [Step 10500/14540]  lr: 0.000082  loss: 1.63384  detection_loss: 1.4793 (cls: 0.3820, box: 1.0974)  rpn_loss: 0.1545 (cls: 0.0741, box: 0.0804)
[2025-08-07 17:28:36 train.log] INFO: Epoch: [9]  [Step 10600/14540]  lr: 0.000082  loss: 1.20875  detection_loss: 1.0888 (cls: 0.3067, box: 0.7821)  rpn_loss: 0.1199 (cls: 0.0719, box: 0.0480)
[2025-08-07 17:28:41 train.log] INFO: Epoch: [9]  [Step 10700/14540]  lr: 0.000082  loss: 1.27368  detection_loss: 1.1790 (cls: 0.2506, box: 0.9284)  rpn_loss: 0.0947 (cls: 0.0538, box: 0.0409)
[2025-08-07 17:28:47 train.log] INFO: Epoch: [9]  [Step 10800/14540]  lr: 0.000082  loss: 1.08144  detection_loss: 0.9339 (cls: 0.2190, box: 0.7149)  rpn_loss: 0.1476 (cls: 0.0165, box: 0.1310)
[2025-08-07 17:28:51 train.log] INFO: Epoch: [9]  [Step 10900/14540]  lr: 0.000082  loss: 1.10019  detection_loss: 0.8810 (cls: 0.1326, box: 0.7485)  rpn_loss: 0.2192 (cls: 0.0730, box: 0.1462)
[2025-08-07 17:28:57 train.log] INFO: Epoch: [9]  [Step 11000/14540]  lr: 0.000082  loss: 1.64481  detection_loss: 1.4938 (cls: 0.3178, box: 1.1760)  rpn_loss: 0.1510 (cls: 0.1096, box: 0.0414)
[2025-08-07 17:29:02 train.log] INFO: Epoch: [9]  [Step 11100/14540]  lr: 0.000082  loss: 1.11222  detection_loss: 1.0051 (cls: 0.2684, box: 0.7367)  rpn_loss: 0.1071 (cls: 0.0499, box: 0.0572)
[2025-08-07 17:29:06 train.log] INFO: Epoch: [9]  [Step 11200/14540]  lr: 0.000082  loss: 0.98448  detection_loss: 0.9091 (cls: 0.1702, box: 0.7389)  rpn_loss: 0.0753 (cls: 0.0444, box: 0.0310)
[2025-08-07 17:29:12 train.log] INFO: Epoch: [9]  [Step 11300/14540]  lr: 0.000082  loss: 1.43598  detection_loss: 1.3042 (cls: 0.2974, box: 1.0069)  rpn_loss: 0.1317 (cls: 0.0549, box: 0.0768)
[2025-08-07 17:29:17 train.log] INFO: Epoch: [9]  [Step 11400/14540]  lr: 0.000082  loss: 1.73935  detection_loss: 1.6472 (cls: 0.5344, box: 1.1129)  rpn_loss: 0.0921 (cls: 0.0571, box: 0.0350)
[2025-08-07 17:29:22 train.log] INFO: Epoch: [9]  [Step 11500/14540]  lr: 0.000082  loss: 1.25712  detection_loss: 1.1126 (cls: 0.2657, box: 0.8469)  rpn_loss: 0.1445 (cls: 0.0821, box: 0.0624)
[2025-08-07 17:29:27 train.log] INFO: Epoch: [9]  [Step 11600/14540]  lr: 0.000082  loss: 1.34653  detection_loss: 1.1331 (cls: 0.2892, box: 0.8439)  rpn_loss: 0.2134 (cls: 0.0624, box: 0.1510)
[2025-08-07 17:29:32 train.log] INFO: Epoch: [9]  [Step 11700/14540]  lr: 0.000082  loss: 1.25177  detection_loss: 1.1653 (cls: 0.2213, box: 0.9440)  rpn_loss: 0.0865 (cls: 0.0576, box: 0.0289)
[2025-08-07 17:29:37 train.log] INFO: Epoch: [9]  [Step 11800/14540]  lr: 0.000082  loss: 1.16444  detection_loss: 1.0700 (cls: 0.3600, box: 0.7100)  rpn_loss: 0.0945 (cls: 0.0652, box: 0.0292)
[2025-08-07 17:29:42 train.log] INFO: Epoch: [9]  [Step 11900/14540]  lr: 0.000082  loss: 2.06078  detection_loss: 1.9468 (cls: 0.3053, box: 1.6414)  rpn_loss: 0.1140 (cls: 0.0632, box: 0.0509)
[2025-08-07 17:29:48 train.log] INFO: Epoch: [9]  [Step 12000/14540]  lr: 0.000082  loss: 1.60351  detection_loss: 1.3920 (cls: 0.2370, box: 1.1550)  rpn_loss: 0.2115 (cls: 0.1046, box: 0.1069)
[2025-08-07 17:29:53 train.log] INFO: Epoch: [9]  [Step 12100/14540]  lr: 0.000082  loss: 1.29607  detection_loss: 1.1981 (cls: 0.1732, box: 1.0249)  rpn_loss: 0.0980 (cls: 0.0569, box: 0.0410)
[2025-08-07 17:29:58 train.log] INFO: Epoch: [9]  [Step 12200/14540]  lr: 0.000082  loss: 1.04750  detection_loss: 0.9340 (cls: 0.3372, box: 0.5968)  rpn_loss: 0.1135 (cls: 0.0494, box: 0.0641)
[2025-08-07 17:30:03 train.log] INFO: Epoch: [9]  [Step 12300/14540]  lr: 0.000082  loss: 1.49070  detection_loss: 1.4131 (cls: 0.2788, box: 1.1343)  rpn_loss: 0.0776 (cls: 0.0183, box: 0.0593)
[2025-08-07 17:30:08 train.log] INFO: Epoch: [9]  [Step 12400/14540]  lr: 0.000082  loss: 1.18202  detection_loss: 1.0708 (cls: 0.3502, box: 0.7205)  rpn_loss: 0.1112 (cls: 0.0760, box: 0.0353)
[2025-08-07 17:30:13 train.log] INFO: Epoch: [9]  [Step 12500/14540]  lr: 0.000082  loss: 0.87967  detection_loss: 0.8240 (cls: 0.1865, box: 0.6375)  rpn_loss: 0.0557 (cls: 0.0264, box: 0.0293)
[2025-08-07 17:30:18 train.log] INFO: Epoch: [9]  [Step 12600/14540]  lr: 0.000082  loss: 1.26735  detection_loss: 1.0705 (cls: 0.3208, box: 0.7496)  rpn_loss: 0.1969 (cls: 0.0582, box: 0.1387)
[2025-08-07 17:30:23 train.log] INFO: Epoch: [9]  [Step 12700/14540]  lr: 0.000082  loss: 1.27041  detection_loss: 1.1026 (cls: 0.3151, box: 0.7875)  rpn_loss: 0.1678 (cls: 0.1423, box: 0.0256)
[2025-08-07 17:30:28 train.log] INFO: Epoch: [9]  [Step 12800/14540]  lr: 0.000082  loss: 0.96049  detection_loss: 0.8606 (cls: 0.2467, box: 0.6140)  rpn_loss: 0.0998 (cls: 0.0607, box: 0.0391)
[2025-08-07 17:30:33 train.log] INFO: Epoch: [9]  [Step 12900/14540]  lr: 0.000082  loss: 1.34516  detection_loss: 1.1950 (cls: 0.2361, box: 0.9589)  rpn_loss: 0.1502 (cls: 0.0683, box: 0.0819)
[2025-08-07 17:30:38 train.log] INFO: Epoch: [9]  [Step 13000/14540]  lr: 0.000082  loss: 1.40259  detection_loss: 1.3250 (cls: 0.3835, box: 0.9415)  rpn_loss: 0.0776 (cls: 0.0656, box: 0.0120)
[2025-08-07 17:30:43 train.log] INFO: Epoch: [9]  [Step 13100/14540]  lr: 0.000082  loss: 1.13871  detection_loss: 1.0129 (cls: 0.1751, box: 0.8378)  rpn_loss: 0.1258 (cls: 0.0723, box: 0.0535)
[2025-08-07 17:30:48 train.log] INFO: Epoch: [9]  [Step 13200/14540]  lr: 0.000082  loss: 1.29695  detection_loss: 1.2298 (cls: 0.2793, box: 0.9505)  rpn_loss: 0.0672 (cls: 0.0395, box: 0.0277)
[2025-08-07 17:30:53 train.log] INFO: Epoch: [9]  [Step 13300/14540]  lr: 0.000082  loss: 1.35945  detection_loss: 1.2204 (cls: 0.2685, box: 0.9519)  rpn_loss: 0.1390 (cls: 0.0914, box: 0.0477)
[2025-08-07 17:30:58 train.log] INFO: Epoch: [9]  [Step 13400/14540]  lr: 0.000082  loss: 1.25441  detection_loss: 1.0962 (cls: 0.1781, box: 0.9180)  rpn_loss: 0.1582 (cls: 0.0080, box: 0.1503)
[2025-08-07 17:31:03 train.log] INFO: Epoch: [9]  [Step 13500/14540]  lr: 0.000082  loss: 1.15587  detection_loss: 1.0396 (cls: 0.2206, box: 0.8190)  rpn_loss: 0.1162 (cls: 0.0600, box: 0.0563)
[2025-08-07 17:31:08 train.log] INFO: Epoch: [9]  [Step 13600/14540]  lr: 0.000082  loss: 0.77571  detection_loss: 0.6941 (cls: 0.1526, box: 0.5415)  rpn_loss: 0.0816 (cls: 0.0434, box: 0.0382)
[2025-08-07 17:31:13 train.log] INFO: Epoch: [9]  [Step 13700/14540]  lr: 0.000082  loss: 1.49904  detection_loss: 1.2773 (cls: 0.2326, box: 1.0447)  rpn_loss: 0.2217 (cls: 0.1145, box: 0.1072)
[2025-08-07 17:31:18 train.log] INFO: Epoch: [9]  [Step 13800/14540]  lr: 0.000082  loss: 1.13762  detection_loss: 1.0035 (cls: 0.2413, box: 0.7622)  rpn_loss: 0.1341 (cls: 0.0914, box: 0.0428)
[2025-08-07 17:31:23 train.log] INFO: Epoch: [9]  [Step 13900/14540]  lr: 0.000082  loss: 1.06322  detection_loss: 1.0152 (cls: 0.1178, box: 0.8974)  rpn_loss: 0.0480 (cls: 0.0291, box: 0.0189)
[2025-08-07 17:31:28 train.log] INFO: Epoch: [9]  [Step 14000/14540]  lr: 0.000082  loss: 0.80624  detection_loss: 0.7191 (cls: 0.1421, box: 0.5770)  rpn_loss: 0.0872 (cls: 0.0261, box: 0.0611)
[2025-08-07 17:31:33 train.log] INFO: Epoch: [9]  [Step 14100/14540]  lr: 0.000082  loss: 1.43214  detection_loss: 1.3356 (cls: 0.2296, box: 1.1060)  rpn_loss: 0.0965 (cls: 0.0377, box: 0.0588)
[2025-08-07 17:31:37 train.log] INFO: Epoch: [9]  [Step 14200/14540]  lr: 0.000082  loss: 1.38618  detection_loss: 1.2068 (cls: 0.2647, box: 0.9421)  rpn_loss: 0.1794 (cls: 0.1190, box: 0.0604)
[2025-08-07 17:31:42 train.log] INFO: Epoch: [9]  [Step 14300/14540]  lr: 0.000082  loss: 1.16355  detection_loss: 1.0916 (cls: 0.2432, box: 0.8484)  rpn_loss: 0.0720 (cls: 0.0331, box: 0.0388)
[2025-08-07 17:31:48 train.log] INFO: Epoch: [9]  [Step 14400/14540]  lr: 0.000082  loss: 1.07812  detection_loss: 0.9799 (cls: 0.3741, box: 0.6058)  rpn_loss: 0.0983 (cls: 0.0601, box: 0.0381)
[2025-08-07 17:31:53 train.log] INFO: Epoch: [9]  [Step 14500/14540]  lr: 0.000082  loss: 1.04250  detection_loss: 0.8903 (cls: 0.2237, box: 0.6666)  rpn_loss: 0.1522 (cls: 0.0659, box: 0.0863)
[2025-08-07 17:34:46 train.log] INFO: Epoch: [10]  [Step 100/14540]  lr: 0.000078  loss: 1.50354  detection_loss: 1.3436 (cls: 0.3449, box: 0.9987)  rpn_loss: 0.1600 (cls: 0.0641, box: 0.0958)
[2025-08-07 17:34:52 train.log] INFO: Epoch: [10]  [Step 200/14540]  lr: 0.000078  loss: 1.59518  detection_loss: 1.4578 (cls: 0.1712, box: 1.2866)  rpn_loss: 0.1374 (cls: 0.0783, box: 0.0591)
[2025-08-07 17:34:57 train.log] INFO: Epoch: [10]  [Step 300/14540]  lr: 0.000078  loss: 1.27347  detection_loss: 1.1321 (cls: 0.4470, box: 0.6851)  rpn_loss: 0.1414 (cls: 0.0730, box: 0.0684)
[2025-08-07 17:35:02 train.log] INFO: Epoch: [10]  [Step 400/14540]  lr: 0.000078  loss: 1.54923  detection_loss: 1.3975 (cls: 0.3803, box: 1.0172)  rpn_loss: 0.1517 (cls: 0.0770, box: 0.0746)
[2025-08-07 17:35:07 train.log] INFO: Epoch: [10]  [Step 500/14540]  lr: 0.000078  loss: 0.93779  detection_loss: 0.8808 (cls: 0.2737, box: 0.6071)  rpn_loss: 0.0570 (cls: 0.0257, box: 0.0313)
[2025-08-07 17:35:12 train.log] INFO: Epoch: [10]  [Step 600/14540]  lr: 0.000078  loss: 1.86459  detection_loss: 1.6997 (cls: 0.3365, box: 1.3632)  rpn_loss: 0.1649 (cls: 0.1101, box: 0.0548)
[2025-08-07 17:35:17 train.log] INFO: Epoch: [10]  [Step 700/14540]  lr: 0.000078  loss: 1.02091  detection_loss: 0.9311 (cls: 0.2493, box: 0.6818)  rpn_loss: 0.0898 (cls: 0.0405, box: 0.0493)
[2025-08-07 17:35:22 train.log] INFO: Epoch: [10]  [Step 800/14540]  lr: 0.000078  loss: 1.24606  detection_loss: 1.1851 (cls: 0.2367, box: 0.9485)  rpn_loss: 0.0609 (cls: 0.0320, box: 0.0289)
[2025-08-07 17:35:27 train.log] INFO: Epoch: [10]  [Step 900/14540]  lr: 0.000078  loss: 1.11150  detection_loss: 0.9525 (cls: 0.3222, box: 0.6303)  rpn_loss: 0.1590 (cls: 0.0810, box: 0.0780)
[2025-08-07 17:35:32 train.log] INFO: Epoch: [10]  [Step 1000/14540]  lr: 0.000078  loss: 1.00741  detection_loss: 0.8481 (cls: 0.2550, box: 0.5930)  rpn_loss: 0.1593 (cls: 0.0712, box: 0.0881)
[2025-08-07 17:35:37 train.log] INFO: Epoch: [10]  [Step 1100/14540]  lr: 0.000078  loss: 2.30056  detection_loss: 1.8767 (cls: 0.5611, box: 1.3156)  rpn_loss: 0.4238 (cls: 0.2369, box: 0.1869)
[2025-08-07 17:35:42 train.log] INFO: Epoch: [10]  [Step 1200/14540]  lr: 0.000078  loss: 1.66257  detection_loss: 1.2122 (cls: 0.3082, box: 0.9039)  rpn_loss: 0.4504 (cls: 0.0953, box: 0.3551)
[2025-08-07 17:35:47 train.log] INFO: Epoch: [10]  [Step 1300/14540]  lr: 0.000078  loss: 0.89770  detection_loss: 0.8162 (cls: 0.2207, box: 0.5955)  rpn_loss: 0.0815 (cls: 0.0631, box: 0.0184)
[2025-08-07 17:35:52 train.log] INFO: Epoch: [10]  [Step 1400/14540]  lr: 0.000078  loss: 0.91183  detection_loss: 0.7988 (cls: 0.2924, box: 0.5064)  rpn_loss: 0.1130 (cls: 0.0832, box: 0.0299)
[2025-08-07 17:35:57 train.log] INFO: Epoch: [10]  [Step 1500/14540]  lr: 0.000078  loss: 1.13876  detection_loss: 1.0404 (cls: 0.3289, box: 0.7115)  rpn_loss: 0.0984 (cls: 0.0567, box: 0.0417)
[2025-08-07 17:36:02 train.log] INFO: Epoch: [10]  [Step 1600/14540]  lr: 0.000078  loss: 1.07702  detection_loss: 0.9420 (cls: 0.2041, box: 0.7380)  rpn_loss: 0.1350 (cls: 0.1042, box: 0.0307)
[2025-08-07 17:36:07 train.log] INFO: Epoch: [10]  [Step 1700/14540]  lr: 0.000078  loss: 0.89982  detection_loss: 0.8573 (cls: 0.2352, box: 0.6221)  rpn_loss: 0.0426 (cls: 0.0217, box: 0.0209)
[2025-08-07 17:36:12 train.log] INFO: Epoch: [10]  [Step 1800/14540]  lr: 0.000078  loss: 1.22403  detection_loss: 1.0759 (cls: 0.2924, box: 0.7835)  rpn_loss: 0.1481 (cls: 0.0889, box: 0.0592)
[2025-08-07 17:36:17 train.log] INFO: Epoch: [10]  [Step 1900/14540]  lr: 0.000078  loss: 0.66132  detection_loss: 0.5554 (cls: 0.1464, box: 0.4090)  rpn_loss: 0.1059 (cls: 0.0235, box: 0.0824)
[2025-08-07 17:36:22 train.log] INFO: Epoch: [10]  [Step 2000/14540]  lr: 0.000078  loss: 1.00791  detection_loss: 0.9100 (cls: 0.2763, box: 0.6337)  rpn_loss: 0.0979 (cls: 0.0561, box: 0.0418)
[2025-08-07 17:36:28 train.log] INFO: Epoch: [10]  [Step 2100/14540]  lr: 0.000078  loss: 1.17081  detection_loss: 0.9514 (cls: 0.1742, box: 0.7773)  rpn_loss: 0.2194 (cls: 0.0444, box: 0.1750)
[2025-08-07 17:36:33 train.log] INFO: Epoch: [10]  [Step 2200/14540]  lr: 0.000078  loss: 1.38758  detection_loss: 1.0167 (cls: 0.1694, box: 0.8474)  rpn_loss: 0.3709 (cls: 0.0637, box: 0.3072)
[2025-08-07 17:36:38 train.log] INFO: Epoch: [10]  [Step 2300/14540]  lr: 0.000078  loss: 1.66007  detection_loss: 1.4714 (cls: 0.3401, box: 1.1313)  rpn_loss: 0.1887 (cls: 0.0773, box: 0.1114)
[2025-08-07 17:36:43 train.log] INFO: Epoch: [10]  [Step 2400/14540]  lr: 0.000078  loss: 0.87573  detection_loss: 0.8302 (cls: 0.1546, box: 0.6755)  rpn_loss: 0.0456 (cls: 0.0226, box: 0.0230)
[2025-08-07 17:36:48 train.log] INFO: Epoch: [10]  [Step 2500/14540]  lr: 0.000078  loss: 0.64053  detection_loss: 0.5838 (cls: 0.2656, box: 0.3183)  rpn_loss: 0.0567 (cls: 0.0353, box: 0.0214)
[2025-08-07 17:36:53 train.log] INFO: Epoch: [10]  [Step 2600/14540]  lr: 0.000078  loss: 1.15211  detection_loss: 1.0430 (cls: 0.1745, box: 0.8684)  rpn_loss: 0.1091 (cls: 0.0534, box: 0.0557)
[2025-08-07 17:36:58 train.log] INFO: Epoch: [10]  [Step 2700/14540]  lr: 0.000078  loss: 1.25889  detection_loss: 1.1138 (cls: 0.2263, box: 0.8876)  rpn_loss: 0.1451 (cls: 0.0829, box: 0.0622)
[2025-08-07 17:37:03 train.log] INFO: Epoch: [10]  [Step 2800/14540]  lr: 0.000078  loss: 0.96233  detection_loss: 0.8715 (cls: 0.1901, box: 0.6814)  rpn_loss: 0.0908 (cls: 0.0313, box: 0.0595)
[2025-08-07 17:37:08 train.log] INFO: Epoch: [10]  [Step 2900/14540]  lr: 0.000078  loss: 1.73477  detection_loss: 1.5405 (cls: 0.3284, box: 1.2120)  rpn_loss: 0.1943 (cls: 0.1349, box: 0.0594)
[2025-08-07 17:37:13 train.log] INFO: Epoch: [10]  [Step 3000/14540]  lr: 0.000078  loss: 1.19675  detection_loss: 1.0340 (cls: 0.3074, box: 0.7266)  rpn_loss: 0.1628 (cls: 0.1301, box: 0.0327)
[2025-08-07 17:37:18 train.log] INFO: Epoch: [10]  [Step 3100/14540]  lr: 0.000078  loss: 1.10256  detection_loss: 1.0576 (cls: 0.2174, box: 0.8402)  rpn_loss: 0.0450 (cls: 0.0221, box: 0.0229)
[2025-08-07 17:37:23 train.log] INFO: Epoch: [10]  [Step 3200/14540]  lr: 0.000078  loss: 1.95703  detection_loss: 1.8612 (cls: 0.4007, box: 1.4605)  rpn_loss: 0.0958 (cls: 0.0697, box: 0.0261)
[2025-08-07 17:37:28 train.log] INFO: Epoch: [10]  [Step 3300/14540]  lr: 0.000078  loss: 1.33643  detection_loss: 1.2298 (cls: 0.2543, box: 0.9755)  rpn_loss: 0.1066 (cls: 0.0410, box: 0.0656)
[2025-08-07 17:37:33 train.log] INFO: Epoch: [10]  [Step 3400/14540]  lr: 0.000078  loss: 1.34312  detection_loss: 1.1588 (cls: 0.3909, box: 0.7679)  rpn_loss: 0.1843 (cls: 0.0636, box: 0.1208)
[2025-08-07 17:37:39 train.log] INFO: Epoch: [10]  [Step 3500/14540]  lr: 0.000078  loss: 0.70042  detection_loss: 0.5781 (cls: 0.1560, box: 0.4220)  rpn_loss: 0.1223 (cls: 0.0917, box: 0.0306)
[2025-08-07 17:37:44 train.log] INFO: Epoch: [10]  [Step 3600/14540]  lr: 0.000078  loss: 1.45531  detection_loss: 1.2353 (cls: 0.2454, box: 0.9899)  rpn_loss: 0.2200 (cls: 0.0684, box: 0.1516)
[2025-08-07 17:37:45 train.log] INFO: Epoch: [10]  [Step 3635/14540]  lr: 0.000078  loss: 1.20603  detection_loss: 1.0943 (cls: 0.3606, box: 0.7338)  rpn_loss: 0.1117 (cls: 0.0594, box: 0.0523)
[2025-08-07 17:37:48 train.log] INFO: Epoch: [10]  [Step 3700/14540]  lr: 0.000078  loss: 1.32665  detection_loss: 1.1690 (cls: 0.3374, box: 0.8317)  rpn_loss: 0.1576 (cls: 0.0632, box: 0.0944)
[2025-08-07 17:37:53 train.log] INFO: Epoch: [10]  [Step 3800/14540]  lr: 0.000078  loss: 0.75262  detection_loss: 0.7052 (cls: 0.1342, box: 0.5710)  rpn_loss: 0.0474 (cls: 0.0263, box: 0.0211)
[2025-08-07 17:37:58 train.log] INFO: Epoch: [10]  [Step 3900/14540]  lr: 0.000078  loss: 0.97865  detection_loss: 0.8936 (cls: 0.2137, box: 0.6799)  rpn_loss: 0.0850 (cls: 0.0323, box: 0.0527)
[2025-08-07 17:38:03 train.log] INFO: Epoch: [10]  [Step 4000/14540]  lr: 0.000078  loss: 1.37960  detection_loss: 1.2369 (cls: 0.2827, box: 0.9542)  rpn_loss: 0.1427 (cls: 0.0596, box: 0.0831)
[2025-08-07 17:38:08 train.log] INFO: Epoch: [10]  [Step 4100/14540]  lr: 0.000078  loss: 1.31082  detection_loss: 1.1749 (cls: 0.2391, box: 0.9358)  rpn_loss: 0.1359 (cls: 0.0633, box: 0.0727)
[2025-08-07 17:38:13 train.log] INFO: Epoch: [10]  [Step 4200/14540]  lr: 0.000078  loss: 0.84563  detection_loss: 0.7727 (cls: 0.1486, box: 0.6240)  rpn_loss: 0.0730 (cls: 0.0316, box: 0.0414)
[2025-08-07 17:38:18 train.log] INFO: Epoch: [10]  [Step 4300/14540]  lr: 0.000078  loss: 1.49983  detection_loss: 1.3890 (cls: 0.3931, box: 0.9959)  rpn_loss: 0.1108 (cls: 0.0682, box: 0.0426)
[2025-08-07 17:38:23 train.log] INFO: Epoch: [10]  [Step 4400/14540]  lr: 0.000078  loss: 1.69606  detection_loss: 1.5427 (cls: 0.4249, box: 1.1179)  rpn_loss: 0.1533 (cls: 0.0811, box: 0.0722)
[2025-08-07 17:38:27 train.log] INFO: Epoch: [10]  [Step 4500/14540]  lr: 0.000078  loss: 1.24361  detection_loss: 1.1296 (cls: 0.3598, box: 0.7698)  rpn_loss: 0.1140 (cls: 0.0931, box: 0.0209)
[2025-08-07 17:38:32 train.log] INFO: Epoch: [10]  [Step 4600/14540]  lr: 0.000078  loss: 1.00650  detection_loss: 0.9079 (cls: 0.3005, box: 0.6075)  rpn_loss: 0.0986 (cls: 0.0291, box: 0.0694)
[2025-08-07 17:38:37 train.log] INFO: Epoch: [10]  [Step 4700/14540]  lr: 0.000078  loss: 1.40967  detection_loss: 1.2848 (cls: 0.2738, box: 1.0110)  rpn_loss: 0.1248 (cls: 0.0600, box: 0.0649)
[2025-08-07 17:38:42 train.log] INFO: Epoch: [10]  [Step 4800/14540]  lr: 0.000078  loss: 1.45817  detection_loss: 1.3435 (cls: 0.2767, box: 1.0668)  rpn_loss: 0.1147 (cls: 0.0695, box: 0.0452)
[2025-08-07 17:38:46 train.log] INFO: Epoch: [10]  [Step 4900/14540]  lr: 0.000078  loss: 1.29558  detection_loss: 1.1894 (cls: 0.2388, box: 0.9506)  rpn_loss: 0.1062 (cls: 0.0728, box: 0.0334)
[2025-08-07 17:38:51 train.log] INFO: Epoch: [10]  [Step 5000/14540]  lr: 0.000078  loss: 1.44781  detection_loss: 1.3796 (cls: 0.3223, box: 1.0573)  rpn_loss: 0.0682 (cls: 0.0513, box: 0.0169)
[2025-08-07 17:38:56 train.log] INFO: Epoch: [10]  [Step 5100/14540]  lr: 0.000078  loss: 1.10346  detection_loss: 1.0327 (cls: 0.2600, box: 0.7727)  rpn_loss: 0.0708 (cls: 0.0452, box: 0.0256)
[2025-08-07 17:39:01 train.log] INFO: Epoch: [10]  [Step 5200/14540]  lr: 0.000078  loss: 1.62880  detection_loss: 1.4369 (cls: 0.3309, box: 1.1060)  rpn_loss: 0.1919 (cls: 0.0842, box: 0.1077)
[2025-08-07 17:39:06 train.log] INFO: Epoch: [10]  [Step 5300/14540]  lr: 0.000078  loss: 1.79208  detection_loss: 1.6238 (cls: 0.4415, box: 1.1823)  rpn_loss: 0.1683 (cls: 0.0583, box: 0.1100)
[2025-08-07 17:39:11 train.log] INFO: Epoch: [10]  [Step 5400/14540]  lr: 0.000078  loss: 1.31476  detection_loss: 1.1461 (cls: 0.4065, box: 0.7396)  rpn_loss: 0.1686 (cls: 0.1157, box: 0.0529)
[2025-08-07 17:39:16 train.log] INFO: Epoch: [10]  [Step 5500/14540]  lr: 0.000078  loss: 1.02641  detection_loss: 0.9573 (cls: 0.1673, box: 0.7900)  rpn_loss: 0.0691 (cls: 0.0310, box: 0.0381)
[2025-08-07 17:39:21 train.log] INFO: Epoch: [10]  [Step 5600/14540]  lr: 0.000078  loss: 1.67619  detection_loss: 1.5266 (cls: 0.2913, box: 1.2353)  rpn_loss: 0.1496 (cls: 0.1201, box: 0.0295)
[2025-08-07 17:39:26 train.log] INFO: Epoch: [10]  [Step 5700/14540]  lr: 0.000078  loss: 0.79049  detection_loss: 0.7060 (cls: 0.2126, box: 0.4934)  rpn_loss: 0.0845 (cls: 0.0693, box: 0.0152)
[2025-08-07 17:39:31 train.log] INFO: Epoch: [10]  [Step 5800/14540]  lr: 0.000078  loss: 1.43172  detection_loss: 1.2487 (cls: 0.4089, box: 0.8399)  rpn_loss: 0.1830 (cls: 0.0585, box: 0.1245)
[2025-08-07 17:39:36 train.log] INFO: Epoch: [10]  [Step 5900/14540]  lr: 0.000078  loss: 1.27509  detection_loss: 1.2085 (cls: 0.1493, box: 1.0592)  rpn_loss: 0.0666 (cls: 0.0214, box: 0.0452)
[2025-08-07 17:39:41 train.log] INFO: Epoch: [10]  [Step 6000/14540]  lr: 0.000078  loss: 1.15056  detection_loss: 1.0418 (cls: 0.1671, box: 0.8747)  rpn_loss: 0.1087 (cls: 0.0305, box: 0.0783)
[2025-08-07 17:39:45 train.log] INFO: Epoch: [10]  [Step 6100/14540]  lr: 0.000078  loss: 1.06158  detection_loss: 1.0143 (cls: 0.1543, box: 0.8600)  rpn_loss: 0.0473 (cls: 0.0251, box: 0.0222)
[2025-08-07 17:39:50 train.log] INFO: Epoch: [10]  [Step 6200/14540]  lr: 0.000078  loss: 1.11616  detection_loss: 0.9685 (cls: 0.2473, box: 0.7212)  rpn_loss: 0.1477 (cls: 0.1082, box: 0.0395)
[2025-08-07 17:39:56 train.log] INFO: Epoch: [10]  [Step 6300/14540]  lr: 0.000078  loss: 1.55911  detection_loss: 1.3890 (cls: 0.2251, box: 1.1639)  rpn_loss: 0.1701 (cls: 0.0808, box: 0.0893)
[2025-08-07 17:40:01 train.log] INFO: Epoch: [10]  [Step 6400/14540]  lr: 0.000078  loss: 0.81651  detection_loss: 0.7077 (cls: 0.1767, box: 0.5310)  rpn_loss: 0.1088 (cls: 0.0191, box: 0.0897)
[2025-08-07 17:40:06 train.log] INFO: Epoch: [10]  [Step 6500/14540]  lr: 0.000078  loss: 1.61344  detection_loss: 1.5189 (cls: 0.4912, box: 1.0277)  rpn_loss: 0.0946 (cls: 0.0368, box: 0.0578)
[2025-08-07 17:40:11 train.log] INFO: Epoch: [10]  [Step 6600/14540]  lr: 0.000078  loss: 1.25128  detection_loss: 1.1255 (cls: 0.2257, box: 0.8998)  rpn_loss: 0.1258 (cls: 0.0756, box: 0.0503)
[2025-08-07 17:40:16 train.log] INFO: Epoch: [10]  [Step 6700/14540]  lr: 0.000078  loss: 1.44641  detection_loss: 1.3836 (cls: 0.2329, box: 1.1507)  rpn_loss: 0.0629 (cls: 0.0390, box: 0.0239)
[2025-08-07 17:40:22 train.log] INFO: Epoch: [10]  [Step 6800/14540]  lr: 0.000078  loss: 0.94115  detection_loss: 0.8473 (cls: 0.1865, box: 0.6608)  rpn_loss: 0.0939 (cls: 0.0543, box: 0.0396)
[2025-08-07 17:40:27 train.log] INFO: Epoch: [10]  [Step 6900/14540]  lr: 0.000078  loss: 0.89829  detection_loss: 0.7971 (cls: 0.1639, box: 0.6332)  rpn_loss: 0.1011 (cls: 0.0242, box: 0.0769)
[2025-08-07 17:40:32 train.log] INFO: Epoch: [10]  [Step 7000/14540]  lr: 0.000078  loss: 1.54054  detection_loss: 1.3432 (cls: 0.3227, box: 1.0205)  rpn_loss: 0.1973 (cls: 0.1415, box: 0.0558)
[2025-08-07 17:40:37 train.log] INFO: Epoch: [10]  [Step 7100/14540]  lr: 0.000078  loss: 1.24956  detection_loss: 1.0676 (cls: 0.3100, box: 0.7576)  rpn_loss: 0.1819 (cls: 0.0435, box: 0.1385)
[2025-08-07 17:40:42 train.log] INFO: Epoch: [10]  [Step 7200/14540]  lr: 0.000078  loss: 1.03927  detection_loss: 0.9551 (cls: 0.2450, box: 0.7101)  rpn_loss: 0.0842 (cls: 0.0507, box: 0.0335)
[2025-08-07 17:40:47 train.log] INFO: Epoch: [10]  [Step 7300/14540]  lr: 0.000078  loss: 0.72739  detection_loss: 0.6318 (cls: 0.1453, box: 0.4865)  rpn_loss: 0.0956 (cls: 0.0654, box: 0.0302)
[2025-08-07 17:40:52 train.log] INFO: Epoch: [10]  [Step 7400/14540]  lr: 0.000078  loss: 0.81992  detection_loss: 0.7317 (cls: 0.2519, box: 0.4798)  rpn_loss: 0.0883 (cls: 0.0394, box: 0.0489)
[2025-08-07 17:40:57 train.log] INFO: Epoch: [10]  [Step 7500/14540]  lr: 0.000078  loss: 1.17366  detection_loss: 1.1059 (cls: 0.1927, box: 0.9132)  rpn_loss: 0.0677 (cls: 0.0303, box: 0.0374)
[2025-08-07 17:41:02 train.log] INFO: Epoch: [10]  [Step 7600/14540]  lr: 0.000078  loss: 1.82536  detection_loss: 1.0711 (cls: 0.2954, box: 0.7757)  rpn_loss: 0.7543 (cls: 0.0254, box: 0.7289)
[2025-08-07 17:41:07 train.log] INFO: Epoch: [10]  [Step 7700/14540]  lr: 0.000078  loss: 1.20639  detection_loss: 1.1619 (cls: 0.3539, box: 0.8080)  rpn_loss: 0.0445 (cls: 0.0158, box: 0.0287)
[2025-08-07 17:41:12 train.log] INFO: Epoch: [10]  [Step 7800/14540]  lr: 0.000078  loss: 1.58953  detection_loss: 1.4412 (cls: 0.3740, box: 1.0672)  rpn_loss: 0.1483 (cls: 0.0486, box: 0.0998)
[2025-08-07 17:41:17 train.log] INFO: Epoch: [10]  [Step 7900/14540]  lr: 0.000078  loss: 1.91132  detection_loss: 1.7638 (cls: 0.5071, box: 1.2567)  rpn_loss: 0.1475 (cls: 0.1068, box: 0.0407)
[2025-08-07 17:41:21 train.log] INFO: Epoch: [10]  [Step 8000/14540]  lr: 0.000078  loss: 1.13552  detection_loss: 0.9132 (cls: 0.1661, box: 0.7471)  rpn_loss: 0.2223 (cls: 0.0455, box: 0.1768)
[2025-08-07 17:41:26 train.log] INFO: Epoch: [10]  [Step 8100/14540]  lr: 0.000078  loss: 1.29582  detection_loss: 1.1738 (cls: 0.3755, box: 0.7983)  rpn_loss: 0.1220 (cls: 0.0315, box: 0.0906)
[2025-08-07 17:41:32 train.log] INFO: Epoch: [10]  [Step 8200/14540]  lr: 0.000078  loss: 1.12011  detection_loss: 0.9852 (cls: 0.3175, box: 0.6677)  rpn_loss: 0.1349 (cls: 0.0991, box: 0.0358)
[2025-08-07 17:41:37 train.log] INFO: Epoch: [10]  [Step 8300/14540]  lr: 0.000078  loss: 1.26677  detection_loss: 1.1359 (cls: 0.3018, box: 0.8341)  rpn_loss: 0.1309 (cls: 0.0725, box: 0.0584)
[2025-08-07 17:41:42 train.log] INFO: Epoch: [10]  [Step 8400/14540]  lr: 0.000078  loss: 1.27602  detection_loss: 1.0213 (cls: 0.3412, box: 0.6801)  rpn_loss: 0.2547 (cls: 0.0721, box: 0.1826)
[2025-08-07 17:41:47 train.log] INFO: Epoch: [10]  [Step 8500/14540]  lr: 0.000078  loss: 1.23668  detection_loss: 1.1301 (cls: 0.3507, box: 0.7794)  rpn_loss: 0.1066 (cls: 0.0543, box: 0.0523)
[2025-08-07 17:41:52 train.log] INFO: Epoch: [10]  [Step 8600/14540]  lr: 0.000078  loss: 1.57550  detection_loss: 1.4700 (cls: 0.2005, box: 1.2695)  rpn_loss: 0.1055 (cls: 0.0490, box: 0.0565)
[2025-08-07 17:41:57 train.log] INFO: Epoch: [10]  [Step 8700/14540]  lr: 0.000078  loss: 0.91544  detection_loss: 0.8273 (cls: 0.2505, box: 0.5768)  rpn_loss: 0.0881 (cls: 0.0636, box: 0.0246)
[2025-08-07 17:42:02 train.log] INFO: Epoch: [10]  [Step 8800/14540]  lr: 0.000078  loss: 1.16853  detection_loss: 1.0924 (cls: 0.2643, box: 0.8281)  rpn_loss: 0.0761 (cls: 0.0309, box: 0.0452)
[2025-08-07 17:42:07 train.log] INFO: Epoch: [10]  [Step 8900/14540]  lr: 0.000078  loss: 1.75266  detection_loss: 1.4961 (cls: 0.5569, box: 0.9392)  rpn_loss: 0.2565 (cls: 0.1799, box: 0.0767)
[2025-08-07 17:42:12 train.log] INFO: Epoch: [10]  [Step 9000/14540]  lr: 0.000078  loss: 2.06556  detection_loss: 1.8693 (cls: 0.4141, box: 1.4552)  rpn_loss: 0.1962 (cls: 0.1170, box: 0.0792)
[2025-08-07 17:42:17 train.log] INFO: Epoch: [10]  [Step 9100/14540]  lr: 0.000078  loss: 1.40324  detection_loss: 1.3390 (cls: 0.2302, box: 1.1088)  rpn_loss: 0.0642 (cls: 0.0212, box: 0.0430)
[2025-08-07 17:42:21 train.log] INFO: Epoch: [10]  [Step 9200/14540]  lr: 0.000078  loss: 1.17550  detection_loss: 1.1298 (cls: 0.2046, box: 0.9252)  rpn_loss: 0.0457 (cls: 0.0225, box: 0.0232)
[2025-08-07 17:42:26 train.log] INFO: Epoch: [10]  [Step 9300/14540]  lr: 0.000078  loss: 1.85455  detection_loss: 1.7006 (cls: 0.4214, box: 1.2792)  rpn_loss: 0.1539 (cls: 0.0740, box: 0.0799)
[2025-08-07 17:42:31 train.log] INFO: Epoch: [10]  [Step 9400/14540]  lr: 0.000078  loss: 1.19546  detection_loss: 1.0973 (cls: 0.2169, box: 0.8804)  rpn_loss: 0.0982 (cls: 0.0419, box: 0.0562)
[2025-08-07 17:42:36 train.log] INFO: Epoch: [10]  [Step 9500/14540]  lr: 0.000078  loss: 1.19796  detection_loss: 1.1087 (cls: 0.1678, box: 0.9408)  rpn_loss: 0.0893 (cls: 0.0167, box: 0.0726)
[2025-08-07 17:42:41 train.log] INFO: Epoch: [10]  [Step 9600/14540]  lr: 0.000078  loss: 1.07682  detection_loss: 0.9707 (cls: 0.2015, box: 0.7692)  rpn_loss: 0.1061 (cls: 0.0299, box: 0.0762)
[2025-08-07 17:42:46 train.log] INFO: Epoch: [10]  [Step 9700/14540]  lr: 0.000078  loss: 1.19505  detection_loss: 1.0371 (cls: 0.1940, box: 0.8432)  rpn_loss: 0.1579 (cls: 0.0238, box: 0.1341)
[2025-08-07 17:42:51 train.log] INFO: Epoch: [10]  [Step 9800/14540]  lr: 0.000078  loss: 1.55915  detection_loss: 1.4580 (cls: 0.5421, box: 0.9160)  rpn_loss: 0.1011 (cls: 0.0784, box: 0.0227)
[2025-08-07 17:42:56 train.log] INFO: Epoch: [10]  [Step 9900/14540]  lr: 0.000078  loss: 0.61712  detection_loss: 0.5456 (cls: 0.1321, box: 0.4134)  rpn_loss: 0.0716 (cls: 0.0220, box: 0.0496)
[2025-08-07 17:43:01 train.log] INFO: Epoch: [10]  [Step 10000/14540]  lr: 0.000078  loss: 1.15465  detection_loss: 0.8286 (cls: 0.3519, box: 0.4767)  rpn_loss: 0.3260 (cls: 0.0714, box: 0.2546)
[2025-08-07 17:43:06 train.log] INFO: Epoch: [10]  [Step 10100/14540]  lr: 0.000078  loss: 2.05447  detection_loss: 1.9390 (cls: 0.3142, box: 1.6248)  rpn_loss: 0.1155 (cls: 0.0353, box: 0.0802)
[2025-08-07 17:43:10 train.log] INFO: Epoch: [10]  [Step 10200/14540]  lr: 0.000078  loss: 1.09507  detection_loss: 1.0040 (cls: 0.2215, box: 0.7825)  rpn_loss: 0.0911 (cls: 0.0578, box: 0.0333)
[2025-08-07 17:43:15 train.log] INFO: Epoch: [10]  [Step 10300/14540]  lr: 0.000078  loss: 1.46501  detection_loss: 1.3389 (cls: 0.3452, box: 0.9937)  rpn_loss: 0.1261 (cls: 0.0613, box: 0.0648)
[2025-08-07 17:43:20 train.log] INFO: Epoch: [10]  [Step 10400/14540]  lr: 0.000078  loss: 1.13399  detection_loss: 0.7554 (cls: 0.1693, box: 0.5861)  rpn_loss: 0.3786 (cls: 0.0590, box: 0.3195)
[2025-08-07 17:43:25 train.log] INFO: Epoch: [10]  [Step 10500/14540]  lr: 0.000078  loss: 1.06673  detection_loss: 0.9134 (cls: 0.2229, box: 0.6906)  rpn_loss: 0.1533 (cls: 0.1097, box: 0.0436)
[2025-08-07 17:43:30 train.log] INFO: Epoch: [10]  [Step 10600/14540]  lr: 0.000078  loss: 1.91023  detection_loss: 1.7250 (cls: 0.2611, box: 1.4640)  rpn_loss: 0.1852 (cls: 0.0690, box: 0.1162)
[2025-08-07 17:43:35 train.log] INFO: Epoch: [10]  [Step 10700/14540]  lr: 0.000078  loss: 1.11940  detection_loss: 1.0442 (cls: 0.2449, box: 0.7993)  rpn_loss: 0.0752 (cls: 0.0337, box: 0.0415)
[2025-08-07 17:43:40 train.log] INFO: Epoch: [10]  [Step 10800/14540]  lr: 0.000078  loss: 1.39877  detection_loss: 1.3099 (cls: 0.3038, box: 1.0061)  rpn_loss: 0.0888 (cls: 0.0656, box: 0.0232)
[2025-08-07 17:43:45 train.log] INFO: Epoch: [10]  [Step 10900/14540]  lr: 0.000078  loss: 1.53204  detection_loss: 1.3616 (cls: 0.3457, box: 1.0160)  rpn_loss: 0.1704 (cls: 0.0906, box: 0.0798)
[2025-08-07 17:43:50 train.log] INFO: Epoch: [10]  [Step 11000/14540]  lr: 0.000078  loss: 1.28572  detection_loss: 1.1846 (cls: 0.2783, box: 0.9062)  rpn_loss: 0.1011 (cls: 0.0501, box: 0.0511)
[2025-08-07 17:43:54 train.log] INFO: Epoch: [10]  [Step 11100/14540]  lr: 0.000078  loss: 1.34264  detection_loss: 1.2186 (cls: 0.1949, box: 1.0237)  rpn_loss: 0.1241 (cls: 0.0616, box: 0.0625)
[2025-08-07 17:43:59 train.log] INFO: Epoch: [10]  [Step 11200/14540]  lr: 0.000078  loss: 1.19084  detection_loss: 1.1099 (cls: 0.2040, box: 0.9059)  rpn_loss: 0.0809 (cls: 0.0555, box: 0.0255)
[2025-08-07 17:44:04 train.log] INFO: Epoch: [10]  [Step 11300/14540]  lr: 0.000078  loss: 1.54813  detection_loss: 1.4692 (cls: 0.3549, box: 1.1143)  rpn_loss: 0.0790 (cls: 0.0502, box: 0.0288)
[2025-08-07 17:44:09 train.log] INFO: Epoch: [10]  [Step 11400/14540]  lr: 0.000078  loss: 2.01083  detection_loss: 1.8341 (cls: 0.3358, box: 1.4983)  rpn_loss: 0.1767 (cls: 0.1063, box: 0.0704)
[2025-08-07 17:44:14 train.log] INFO: Epoch: [10]  [Step 11500/14540]  lr: 0.000078  loss: 1.65976  detection_loss: 1.5749 (cls: 0.4488, box: 1.1261)  rpn_loss: 0.0848 (cls: 0.0628, box: 0.0221)
[2025-08-07 17:44:19 train.log] INFO: Epoch: [10]  [Step 11600/14540]  lr: 0.000078  loss: 1.24542  detection_loss: 1.0054 (cls: 0.1573, box: 0.8481)  rpn_loss: 0.2400 (cls: 0.0187, box: 0.2214)
[2025-08-07 17:44:24 train.log] INFO: Epoch: [10]  [Step 11700/14540]  lr: 0.000078  loss: 1.41394  detection_loss: 1.2928 (cls: 0.4555, box: 0.8373)  rpn_loss: 0.1211 (cls: 0.0885, box: 0.0326)
[2025-08-07 17:44:29 train.log] INFO: Epoch: [10]  [Step 11800/14540]  lr: 0.000078  loss: 1.70177  detection_loss: 1.5242 (cls: 0.4833, box: 1.0409)  rpn_loss: 0.1776 (cls: 0.0930, box: 0.0846)
[2025-08-07 17:44:34 train.log] INFO: Epoch: [10]  [Step 11900/14540]  lr: 0.000078  loss: 1.24424  detection_loss: 1.0901 (cls: 0.1854, box: 0.9047)  rpn_loss: 0.1542 (cls: 0.0658, box: 0.0883)
[2025-08-07 17:44:39 train.log] INFO: Epoch: [10]  [Step 12000/14540]  lr: 0.000078  loss: 0.54788  detection_loss: 0.4841 (cls: 0.1168, box: 0.3673)  rpn_loss: 0.0638 (cls: 0.0514, box: 0.0124)
[2025-08-07 17:44:44 train.log] INFO: Epoch: [10]  [Step 12100/14540]  lr: 0.000078  loss: 1.41837  detection_loss: 1.3178 (cls: 0.3196, box: 0.9983)  rpn_loss: 0.1005 (cls: 0.0618, box: 0.0387)
[2025-08-07 17:44:49 train.log] INFO: Epoch: [10]  [Step 12200/14540]  lr: 0.000078  loss: 1.12346  detection_loss: 1.0057 (cls: 0.1597, box: 0.8461)  rpn_loss: 0.1177 (cls: 0.1004, box: 0.0173)
[2025-08-07 17:44:53 train.log] INFO: Epoch: [10]  [Step 12300/14540]  lr: 0.000078  loss: 0.76086  detection_loss: 0.7104 (cls: 0.1358, box: 0.5746)  rpn_loss: 0.0504 (cls: 0.0295, box: 0.0209)
[2025-08-07 17:44:58 train.log] INFO: Epoch: [10]  [Step 12400/14540]  lr: 0.000078  loss: 0.98732  detection_loss: 0.8200 (cls: 0.1979, box: 0.6221)  rpn_loss: 0.1674 (cls: 0.1011, box: 0.0663)
[2025-08-07 17:45:03 train.log] INFO: Epoch: [10]  [Step 12500/14540]  lr: 0.000078  loss: 0.72853  detection_loss: 0.6636 (cls: 0.1810, box: 0.4826)  rpn_loss: 0.0650 (cls: 0.0300, box: 0.0350)
[2025-08-07 17:45:08 train.log] INFO: Epoch: [10]  [Step 12600/14540]  lr: 0.000078  loss: 1.20467  detection_loss: 1.1161 (cls: 0.2387, box: 0.8774)  rpn_loss: 0.0885 (cls: 0.0327, box: 0.0558)
[2025-08-07 17:45:13 train.log] INFO: Epoch: [10]  [Step 12700/14540]  lr: 0.000078  loss: 0.96740  detection_loss: 0.8471 (cls: 0.1977, box: 0.6494)  rpn_loss: 0.1203 (cls: 0.0512, box: 0.0691)
[2025-08-07 17:45:18 train.log] INFO: Epoch: [10]  [Step 12800/14540]  lr: 0.000078  loss: 0.87364  detection_loss: 0.8133 (cls: 0.2085, box: 0.6048)  rpn_loss: 0.0604 (cls: 0.0421, box: 0.0182)
[2025-08-07 17:45:23 train.log] INFO: Epoch: [10]  [Step 12900/14540]  lr: 0.000078  loss: 0.96417  detection_loss: 0.8666 (cls: 0.2598, box: 0.6068)  rpn_loss: 0.0975 (cls: 0.0527, box: 0.0448)
[2025-08-07 17:45:28 train.log] INFO: Epoch: [10]  [Step 13000/14540]  lr: 0.000078  loss: 1.57047  detection_loss: 1.2739 (cls: 0.3317, box: 0.9421)  rpn_loss: 0.2966 (cls: 0.2574, box: 0.0392)
[2025-08-07 17:45:33 train.log] INFO: Epoch: [10]  [Step 13100/14540]  lr: 0.000078  loss: 0.89072  detection_loss: 0.7918 (cls: 0.1687, box: 0.6231)  rpn_loss: 0.0989 (cls: 0.0758, box: 0.0231)
[2025-08-07 17:45:38 train.log] INFO: Epoch: [10]  [Step 13200/14540]  lr: 0.000078  loss: 1.25843  detection_loss: 1.0815 (cls: 0.4185, box: 0.6629)  rpn_loss: 0.1770 (cls: 0.1519, box: 0.0250)
[2025-08-07 17:45:43 train.log] INFO: Epoch: [10]  [Step 13300/14540]  lr: 0.000078  loss: 1.34643  detection_loss: 1.2440 (cls: 0.2831, box: 0.9609)  rpn_loss: 0.1024 (cls: 0.0513, box: 0.0512)
[2025-08-07 17:45:48 train.log] INFO: Epoch: [10]  [Step 13400/14540]  lr: 0.000078  loss: 1.23276  detection_loss: 1.1090 (cls: 0.1729, box: 0.9362)  rpn_loss: 0.1237 (cls: 0.0973, box: 0.0264)
[2025-08-07 17:45:53 train.log] INFO: Epoch: [10]  [Step 13500/14540]  lr: 0.000078  loss: 1.18977  detection_loss: 0.9458 (cls: 0.1911, box: 0.7547)  rpn_loss: 0.2440 (cls: 0.2230, box: 0.0211)
[2025-08-07 17:45:58 train.log] INFO: Epoch: [10]  [Step 13600/14540]  lr: 0.000078  loss: 0.88270  detection_loss: 0.7686 (cls: 0.1819, box: 0.5867)  rpn_loss: 0.1141 (cls: 0.0656, box: 0.0485)
[2025-08-07 17:46:03 train.log] INFO: Epoch: [10]  [Step 13700/14540]  lr: 0.000078  loss: 0.70617  detection_loss: 0.6373 (cls: 0.1570, box: 0.4803)  rpn_loss: 0.0689 (cls: 0.0237, box: 0.0452)
[2025-08-07 17:46:07 train.log] INFO: Epoch: [10]  [Step 13800/14540]  lr: 0.000078  loss: 2.23045  detection_loss: 2.0453 (cls: 0.3845, box: 1.6608)  rpn_loss: 0.1852 (cls: 0.1502, box: 0.0350)
[2025-08-07 17:46:12 train.log] INFO: Epoch: [10]  [Step 13900/14540]  lr: 0.000078  loss: 1.02607  detection_loss: 0.9921 (cls: 0.1256, box: 0.8665)  rpn_loss: 0.0340 (cls: 0.0131, box: 0.0209)
[2025-08-07 17:46:17 train.log] INFO: Epoch: [10]  [Step 14000/14540]  lr: 0.000078  loss: 1.06487  detection_loss: 0.9514 (cls: 0.2003, box: 0.7511)  rpn_loss: 0.1135 (cls: 0.0491, box: 0.0644)
[2025-08-07 17:46:22 train.log] INFO: Epoch: [10]  [Step 14100/14540]  lr: 0.000078  loss: 1.39890  detection_loss: 1.2515 (cls: 0.3081, box: 0.9435)  rpn_loss: 0.1474 (cls: 0.0871, box: 0.0603)
[2025-08-07 17:46:27 train.log] INFO: Epoch: [10]  [Step 14200/14540]  lr: 0.000078  loss: 0.97611  detection_loss: 0.8644 (cls: 0.2176, box: 0.6467)  rpn_loss: 0.1118 (cls: 0.0635, box: 0.0482)
[2025-08-07 17:46:32 train.log] INFO: Epoch: [10]  [Step 14300/14540]  lr: 0.000078  loss: 1.64809  detection_loss: 1.5336 (cls: 0.2341, box: 1.2995)  rpn_loss: 0.1145 (cls: 0.0855, box: 0.0290)
[2025-08-07 17:46:37 train.log] INFO: Epoch: [10]  [Step 14400/14540]  lr: 0.000078  loss: 2.08397  detection_loss: 1.8070 (cls: 0.4454, box: 1.3616)  rpn_loss: 0.2770 (cls: 0.1395, box: 0.1375)
[2025-08-07 17:46:42 train.log] INFO: Epoch: [10]  [Step 14500/14540]  lr: 0.000078  loss: 1.43450  detection_loss: 1.3090 (cls: 0.5115, box: 0.7975)  rpn_loss: 0.1255 (cls: 0.0757, box: 0.0498)
[2025-08-07 17:49:50 train.log] INFO: Epoch: [11]  [Step 100/14540]  lr: 0.000073  loss: 1.23206  detection_loss: 1.0670 (cls: 0.2425, box: 0.8245)  rpn_loss: 0.1651 (cls: 0.1008, box: 0.0643)
[2025-08-07 17:49:55 train.log] INFO: Epoch: [11]  [Step 200/14540]  lr: 0.000073  loss: 1.70351  detection_loss: 1.5923 (cls: 0.3402, box: 1.2521)  rpn_loss: 0.1112 (cls: 0.0532, box: 0.0580)
[2025-08-07 17:50:00 train.log] INFO: Epoch: [11]  [Step 300/14540]  lr: 0.000073  loss: 1.49173  detection_loss: 1.3558 (cls: 0.2138, box: 1.1419)  rpn_loss: 0.1359 (cls: 0.0560, box: 0.0800)
[2025-08-07 17:50:05 train.log] INFO: Epoch: [11]  [Step 400/14540]  lr: 0.000073  loss: 0.75692  detection_loss: 0.6353 (cls: 0.0929, box: 0.5424)  rpn_loss: 0.1216 (cls: 0.0598, box: 0.0618)
[2025-08-07 17:50:10 train.log] INFO: Epoch: [11]  [Step 500/14540]  lr: 0.000073  loss: 1.26215  detection_loss: 1.1601 (cls: 0.2193, box: 0.9408)  rpn_loss: 0.1021 (cls: 0.0575, box: 0.0446)
[2025-08-07 17:50:15 train.log] INFO: Epoch: [11]  [Step 600/14540]  lr: 0.000073  loss: 1.22712  detection_loss: 1.0351 (cls: 0.2558, box: 0.7793)  rpn_loss: 0.1920 (cls: 0.1308, box: 0.0612)
[2025-08-07 17:50:20 train.log] INFO: Epoch: [11]  [Step 700/14540]  lr: 0.000073  loss: 1.05562  detection_loss: 0.9246 (cls: 0.2305, box: 0.6941)  rpn_loss: 0.1311 (cls: 0.0454, box: 0.0857)
[2025-08-07 17:50:25 train.log] INFO: Epoch: [11]  [Step 800/14540]  lr: 0.000073  loss: 1.35715  detection_loss: 1.2538 (cls: 0.4987, box: 0.7551)  rpn_loss: 0.1034 (cls: 0.0332, box: 0.0701)
[2025-08-07 17:50:30 train.log] INFO: Epoch: [11]  [Step 900/14540]  lr: 0.000073  loss: 1.05568  detection_loss: 0.9200 (cls: 0.1993, box: 0.7207)  rpn_loss: 0.1357 (cls: 0.0212, box: 0.1145)
[2025-08-07 17:50:34 train.log] INFO: Epoch: [11]  [Step 1000/14540]  lr: 0.000073  loss: 1.30331  detection_loss: 1.1913 (cls: 0.2500, box: 0.9413)  rpn_loss: 0.1120 (cls: 0.0464, box: 0.0657)
[2025-08-07 17:50:39 train.log] INFO: Epoch: [11]  [Step 1100/14540]  lr: 0.000073  loss: 1.02437  detection_loss: 0.8450 (cls: 0.2158, box: 0.6292)  rpn_loss: 0.1794 (cls: 0.0933, box: 0.0861)
[2025-08-07 17:50:44 train.log] INFO: Epoch: [11]  [Step 1200/14540]  lr: 0.000073  loss: 1.08083  detection_loss: 0.9440 (cls: 0.2228, box: 0.7212)  rpn_loss: 0.1368 (cls: 0.0407, box: 0.0961)
[2025-08-07 17:50:49 train.log] INFO: Epoch: [11]  [Step 1300/14540]  lr: 0.000073  loss: 1.27181  detection_loss: 1.1587 (cls: 0.1623, box: 0.9964)  rpn_loss: 0.1131 (cls: 0.0256, box: 0.0875)
[2025-08-07 17:50:54 train.log] INFO: Epoch: [11]  [Step 1400/14540]  lr: 0.000073  loss: 1.25744  detection_loss: 1.0029 (cls: 0.2742, box: 0.7287)  rpn_loss: 0.2545 (cls: 0.0343, box: 0.2203)
[2025-08-07 17:50:59 train.log] INFO: Epoch: [11]  [Step 1500/14540]  lr: 0.000073  loss: 1.57633  detection_loss: 1.4563 (cls: 0.3642, box: 1.0922)  rpn_loss: 0.1200 (cls: 0.0807, box: 0.0393)
[2025-08-07 17:51:04 train.log] INFO: Epoch: [11]  [Step 1600/14540]  lr: 0.000073  loss: 1.46574  detection_loss: 1.2328 (cls: 0.1582, box: 1.0746)  rpn_loss: 0.2330 (cls: 0.0187, box: 0.2143)
[2025-08-07 17:51:09 train.log] INFO: Epoch: [11]  [Step 1700/14540]  lr: 0.000073  loss: 0.94341  detection_loss: 0.8551 (cls: 0.2482, box: 0.6068)  rpn_loss: 0.0883 (cls: 0.0502, box: 0.0382)
[2025-08-07 17:51:14 train.log] INFO: Epoch: [11]  [Step 1800/14540]  lr: 0.000073  loss: 1.55986  detection_loss: 1.3895 (cls: 0.2487, box: 1.1409)  rpn_loss: 0.1703 (cls: 0.1448, box: 0.0255)
[2025-08-07 17:51:19 train.log] INFO: Epoch: [11]  [Step 1900/14540]  lr: 0.000073  loss: 1.30656  detection_loss: 1.0732 (cls: 0.3768, box: 0.6963)  rpn_loss: 0.2334 (cls: 0.0788, box: 0.1546)
[2025-08-07 17:51:24 train.log] INFO: Epoch: [11]  [Step 2000/14540]  lr: 0.000073  loss: 1.56636  detection_loss: 1.3793 (cls: 0.5190, box: 0.8602)  rpn_loss: 0.1871 (cls: 0.1018, box: 0.0853)
[2025-08-07 17:51:29 train.log] INFO: Epoch: [11]  [Step 2100/14540]  lr: 0.000073  loss: 1.00065  detection_loss: 0.8907 (cls: 0.2963, box: 0.5944)  rpn_loss: 0.1099 (cls: 0.0688, box: 0.0412)
[2025-08-07 17:51:34 train.log] INFO: Epoch: [11]  [Step 2200/14540]  lr: 0.000073  loss: 1.44932  detection_loss: 1.2626 (cls: 0.4386, box: 0.8240)  rpn_loss: 0.1867 (cls: 0.1386, box: 0.0482)
[2025-08-07 17:51:39 train.log] INFO: Epoch: [11]  [Step 2300/14540]  lr: 0.000073  loss: 1.29084  detection_loss: 1.1751 (cls: 0.3585, box: 0.8166)  rpn_loss: 0.1157 (cls: 0.0633, box: 0.0524)
[2025-08-07 17:51:44 train.log] INFO: Epoch: [11]  [Step 2400/14540]  lr: 0.000073  loss: 1.36005  detection_loss: 1.2741 (cls: 0.3435, box: 0.9306)  rpn_loss: 0.0860 (cls: 0.0462, box: 0.0397)
[2025-08-07 17:51:49 train.log] INFO: Epoch: [11]  [Step 2500/14540]  lr: 0.000073  loss: 0.96286  detection_loss: 0.8587 (cls: 0.2295, box: 0.6292)  rpn_loss: 0.1042 (cls: 0.0727, box: 0.0315)
[2025-08-07 17:51:54 train.log] INFO: Epoch: [11]  [Step 2600/14540]  lr: 0.000073  loss: 1.00657  detection_loss: 0.8210 (cls: 0.2276, box: 0.5934)  rpn_loss: 0.1855 (cls: 0.1470, box: 0.0385)
[2025-08-07 17:51:59 train.log] INFO: Epoch: [11]  [Step 2700/14540]  lr: 0.000073  loss: 1.00612  detection_loss: 0.8879 (cls: 0.3435, box: 0.5444)  rpn_loss: 0.1182 (cls: 0.0972, box: 0.0209)
[2025-08-07 17:52:03 train.log] INFO: Epoch: [11]  [Step 2800/14540]  lr: 0.000073  loss: 1.50695  detection_loss: 1.4327 (cls: 0.2518, box: 1.1808)  rpn_loss: 0.0743 (cls: 0.0547, box: 0.0196)
[2025-08-07 17:52:08 train.log] INFO: Epoch: [11]  [Step 2900/14540]  lr: 0.000073  loss: 1.17251  detection_loss: 1.1088 (cls: 0.1801, box: 0.9287)  rpn_loss: 0.0637 (cls: 0.0485, box: 0.0153)
[2025-08-07 17:52:13 train.log] INFO: Epoch: [11]  [Step 3000/14540]  lr: 0.000073  loss: 1.55878  detection_loss: 1.4230 (cls: 0.4441, box: 0.9789)  rpn_loss: 0.1357 (cls: 0.0714, box: 0.0643)
[2025-08-07 17:52:18 train.log] INFO: Epoch: [11]  [Step 3100/14540]  lr: 0.000073  loss: 1.05333  detection_loss: 0.9055 (cls: 0.2980, box: 0.6075)  rpn_loss: 0.1478 (cls: 0.0365, box: 0.1114)
[2025-08-07 17:52:23 train.log] INFO: Epoch: [11]  [Step 3200/14540]  lr: 0.000073  loss: 1.00979  detection_loss: 0.9638 (cls: 0.1395, box: 0.8243)  rpn_loss: 0.0460 (cls: 0.0322, box: 0.0138)
[2025-08-07 17:52:28 train.log] INFO: Epoch: [11]  [Step 3300/14540]  lr: 0.000073  loss: 1.52134  detection_loss: 1.3045 (cls: 0.3826, box: 0.9219)  rpn_loss: 0.2168 (cls: 0.1438, box: 0.0731)
[2025-08-07 17:52:33 train.log] INFO: Epoch: [11]  [Step 3400/14540]  lr: 0.000073  loss: 0.70642  detection_loss: 0.6329 (cls: 0.1418, box: 0.4911)  rpn_loss: 0.0735 (cls: 0.0387, box: 0.0348)
[2025-08-07 17:52:38 train.log] INFO: Epoch: [11]  [Step 3500/14540]  lr: 0.000073  loss: 1.19437  detection_loss: 1.0925 (cls: 0.4294, box: 0.6630)  rpn_loss: 0.1019 (cls: 0.0867, box: 0.0152)
[2025-08-07 17:52:43 train.log] INFO: Epoch: [11]  [Step 3600/14540]  lr: 0.000073  loss: 1.25987  detection_loss: 1.1079 (cls: 0.3311, box: 0.7768)  rpn_loss: 0.1520 (cls: 0.0999, box: 0.0521)
[2025-08-07 17:52:45 train.log] INFO: Epoch: [11]  [Step 3635/14540]  lr: 0.000073  loss: 0.79241  detection_loss: 0.7024 (cls: 0.1594, box: 0.5430)  rpn_loss: 0.0900 (cls: 0.0711, box: 0.0189)
[2025-08-07 17:52:48 train.log] INFO: Epoch: [11]  [Step 3700/14540]  lr: 0.000073  loss: 1.03834  detection_loss: 0.8844 (cls: 0.1944, box: 0.6900)  rpn_loss: 0.1539 (cls: 0.1197, box: 0.0343)
[2025-08-07 17:52:53 train.log] INFO: Epoch: [11]  [Step 3800/14540]  lr: 0.000073  loss: 1.44280  detection_loss: 1.3405 (cls: 0.3026, box: 1.0379)  rpn_loss: 0.1023 (cls: 0.0408, box: 0.0615)
[2025-08-07 17:52:58 train.log] INFO: Epoch: [11]  [Step 3900/14540]  lr: 0.000073  loss: 1.09746  detection_loss: 0.6827 (cls: 0.2781, box: 0.4046)  rpn_loss: 0.4148 (cls: 0.0860, box: 0.3287)
[2025-08-07 17:53:03 train.log] INFO: Epoch: [11]  [Step 4000/14540]  lr: 0.000073  loss: 0.86699  detection_loss: 0.7647 (cls: 0.2024, box: 0.5623)  rpn_loss: 0.1023 (cls: 0.0327, box: 0.0696)
[2025-08-07 17:53:08 train.log] INFO: Epoch: [11]  [Step 4100/14540]  lr: 0.000073  loss: 1.07812  detection_loss: 1.0058 (cls: 0.1397, box: 0.8661)  rpn_loss: 0.0723 (cls: 0.0402, box: 0.0322)
[2025-08-07 17:53:13 train.log] INFO: Epoch: [11]  [Step 4200/14540]  lr: 0.000073  loss: 1.38262  detection_loss: 1.1970 (cls: 0.2428, box: 0.9542)  rpn_loss: 0.1856 (cls: 0.0769, box: 0.1087)
[2025-08-07 17:53:18 train.log] INFO: Epoch: [11]  [Step 4300/14540]  lr: 0.000073  loss: 0.95862  detection_loss: 0.8134 (cls: 0.1942, box: 0.6192)  rpn_loss: 0.1452 (cls: 0.0305, box: 0.1147)
[2025-08-07 17:53:23 train.log] INFO: Epoch: [11]  [Step 4400/14540]  lr: 0.000073  loss: 1.07702  detection_loss: 0.9633 (cls: 0.3459, box: 0.6173)  rpn_loss: 0.1137 (cls: 0.0819, box: 0.0319)
[2025-08-07 17:53:28 train.log] INFO: Epoch: [11]  [Step 4500/14540]  lr: 0.000073  loss: 0.49844  detection_loss: 0.4362 (cls: 0.1676, box: 0.2685)  rpn_loss: 0.0623 (cls: 0.0290, box: 0.0333)
[2025-08-07 17:53:33 train.log] INFO: Epoch: [11]  [Step 4600/14540]  lr: 0.000073  loss: 1.05932  detection_loss: 0.9120 (cls: 0.2931, box: 0.6189)  rpn_loss: 0.1473 (cls: 0.0980, box: 0.0492)
[2025-08-07 17:53:38 train.log] INFO: Epoch: [11]  [Step 4700/14540]  lr: 0.000073  loss: 0.90676  detection_loss: 0.8516 (cls: 0.1708, box: 0.6808)  rpn_loss: 0.0552 (cls: 0.0382, box: 0.0170)
[2025-08-07 17:53:43 train.log] INFO: Epoch: [11]  [Step 4800/14540]  lr: 0.000073  loss: 1.51087  detection_loss: 0.9818 (cls: 0.1494, box: 0.8324)  rpn_loss: 0.5291 (cls: 0.0229, box: 0.5061)
[2025-08-07 17:53:47 train.log] INFO: Epoch: [11]  [Step 4900/14540]  lr: 0.000073  loss: 1.32106  detection_loss: 1.1643 (cls: 0.3874, box: 0.7769)  rpn_loss: 0.1568 (cls: 0.0713, box: 0.0854)
[2025-08-07 17:53:52 train.log] INFO: Epoch: [11]  [Step 5000/14540]  lr: 0.000073  loss: 0.97359  detection_loss: 0.9296 (cls: 0.1385, box: 0.7912)  rpn_loss: 0.0439 (cls: 0.0185, box: 0.0254)
[2025-08-07 17:53:57 train.log] INFO: Epoch: [11]  [Step 5100/14540]  lr: 0.000073  loss: 1.34983  detection_loss: 1.2414 (cls: 0.3073, box: 0.9342)  rpn_loss: 0.1084 (cls: 0.0508, box: 0.0576)
[2025-08-07 17:54:02 train.log] INFO: Epoch: [11]  [Step 5200/14540]  lr: 0.000073  loss: 1.02002  detection_loss: 0.9291 (cls: 0.2027, box: 0.7264)  rpn_loss: 0.0909 (cls: 0.0341, box: 0.0568)
[2025-08-07 17:54:07 train.log] INFO: Epoch: [11]  [Step 5300/14540]  lr: 0.000073  loss: 1.10745  detection_loss: 0.9448 (cls: 0.3242, box: 0.6205)  rpn_loss: 0.1627 (cls: 0.0836, box: 0.0791)
[2025-08-07 17:54:12 train.log] INFO: Epoch: [11]  [Step 5400/14540]  lr: 0.000073  loss: 1.17328  detection_loss: 1.0770 (cls: 0.2678, box: 0.8093)  rpn_loss: 0.0962 (cls: 0.0504, box: 0.0459)
[2025-08-07 17:54:17 train.log] INFO: Epoch: [11]  [Step 5500/14540]  lr: 0.000073  loss: 1.58380  detection_loss: 1.4536 (cls: 0.3449, box: 1.1087)  rpn_loss: 0.1302 (cls: 0.0470, box: 0.0832)
[2025-08-07 17:54:22 train.log] INFO: Epoch: [11]  [Step 5600/14540]  lr: 0.000073  loss: 1.49168  detection_loss: 1.3901 (cls: 0.3253, box: 1.0648)  rpn_loss: 0.1016 (cls: 0.0722, box: 0.0294)
[2025-08-07 17:54:27 train.log] INFO: Epoch: [11]  [Step 5700/14540]  lr: 0.000073  loss: 0.98450  detection_loss: 0.9025 (cls: 0.1682, box: 0.7343)  rpn_loss: 0.0820 (cls: 0.0559, box: 0.0261)
[2025-08-07 17:54:31 train.log] INFO: Epoch: [11]  [Step 5800/14540]  lr: 0.000073  loss: 1.31577  detection_loss: 1.1969 (cls: 0.2709, box: 0.9261)  rpn_loss: 0.1188 (cls: 0.0635, box: 0.0553)
[2025-08-07 17:54:36 train.log] INFO: Epoch: [11]  [Step 5900/14540]  lr: 0.000073  loss: 0.96711  detection_loss: 0.8490 (cls: 0.2143, box: 0.6347)  rpn_loss: 0.1182 (cls: 0.0355, box: 0.0827)
[2025-08-07 17:54:41 train.log] INFO: Epoch: [11]  [Step 6000/14540]  lr: 0.000073  loss: 0.96401  detection_loss: 0.8519 (cls: 0.2124, box: 0.6394)  rpn_loss: 0.1121 (cls: 0.0286, box: 0.0835)
[2025-08-07 17:54:46 train.log] INFO: Epoch: [11]  [Step 6100/14540]  lr: 0.000073  loss: 1.18461  detection_loss: 1.1044 (cls: 0.3031, box: 0.8013)  rpn_loss: 0.0802 (cls: 0.0478, box: 0.0323)
[2025-08-07 17:54:51 train.log] INFO: Epoch: [11]  [Step 6200/14540]  lr: 0.000073  loss: 1.06416  detection_loss: 0.9790 (cls: 0.3014, box: 0.6776)  rpn_loss: 0.0852 (cls: 0.0454, box: 0.0398)
[2025-08-07 17:54:56 train.log] INFO: Epoch: [11]  [Step 6300/14540]  lr: 0.000073  loss: 1.19480  detection_loss: 1.0353 (cls: 0.2161, box: 0.8191)  rpn_loss: 0.1595 (cls: 0.0833, box: 0.0763)
[2025-08-07 17:55:01 train.log] INFO: Epoch: [11]  [Step 6400/14540]  lr: 0.000073  loss: 1.00781  detection_loss: 0.9196 (cls: 0.1964, box: 0.7233)  rpn_loss: 0.0882 (cls: 0.0417, box: 0.0464)
[2025-08-07 17:55:06 train.log] INFO: Epoch: [11]  [Step 6500/14540]  lr: 0.000073  loss: 1.14900  detection_loss: 1.0603 (cls: 0.2356, box: 0.8247)  rpn_loss: 0.0887 (cls: 0.0466, box: 0.0421)
[2025-08-07 17:55:11 train.log] INFO: Epoch: [11]  [Step 6600/14540]  lr: 0.000073  loss: 1.18084  detection_loss: 1.0891 (cls: 0.2277, box: 0.8613)  rpn_loss: 0.0918 (cls: 0.0585, box: 0.0333)
[2025-08-07 17:55:16 train.log] INFO: Epoch: [11]  [Step 6700/14540]  lr: 0.000073  loss: 1.32917  detection_loss: 1.2029 (cls: 0.3004, box: 0.9026)  rpn_loss: 0.1262 (cls: 0.0878, box: 0.0384)
[2025-08-07 17:55:21 train.log] INFO: Epoch: [11]  [Step 6800/14540]  lr: 0.000073  loss: 0.96128  detection_loss: 0.8222 (cls: 0.1233, box: 0.6989)  rpn_loss: 0.1391 (cls: 0.0415, box: 0.0976)
[2025-08-07 17:55:26 train.log] INFO: Epoch: [11]  [Step 6900/14540]  lr: 0.000073  loss: 0.88618  detection_loss: 0.8486 (cls: 0.3482, box: 0.5004)  rpn_loss: 0.0376 (cls: 0.0214, box: 0.0162)
[2025-08-07 17:55:31 train.log] INFO: Epoch: [11]  [Step 7000/14540]  lr: 0.000073  loss: 1.55727  detection_loss: 1.2715 (cls: 0.3894, box: 0.8821)  rpn_loss: 0.2857 (cls: 0.1065, box: 0.1792)
[2025-08-07 17:55:35 train.log] INFO: Epoch: [11]  [Step 7100/14540]  lr: 0.000073  loss: 0.84353  detection_loss: 0.7514 (cls: 0.2584, box: 0.4930)  rpn_loss: 0.0921 (cls: 0.0689, box: 0.0232)
[2025-08-07 17:55:40 train.log] INFO: Epoch: [11]  [Step 7200/14540]  lr: 0.000073  loss: 1.26487  detection_loss: 1.1824 (cls: 0.3328, box: 0.8496)  rpn_loss: 0.0825 (cls: 0.0408, box: 0.0417)
[2025-08-07 17:55:45 train.log] INFO: Epoch: [11]  [Step 7300/14540]  lr: 0.000073  loss: 1.52090  detection_loss: 1.3350 (cls: 0.2720, box: 1.0629)  rpn_loss: 0.1859 (cls: 0.0633, box: 0.1226)
[2025-08-07 17:55:50 train.log] INFO: Epoch: [11]  [Step 7400/14540]  lr: 0.000073  loss: 0.97058  detection_loss: 0.8804 (cls: 0.1714, box: 0.7090)  rpn_loss: 0.0901 (cls: 0.0627, box: 0.0275)
[2025-08-07 17:55:55 train.log] INFO: Epoch: [11]  [Step 7500/14540]  lr: 0.000073  loss: 1.32768  detection_loss: 0.8430 (cls: 0.2116, box: 0.6314)  rpn_loss: 0.4847 (cls: 0.0744, box: 0.4103)
[2025-08-07 17:56:00 train.log] INFO: Epoch: [11]  [Step 7600/14540]  lr: 0.000073  loss: 1.25774  detection_loss: 1.0191 (cls: 0.1816, box: 0.8375)  rpn_loss: 0.2386 (cls: 0.2040, box: 0.0346)
[2025-08-07 17:56:05 train.log] INFO: Epoch: [11]  [Step 7700/14540]  lr: 0.000073  loss: 0.83163  detection_loss: 0.7576 (cls: 0.1180, box: 0.6395)  rpn_loss: 0.0741 (cls: 0.0214, box: 0.0526)
[2025-08-07 17:56:10 train.log] INFO: Epoch: [11]  [Step 7800/14540]  lr: 0.000073  loss: 1.38109  detection_loss: 1.2296 (cls: 0.3623, box: 0.8672)  rpn_loss: 0.1515 (cls: 0.1107, box: 0.0408)
[2025-08-07 17:56:14 train.log] INFO: Epoch: [11]  [Step 7900/14540]  lr: 0.000073  loss: 1.26253  detection_loss: 0.9886 (cls: 0.1979, box: 0.7907)  rpn_loss: 0.2739 (cls: 0.0417, box: 0.2322)
[2025-08-07 17:56:19 train.log] INFO: Epoch: [11]  [Step 8000/14540]  lr: 0.000073  loss: 1.22384  detection_loss: 1.0125 (cls: 0.2954, box: 0.7171)  rpn_loss: 0.2114 (cls: 0.0941, box: 0.1173)
[2025-08-07 17:56:24 train.log] INFO: Epoch: [11]  [Step 8100/14540]  lr: 0.000073  loss: 1.41562  detection_loss: 1.3117 (cls: 0.3464, box: 0.9653)  rpn_loss: 0.1039 (cls: 0.0330, box: 0.0709)
[2025-08-07 17:56:29 train.log] INFO: Epoch: [11]  [Step 8200/14540]  lr: 0.000073  loss: 1.51597  detection_loss: 1.2370 (cls: 0.3997, box: 0.8373)  rpn_loss: 0.2790 (cls: 0.0783, box: 0.2007)
[2025-08-07 17:56:34 train.log] INFO: Epoch: [11]  [Step 8300/14540]  lr: 0.000073  loss: 1.24161  detection_loss: 1.0799 (cls: 0.3416, box: 0.7383)  rpn_loss: 0.1617 (cls: 0.1226, box: 0.0391)
[2025-08-07 17:56:39 train.log] INFO: Epoch: [11]  [Step 8400/14540]  lr: 0.000073  loss: 1.20930  detection_loss: 1.0888 (cls: 0.2927, box: 0.7960)  rpn_loss: 0.1205 (cls: 0.0894, box: 0.0311)
[2025-08-07 17:56:44 train.log] INFO: Epoch: [11]  [Step 8500/14540]  lr: 0.000073  loss: 1.26457  detection_loss: 1.0248 (cls: 0.4143, box: 0.6105)  rpn_loss: 0.2398 (cls: 0.1884, box: 0.0514)
[2025-08-07 17:56:49 train.log] INFO: Epoch: [11]  [Step 8600/14540]  lr: 0.000073  loss: 1.35072  detection_loss: 1.2429 (cls: 0.2647, box: 0.9782)  rpn_loss: 0.1078 (cls: 0.0860, box: 0.0218)
[2025-08-07 17:56:54 train.log] INFO: Epoch: [11]  [Step 8700/14540]  lr: 0.000073  loss: 1.43698  detection_loss: 1.1953 (cls: 0.2647, box: 0.9307)  rpn_loss: 0.2416 (cls: 0.0883, box: 0.1534)
[2025-08-07 17:56:59 train.log] INFO: Epoch: [11]  [Step 8800/14540]  lr: 0.000073  loss: 1.31314  detection_loss: 1.2263 (cls: 0.2101, box: 1.0161)  rpn_loss: 0.0869 (cls: 0.0635, box: 0.0234)
[2025-08-07 17:57:03 train.log] INFO: Epoch: [11]  [Step 8900/14540]  lr: 0.000073  loss: 1.27848  detection_loss: 1.1732 (cls: 0.1729, box: 1.0002)  rpn_loss: 0.1053 (cls: 0.0650, box: 0.0403)
[2025-08-07 17:57:08 train.log] INFO: Epoch: [11]  [Step 9000/14540]  lr: 0.000073  loss: 1.19185  detection_loss: 0.8552 (cls: 0.1520, box: 0.7032)  rpn_loss: 0.3366 (cls: 0.0133, box: 0.3233)
[2025-08-07 17:57:13 train.log] INFO: Epoch: [11]  [Step 9100/14540]  lr: 0.000073  loss: 0.41271  detection_loss: 0.3562 (cls: 0.1080, box: 0.2482)  rpn_loss: 0.0565 (cls: 0.0227, box: 0.0339)
[2025-08-07 17:57:18 train.log] INFO: Epoch: [11]  [Step 9200/14540]  lr: 0.000073  loss: 1.40233  detection_loss: 1.2421 (cls: 0.3561, box: 0.8860)  rpn_loss: 0.1602 (cls: 0.0836, box: 0.0767)
[2025-08-07 17:57:23 train.log] INFO: Epoch: [11]  [Step 9300/14540]  lr: 0.000073  loss: 1.81251  detection_loss: 1.6115 (cls: 0.2777, box: 1.3339)  rpn_loss: 0.2010 (cls: 0.1437, box: 0.0573)
[2025-08-07 17:57:28 train.log] INFO: Epoch: [11]  [Step 9400/14540]  lr: 0.000073  loss: 1.23370  detection_loss: 1.1029 (cls: 0.2831, box: 0.8198)  rpn_loss: 0.1308 (cls: 0.0486, box: 0.0822)
[2025-08-07 17:57:33 train.log] INFO: Epoch: [11]  [Step 9500/14540]  lr: 0.000073  loss: 1.34584  detection_loss: 1.2077 (cls: 0.4369, box: 0.7707)  rpn_loss: 0.1382 (cls: 0.0422, box: 0.0960)
[2025-08-07 17:57:38 train.log] INFO: Epoch: [11]  [Step 9600/14540]  lr: 0.000073  loss: 0.97118  detection_loss: 0.8596 (cls: 0.2554, box: 0.6042)  rpn_loss: 0.1116 (cls: 0.0860, box: 0.0256)
[2025-08-07 17:57:43 train.log] INFO: Epoch: [11]  [Step 9700/14540]  lr: 0.000073  loss: 0.61254  detection_loss: 0.5631 (cls: 0.1570, box: 0.4061)  rpn_loss: 0.0494 (cls: 0.0290, box: 0.0205)
[2025-08-07 17:57:48 train.log] INFO: Epoch: [11]  [Step 9800/14540]  lr: 0.000073  loss: 1.04273  detection_loss: 0.9080 (cls: 0.2474, box: 0.6606)  rpn_loss: 0.1347 (cls: 0.0653, box: 0.0693)
[2025-08-07 17:57:52 train.log] INFO: Epoch: [11]  [Step 9900/14540]  lr: 0.000073  loss: 1.14974  detection_loss: 1.0484 (cls: 0.1761, box: 0.8722)  rpn_loss: 0.1014 (cls: 0.0480, box: 0.0534)
[2025-08-07 17:57:57 train.log] INFO: Epoch: [11]  [Step 10000/14540]  lr: 0.000073  loss: 1.64374  detection_loss: 1.5257 (cls: 0.4272, box: 1.0985)  rpn_loss: 0.1180 (cls: 0.0616, box: 0.0564)
[2025-08-07 17:58:02 train.log] INFO: Epoch: [11]  [Step 10100/14540]  lr: 0.000073  loss: 0.93498  detection_loss: 0.8932 (cls: 0.2032, box: 0.6900)  rpn_loss: 0.0418 (cls: 0.0233, box: 0.0186)
[2025-08-07 17:58:07 train.log] INFO: Epoch: [11]  [Step 10200/14540]  lr: 0.000073  loss: 1.57445  detection_loss: 1.4304 (cls: 0.4023, box: 1.0281)  rpn_loss: 0.1441 (cls: 0.1128, box: 0.0312)
[2025-08-07 17:58:12 train.log] INFO: Epoch: [11]  [Step 10300/14540]  lr: 0.000073  loss: 1.40316  detection_loss: 1.2344 (cls: 0.3732, box: 0.8612)  rpn_loss: 0.1688 (cls: 0.0810, box: 0.0878)
[2025-08-07 17:58:17 train.log] INFO: Epoch: [11]  [Step 10400/14540]  lr: 0.000073  loss: 1.50378  detection_loss: 1.3858 (cls: 0.4444, box: 0.9414)  rpn_loss: 0.1180 (cls: 0.0536, box: 0.0644)
[2025-08-07 17:58:22 train.log] INFO: Epoch: [11]  [Step 10500/14540]  lr: 0.000073  loss: 1.03901  detection_loss: 0.8631 (cls: 0.1896, box: 0.6735)  rpn_loss: 0.1759 (cls: 0.0446, box: 0.1314)
[2025-08-07 17:58:27 train.log] INFO: Epoch: [11]  [Step 10600/14540]  lr: 0.000073  loss: 1.42152  detection_loss: 1.2956 (cls: 0.2547, box: 1.0410)  rpn_loss: 0.1259 (cls: 0.0548, box: 0.0710)
[2025-08-07 17:58:32 train.log] INFO: Epoch: [11]  [Step 10700/14540]  lr: 0.000073  loss: 1.23818  detection_loss: 1.1310 (cls: 0.1563, box: 0.9747)  rpn_loss: 0.1072 (cls: 0.0323, box: 0.0749)
[2025-08-07 17:58:37 train.log] INFO: Epoch: [11]  [Step 10800/14540]  lr: 0.000073  loss: 1.30032  detection_loss: 1.1976 (cls: 0.2844, box: 0.9132)  rpn_loss: 0.1027 (cls: 0.0252, box: 0.0775)
[2025-08-07 17:58:42 train.log] INFO: Epoch: [11]  [Step 10900/14540]  lr: 0.000073  loss: 1.49545  detection_loss: 1.3766 (cls: 0.1493, box: 1.2274)  rpn_loss: 0.1188 (cls: 0.0611, box: 0.0577)
[2025-08-07 17:58:47 train.log] INFO: Epoch: [11]  [Step 11000/14540]  lr: 0.000073  loss: 0.92077  detection_loss: 0.8541 (cls: 0.1686, box: 0.6855)  rpn_loss: 0.0666 (cls: 0.0557, box: 0.0109)
[2025-08-07 17:58:52 train.log] INFO: Epoch: [11]  [Step 11100/14540]  lr: 0.000073  loss: 1.42928  detection_loss: 1.2434 (cls: 0.2289, box: 1.0144)  rpn_loss: 0.1859 (cls: 0.1172, box: 0.0687)
[2025-08-07 17:58:57 train.log] INFO: Epoch: [11]  [Step 11200/14540]  lr: 0.000073  loss: 0.96468  detection_loss: 0.8821 (cls: 0.3264, box: 0.5557)  rpn_loss: 0.0825 (cls: 0.0564, box: 0.0261)
[2025-08-07 17:59:02 train.log] INFO: Epoch: [11]  [Step 11300/14540]  lr: 0.000073  loss: 1.12042  detection_loss: 0.9188 (cls: 0.2120, box: 0.7069)  rpn_loss: 0.2016 (cls: 0.1011, box: 0.1005)
[2025-08-07 17:59:07 train.log] INFO: Epoch: [11]  [Step 11400/14540]  lr: 0.000073  loss: 1.67405  detection_loss: 1.4037 (cls: 0.3759, box: 1.0278)  rpn_loss: 0.2703 (cls: 0.1077, box: 0.1626)
[2025-08-07 17:59:12 train.log] INFO: Epoch: [11]  [Step 11500/14540]  lr: 0.000073  loss: 1.03664  detection_loss: 0.9430 (cls: 0.2137, box: 0.7293)  rpn_loss: 0.0936 (cls: 0.0706, box: 0.0230)
[2025-08-07 17:59:17 train.log] INFO: Epoch: [11]  [Step 11600/14540]  lr: 0.000073  loss: 1.03911  detection_loss: 0.8954 (cls: 0.1866, box: 0.7087)  rpn_loss: 0.1438 (cls: 0.0555, box: 0.0882)
[2025-08-07 17:59:22 train.log] INFO: Epoch: [11]  [Step 11700/14540]  lr: 0.000073  loss: 1.39975  detection_loss: 1.3281 (cls: 0.2883, box: 1.0397)  rpn_loss: 0.0717 (cls: 0.0495, box: 0.0221)
[2025-08-07 17:59:26 train.log] INFO: Epoch: [11]  [Step 11800/14540]  lr: 0.000073  loss: 1.20991  detection_loss: 1.1417 (cls: 0.3052, box: 0.8365)  rpn_loss: 0.0682 (cls: 0.0383, box: 0.0299)
[2025-08-07 17:59:31 train.log] INFO: Epoch: [11]  [Step 11900/14540]  lr: 0.000073  loss: 1.49435  detection_loss: 1.2091 (cls: 0.3495, box: 0.8595)  rpn_loss: 0.2853 (cls: 0.1220, box: 0.1633)
[2025-08-07 17:59:36 train.log] INFO: Epoch: [11]  [Step 12000/14540]  lr: 0.000073  loss: 0.85318  detection_loss: 0.8004 (cls: 0.0908, box: 0.7097)  rpn_loss: 0.0528 (cls: 0.0119, box: 0.0409)
[2025-08-07 17:59:41 train.log] INFO: Epoch: [11]  [Step 12100/14540]  lr: 0.000073  loss: 0.77497  detection_loss: 0.6775 (cls: 0.1113, box: 0.5662)  rpn_loss: 0.0975 (cls: 0.0502, box: 0.0473)
[2025-08-07 17:59:46 train.log] INFO: Epoch: [11]  [Step 12200/14540]  lr: 0.000073  loss: 1.33022  detection_loss: 1.2038 (cls: 0.3016, box: 0.9022)  rpn_loss: 0.1264 (cls: 0.0738, box: 0.0526)
[2025-08-07 17:59:51 train.log] INFO: Epoch: [11]  [Step 12300/14540]  lr: 0.000073  loss: 1.31876  detection_loss: 1.1326 (cls: 0.2652, box: 0.8675)  rpn_loss: 0.1861 (cls: 0.1471, box: 0.0390)
[2025-08-07 17:59:56 train.log] INFO: Epoch: [11]  [Step 12400/14540]  lr: 0.000073  loss: 1.52733  detection_loss: 1.3097 (cls: 0.2977, box: 1.0121)  rpn_loss: 0.2176 (cls: 0.0407, box: 0.1769)
[2025-08-07 18:00:01 train.log] INFO: Epoch: [11]  [Step 12500/14540]  lr: 0.000073  loss: 0.76514  detection_loss: 0.7027 (cls: 0.1959, box: 0.5068)  rpn_loss: 0.0624 (cls: 0.0413, box: 0.0212)
[2025-08-07 18:00:06 train.log] INFO: Epoch: [11]  [Step 12600/14540]  lr: 0.000073  loss: 0.82909  detection_loss: 0.7322 (cls: 0.1908, box: 0.5414)  rpn_loss: 0.0969 (cls: 0.0371, box: 0.0598)
[2025-08-07 18:00:11 train.log] INFO: Epoch: [11]  [Step 12700/14540]  lr: 0.000073  loss: 1.06960  detection_loss: 0.9645 (cls: 0.2344, box: 0.7301)  rpn_loss: 0.1051 (cls: 0.0348, box: 0.0703)
[2025-08-07 18:00:16 train.log] INFO: Epoch: [11]  [Step 12800/14540]  lr: 0.000073  loss: 1.33081  detection_loss: 1.1082 (cls: 0.2461, box: 0.8621)  rpn_loss: 0.2226 (cls: 0.0422, box: 0.1804)
[2025-08-07 18:00:21 train.log] INFO: Epoch: [11]  [Step 12900/14540]  lr: 0.000073  loss: 1.48960  detection_loss: 1.3420 (cls: 0.4428, box: 0.8992)  rpn_loss: 0.1476 (cls: 0.0653, box: 0.0823)
[2025-08-07 18:00:26 train.log] INFO: Epoch: [11]  [Step 13000/14540]  lr: 0.000073  loss: 1.49031  detection_loss: 1.3930 (cls: 0.3375, box: 1.0555)  rpn_loss: 0.0973 (cls: 0.0596, box: 0.0378)
[2025-08-07 18:00:31 train.log] INFO: Epoch: [11]  [Step 13100/14540]  lr: 0.000073  loss: 1.60056  detection_loss: 1.4497 (cls: 0.4198, box: 1.0298)  rpn_loss: 0.1509 (cls: 0.0569, box: 0.0940)
[2025-08-07 18:00:36 train.log] INFO: Epoch: [11]  [Step 13200/14540]  lr: 0.000073  loss: 1.06753  detection_loss: 1.0068 (cls: 0.1372, box: 0.8696)  rpn_loss: 0.0607 (cls: 0.0297, box: 0.0310)
[2025-08-07 18:00:41 train.log] INFO: Epoch: [11]  [Step 13300/14540]  lr: 0.000073  loss: 1.29461  detection_loss: 1.1860 (cls: 0.3224, box: 0.8636)  rpn_loss: 0.1086 (cls: 0.0612, box: 0.0474)
[2025-08-07 18:00:46 train.log] INFO: Epoch: [11]  [Step 13400/14540]  lr: 0.000073  loss: 1.69254  detection_loss: 1.4376 (cls: 0.4048, box: 1.0328)  rpn_loss: 0.2550 (cls: 0.1987, box: 0.0563)
[2025-08-07 18:00:51 train.log] INFO: Epoch: [11]  [Step 13500/14540]  lr: 0.000073  loss: 1.48172  detection_loss: 1.3935 (cls: 0.3514, box: 1.0421)  rpn_loss: 0.0882 (cls: 0.0553, box: 0.0329)
[2025-08-07 18:00:56 train.log] INFO: Epoch: [11]  [Step 13600/14540]  lr: 0.000073  loss: 1.10753  detection_loss: 1.0037 (cls: 0.2772, box: 0.7265)  rpn_loss: 0.1038 (cls: 0.0461, box: 0.0577)
[2025-08-07 18:01:01 train.log] INFO: Epoch: [11]  [Step 13700/14540]  lr: 0.000073  loss: 0.98226  detection_loss: 0.8718 (cls: 0.1858, box: 0.6860)  rpn_loss: 0.1104 (cls: 0.0416, box: 0.0688)
[2025-08-07 18:01:06 train.log] INFO: Epoch: [11]  [Step 13800/14540]  lr: 0.000073  loss: 0.94275  detection_loss: 0.7915 (cls: 0.1243, box: 0.6672)  rpn_loss: 0.1512 (cls: 0.0288, box: 0.1224)
[2025-08-07 18:01:11 train.log] INFO: Epoch: [11]  [Step 13900/14540]  lr: 0.000073  loss: 1.36711  detection_loss: 1.2794 (cls: 0.2138, box: 1.0656)  rpn_loss: 0.0877 (cls: 0.0414, box: 0.0463)
[2025-08-07 18:01:16 train.log] INFO: Epoch: [11]  [Step 14000/14540]  lr: 0.000073  loss: 1.66552  detection_loss: 1.4581 (cls: 0.4121, box: 1.0460)  rpn_loss: 0.2074 (cls: 0.1810, box: 0.0263)
[2025-08-07 18:01:21 train.log] INFO: Epoch: [11]  [Step 14100/14540]  lr: 0.000073  loss: 0.96618  detection_loss: 0.8087 (cls: 0.1946, box: 0.6141)  rpn_loss: 0.1575 (cls: 0.0346, box: 0.1229)
[2025-08-07 18:01:26 train.log] INFO: Epoch: [11]  [Step 14200/14540]  lr: 0.000073  loss: 1.40150  detection_loss: 1.3193 (cls: 0.3005, box: 1.0188)  rpn_loss: 0.0822 (cls: 0.0247, box: 0.0575)
[2025-08-07 18:01:32 train.log] INFO: Epoch: [11]  [Step 14300/14540]  lr: 0.000073  loss: 1.51550  detection_loss: 1.3125 (cls: 0.4461, box: 0.8664)  rpn_loss: 0.2030 (cls: 0.0808, box: 0.1222)
[2025-08-07 18:01:37 train.log] INFO: Epoch: [11]  [Step 14400/14540]  lr: 0.000073  loss: 0.78985  detection_loss: 0.6975 (cls: 0.1732, box: 0.5242)  rpn_loss: 0.0924 (cls: 0.0634, box: 0.0289)
[2025-08-07 18:01:42 train.log] INFO: Epoch: [11]  [Step 14500/14540]  lr: 0.000073  loss: 1.87551  detection_loss: 1.5655 (cls: 0.3116, box: 1.2539)  rpn_loss: 0.3100 (cls: 0.0722, box: 0.2378)
[2025-08-07 18:04:47 train.log] INFO: Epoch: [12]  [Step 100/14540]  lr: 0.000067  loss: 0.84574  detection_loss: 0.7441 (cls: 0.1724, box: 0.5717)  rpn_loss: 0.1017 (cls: 0.0790, box: 0.0226)
[2025-08-07 18:04:52 train.log] INFO: Epoch: [12]  [Step 200/14540]  lr: 0.000067  loss: 1.42523  detection_loss: 1.2049 (cls: 0.4266, box: 0.7783)  rpn_loss: 0.2203 (cls: 0.0628, box: 0.1575)
[2025-08-07 18:04:57 train.log] INFO: Epoch: [12]  [Step 300/14540]  lr: 0.000067  loss: 1.39524  detection_loss: 1.1829 (cls: 0.2788, box: 0.9041)  rpn_loss: 0.2123 (cls: 0.0542, box: 0.1581)
[2025-08-07 18:05:02 train.log] INFO: Epoch: [12]  [Step 400/14540]  lr: 0.000067  loss: 1.28775  detection_loss: 1.1562 (cls: 0.2620, box: 0.8943)  rpn_loss: 0.1315 (cls: 0.0189, box: 0.1126)
[2025-08-07 18:05:07 train.log] INFO: Epoch: [12]  [Step 500/14540]  lr: 0.000067  loss: 0.98912  detection_loss: 0.9169 (cls: 0.2513, box: 0.6656)  rpn_loss: 0.0722 (cls: 0.0406, box: 0.0316)
[2025-08-07 18:05:12 train.log] INFO: Epoch: [12]  [Step 600/14540]  lr: 0.000067  loss: 1.13845  detection_loss: 1.0520 (cls: 0.2287, box: 0.8232)  rpn_loss: 0.0865 (cls: 0.0448, box: 0.0417)
[2025-08-07 18:05:17 train.log] INFO: Epoch: [12]  [Step 700/14540]  lr: 0.000067  loss: 0.84948  detection_loss: 0.7149 (cls: 0.1740, box: 0.5409)  rpn_loss: 0.1345 (cls: 0.0328, box: 0.1017)
[2025-08-07 18:05:23 train.log] INFO: Epoch: [12]  [Step 800/14540]  lr: 0.000067  loss: 1.04914  detection_loss: 0.9859 (cls: 0.2168, box: 0.7691)  rpn_loss: 0.0633 (cls: 0.0292, box: 0.0341)
[2025-08-07 18:05:28 train.log] INFO: Epoch: [12]  [Step 900/14540]  lr: 0.000067  loss: 0.95467  detection_loss: 0.8910 (cls: 0.1986, box: 0.6924)  rpn_loss: 0.0637 (cls: 0.0367, box: 0.0269)
[2025-08-07 18:05:33 train.log] INFO: Epoch: [12]  [Step 1000/14540]  lr: 0.000067  loss: 1.16272  detection_loss: 0.9910 (cls: 0.2564, box: 0.7346)  rpn_loss: 0.1717 (cls: 0.0892, box: 0.0825)
[2025-08-07 18:05:38 train.log] INFO: Epoch: [12]  [Step 1100/14540]  lr: 0.000067  loss: 1.45506  detection_loss: 1.3751 (cls: 0.2572, box: 1.1179)  rpn_loss: 0.0799 (cls: 0.0280, box: 0.0519)
[2025-08-07 18:05:43 train.log] INFO: Epoch: [12]  [Step 1200/14540]  lr: 0.000067  loss: 1.55757  detection_loss: 1.1997 (cls: 0.2780, box: 0.9217)  rpn_loss: 0.3579 (cls: 0.1160, box: 0.2419)
[2025-08-07 18:05:48 train.log] INFO: Epoch: [12]  [Step 1300/14540]  lr: 0.000067  loss: 1.12039  detection_loss: 0.9361 (cls: 0.1753, box: 0.7608)  rpn_loss: 0.1843 (cls: 0.0690, box: 0.1153)
[2025-08-07 18:05:53 train.log] INFO: Epoch: [12]  [Step 1400/14540]  lr: 0.000067  loss: 1.00525  detection_loss: 0.8574 (cls: 0.2371, box: 0.6202)  rpn_loss: 0.1479 (cls: 0.0652, box: 0.0826)
[2025-08-07 18:05:58 train.log] INFO: Epoch: [12]  [Step 1500/14540]  lr: 0.000067  loss: 1.47606  detection_loss: 1.3631 (cls: 0.2768, box: 1.0863)  rpn_loss: 0.1130 (cls: 0.0688, box: 0.0442)
[2025-08-07 18:06:03 train.log] INFO: Epoch: [12]  [Step 1600/14540]  lr: 0.000067  loss: 1.48728  detection_loss: 1.3390 (cls: 0.3169, box: 1.0221)  rpn_loss: 0.1483 (cls: 0.0751, box: 0.0732)
[2025-08-07 18:06:09 train.log] INFO: Epoch: [12]  [Step 1700/14540]  lr: 0.000067  loss: 0.66427  detection_loss: 0.5916 (cls: 0.1627, box: 0.4289)  rpn_loss: 0.0727 (cls: 0.0430, box: 0.0296)
[2025-08-07 18:06:14 train.log] INFO: Epoch: [12]  [Step 1800/14540]  lr: 0.000067  loss: 1.05839  detection_loss: 0.9277 (cls: 0.2533, box: 0.6744)  rpn_loss: 0.1307 (cls: 0.0483, box: 0.0824)
[2025-08-07 18:06:19 train.log] INFO: Epoch: [12]  [Step 1900/14540]  lr: 0.000067  loss: 1.23752  detection_loss: 1.1700 (cls: 0.3868, box: 0.7832)  rpn_loss: 0.0675 (cls: 0.0392, box: 0.0282)
[2025-08-07 18:06:24 train.log] INFO: Epoch: [12]  [Step 2000/14540]  lr: 0.000067  loss: 1.42837  detection_loss: 1.1805 (cls: 0.3541, box: 0.8264)  rpn_loss: 0.2479 (cls: 0.0693, box: 0.1786)
[2025-08-07 18:06:29 train.log] INFO: Epoch: [12]  [Step 2100/14540]  lr: 0.000067  loss: 0.89662  detection_loss: 0.6984 (cls: 0.0828, box: 0.6156)  rpn_loss: 0.1983 (cls: 0.0298, box: 0.1684)
[2025-08-07 18:06:34 train.log] INFO: Epoch: [12]  [Step 2200/14540]  lr: 0.000067  loss: 1.13733  detection_loss: 1.0303 (cls: 0.2802, box: 0.7501)  rpn_loss: 0.1070 (cls: 0.0539, box: 0.0532)
[2025-08-07 18:06:39 train.log] INFO: Epoch: [12]  [Step 2300/14540]  lr: 0.000067  loss: 0.91331  detection_loss: 0.8521 (cls: 0.1808, box: 0.6713)  rpn_loss: 0.0612 (cls: 0.0465, box: 0.0148)
[2025-08-07 18:06:44 train.log] INFO: Epoch: [12]  [Step 2400/14540]  lr: 0.000067  loss: 0.93081  detection_loss: 0.8489 (cls: 0.3004, box: 0.5485)  rpn_loss: 0.0819 (cls: 0.0491, box: 0.0328)
[2025-08-07 18:06:49 train.log] INFO: Epoch: [12]  [Step 2500/14540]  lr: 0.000067  loss: 0.91600  detection_loss: 0.8275 (cls: 0.1837, box: 0.6439)  rpn_loss: 0.0885 (cls: 0.0530, box: 0.0354)
[2025-08-07 18:06:54 train.log] INFO: Epoch: [12]  [Step 2600/14540]  lr: 0.000067  loss: 0.84220  detection_loss: 0.7551 (cls: 0.1455, box: 0.6096)  rpn_loss: 0.0871 (cls: 0.0678, box: 0.0193)
[2025-08-07 18:06:59 train.log] INFO: Epoch: [12]  [Step 2700/14540]  lr: 0.000067  loss: 1.58911  detection_loss: 1.2794 (cls: 0.3660, box: 0.9133)  rpn_loss: 0.3097 (cls: 0.2679, box: 0.0419)
[2025-08-07 18:07:04 train.log] INFO: Epoch: [12]  [Step 2800/14540]  lr: 0.000067  loss: 1.21944  detection_loss: 1.0794 (cls: 0.3219, box: 0.7575)  rpn_loss: 0.1400 (cls: 0.0620, box: 0.0780)
[2025-08-07 18:07:09 train.log] INFO: Epoch: [12]  [Step 2900/14540]  lr: 0.000067  loss: 1.06897  detection_loss: 0.9185 (cls: 0.1627, box: 0.7559)  rpn_loss: 0.1504 (cls: 0.0351, box: 0.1153)
[2025-08-07 18:07:14 train.log] INFO: Epoch: [12]  [Step 3000/14540]  lr: 0.000067  loss: 1.01180  detection_loss: 0.9232 (cls: 0.2570, box: 0.6663)  rpn_loss: 0.0886 (cls: 0.0318, box: 0.0568)
[2025-08-07 18:07:20 train.log] INFO: Epoch: [12]  [Step 3100/14540]  lr: 0.000067  loss: 1.06636  detection_loss: 0.9930 (cls: 0.2722, box: 0.7208)  rpn_loss: 0.0733 (cls: 0.0396, box: 0.0338)
[2025-08-07 18:07:25 train.log] INFO: Epoch: [12]  [Step 3200/14540]  lr: 0.000067  loss: 0.81239  detection_loss: 0.6493 (cls: 0.1215, box: 0.5278)  rpn_loss: 0.1631 (cls: 0.0951, box: 0.0680)
[2025-08-07 18:07:30 train.log] INFO: Epoch: [12]  [Step 3300/14540]  lr: 0.000067  loss: 1.15806  detection_loss: 1.0578 (cls: 0.1546, box: 0.9032)  rpn_loss: 0.1002 (cls: 0.0667, box: 0.0335)
[2025-08-07 18:07:35 train.log] INFO: Epoch: [12]  [Step 3400/14540]  lr: 0.000067  loss: 0.84835  detection_loss: 0.7348 (cls: 0.2347, box: 0.5001)  rpn_loss: 0.1135 (cls: 0.0455, box: 0.0680)
[2025-08-07 18:07:40 train.log] INFO: Epoch: [12]  [Step 3500/14540]  lr: 0.000067  loss: 1.26177  detection_loss: 1.1095 (cls: 0.1714, box: 0.9382)  rpn_loss: 0.1523 (cls: 0.0339, box: 0.1183)
[2025-08-07 18:07:46 train.log] INFO: Epoch: [12]  [Step 3600/14540]  lr: 0.000067  loss: 0.92572  detection_loss: 0.8545 (cls: 0.1404, box: 0.7141)  rpn_loss: 0.0712 (cls: 0.0401, box: 0.0312)
[2025-08-07 18:07:47 train.log] INFO: Epoch: [12]  [Step 3635/14540]  lr: 0.000067  loss: 1.47106  detection_loss: 1.3004 (cls: 0.3799, box: 0.9205)  rpn_loss: 0.1707 (cls: 0.0872, box: 0.0835)
[2025-08-07 18:07:51 train.log] INFO: Epoch: [12]  [Step 3700/14540]  lr: 0.000067  loss: 1.53057  detection_loss: 1.4257 (cls: 0.1383, box: 1.2874)  rpn_loss: 0.1049 (cls: 0.0556, box: 0.0493)
[2025-08-07 18:07:56 train.log] INFO: Epoch: [12]  [Step 3800/14540]  lr: 0.000067  loss: 0.82299  detection_loss: 0.7765 (cls: 0.1694, box: 0.6071)  rpn_loss: 0.0465 (cls: 0.0216, box: 0.0249)
[2025-08-07 18:08:01 train.log] INFO: Epoch: [12]  [Step 3900/14540]  lr: 0.000067  loss: 2.15090  detection_loss: 1.9515 (cls: 0.4422, box: 1.5094)  rpn_loss: 0.1994 (cls: 0.0741, box: 0.1253)
[2025-08-07 18:08:06 train.log] INFO: Epoch: [12]  [Step 4000/14540]  lr: 0.000067  loss: 1.49876  detection_loss: 1.1114 (cls: 0.3051, box: 0.8063)  rpn_loss: 0.3873 (cls: 0.0491, box: 0.3382)
[2025-08-07 18:08:11 train.log] INFO: Epoch: [12]  [Step 4100/14540]  lr: 0.000067  loss: 1.70476  detection_loss: 1.6150 (cls: 0.4297, box: 1.1852)  rpn_loss: 0.0898 (cls: 0.0606, box: 0.0292)
[2025-08-07 18:08:16 train.log] INFO: Epoch: [12]  [Step 4200/14540]  lr: 0.000067  loss: 1.14940  detection_loss: 0.9169 (cls: 0.1869, box: 0.7301)  rpn_loss: 0.2325 (cls: 0.1186, box: 0.1139)
[2025-08-07 18:08:21 train.log] INFO: Epoch: [12]  [Step 4300/14540]  lr: 0.000067  loss: 0.97226  detection_loss: 0.7934 (cls: 0.1703, box: 0.6231)  rpn_loss: 0.1788 (cls: 0.0619, box: 0.1169)
[2025-08-07 18:08:26 train.log] INFO: Epoch: [12]  [Step 4400/14540]  lr: 0.000067  loss: 0.97523  detection_loss: 0.7663 (cls: 0.1511, box: 0.6152)  rpn_loss: 0.2089 (cls: 0.0282, box: 0.1807)
[2025-08-07 18:08:31 train.log] INFO: Epoch: [12]  [Step 4500/14540]  lr: 0.000067  loss: 1.17488  detection_loss: 1.0319 (cls: 0.3369, box: 0.6950)  rpn_loss: 0.1430 (cls: 0.0323, box: 0.1107)
[2025-08-07 18:08:36 train.log] INFO: Epoch: [12]  [Step 4600/14540]  lr: 0.000067  loss: 0.83529  detection_loss: 0.7403 (cls: 0.1453, box: 0.5950)  rpn_loss: 0.0950 (cls: 0.0660, box: 0.0291)
[2025-08-07 18:08:41 train.log] INFO: Epoch: [12]  [Step 4700/14540]  lr: 0.000067  loss: 1.28241  detection_loss: 1.2084 (cls: 0.2851, box: 0.9233)  rpn_loss: 0.0740 (cls: 0.0499, box: 0.0241)
[2025-08-07 18:08:46 train.log] INFO: Epoch: [12]  [Step 4800/14540]  lr: 0.000067  loss: 1.74988  detection_loss: 1.6101 (cls: 0.5824, box: 1.0277)  rpn_loss: 0.1397 (cls: 0.0519, box: 0.0879)
[2025-08-07 18:08:51 train.log] INFO: Epoch: [12]  [Step 4900/14540]  lr: 0.000067  loss: 1.15417  detection_loss: 1.0749 (cls: 0.1447, box: 0.9302)  rpn_loss: 0.0793 (cls: 0.0322, box: 0.0470)
[2025-08-07 18:08:56 train.log] INFO: Epoch: [12]  [Step 5000/14540]  lr: 0.000067  loss: 0.96802  detection_loss: 0.8537 (cls: 0.1964, box: 0.6573)  rpn_loss: 0.1143 (cls: 0.0664, box: 0.0479)
[2025-08-07 18:09:01 train.log] INFO: Epoch: [12]  [Step 5100/14540]  lr: 0.000067  loss: 0.57248  detection_loss: 0.5279 (cls: 0.1737, box: 0.3543)  rpn_loss: 0.0446 (cls: 0.0237, box: 0.0209)
[2025-08-07 18:09:06 train.log] INFO: Epoch: [12]  [Step 5200/14540]  lr: 0.000067  loss: 1.15043  detection_loss: 0.9158 (cls: 0.2376, box: 0.6781)  rpn_loss: 0.2347 (cls: 0.0450, box: 0.1896)
[2025-08-07 18:09:11 train.log] INFO: Epoch: [12]  [Step 5300/14540]  lr: 0.000067  loss: 0.79591  detection_loss: 0.7123 (cls: 0.1713, box: 0.5410)  rpn_loss: 0.0836 (cls: 0.0357, box: 0.0479)
[2025-08-07 18:09:15 train.log] INFO: Epoch: [12]  [Step 5400/14540]  lr: 0.000067  loss: 1.20963  detection_loss: 1.1261 (cls: 0.2614, box: 0.8647)  rpn_loss: 0.0835 (cls: 0.0554, box: 0.0282)
[2025-08-07 18:09:20 train.log] INFO: Epoch: [12]  [Step 5500/14540]  lr: 0.000067  loss: 1.67967  detection_loss: 1.5264 (cls: 0.4115, box: 1.1149)  rpn_loss: 0.1533 (cls: 0.1142, box: 0.0390)
[2025-08-07 18:09:25 train.log] INFO: Epoch: [12]  [Step 5600/14540]  lr: 0.000067  loss: 1.35563  detection_loss: 1.2536 (cls: 0.3987, box: 0.8549)  rpn_loss: 0.1021 (cls: 0.0468, box: 0.0553)
[2025-08-07 18:09:30 train.log] INFO: Epoch: [12]  [Step 5700/14540]  lr: 0.000067  loss: 1.56925  detection_loss: 1.3612 (cls: 0.3899, box: 0.9713)  rpn_loss: 0.2080 (cls: 0.1033, box: 0.1047)
[2025-08-07 18:09:35 train.log] INFO: Epoch: [12]  [Step 5800/14540]  lr: 0.000067  loss: 1.17133  detection_loss: 1.0677 (cls: 0.3117, box: 0.7560)  rpn_loss: 0.1036 (cls: 0.0562, box: 0.0474)
[2025-08-07 18:09:40 train.log] INFO: Epoch: [12]  [Step 5900/14540]  lr: 0.000067  loss: 1.26038  detection_loss: 1.0993 (cls: 0.2467, box: 0.8526)  rpn_loss: 0.1611 (cls: 0.0195, box: 0.1416)
[2025-08-07 18:09:45 train.log] INFO: Epoch: [12]  [Step 6000/14540]  lr: 0.000067  loss: 0.70383  detection_loss: 0.5398 (cls: 0.1282, box: 0.4116)  rpn_loss: 0.1640 (cls: 0.0332, box: 0.1307)
[2025-08-07 18:09:50 train.log] INFO: Epoch: [12]  [Step 6100/14540]  lr: 0.000067  loss: 0.79522  detection_loss: 0.7153 (cls: 0.1415, box: 0.5739)  rpn_loss: 0.0799 (cls: 0.0277, box: 0.0522)
[2025-08-07 18:09:55 train.log] INFO: Epoch: [12]  [Step 6200/14540]  lr: 0.000067  loss: 1.01458  detection_loss: 0.9211 (cls: 0.2226, box: 0.6986)  rpn_loss: 0.0935 (cls: 0.0506, box: 0.0428)
[2025-08-07 18:10:00 train.log] INFO: Epoch: [12]  [Step 6300/14540]  lr: 0.000067  loss: 1.27982  detection_loss: 1.2238 (cls: 0.2119, box: 1.0119)  rpn_loss: 0.0560 (cls: 0.0333, box: 0.0227)
[2025-08-07 18:10:05 train.log] INFO: Epoch: [12]  [Step 6400/14540]  lr: 0.000067  loss: 0.51675  detection_loss: 0.4667 (cls: 0.1232, box: 0.3435)  rpn_loss: 0.0501 (cls: 0.0283, box: 0.0217)
[2025-08-07 18:10:10 train.log] INFO: Epoch: [12]  [Step 6500/14540]  lr: 0.000067  loss: 1.46704  detection_loss: 1.3276 (cls: 0.2999, box: 1.0277)  rpn_loss: 0.1395 (cls: 0.0677, box: 0.0717)
[2025-08-07 18:10:15 train.log] INFO: Epoch: [12]  [Step 6600/14540]  lr: 0.000067  loss: 1.49278  detection_loss: 1.3319 (cls: 0.4118, box: 0.9200)  rpn_loss: 0.1609 (cls: 0.0881, box: 0.0728)
[2025-08-07 18:10:20 train.log] INFO: Epoch: [12]  [Step 6700/14540]  lr: 0.000067  loss: 1.07352  detection_loss: 0.8610 (cls: 0.1796, box: 0.6814)  rpn_loss: 0.2126 (cls: 0.1644, box: 0.0482)
[2025-08-07 18:10:25 train.log] INFO: Epoch: [12]  [Step 6800/14540]  lr: 0.000067  loss: 1.42936  detection_loss: 1.2978 (cls: 0.2800, box: 1.0178)  rpn_loss: 0.1316 (cls: 0.0336, box: 0.0979)
[2025-08-07 18:10:30 train.log] INFO: Epoch: [12]  [Step 6900/14540]  lr: 0.000067  loss: 1.23905  detection_loss: 1.1237 (cls: 0.2110, box: 0.9127)  rpn_loss: 0.1153 (cls: 0.0928, box: 0.0226)
[2025-08-07 18:10:35 train.log] INFO: Epoch: [12]  [Step 7000/14540]  lr: 0.000067  loss: 1.71886  detection_loss: 1.5370 (cls: 0.2798, box: 1.2572)  rpn_loss: 0.1819 (cls: 0.1314, box: 0.0505)
[2025-08-07 18:10:40 train.log] INFO: Epoch: [12]  [Step 7100/14540]  lr: 0.000067  loss: 1.04751  detection_loss: 0.9358 (cls: 0.2248, box: 0.7110)  rpn_loss: 0.1117 (cls: 0.0794, box: 0.0323)
[2025-08-07 18:10:45 train.log] INFO: Epoch: [12]  [Step 7200/14540]  lr: 0.000067  loss: 0.53358  detection_loss: 0.4512 (cls: 0.0961, box: 0.3551)  rpn_loss: 0.0824 (cls: 0.0328, box: 0.0496)
[2025-08-07 18:10:50 train.log] INFO: Epoch: [12]  [Step 7300/14540]  lr: 0.000067  loss: 1.15107  detection_loss: 1.0815 (cls: 0.2919, box: 0.7896)  rpn_loss: 0.0696 (cls: 0.0393, box: 0.0303)
[2025-08-07 18:10:55 train.log] INFO: Epoch: [12]  [Step 7400/14540]  lr: 0.000067  loss: 1.60669  detection_loss: 1.4602 (cls: 0.4603, box: 0.9999)  rpn_loss: 0.1465 (cls: 0.0651, box: 0.0814)
[2025-08-07 18:11:01 train.log] INFO: Epoch: [12]  [Step 7500/14540]  lr: 0.000067  loss: 1.18510  detection_loss: 1.1017 (cls: 0.1950, box: 0.9067)  rpn_loss: 0.0834 (cls: 0.0580, box: 0.0254)
[2025-08-07 18:11:06 train.log] INFO: Epoch: [12]  [Step 7600/14540]  lr: 0.000067  loss: 1.26799  detection_loss: 1.1436 (cls: 0.2978, box: 0.8458)  rpn_loss: 0.1244 (cls: 0.0631, box: 0.0613)
[2025-08-07 18:11:11 train.log] INFO: Epoch: [12]  [Step 7700/14540]  lr: 0.000067  loss: 0.67207  detection_loss: 0.6309 (cls: 0.1741, box: 0.4568)  rpn_loss: 0.0411 (cls: 0.0261, box: 0.0150)
[2025-08-07 18:11:16 train.log] INFO: Epoch: [12]  [Step 7800/14540]  lr: 0.000067  loss: 1.40093  detection_loss: 1.0895 (cls: 0.1876, box: 0.9019)  rpn_loss: 0.3114 (cls: 0.0710, box: 0.2404)
[2025-08-07 18:11:21 train.log] INFO: Epoch: [12]  [Step 7900/14540]  lr: 0.000067  loss: 0.98405  detection_loss: 0.9042 (cls: 0.1792, box: 0.7251)  rpn_loss: 0.0798 (cls: 0.0584, box: 0.0215)
[2025-08-07 18:11:26 train.log] INFO: Epoch: [12]  [Step 8000/14540]  lr: 0.000067  loss: 0.88421  detection_loss: 0.7267 (cls: 0.2514, box: 0.4753)  rpn_loss: 0.1575 (cls: 0.0286, box: 0.1289)
[2025-08-07 18:11:31 train.log] INFO: Epoch: [12]  [Step 8100/14540]  lr: 0.000067  loss: 1.68708  detection_loss: 1.5825 (cls: 0.2688, box: 1.3136)  rpn_loss: 0.1046 (cls: 0.0270, box: 0.0776)
[2025-08-07 18:11:36 train.log] INFO: Epoch: [12]  [Step 8200/14540]  lr: 0.000067  loss: 1.15299  detection_loss: 1.0287 (cls: 0.2626, box: 0.7661)  rpn_loss: 0.1243 (cls: 0.0390, box: 0.0853)
[2025-08-07 18:11:41 train.log] INFO: Epoch: [12]  [Step 8300/14540]  lr: 0.000067  loss: 1.25069  detection_loss: 1.1130 (cls: 0.1799, box: 0.9331)  rpn_loss: 0.1377 (cls: 0.0903, box: 0.0474)
[2025-08-07 18:11:46 train.log] INFO: Epoch: [12]  [Step 8400/14540]  lr: 0.000067  loss: 1.68839  detection_loss: 1.6052 (cls: 0.3168, box: 1.2883)  rpn_loss: 0.0832 (cls: 0.0323, box: 0.0509)
[2025-08-07 18:11:51 train.log] INFO: Epoch: [12]  [Step 8500/14540]  lr: 0.000067  loss: 1.38940  detection_loss: 1.2436 (cls: 0.2353, box: 1.0083)  rpn_loss: 0.1458 (cls: 0.0658, box: 0.0799)
[2025-08-07 18:11:56 train.log] INFO: Epoch: [12]  [Step 8600/14540]  lr: 0.000067  loss: 0.94806  detection_loss: 0.8607 (cls: 0.2601, box: 0.6006)  rpn_loss: 0.0873 (cls: 0.0405, box: 0.0468)
[2025-08-07 18:12:01 train.log] INFO: Epoch: [12]  [Step 8700/14540]  lr: 0.000067  loss: 1.28488  detection_loss: 1.1196 (cls: 0.2647, box: 0.8549)  rpn_loss: 0.1652 (cls: 0.0663, box: 0.0990)
[2025-08-07 18:12:06 train.log] INFO: Epoch: [12]  [Step 8800/14540]  lr: 0.000067  loss: 1.03771  detection_loss: 0.8998 (cls: 0.3623, box: 0.5375)  rpn_loss: 0.1379 (cls: 0.1015, box: 0.0364)
[2025-08-07 18:12:11 train.log] INFO: Epoch: [12]  [Step 8900/14540]  lr: 0.000067  loss: 2.08765  detection_loss: 1.8179 (cls: 0.4826, box: 1.3353)  rpn_loss: 0.2698 (cls: 0.2287, box: 0.0411)
[2025-08-07 18:12:16 train.log] INFO: Epoch: [12]  [Step 9000/14540]  lr: 0.000067  loss: 1.24048  detection_loss: 1.1093 (cls: 0.3213, box: 0.7880)  rpn_loss: 0.1312 (cls: 0.0864, box: 0.0447)
[2025-08-07 18:12:21 train.log] INFO: Epoch: [12]  [Step 9100/14540]  lr: 0.000067  loss: 1.31882  detection_loss: 1.1352 (cls: 0.3858, box: 0.7494)  rpn_loss: 0.1836 (cls: 0.1441, box: 0.0395)
[2025-08-07 18:12:26 train.log] INFO: Epoch: [12]  [Step 9200/14540]  lr: 0.000067  loss: 1.84373  detection_loss: 1.7160 (cls: 0.4314, box: 1.2846)  rpn_loss: 0.1277 (cls: 0.0740, box: 0.0538)
[2025-08-07 18:12:31 train.log] INFO: Epoch: [12]  [Step 9300/14540]  lr: 0.000067  loss: 0.93246  detection_loss: 0.8213 (cls: 0.1564, box: 0.6649)  rpn_loss: 0.1111 (cls: 0.0301, box: 0.0810)
[2025-08-07 18:12:36 train.log] INFO: Epoch: [12]  [Step 9400/14540]  lr: 0.000067  loss: 1.50201  detection_loss: 1.4413 (cls: 0.3249, box: 1.1165)  rpn_loss: 0.0607 (cls: 0.0405, box: 0.0202)
[2025-08-07 18:12:41 train.log] INFO: Epoch: [12]  [Step 9500/14540]  lr: 0.000067  loss: 1.26618  detection_loss: 1.1366 (cls: 0.4336, box: 0.7030)  rpn_loss: 0.1296 (cls: 0.0847, box: 0.0449)
[2025-08-07 18:12:46 train.log] INFO: Epoch: [12]  [Step 9600/14540]  lr: 0.000067  loss: 1.13646  detection_loss: 1.0433 (cls: 0.2626, box: 0.7806)  rpn_loss: 0.0932 (cls: 0.0612, box: 0.0320)
[2025-08-07 18:12:50 train.log] INFO: Epoch: [12]  [Step 9700/14540]  lr: 0.000067  loss: 0.81274  detection_loss: 0.6676 (cls: 0.2514, box: 0.4162)  rpn_loss: 0.1451 (cls: 0.0658, box: 0.0793)
[2025-08-07 18:12:55 train.log] INFO: Epoch: [12]  [Step 9800/14540]  lr: 0.000067  loss: 1.57738  detection_loss: 1.2699 (cls: 0.3363, box: 0.9336)  rpn_loss: 0.3075 (cls: 0.1410, box: 0.1665)
[2025-08-07 18:13:00 train.log] INFO: Epoch: [12]  [Step 9900/14540]  lr: 0.000067  loss: 1.35865  detection_loss: 1.2319 (cls: 0.2380, box: 0.9939)  rpn_loss: 0.1267 (cls: 0.0551, box: 0.0716)
[2025-08-07 18:13:05 train.log] INFO: Epoch: [12]  [Step 10000/14540]  lr: 0.000067  loss: 0.77819  detection_loss: 0.7073 (cls: 0.1630, box: 0.5443)  rpn_loss: 0.0709 (cls: 0.0445, box: 0.0264)
[2025-08-07 18:13:10 train.log] INFO: Epoch: [12]  [Step 10100/14540]  lr: 0.000067  loss: 1.23882  detection_loss: 1.1510 (cls: 0.3899, box: 0.7612)  rpn_loss: 0.0878 (cls: 0.0461, box: 0.0417)
[2025-08-07 18:13:15 train.log] INFO: Epoch: [12]  [Step 10200/14540]  lr: 0.000067  loss: 1.26675  detection_loss: 1.1860 (cls: 0.2151, box: 0.9708)  rpn_loss: 0.0808 (cls: 0.0301, box: 0.0507)
[2025-08-07 18:13:20 train.log] INFO: Epoch: [12]  [Step 10300/14540]  lr: 0.000067  loss: 0.81364  detection_loss: 0.7220 (cls: 0.2655, box: 0.4565)  rpn_loss: 0.0916 (cls: 0.0557, box: 0.0359)
[2025-08-07 18:13:25 train.log] INFO: Epoch: [12]  [Step 10400/14540]  lr: 0.000067  loss: 1.02116  detection_loss: 0.8890 (cls: 0.2568, box: 0.6322)  rpn_loss: 0.1322 (cls: 0.1042, box: 0.0280)
[2025-08-07 18:13:30 train.log] INFO: Epoch: [12]  [Step 10500/14540]  lr: 0.000067  loss: 0.94640  detection_loss: 0.8346 (cls: 0.1277, box: 0.7069)  rpn_loss: 0.1118 (cls: 0.0625, box: 0.0493)
[2025-08-07 18:13:35 train.log] INFO: Epoch: [12]  [Step 10600/14540]  lr: 0.000067  loss: 0.87710  detection_loss: 0.7229 (cls: 0.2486, box: 0.4744)  rpn_loss: 0.1542 (cls: 0.1236, box: 0.0305)
[2025-08-07 18:13:40 train.log] INFO: Epoch: [12]  [Step 10700/14540]  lr: 0.000067  loss: 0.96767  detection_loss: 0.9211 (cls: 0.2029, box: 0.7182)  rpn_loss: 0.0466 (cls: 0.0249, box: 0.0217)
[2025-08-07 18:13:44 train.log] INFO: Epoch: [12]  [Step 10800/14540]  lr: 0.000067  loss: 0.67995  detection_loss: 0.5917 (cls: 0.1203, box: 0.4714)  rpn_loss: 0.0883 (cls: 0.0375, box: 0.0508)
[2025-08-07 18:13:49 train.log] INFO: Epoch: [12]  [Step 10900/14540]  lr: 0.000067  loss: 1.03728  detection_loss: 0.9515 (cls: 0.2843, box: 0.6672)  rpn_loss: 0.0857 (cls: 0.0556, box: 0.0301)
[2025-08-07 18:13:54 train.log] INFO: Epoch: [12]  [Step 11000/14540]  lr: 0.000067  loss: 1.73391  detection_loss: 1.3681 (cls: 0.3967, box: 0.9714)  rpn_loss: 0.3658 (cls: 0.1329, box: 0.2329)
[2025-08-07 18:13:59 train.log] INFO: Epoch: [12]  [Step 11100/14540]  lr: 0.000067  loss: 0.87893  detection_loss: 0.8190 (cls: 0.2114, box: 0.6077)  rpn_loss: 0.0599 (cls: 0.0186, box: 0.0413)
[2025-08-07 18:14:04 train.log] INFO: Epoch: [12]  [Step 11200/14540]  lr: 0.000067  loss: 1.08783  detection_loss: 1.0323 (cls: 0.1614, box: 0.8709)  rpn_loss: 0.0555 (cls: 0.0291, box: 0.0264)
[2025-08-07 18:14:09 train.log] INFO: Epoch: [12]  [Step 11300/14540]  lr: 0.000067  loss: 0.91191  detection_loss: 0.8544 (cls: 0.2177, box: 0.6367)  rpn_loss: 0.0575 (cls: 0.0356, box: 0.0220)
[2025-08-07 18:14:14 train.log] INFO: Epoch: [12]  [Step 11400/14540]  lr: 0.000067  loss: 1.16243  detection_loss: 1.0907 (cls: 0.3023, box: 0.7884)  rpn_loss: 0.0718 (cls: 0.0443, box: 0.0274)
[2025-08-07 18:14:19 train.log] INFO: Epoch: [12]  [Step 11500/14540]  lr: 0.000067  loss: 0.84085  detection_loss: 0.7200 (cls: 0.1800, box: 0.5400)  rpn_loss: 0.1208 (cls: 0.0711, box: 0.0497)
[2025-08-07 18:14:24 train.log] INFO: Epoch: [12]  [Step 11600/14540]  lr: 0.000067  loss: 0.87627  detection_loss: 0.8046 (cls: 0.1746, box: 0.6300)  rpn_loss: 0.0717 (cls: 0.0516, box: 0.0201)
[2025-08-07 18:14:29 train.log] INFO: Epoch: [12]  [Step 11700/14540]  lr: 0.000067  loss: 1.51661  detection_loss: 1.3748 (cls: 0.2991, box: 1.0756)  rpn_loss: 0.1419 (cls: 0.0642, box: 0.0776)
[2025-08-07 18:14:34 train.log] INFO: Epoch: [12]  [Step 11800/14540]  lr: 0.000067  loss: 0.85116  detection_loss: 0.7643 (cls: 0.1790, box: 0.5853)  rpn_loss: 0.0869 (cls: 0.0413, box: 0.0455)
[2025-08-07 18:14:39 train.log] INFO: Epoch: [12]  [Step 11900/14540]  lr: 0.000067  loss: 0.83227  detection_loss: 0.7364 (cls: 0.1585, box: 0.5779)  rpn_loss: 0.0959 (cls: 0.0420, box: 0.0539)
[2025-08-07 18:14:44 train.log] INFO: Epoch: [12]  [Step 12000/14540]  lr: 0.000067  loss: 0.60227  detection_loss: 0.5682 (cls: 0.1100, box: 0.4582)  rpn_loss: 0.0341 (cls: 0.0204, box: 0.0136)
[2025-08-07 18:14:49 train.log] INFO: Epoch: [12]  [Step 12100/14540]  lr: 0.000067  loss: 1.20195  detection_loss: 1.1008 (cls: 0.2561, box: 0.8446)  rpn_loss: 0.1012 (cls: 0.0484, box: 0.0528)
[2025-08-07 18:14:54 train.log] INFO: Epoch: [12]  [Step 12200/14540]  lr: 0.000067  loss: 1.95285  detection_loss: 1.8234 (cls: 0.5195, box: 1.3038)  rpn_loss: 0.1295 (cls: 0.0623, box: 0.0671)
[2025-08-07 18:14:59 train.log] INFO: Epoch: [12]  [Step 12300/14540]  lr: 0.000067  loss: 1.03119  detection_loss: 0.9287 (cls: 0.1927, box: 0.7360)  rpn_loss: 0.1025 (cls: 0.0732, box: 0.0294)
[2025-08-07 18:15:04 train.log] INFO: Epoch: [12]  [Step 12400/14540]  lr: 0.000067  loss: 0.83312  detection_loss: 0.6906 (cls: 0.1617, box: 0.5289)  rpn_loss: 0.1425 (cls: 0.1183, box: 0.0242)
[2025-08-07 18:15:09 train.log] INFO: Epoch: [12]  [Step 12500/14540]  lr: 0.000067  loss: 1.28531  detection_loss: 1.0860 (cls: 0.2411, box: 0.8449)  rpn_loss: 0.1993 (cls: 0.1151, box: 0.0842)
[2025-08-07 18:15:14 train.log] INFO: Epoch: [12]  [Step 12600/14540]  lr: 0.000067  loss: 1.16110  detection_loss: 1.0485 (cls: 0.1491, box: 0.8994)  rpn_loss: 0.1126 (cls: 0.0715, box: 0.0412)
[2025-08-07 18:15:19 train.log] INFO: Epoch: [12]  [Step 12700/14540]  lr: 0.000067  loss: 2.30554  detection_loss: 2.1653 (cls: 0.3560, box: 1.8093)  rpn_loss: 0.1403 (cls: 0.0845, box: 0.0558)
[2025-08-07 18:15:24 train.log] INFO: Epoch: [12]  [Step 12800/14540]  lr: 0.000067  loss: 1.08049  detection_loss: 0.9753 (cls: 0.2863, box: 0.6890)  rpn_loss: 0.1052 (cls: 0.0655, box: 0.0397)
[2025-08-07 18:15:30 train.log] INFO: Epoch: [12]  [Step 12900/14540]  lr: 0.000067  loss: 0.67368  detection_loss: 0.5983 (cls: 0.1116, box: 0.4868)  rpn_loss: 0.0754 (cls: 0.0408, box: 0.0346)
[2025-08-07 18:15:35 train.log] INFO: Epoch: [12]  [Step 13000/14540]  lr: 0.000067  loss: 1.39561  detection_loss: 1.2599 (cls: 0.2647, box: 0.9952)  rpn_loss: 0.1357 (cls: 0.0287, box: 0.1070)
[2025-08-07 18:15:40 train.log] INFO: Epoch: [12]  [Step 13100/14540]  lr: 0.000067  loss: 1.03864  detection_loss: 0.9385 (cls: 0.3903, box: 0.5482)  rpn_loss: 0.1001 (cls: 0.0764, box: 0.0237)
[2025-08-07 18:15:45 train.log] INFO: Epoch: [12]  [Step 13200/14540]  lr: 0.000067  loss: 1.03363  detection_loss: 0.9730 (cls: 0.2409, box: 0.7321)  rpn_loss: 0.0607 (cls: 0.0228, box: 0.0379)
[2025-08-07 18:15:49 train.log] INFO: Epoch: [12]  [Step 13300/14540]  lr: 0.000067  loss: 0.76482  detection_loss: 0.6974 (cls: 0.1880, box: 0.5095)  rpn_loss: 0.0674 (cls: 0.0505, box: 0.0169)
[2025-08-07 18:15:54 train.log] INFO: Epoch: [12]  [Step 13400/14540]  lr: 0.000067  loss: 1.92981  detection_loss: 1.8279 (cls: 0.4526, box: 1.3753)  rpn_loss: 0.1019 (cls: 0.0556, box: 0.0463)
[2025-08-07 18:15:59 train.log] INFO: Epoch: [12]  [Step 13500/14540]  lr: 0.000067  loss: 0.96217  detection_loss: 0.8681 (cls: 0.1729, box: 0.6952)  rpn_loss: 0.0941 (cls: 0.0470, box: 0.0471)
[2025-08-07 18:16:04 train.log] INFO: Epoch: [12]  [Step 13600/14540]  lr: 0.000067  loss: 1.76380  detection_loss: 1.6112 (cls: 0.4501, box: 1.1611)  rpn_loss: 0.1526 (cls: 0.1031, box: 0.0496)
[2025-08-07 18:16:09 train.log] INFO: Epoch: [12]  [Step 13700/14540]  lr: 0.000067  loss: 1.22754  detection_loss: 1.1005 (cls: 0.1851, box: 0.9154)  rpn_loss: 0.1270 (cls: 0.0321, box: 0.0950)
[2025-08-07 18:16:14 train.log] INFO: Epoch: [12]  [Step 13800/14540]  lr: 0.000067  loss: 1.70624  detection_loss: 1.5525 (cls: 0.2241, box: 1.3285)  rpn_loss: 0.1537 (cls: 0.0609, box: 0.0928)
[2025-08-07 18:16:19 train.log] INFO: Epoch: [12]  [Step 13900/14540]  lr: 0.000067  loss: 1.58214  detection_loss: 1.3237 (cls: 0.3024, box: 1.0213)  rpn_loss: 0.2585 (cls: 0.0792, box: 0.1792)
[2025-08-07 18:16:24 train.log] INFO: Epoch: [12]  [Step 14000/14540]  lr: 0.000067  loss: 0.61626  detection_loss: 0.5296 (cls: 0.1087, box: 0.4208)  rpn_loss: 0.0867 (cls: 0.0505, box: 0.0362)
[2025-08-07 18:16:29 train.log] INFO: Epoch: [12]  [Step 14100/14540]  lr: 0.000067  loss: 0.70428  detection_loss: 0.6351 (cls: 0.1041, box: 0.5311)  rpn_loss: 0.0691 (cls: 0.0227, box: 0.0465)
[2025-08-07 18:16:34 train.log] INFO: Epoch: [12]  [Step 14200/14540]  lr: 0.000067  loss: 0.86915  detection_loss: 0.7588 (cls: 0.2390, box: 0.5198)  rpn_loss: 0.1104 (cls: 0.0568, box: 0.0536)
[2025-08-07 18:16:39 train.log] INFO: Epoch: [12]  [Step 14300/14540]  lr: 0.000067  loss: 0.93217  detection_loss: 0.8313 (cls: 0.2242, box: 0.6071)  rpn_loss: 0.1009 (cls: 0.0617, box: 0.0392)
[2025-08-07 18:16:44 train.log] INFO: Epoch: [12]  [Step 14400/14540]  lr: 0.000067  loss: 1.31361  detection_loss: 1.1541 (cls: 0.2077, box: 0.9464)  rpn_loss: 0.1595 (cls: 0.0445, box: 0.1150)
[2025-08-07 18:16:49 train.log] INFO: Epoch: [12]  [Step 14500/14540]  lr: 0.000067  loss: 1.49771  detection_loss: 1.2153 (cls: 0.3549, box: 0.8604)  rpn_loss: 0.2824 (cls: 0.0481, box: 0.2343)
[2025-08-07 18:19:55 train.log] INFO: Epoch: [13]  [Step 100/14540]  lr: 0.000062  loss: 1.30193  detection_loss: 1.2024 (cls: 0.2417, box: 0.9607)  rpn_loss: 0.0995 (cls: 0.0710, box: 0.0286)
[2025-08-07 18:20:00 train.log] INFO: Epoch: [13]  [Step 200/14540]  lr: 0.000062  loss: 0.90962  detection_loss: 0.7544 (cls: 0.1703, box: 0.5841)  rpn_loss: 0.1552 (cls: 0.1272, box: 0.0280)
[2025-08-07 18:20:05 train.log] INFO: Epoch: [13]  [Step 300/14540]  lr: 0.000062  loss: 1.46040  detection_loss: 1.3615 (cls: 0.2178, box: 1.1437)  rpn_loss: 0.0989 (cls: 0.0626, box: 0.0363)
[2025-08-07 18:20:10 train.log] INFO: Epoch: [13]  [Step 400/14540]  lr: 0.000062  loss: 0.94071  detection_loss: 0.7973 (cls: 0.3260, box: 0.4713)  rpn_loss: 0.1435 (cls: 0.0381, box: 0.1053)
[2025-08-07 18:20:15 train.log] INFO: Epoch: [13]  [Step 500/14540]  lr: 0.000062  loss: 0.76409  detection_loss: 0.7159 (cls: 0.2489, box: 0.4670)  rpn_loss: 0.0481 (cls: 0.0238, box: 0.0244)
[2025-08-07 18:20:20 train.log] INFO: Epoch: [13]  [Step 600/14540]  lr: 0.000062  loss: 1.13107  detection_loss: 1.0558 (cls: 0.3200, box: 0.7358)  rpn_loss: 0.0753 (cls: 0.0355, box: 0.0398)
[2025-08-07 18:20:25 train.log] INFO: Epoch: [13]  [Step 700/14540]  lr: 0.000062  loss: 0.81935  detection_loss: 0.7724 (cls: 0.3222, box: 0.4501)  rpn_loss: 0.0470 (cls: 0.0361, box: 0.0109)
[2025-08-07 18:20:30 train.log] INFO: Epoch: [13]  [Step 800/14540]  lr: 0.000062  loss: 1.73401  detection_loss: 1.5414 (cls: 0.4819, box: 1.0595)  rpn_loss: 0.1926 (cls: 0.1517, box: 0.0409)
[2025-08-07 18:20:35 train.log] INFO: Epoch: [13]  [Step 900/14540]  lr: 0.000062  loss: 0.68518  detection_loss: 0.5849 (cls: 0.2040, box: 0.3809)  rpn_loss: 0.1003 (cls: 0.0777, box: 0.0226)
[2025-08-07 18:20:40 train.log] INFO: Epoch: [13]  [Step 1000/14540]  lr: 0.000062  loss: 1.25889  detection_loss: 1.1503 (cls: 0.2378, box: 0.9125)  rpn_loss: 0.1086 (cls: 0.0772, box: 0.0314)
[2025-08-07 18:20:45 train.log] INFO: Epoch: [13]  [Step 1100/14540]  lr: 0.000062  loss: 1.45948  detection_loss: 1.3417 (cls: 0.2811, box: 1.0606)  rpn_loss: 0.1177 (cls: 0.0730, box: 0.0447)
[2025-08-07 18:20:50 train.log] INFO: Epoch: [13]  [Step 1200/14540]  lr: 0.000062  loss: 1.23811  detection_loss: 1.1421 (cls: 0.2279, box: 0.9143)  rpn_loss: 0.0960 (cls: 0.0570, box: 0.0390)
[2025-08-07 18:20:55 train.log] INFO: Epoch: [13]  [Step 1300/14540]  lr: 0.000062  loss: 1.27734  detection_loss: 1.1538 (cls: 0.2803, box: 0.8735)  rpn_loss: 0.1236 (cls: 0.0714, box: 0.0521)
[2025-08-07 18:21:00 train.log] INFO: Epoch: [13]  [Step 1400/14540]  lr: 0.000062  loss: 1.41914  detection_loss: 1.2948 (cls: 0.3218, box: 0.9730)  rpn_loss: 0.1244 (cls: 0.0721, box: 0.0522)
[2025-08-07 18:21:05 train.log] INFO: Epoch: [13]  [Step 1500/14540]  lr: 0.000062  loss: 0.93371  detection_loss: 0.8302 (cls: 0.3220, box: 0.5082)  rpn_loss: 0.1035 (cls: 0.0670, box: 0.0365)
[2025-08-07 18:21:10 train.log] INFO: Epoch: [13]  [Step 1600/14540]  lr: 0.000062  loss: 1.32199  detection_loss: 1.1919 (cls: 0.3064, box: 0.8855)  rpn_loss: 0.1301 (cls: 0.0708, box: 0.0593)
[2025-08-07 18:21:15 train.log] INFO: Epoch: [13]  [Step 1700/14540]  lr: 0.000062  loss: 0.67526  detection_loss: 0.6131 (cls: 0.1380, box: 0.4751)  rpn_loss: 0.0622 (cls: 0.0203, box: 0.0419)
[2025-08-07 18:21:19 train.log] INFO: Epoch: [13]  [Step 1800/14540]  lr: 0.000062  loss: 1.19266  detection_loss: 1.1251 (cls: 0.3628, box: 0.7623)  rpn_loss: 0.0676 (cls: 0.0459, box: 0.0217)
[2025-08-07 18:21:24 train.log] INFO: Epoch: [13]  [Step 1900/14540]  lr: 0.000062  loss: 1.23295  detection_loss: 1.1651 (cls: 0.2201, box: 0.9450)  rpn_loss: 0.0679 (cls: 0.0413, box: 0.0266)
[2025-08-07 18:21:29 train.log] INFO: Epoch: [13]  [Step 2000/14540]  lr: 0.000062  loss: 1.00754  detection_loss: 0.9593 (cls: 0.1709, box: 0.7884)  rpn_loss: 0.0483 (cls: 0.0328, box: 0.0154)
[2025-08-07 18:21:34 train.log] INFO: Epoch: [13]  [Step 2100/14540]  lr: 0.000062  loss: 1.10101  detection_loss: 0.9588 (cls: 0.2993, box: 0.6595)  rpn_loss: 0.1422 (cls: 0.0979, box: 0.0443)
[2025-08-07 18:21:39 train.log] INFO: Epoch: [13]  [Step 2200/14540]  lr: 0.000062  loss: 1.26448  detection_loss: 1.1686 (cls: 0.1715, box: 0.9972)  rpn_loss: 0.0959 (cls: 0.0178, box: 0.0781)
[2025-08-07 18:21:44 train.log] INFO: Epoch: [13]  [Step 2300/14540]  lr: 0.000062  loss: 1.20437  detection_loss: 1.0081 (cls: 0.3284, box: 0.6797)  rpn_loss: 0.1963 (cls: 0.0535, box: 0.1427)
[2025-08-07 18:21:49 train.log] INFO: Epoch: [13]  [Step 2400/14540]  lr: 0.000062  loss: 1.59957  detection_loss: 1.4461 (cls: 0.3406, box: 1.1055)  rpn_loss: 0.1535 (cls: 0.0820, box: 0.0714)
[2025-08-07 18:21:54 train.log] INFO: Epoch: [13]  [Step 2500/14540]  lr: 0.000062  loss: 0.98060  detection_loss: 0.6925 (cls: 0.3174, box: 0.3751)  rpn_loss: 0.2881 (cls: 0.0265, box: 0.2617)
[2025-08-07 18:21:59 train.log] INFO: Epoch: [13]  [Step 2600/14540]  lr: 0.000062  loss: 0.71597  detection_loss: 0.6707 (cls: 0.1238, box: 0.5469)  rpn_loss: 0.0452 (cls: 0.0292, box: 0.0161)
[2025-08-07 18:22:04 train.log] INFO: Epoch: [13]  [Step 2700/14540]  lr: 0.000062  loss: 1.10197  detection_loss: 1.0167 (cls: 0.3289, box: 0.6878)  rpn_loss: 0.0853 (cls: 0.0491, box: 0.0361)
[2025-08-07 18:22:08 train.log] INFO: Epoch: [13]  [Step 2800/14540]  lr: 0.000062  loss: 1.81207  detection_loss: 1.6442 (cls: 0.2830, box: 1.3612)  rpn_loss: 0.1678 (cls: 0.0429, box: 0.1250)
[2025-08-07 18:22:13 train.log] INFO: Epoch: [13]  [Step 2900/14540]  lr: 0.000062  loss: 0.90557  detection_loss: 0.8070 (cls: 0.2169, box: 0.5900)  rpn_loss: 0.0986 (cls: 0.0468, box: 0.0518)
[2025-08-07 18:22:18 train.log] INFO: Epoch: [13]  [Step 3000/14540]  lr: 0.000062  loss: 1.09152  detection_loss: 0.9593 (cls: 0.2305, box: 0.7288)  rpn_loss: 0.1322 (cls: 0.0975, box: 0.0347)
[2025-08-07 18:22:23 train.log] INFO: Epoch: [13]  [Step 3100/14540]  lr: 0.000062  loss: 1.30345  detection_loss: 1.0949 (cls: 0.2236, box: 0.8713)  rpn_loss: 0.2086 (cls: 0.0212, box: 0.1874)
[2025-08-07 18:22:28 train.log] INFO: Epoch: [13]  [Step 3200/14540]  lr: 0.000062  loss: 1.36397  detection_loss: 1.1868 (cls: 0.2954, box: 0.8914)  rpn_loss: 0.1772 (cls: 0.0485, box: 0.1287)
[2025-08-07 18:22:33 train.log] INFO: Epoch: [13]  [Step 3300/14540]  lr: 0.000062  loss: 1.11047  detection_loss: 1.0554 (cls: 0.1368, box: 0.9185)  rpn_loss: 0.0551 (cls: 0.0145, box: 0.0406)
[2025-08-07 18:22:38 train.log] INFO: Epoch: [13]  [Step 3400/14540]  lr: 0.000062  loss: 0.94648  detection_loss: 0.7268 (cls: 0.2314, box: 0.4954)  rpn_loss: 0.2197 (cls: 0.0291, box: 0.1906)
[2025-08-07 18:22:43 train.log] INFO: Epoch: [13]  [Step 3500/14540]  lr: 0.000062  loss: 1.09239  detection_loss: 0.9493 (cls: 0.1939, box: 0.7555)  rpn_loss: 0.1431 (cls: 0.1167, box: 0.0263)
[2025-08-07 18:22:48 train.log] INFO: Epoch: [13]  [Step 3600/14540]  lr: 0.000062  loss: 1.37066  detection_loss: 1.2009 (cls: 0.2985, box: 0.9024)  rpn_loss: 0.1698 (cls: 0.1454, box: 0.0244)
[2025-08-07 18:22:49 train.log] INFO: Epoch: [13]  [Step 3635/14540]  lr: 0.000062  loss: 1.21803  detection_loss: 1.1254 (cls: 0.3403, box: 0.7851)  rpn_loss: 0.0926 (cls: 0.0361, box: 0.0565)
[2025-08-07 18:22:52 train.log] INFO: Epoch: [13]  [Step 3700/14540]  lr: 0.000062  loss: 1.04660  detection_loss: 0.9674 (cls: 0.1481, box: 0.8193)  rpn_loss: 0.0792 (cls: 0.0468, box: 0.0324)
[2025-08-07 18:22:57 train.log] INFO: Epoch: [13]  [Step 3800/14540]  lr: 0.000062  loss: 1.04282  detection_loss: 0.9486 (cls: 0.1260, box: 0.8226)  rpn_loss: 0.0942 (cls: 0.0310, box: 0.0632)
[2025-08-07 18:23:02 train.log] INFO: Epoch: [13]  [Step 3900/14540]  lr: 0.000062  loss: 0.75664  detection_loss: 0.6739 (cls: 0.1524, box: 0.5215)  rpn_loss: 0.0827 (cls: 0.0489, box: 0.0338)
[2025-08-07 18:23:07 train.log] INFO: Epoch: [13]  [Step 4000/14540]  lr: 0.000062  loss: 0.80029  detection_loss: 0.6762 (cls: 0.2024, box: 0.4738)  rpn_loss: 0.1240 (cls: 0.0956, box: 0.0285)
[2025-08-07 18:23:12 train.log] INFO: Epoch: [13]  [Step 4100/14540]  lr: 0.000062  loss: 1.21035  detection_loss: 1.1213 (cls: 0.1837, box: 0.9376)  rpn_loss: 0.0890 (cls: 0.0362, box: 0.0528)
[2025-08-07 18:23:17 train.log] INFO: Epoch: [13]  [Step 4200/14540]  lr: 0.000062  loss: 0.77548  detection_loss: 0.7001 (cls: 0.1375, box: 0.5626)  rpn_loss: 0.0753 (cls: 0.0580, box: 0.0173)
[2025-08-07 18:23:22 train.log] INFO: Epoch: [13]  [Step 4300/14540]  lr: 0.000062  loss: 0.97479  detection_loss: 0.8442 (cls: 0.2216, box: 0.6225)  rpn_loss: 0.1306 (cls: 0.0682, box: 0.0624)
[2025-08-07 18:23:27 train.log] INFO: Epoch: [13]  [Step 4400/14540]  lr: 0.000062  loss: 1.18966  detection_loss: 1.0172 (cls: 0.2287, box: 0.7886)  rpn_loss: 0.1724 (cls: 0.1419, box: 0.0306)
[2025-08-07 18:23:32 train.log] INFO: Epoch: [13]  [Step 4500/14540]  lr: 0.000062  loss: 0.73061  detection_loss: 0.6703 (cls: 0.1410, box: 0.5293)  rpn_loss: 0.0603 (cls: 0.0349, box: 0.0255)
[2025-08-07 18:23:36 train.log] INFO: Epoch: [13]  [Step 4600/14540]  lr: 0.000062  loss: 2.03703  detection_loss: 1.8312 (cls: 0.4405, box: 1.3907)  rpn_loss: 0.2059 (cls: 0.1009, box: 0.1050)
[2025-08-07 18:23:41 train.log] INFO: Epoch: [13]  [Step 4700/14540]  lr: 0.000062  loss: 2.04760  detection_loss: 1.8697 (cls: 0.3949, box: 1.4747)  rpn_loss: 0.1780 (cls: 0.1235, box: 0.0545)
[2025-08-07 18:23:46 train.log] INFO: Epoch: [13]  [Step 4800/14540]  lr: 0.000062  loss: 1.58639  detection_loss: 1.3595 (cls: 0.4428, box: 0.9168)  rpn_loss: 0.2268 (cls: 0.1943, box: 0.0325)
[2025-08-07 18:23:51 train.log] INFO: Epoch: [13]  [Step 4900/14540]  lr: 0.000062  loss: 0.82757  detection_loss: 0.7740 (cls: 0.1870, box: 0.5870)  rpn_loss: 0.0536 (cls: 0.0284, box: 0.0252)
[2025-08-07 18:23:56 train.log] INFO: Epoch: [13]  [Step 5000/14540]  lr: 0.000062  loss: 0.76617  detection_loss: 0.6809 (cls: 0.1842, box: 0.4967)  rpn_loss: 0.0853 (cls: 0.0392, box: 0.0461)
[2025-08-07 18:24:01 train.log] INFO: Epoch: [13]  [Step 5100/14540]  lr: 0.000062  loss: 0.80465  detection_loss: 0.6859 (cls: 0.1126, box: 0.5732)  rpn_loss: 0.1188 (cls: 0.0818, box: 0.0370)
[2025-08-07 18:24:06 train.log] INFO: Epoch: [13]  [Step 5200/14540]  lr: 0.000062  loss: 1.28745  detection_loss: 1.1113 (cls: 0.4107, box: 0.7007)  rpn_loss: 0.1761 (cls: 0.0630, box: 0.1131)
[2025-08-07 18:24:11 train.log] INFO: Epoch: [13]  [Step 5300/14540]  lr: 0.000062  loss: 1.07802  detection_loss: 0.8674 (cls: 0.1834, box: 0.6841)  rpn_loss: 0.2106 (cls: 0.1556, box: 0.0550)
[2025-08-07 18:24:16 train.log] INFO: Epoch: [13]  [Step 5400/14540]  lr: 0.000062  loss: 0.77331  detection_loss: 0.5511 (cls: 0.1360, box: 0.4152)  rpn_loss: 0.2222 (cls: 0.0852, box: 0.1369)
[2025-08-07 18:24:21 train.log] INFO: Epoch: [13]  [Step 5500/14540]  lr: 0.000062  loss: 1.13705  detection_loss: 1.0737 (cls: 0.1885, box: 0.8853)  rpn_loss: 0.0633 (cls: 0.0345, box: 0.0288)
[2025-08-07 18:24:26 train.log] INFO: Epoch: [13]  [Step 5600/14540]  lr: 0.000062  loss: 0.65018  detection_loss: 0.6049 (cls: 0.0625, box: 0.5424)  rpn_loss: 0.0453 (cls: 0.0083, box: 0.0370)
[2025-08-07 18:24:31 train.log] INFO: Epoch: [13]  [Step 5700/14540]  lr: 0.000062  loss: 1.65391  detection_loss: 1.5414 (cls: 0.3288, box: 1.2126)  rpn_loss: 0.1125 (cls: 0.0355, box: 0.0770)
[2025-08-07 18:24:37 train.log] INFO: Epoch: [13]  [Step 5800/14540]  lr: 0.000062  loss: 1.50607  detection_loss: 1.4192 (cls: 0.3291, box: 1.0901)  rpn_loss: 0.0868 (cls: 0.0429, box: 0.0440)
[2025-08-07 18:24:42 train.log] INFO: Epoch: [13]  [Step 5900/14540]  lr: 0.000062  loss: 1.31864  detection_loss: 1.1748 (cls: 0.3019, box: 0.8729)  rpn_loss: 0.1439 (cls: 0.0721, box: 0.0718)
[2025-08-07 18:24:47 train.log] INFO: Epoch: [13]  [Step 6000/14540]  lr: 0.000062  loss: 0.90973  detection_loss: 0.7701 (cls: 0.1498, box: 0.6203)  rpn_loss: 0.1396 (cls: 0.0303, box: 0.1094)
[2025-08-07 18:24:53 train.log] INFO: Epoch: [13]  [Step 6100/14540]  lr: 0.000062  loss: 1.38327  detection_loss: 1.2948 (cls: 0.3602, box: 0.9346)  rpn_loss: 0.0885 (cls: 0.0468, box: 0.0417)
[2025-08-07 18:24:59 train.log] INFO: Epoch: [13]  [Step 6200/14540]  lr: 0.000062  loss: 1.17462  detection_loss: 1.0447 (cls: 0.1855, box: 0.8592)  rpn_loss: 0.1299 (cls: 0.1105, box: 0.0194)
[2025-08-07 18:25:04 train.log] INFO: Epoch: [13]  [Step 6300/14540]  lr: 0.000062  loss: 1.04712  detection_loss: 0.9138 (cls: 0.2435, box: 0.6703)  rpn_loss: 0.1333 (cls: 0.0834, box: 0.0499)
[2025-08-07 18:25:09 train.log] INFO: Epoch: [13]  [Step 6400/14540]  lr: 0.000062  loss: 1.09634  detection_loss: 0.9622 (cls: 0.2633, box: 0.6989)  rpn_loss: 0.1342 (cls: 0.0896, box: 0.0446)
[2025-08-07 18:25:14 train.log] INFO: Epoch: [13]  [Step 6500/14540]  lr: 0.000062  loss: 0.90830  detection_loss: 0.7899 (cls: 0.1643, box: 0.6256)  rpn_loss: 0.1184 (cls: 0.0387, box: 0.0798)
[2025-08-07 18:25:19 train.log] INFO: Epoch: [13]  [Step 6600/14540]  lr: 0.000062  loss: 0.97495  detection_loss: 0.8914 (cls: 0.2784, box: 0.6130)  rpn_loss: 0.0835 (cls: 0.0590, box: 0.0245)
[2025-08-07 18:25:24 train.log] INFO: Epoch: [13]  [Step 6700/14540]  lr: 0.000062  loss: 1.20985  detection_loss: 1.0647 (cls: 0.2408, box: 0.8239)  rpn_loss: 0.1452 (cls: 0.1187, box: 0.0265)
[2025-08-07 18:25:30 train.log] INFO: Epoch: [13]  [Step 6800/14540]  lr: 0.000062  loss: 1.22192  detection_loss: 1.1051 (cls: 0.3073, box: 0.7978)  rpn_loss: 0.1168 (cls: 0.0660, box: 0.0508)
[2025-08-07 18:25:35 train.log] INFO: Epoch: [13]  [Step 6900/14540]  lr: 0.000062  loss: 0.97039  detection_loss: 0.7929 (cls: 0.2005, box: 0.5924)  rpn_loss: 0.1775 (cls: 0.0447, box: 0.1328)
[2025-08-07 18:25:40 train.log] INFO: Epoch: [13]  [Step 7000/14540]  lr: 0.000062  loss: 1.87768  detection_loss: 1.6189 (cls: 0.3912, box: 1.2278)  rpn_loss: 0.2587 (cls: 0.1438, box: 0.1150)
[2025-08-07 18:25:46 train.log] INFO: Epoch: [13]  [Step 7100/14540]  lr: 0.000062  loss: 1.14786  detection_loss: 1.0958 (cls: 0.2267, box: 0.8691)  rpn_loss: 0.0521 (cls: 0.0256, box: 0.0264)
[2025-08-07 18:25:51 train.log] INFO: Epoch: [13]  [Step 7200/14540]  lr: 0.000062  loss: 1.28556  detection_loss: 1.1719 (cls: 0.4699, box: 0.7020)  rpn_loss: 0.1137 (cls: 0.0851, box: 0.0286)
[2025-08-07 18:25:56 train.log] INFO: Epoch: [13]  [Step 7300/14540]  lr: 0.000062  loss: 1.25217  detection_loss: 1.1309 (cls: 0.2888, box: 0.8421)  rpn_loss: 0.1213 (cls: 0.0839, box: 0.0374)
[2025-08-07 18:26:01 train.log] INFO: Epoch: [13]  [Step 7400/14540]  lr: 0.000062  loss: 0.87449  detection_loss: 0.8265 (cls: 0.0989, box: 0.7275)  rpn_loss: 0.0480 (cls: 0.0333, box: 0.0147)
[2025-08-07 18:26:06 train.log] INFO: Epoch: [13]  [Step 7500/14540]  lr: 0.000062  loss: 0.92823  detection_loss: 0.8464 (cls: 0.1486, box: 0.6978)  rpn_loss: 0.0818 (cls: 0.0542, box: 0.0277)
[2025-08-07 18:26:12 train.log] INFO: Epoch: [13]  [Step 7600/14540]  lr: 0.000062  loss: 1.00181  detection_loss: 0.9102 (cls: 0.1570, box: 0.7532)  rpn_loss: 0.0916 (cls: 0.0270, box: 0.0646)
[2025-08-07 18:26:17 train.log] INFO: Epoch: [13]  [Step 7700/14540]  lr: 0.000062  loss: 1.20829  detection_loss: 1.1077 (cls: 0.3323, box: 0.7754)  rpn_loss: 0.1006 (cls: 0.0585, box: 0.0422)
[2025-08-07 18:26:22 train.log] INFO: Epoch: [13]  [Step 7800/14540]  lr: 0.000062  loss: 1.26581  detection_loss: 1.0980 (cls: 0.2221, box: 0.8759)  rpn_loss: 0.1678 (cls: 0.0538, box: 0.1140)
[2025-08-07 18:26:27 train.log] INFO: Epoch: [13]  [Step 7900/14540]  lr: 0.000062  loss: 1.25341  detection_loss: 1.1719 (cls: 0.2137, box: 0.9581)  rpn_loss: 0.0815 (cls: 0.0383, box: 0.0432)
[2025-08-07 18:26:32 train.log] INFO: Epoch: [13]  [Step 8000/14540]  lr: 0.000062  loss: 1.07478  detection_loss: 0.9970 (cls: 0.2218, box: 0.7752)  rpn_loss: 0.0778 (cls: 0.0594, box: 0.0184)
[2025-08-07 18:26:37 train.log] INFO: Epoch: [13]  [Step 8100/14540]  lr: 0.000062  loss: 1.48898  detection_loss: 1.3274 (cls: 0.5182, box: 0.8092)  rpn_loss: 0.1616 (cls: 0.0519, box: 0.1097)
[2025-08-07 18:26:42 train.log] INFO: Epoch: [13]  [Step 8200/14540]  lr: 0.000062  loss: 1.41694  detection_loss: 1.2850 (cls: 0.3408, box: 0.9441)  rpn_loss: 0.1320 (cls: 0.0662, box: 0.0658)
[2025-08-07 18:26:47 train.log] INFO: Epoch: [13]  [Step 8300/14540]  lr: 0.000062  loss: 1.40054  detection_loss: 1.3094 (cls: 0.2740, box: 1.0354)  rpn_loss: 0.0911 (cls: 0.0577, box: 0.0334)
[2025-08-07 18:26:51 train.log] INFO: Epoch: [13]  [Step 8400/14540]  lr: 0.000062  loss: 0.94327  detection_loss: 0.8621 (cls: 0.1877, box: 0.6744)  rpn_loss: 0.0812 (cls: 0.0591, box: 0.0221)
[2025-08-07 18:26:56 train.log] INFO: Epoch: [13]  [Step 8500/14540]  lr: 0.000062  loss: 0.86063  detection_loss: 0.7736 (cls: 0.1969, box: 0.5767)  rpn_loss: 0.0870 (cls: 0.0738, box: 0.0132)
[2025-08-07 18:27:01 train.log] INFO: Epoch: [13]  [Step 8600/14540]  lr: 0.000062  loss: 1.35455  detection_loss: 1.2163 (cls: 0.2026, box: 1.0137)  rpn_loss: 0.1383 (cls: 0.1010, box: 0.0373)
[2025-08-07 18:27:06 train.log] INFO: Epoch: [13]  [Step 8700/14540]  lr: 0.000062  loss: 0.80740  detection_loss: 0.7106 (cls: 0.1754, box: 0.5352)  rpn_loss: 0.0968 (cls: 0.0153, box: 0.0816)
[2025-08-07 18:27:11 train.log] INFO: Epoch: [13]  [Step 8800/14540]  lr: 0.000062  loss: 1.19406  detection_loss: 1.0186 (cls: 0.2283, box: 0.7903)  rpn_loss: 0.1754 (cls: 0.0225, box: 0.1529)
[2025-08-07 18:27:16 train.log] INFO: Epoch: [13]  [Step 8900/14540]  lr: 0.000062  loss: 1.27827  detection_loss: 1.2117 (cls: 0.3261, box: 0.8856)  rpn_loss: 0.0665 (cls: 0.0363, box: 0.0302)
[2025-08-07 18:27:21 train.log] INFO: Epoch: [13]  [Step 9000/14540]  lr: 0.000062  loss: 1.14701  detection_loss: 1.0229 (cls: 0.2742, box: 0.7487)  rpn_loss: 0.1242 (cls: 0.0521, box: 0.0721)
[2025-08-07 18:27:26 train.log] INFO: Epoch: [13]  [Step 9100/14540]  lr: 0.000062  loss: 1.58589  detection_loss: 1.3773 (cls: 0.3416, box: 1.0356)  rpn_loss: 0.2086 (cls: 0.0805, box: 0.1281)
[2025-08-07 18:27:31 train.log] INFO: Epoch: [13]  [Step 9200/14540]  lr: 0.000062  loss: 0.99418  detection_loss: 0.9134 (cls: 0.2476, box: 0.6658)  rpn_loss: 0.0808 (cls: 0.0249, box: 0.0559)
[2025-08-07 18:27:36 train.log] INFO: Epoch: [13]  [Step 9300/14540]  lr: 0.000062  loss: 1.18956  detection_loss: 1.0466 (cls: 0.2682, box: 0.7784)  rpn_loss: 0.1430 (cls: 0.0167, box: 0.1262)
[2025-08-07 18:27:40 train.log] INFO: Epoch: [13]  [Step 9400/14540]  lr: 0.000062  loss: 1.05622  detection_loss: 0.9696 (cls: 0.2676, box: 0.7020)  rpn_loss: 0.0866 (cls: 0.0359, box: 0.0507)
[2025-08-07 18:27:45 train.log] INFO: Epoch: [13]  [Step 9500/14540]  lr: 0.000062  loss: 1.15580  detection_loss: 1.0520 (cls: 0.2110, box: 0.8410)  rpn_loss: 0.1038 (cls: 0.0720, box: 0.0318)
[2025-08-07 18:27:50 train.log] INFO: Epoch: [13]  [Step 9600/14540]  lr: 0.000062  loss: 0.93238  detection_loss: 0.8398 (cls: 0.2310, box: 0.6088)  rpn_loss: 0.0926 (cls: 0.0263, box: 0.0663)
[2025-08-07 18:27:55 train.log] INFO: Epoch: [13]  [Step 9700/14540]  lr: 0.000062  loss: 1.25139  detection_loss: 1.0106 (cls: 0.2948, box: 0.7158)  rpn_loss: 0.2408 (cls: 0.0564, box: 0.1844)
[2025-08-07 18:28:00 train.log] INFO: Epoch: [13]  [Step 9800/14540]  lr: 0.000062  loss: 1.31822  detection_loss: 1.2343 (cls: 0.3340, box: 0.9004)  rpn_loss: 0.0839 (cls: 0.0718, box: 0.0121)
[2025-08-07 18:28:05 train.log] INFO: Epoch: [13]  [Step 9900/14540]  lr: 0.000062  loss: 1.64949  detection_loss: 1.4289 (cls: 0.3299, box: 1.0990)  rpn_loss: 0.2206 (cls: 0.1280, box: 0.0926)
[2025-08-07 18:28:10 train.log] INFO: Epoch: [13]  [Step 10000/14540]  lr: 0.000062  loss: 0.49668  detection_loss: 0.4492 (cls: 0.1131, box: 0.3361)  rpn_loss: 0.0474 (cls: 0.0272, box: 0.0202)
[2025-08-07 18:28:15 train.log] INFO: Epoch: [13]  [Step 10100/14540]  lr: 0.000062  loss: 1.24366  detection_loss: 1.1322 (cls: 0.2520, box: 0.8802)  rpn_loss: 0.1114 (cls: 0.0891, box: 0.0224)
[2025-08-07 18:28:20 train.log] INFO: Epoch: [13]  [Step 10200/14540]  lr: 0.000062  loss: 0.76569  detection_loss: 0.6875 (cls: 0.1199, box: 0.5676)  rpn_loss: 0.0781 (cls: 0.0246, box: 0.0536)
[2025-08-07 18:28:25 train.log] INFO: Epoch: [13]  [Step 10300/14540]  lr: 0.000062  loss: 0.85089  detection_loss: 0.8131 (cls: 0.2517, box: 0.5614)  rpn_loss: 0.0378 (cls: 0.0294, box: 0.0083)
[2025-08-07 18:28:30 train.log] INFO: Epoch: [13]  [Step 10400/14540]  lr: 0.000062  loss: 1.35935  detection_loss: 1.2203 (cls: 0.3042, box: 0.9161)  rpn_loss: 0.1391 (cls: 0.0381, box: 0.1010)
[2025-08-07 18:28:35 train.log] INFO: Epoch: [13]  [Step 10500/14540]  lr: 0.000062  loss: 1.99727  detection_loss: 1.8415 (cls: 0.5137, box: 1.3278)  rpn_loss: 0.1557 (cls: 0.1106, box: 0.0451)
[2025-08-07 18:28:40 train.log] INFO: Epoch: [13]  [Step 10600/14540]  lr: 0.000062  loss: 1.79554  detection_loss: 1.2623 (cls: 0.3076, box: 0.9547)  rpn_loss: 0.5333 (cls: 0.0447, box: 0.4886)
[2025-08-07 18:28:45 train.log] INFO: Epoch: [13]  [Step 10700/14540]  lr: 0.000062  loss: 1.13649  detection_loss: 1.0120 (cls: 0.2028, box: 0.8092)  rpn_loss: 0.1245 (cls: 0.1054, box: 0.0191)
[2025-08-07 18:28:50 train.log] INFO: Epoch: [13]  [Step 10800/14540]  lr: 0.000062  loss: 1.48743  detection_loss: 1.3616 (cls: 0.2198, box: 1.1418)  rpn_loss: 0.1259 (cls: 0.0529, box: 0.0730)
[2025-08-07 18:28:55 train.log] INFO: Epoch: [13]  [Step 10900/14540]  lr: 0.000062  loss: 1.23754  detection_loss: 1.1347 (cls: 0.1869, box: 0.9478)  rpn_loss: 0.1029 (cls: 0.0235, box: 0.0793)
[2025-08-07 18:28:59 train.log] INFO: Epoch: [13]  [Step 11000/14540]  lr: 0.000062  loss: 0.68705  detection_loss: 0.5839 (cls: 0.1193, box: 0.4647)  rpn_loss: 0.1031 (cls: 0.0585, box: 0.0446)
[2025-08-07 18:29:04 train.log] INFO: Epoch: [13]  [Step 11100/14540]  lr: 0.000062  loss: 0.55143  detection_loss: 0.4775 (cls: 0.1575, box: 0.3200)  rpn_loss: 0.0740 (cls: 0.0527, box: 0.0212)
[2025-08-07 18:29:09 train.log] INFO: Epoch: [13]  [Step 11200/14540]  lr: 0.000062  loss: 1.51104  detection_loss: 1.3583 (cls: 0.2675, box: 1.0908)  rpn_loss: 0.1528 (cls: 0.0934, box: 0.0594)
[2025-08-07 18:29:14 train.log] INFO: Epoch: [13]  [Step 11300/14540]  lr: 0.000062  loss: 1.12511  detection_loss: 1.0239 (cls: 0.2172, box: 0.8067)  rpn_loss: 0.1012 (cls: 0.0675, box: 0.0337)
[2025-08-07 18:29:19 train.log] INFO: Epoch: [13]  [Step 11400/14540]  lr: 0.000062  loss: 0.93639  detection_loss: 0.8658 (cls: 0.1927, box: 0.6731)  rpn_loss: 0.0706 (cls: 0.0308, box: 0.0397)
[2025-08-07 18:29:24 train.log] INFO: Epoch: [13]  [Step 11500/14540]  lr: 0.000062  loss: 0.94926  detection_loss: 0.8643 (cls: 0.1797, box: 0.6847)  rpn_loss: 0.0849 (cls: 0.0474, box: 0.0375)
[2025-08-07 18:29:29 train.log] INFO: Epoch: [13]  [Step 11600/14540]  lr: 0.000062  loss: 0.99513  detection_loss: 0.9277 (cls: 0.2630, box: 0.6647)  rpn_loss: 0.0674 (cls: 0.0322, box: 0.0352)
[2025-08-07 18:29:34 train.log] INFO: Epoch: [13]  [Step 11700/14540]  lr: 0.000062  loss: 1.64111  detection_loss: 1.4495 (cls: 0.1699, box: 1.2797)  rpn_loss: 0.1916 (cls: 0.0240, box: 0.1676)
[2025-08-07 18:29:39 train.log] INFO: Epoch: [13]  [Step 11800/14540]  lr: 0.000062  loss: 0.76814  detection_loss: 0.6082 (cls: 0.1522, box: 0.4560)  rpn_loss: 0.1600 (cls: 0.0918, box: 0.0682)
[2025-08-07 18:29:44 train.log] INFO: Epoch: [13]  [Step 11900/14540]  lr: 0.000062  loss: 1.14217  detection_loss: 1.0356 (cls: 0.3407, box: 0.6949)  rpn_loss: 0.1066 (cls: 0.0608, box: 0.0458)
[2025-08-07 18:29:49 train.log] INFO: Epoch: [13]  [Step 12000/14540]  lr: 0.000062  loss: 1.19674  detection_loss: 1.0747 (cls: 0.3329, box: 0.7418)  rpn_loss: 0.1220 (cls: 0.0941, box: 0.0279)
[2025-08-07 18:29:54 train.log] INFO: Epoch: [13]  [Step 12100/14540]  lr: 0.000062  loss: 1.07044  detection_loss: 0.9879 (cls: 0.1710, box: 0.8170)  rpn_loss: 0.0825 (cls: 0.0194, box: 0.0631)
[2025-08-07 18:29:59 train.log] INFO: Epoch: [13]  [Step 12200/14540]  lr: 0.000062  loss: 1.64188  detection_loss: 1.2860 (cls: 0.3550, box: 0.9310)  rpn_loss: 0.3559 (cls: 0.0775, box: 0.2784)
[2025-08-07 18:30:03 train.log] INFO: Epoch: [13]  [Step 12300/14540]  lr: 0.000062  loss: 1.20316  detection_loss: 1.0125 (cls: 0.3070, box: 0.7055)  rpn_loss: 0.1907 (cls: 0.0565, box: 0.1342)
[2025-08-07 18:30:08 train.log] INFO: Epoch: [13]  [Step 12400/14540]  lr: 0.000062  loss: 0.78031  detection_loss: 0.6935 (cls: 0.1549, box: 0.5386)  rpn_loss: 0.0868 (cls: 0.0384, box: 0.0483)
[2025-08-07 18:30:13 train.log] INFO: Epoch: [13]  [Step 12500/14540]  lr: 0.000062  loss: 0.98140  detection_loss: 0.8925 (cls: 0.2066, box: 0.6859)  rpn_loss: 0.0889 (cls: 0.0593, box: 0.0296)
[2025-08-07 18:30:18 train.log] INFO: Epoch: [13]  [Step 12600/14540]  lr: 0.000062  loss: 0.92694  detection_loss: 0.7625 (cls: 0.2137, box: 0.5488)  rpn_loss: 0.1644 (cls: 0.1406, box: 0.0239)
[2025-08-07 18:30:23 train.log] INFO: Epoch: [13]  [Step 12700/14540]  lr: 0.000062  loss: 1.37676  detection_loss: 1.2460 (cls: 0.4543, box: 0.7917)  rpn_loss: 0.1308 (cls: 0.0591, box: 0.0717)
[2025-08-07 18:30:28 train.log] INFO: Epoch: [13]  [Step 12800/14540]  lr: 0.000062  loss: 1.62538  detection_loss: 1.5119 (cls: 0.2912, box: 1.2206)  rpn_loss: 0.1135 (cls: 0.0534, box: 0.0601)
[2025-08-07 18:30:33 train.log] INFO: Epoch: [13]  [Step 12900/14540]  lr: 0.000062  loss: 1.62323  detection_loss: 1.4695 (cls: 0.4015, box: 1.0680)  rpn_loss: 0.1538 (cls: 0.0482, box: 0.1056)
[2025-08-07 18:30:38 train.log] INFO: Epoch: [13]  [Step 13000/14540]  lr: 0.000062  loss: 1.04837  detection_loss: 0.9517 (cls: 0.1998, box: 0.7518)  rpn_loss: 0.0967 (cls: 0.0414, box: 0.0553)
[2025-08-07 18:30:43 train.log] INFO: Epoch: [13]  [Step 13100/14540]  lr: 0.000062  loss: 0.93013  detection_loss: 0.8742 (cls: 0.2148, box: 0.6595)  rpn_loss: 0.0559 (cls: 0.0329, box: 0.0230)
[2025-08-07 18:30:48 train.log] INFO: Epoch: [13]  [Step 13200/14540]  lr: 0.000062  loss: 1.62528  detection_loss: 1.4917 (cls: 0.5166, box: 0.9752)  rpn_loss: 0.1336 (cls: 0.0653, box: 0.0683)
[2025-08-07 18:30:53 train.log] INFO: Epoch: [13]  [Step 13300/14540]  lr: 0.000062  loss: 0.72230  detection_loss: 0.6633 (cls: 0.1255, box: 0.5378)  rpn_loss: 0.0590 (cls: 0.0344, box: 0.0246)
[2025-08-07 18:30:57 train.log] INFO: Epoch: [13]  [Step 13400/14540]  lr: 0.000062  loss: 1.19980  detection_loss: 1.1022 (cls: 0.2661, box: 0.8361)  rpn_loss: 0.0976 (cls: 0.0494, box: 0.0482)
[2025-08-07 18:31:02 train.log] INFO: Epoch: [13]  [Step 13500/14540]  lr: 0.000062  loss: 1.13452  detection_loss: 1.0379 (cls: 0.3090, box: 0.7289)  rpn_loss: 0.0966 (cls: 0.0737, box: 0.0230)
[2025-08-07 18:31:07 train.log] INFO: Epoch: [13]  [Step 13600/14540]  lr: 0.000062  loss: 1.19117  detection_loss: 1.0637 (cls: 0.3171, box: 0.7466)  rpn_loss: 0.1275 (cls: 0.0248, box: 0.1027)
[2025-08-07 18:31:12 train.log] INFO: Epoch: [13]  [Step 13700/14540]  lr: 0.000062  loss: 1.24361  detection_loss: 1.0942 (cls: 0.1599, box: 0.9344)  rpn_loss: 0.1494 (cls: 0.1235, box: 0.0259)
[2025-08-07 18:31:17 train.log] INFO: Epoch: [13]  [Step 13800/14540]  lr: 0.000062  loss: 1.30051  detection_loss: 1.1855 (cls: 0.2559, box: 0.9296)  rpn_loss: 0.1150 (cls: 0.0499, box: 0.0651)
[2025-08-07 18:31:22 train.log] INFO: Epoch: [13]  [Step 13900/14540]  lr: 0.000062  loss: 1.29854  detection_loss: 1.2181 (cls: 0.3240, box: 0.8941)  rpn_loss: 0.0804 (cls: 0.0455, box: 0.0349)
[2025-08-07 18:31:27 train.log] INFO: Epoch: [13]  [Step 14000/14540]  lr: 0.000062  loss: 1.12710  detection_loss: 0.9478 (cls: 0.2726, box: 0.6752)  rpn_loss: 0.1793 (cls: 0.0351, box: 0.1443)
[2025-08-07 18:31:32 train.log] INFO: Epoch: [13]  [Step 14100/14540]  lr: 0.000062  loss: 1.12152  detection_loss: 1.0353 (cls: 0.2647, box: 0.7706)  rpn_loss: 0.0862 (cls: 0.0589, box: 0.0273)
[2025-08-07 18:31:37 train.log] INFO: Epoch: [13]  [Step 14200/14540]  lr: 0.000062  loss: 1.03177  detection_loss: 0.9654 (cls: 0.1460, box: 0.8194)  rpn_loss: 0.0664 (cls: 0.0079, box: 0.0585)
[2025-08-07 18:31:42 train.log] INFO: Epoch: [13]  [Step 14300/14540]  lr: 0.000062  loss: 1.31232  detection_loss: 1.1730 (cls: 0.1859, box: 0.9871)  rpn_loss: 0.1394 (cls: 0.0492, box: 0.0901)
[2025-08-07 18:31:47 train.log] INFO: Epoch: [13]  [Step 14400/14540]  lr: 0.000062  loss: 1.67174  detection_loss: 1.5493 (cls: 0.3422, box: 1.2071)  rpn_loss: 0.1224 (cls: 0.0887, box: 0.0337)
[2025-08-07 18:31:52 train.log] INFO: Epoch: [13]  [Step 14500/14540]  lr: 0.000062  loss: 1.42631  detection_loss: 1.2935 (cls: 0.3768, box: 0.9167)  rpn_loss: 0.1328 (cls: 0.0830, box: 0.0498)
[2025-08-07 18:34:59 train.log] INFO: Epoch: [14]  [Step 100/14540]  lr: 0.000056  loss: 0.94577  detection_loss: 0.8326 (cls: 0.1364, box: 0.6962)  rpn_loss: 0.1132 (cls: 0.0731, box: 0.0401)
[2025-08-07 18:35:04 train.log] INFO: Epoch: [14]  [Step 200/14540]  lr: 0.000056  loss: 1.23377  detection_loss: 0.8895 (cls: 0.2695, box: 0.6199)  rpn_loss: 0.3443 (cls: 0.3099, box: 0.0344)
[2025-08-07 18:35:09 train.log] INFO: Epoch: [14]  [Step 300/14540]  lr: 0.000056  loss: 0.99913  detection_loss: 0.9382 (cls: 0.1682, box: 0.7701)  rpn_loss: 0.0609 (cls: 0.0289, box: 0.0320)
[2025-08-07 18:35:14 train.log] INFO: Epoch: [14]  [Step 400/14540]  lr: 0.000056  loss: 1.80185  detection_loss: 1.4759 (cls: 0.3024, box: 1.1735)  rpn_loss: 0.3260 (cls: 0.0552, box: 0.2708)
[2025-08-07 18:35:19 train.log] INFO: Epoch: [14]  [Step 500/14540]  lr: 0.000056  loss: 0.50792  detection_loss: 0.4691 (cls: 0.0886, box: 0.3805)  rpn_loss: 0.0388 (cls: 0.0242, box: 0.0145)
[2025-08-07 18:35:24 train.log] INFO: Epoch: [14]  [Step 600/14540]  lr: 0.000056  loss: 1.26179  detection_loss: 0.8211 (cls: 0.1853, box: 0.6358)  rpn_loss: 0.4407 (cls: 0.0524, box: 0.3884)
[2025-08-07 18:35:29 train.log] INFO: Epoch: [14]  [Step 700/14540]  lr: 0.000056  loss: 1.32024  detection_loss: 1.2328 (cls: 0.3253, box: 0.9076)  rpn_loss: 0.0874 (cls: 0.0399, box: 0.0475)
[2025-08-07 18:35:34 train.log] INFO: Epoch: [14]  [Step 800/14540]  lr: 0.000056  loss: 0.89907  detection_loss: 0.8293 (cls: 0.1853, box: 0.6440)  rpn_loss: 0.0698 (cls: 0.0465, box: 0.0233)
[2025-08-07 18:35:39 train.log] INFO: Epoch: [14]  [Step 900/14540]  lr: 0.000056  loss: 0.98083  detection_loss: 0.7037 (cls: 0.1494, box: 0.5543)  rpn_loss: 0.2771 (cls: 0.0427, box: 0.2345)
[2025-08-07 18:35:44 train.log] INFO: Epoch: [14]  [Step 1000/14540]  lr: 0.000056  loss: 1.49310  detection_loss: 1.4007 (cls: 0.2523, box: 1.1485)  rpn_loss: 0.0924 (cls: 0.0204, box: 0.0720)
[2025-08-07 18:35:49 train.log] INFO: Epoch: [14]  [Step 1100/14540]  lr: 0.000056  loss: 1.13078  detection_loss: 1.0485 (cls: 0.1967, box: 0.8518)  rpn_loss: 0.0823 (cls: 0.0637, box: 0.0186)
[2025-08-07 18:35:53 train.log] INFO: Epoch: [14]  [Step 1200/14540]  lr: 0.000056  loss: 1.03202  detection_loss: 0.8550 (cls: 0.2086, box: 0.6464)  rpn_loss: 0.1771 (cls: 0.0541, box: 0.1230)
[2025-08-07 18:35:58 train.log] INFO: Epoch: [14]  [Step 1300/14540]  lr: 0.000056  loss: 1.35606  detection_loss: 1.0574 (cls: 0.3243, box: 0.7331)  rpn_loss: 0.2987 (cls: 0.1755, box: 0.1231)
[2025-08-07 18:36:03 train.log] INFO: Epoch: [14]  [Step 1400/14540]  lr: 0.000056  loss: 0.98877  detection_loss: 0.8660 (cls: 0.2260, box: 0.6400)  rpn_loss: 0.1228 (cls: 0.0388, box: 0.0840)
[2025-08-07 18:36:08 train.log] INFO: Epoch: [14]  [Step 1500/14540]  lr: 0.000056  loss: 1.27530  detection_loss: 1.1865 (cls: 0.2269, box: 0.9597)  rpn_loss: 0.0888 (cls: 0.0337, box: 0.0551)
[2025-08-07 18:36:13 train.log] INFO: Epoch: [14]  [Step 1600/14540]  lr: 0.000056  loss: 1.48348  detection_loss: 1.4011 (cls: 0.2810, box: 1.1201)  rpn_loss: 0.0824 (cls: 0.0308, box: 0.0516)
[2025-08-07 18:36:18 train.log] INFO: Epoch: [14]  [Step 1700/14540]  lr: 0.000056  loss: 1.45870  detection_loss: 1.3476 (cls: 0.3188, box: 1.0288)  rpn_loss: 0.1111 (cls: 0.0638, box: 0.0473)
[2025-08-07 18:36:23 train.log] INFO: Epoch: [14]  [Step 1800/14540]  lr: 0.000056  loss: 1.09532  detection_loss: 1.0057 (cls: 0.1479, box: 0.8578)  rpn_loss: 0.0896 (cls: 0.0709, box: 0.0187)
[2025-08-07 18:36:28 train.log] INFO: Epoch: [14]  [Step 1900/14540]  lr: 0.000056  loss: 1.01104  detection_loss: 0.9092 (cls: 0.2052, box: 0.7040)  rpn_loss: 0.1018 (cls: 0.0712, box: 0.0306)
[2025-08-07 18:36:33 train.log] INFO: Epoch: [14]  [Step 2000/14540]  lr: 0.000056  loss: 1.17805  detection_loss: 1.0009 (cls: 0.2788, box: 0.7221)  rpn_loss: 0.1772 (cls: 0.0609, box: 0.1163)
[2025-08-07 18:36:38 train.log] INFO: Epoch: [14]  [Step 2100/14540]  lr: 0.000056  loss: 0.87750  detection_loss: 0.7779 (cls: 0.1377, box: 0.6402)  rpn_loss: 0.0996 (cls: 0.0726, box: 0.0270)
[2025-08-07 18:36:43 train.log] INFO: Epoch: [14]  [Step 2200/14540]  lr: 0.000056  loss: 0.95511  detection_loss: 0.8609 (cls: 0.2749, box: 0.5859)  rpn_loss: 0.0943 (cls: 0.0749, box: 0.0193)
[2025-08-07 18:36:47 train.log] INFO: Epoch: [14]  [Step 2300/14540]  lr: 0.000056  loss: 1.52480  detection_loss: 1.3963 (cls: 0.4387, box: 0.9575)  rpn_loss: 0.1285 (cls: 0.0574, box: 0.0712)
[2025-08-07 18:36:52 train.log] INFO: Epoch: [14]  [Step 2400/14540]  lr: 0.000056  loss: 0.71169  detection_loss: 0.5975 (cls: 0.1652, box: 0.4323)  rpn_loss: 0.1142 (cls: 0.0788, box: 0.0354)
[2025-08-07 18:36:57 train.log] INFO: Epoch: [14]  [Step 2500/14540]  lr: 0.000056  loss: 0.68350  detection_loss: 0.6440 (cls: 0.1271, box: 0.5169)  rpn_loss: 0.0395 (cls: 0.0223, box: 0.0172)
[2025-08-07 18:37:02 train.log] INFO: Epoch: [14]  [Step 2600/14540]  lr: 0.000056  loss: 0.98989  detection_loss: 0.9058 (cls: 0.2472, box: 0.6586)  rpn_loss: 0.0841 (cls: 0.0647, box: 0.0194)
[2025-08-07 18:37:07 train.log] INFO: Epoch: [14]  [Step 2700/14540]  lr: 0.000056  loss: 0.92737  detection_loss: 0.8426 (cls: 0.2778, box: 0.5648)  rpn_loss: 0.0848 (cls: 0.0565, box: 0.0283)
[2025-08-07 18:37:12 train.log] INFO: Epoch: [14]  [Step 2800/14540]  lr: 0.000056  loss: 1.68225  detection_loss: 1.3608 (cls: 0.4080, box: 0.9528)  rpn_loss: 0.3214 (cls: 0.0625, box: 0.2589)
[2025-08-07 18:37:17 train.log] INFO: Epoch: [14]  [Step 2900/14540]  lr: 0.000056  loss: 0.58717  detection_loss: 0.5386 (cls: 0.1834, box: 0.3552)  rpn_loss: 0.0486 (cls: 0.0312, box: 0.0173)
[2025-08-07 18:37:22 train.log] INFO: Epoch: [14]  [Step 3000/14540]  lr: 0.000056  loss: 1.53799  detection_loss: 1.4515 (cls: 0.3566, box: 1.0949)  rpn_loss: 0.0865 (cls: 0.0412, box: 0.0453)
[2025-08-07 18:37:27 train.log] INFO: Epoch: [14]  [Step 3100/14540]  lr: 0.000056  loss: 0.80415  detection_loss: 0.7102 (cls: 0.1339, box: 0.5763)  rpn_loss: 0.0939 (cls: 0.0686, box: 0.0254)
[2025-08-07 18:37:32 train.log] INFO: Epoch: [14]  [Step 3200/14540]  lr: 0.000056  loss: 0.89189  detection_loss: 0.6507 (cls: 0.1626, box: 0.4881)  rpn_loss: 0.2412 (cls: 0.0404, box: 0.2008)
[2025-08-07 18:37:37 train.log] INFO: Epoch: [14]  [Step 3300/14540]  lr: 0.000056  loss: 1.22700  detection_loss: 1.0685 (cls: 0.2561, box: 0.8123)  rpn_loss: 0.1585 (cls: 0.0596, box: 0.0989)
[2025-08-07 18:37:41 train.log] INFO: Epoch: [14]  [Step 3400/14540]  lr: 0.000056  loss: 1.14539  detection_loss: 1.0834 (cls: 0.1196, box: 0.9638)  rpn_loss: 0.0620 (cls: 0.0220, box: 0.0400)
[2025-08-07 18:37:46 train.log] INFO: Epoch: [14]  [Step 3500/14540]  lr: 0.000056  loss: 1.50125  detection_loss: 1.2318 (cls: 0.3757, box: 0.8561)  rpn_loss: 0.2695 (cls: 0.2390, box: 0.0305)
[2025-08-07 18:37:51 train.log] INFO: Epoch: [14]  [Step 3600/14540]  lr: 0.000056  loss: 0.77687  detection_loss: 0.7055 (cls: 0.1737, box: 0.5318)  rpn_loss: 0.0714 (cls: 0.0391, box: 0.0323)
[2025-08-07 18:37:53 train.log] INFO: Epoch: [14]  [Step 3635/14540]  lr: 0.000056  loss: 1.23411  detection_loss: 1.0450 (cls: 0.3471, box: 0.6979)  rpn_loss: 0.1892 (cls: 0.0710, box: 0.1182)
[2025-08-07 18:37:56 train.log] INFO: Epoch: [14]  [Step 3700/14540]  lr: 0.000056  loss: 1.67883  detection_loss: 1.6149 (cls: 0.4664, box: 1.1484)  rpn_loss: 0.0640 (cls: 0.0267, box: 0.0372)
[2025-08-07 18:38:01 train.log] INFO: Epoch: [14]  [Step 3800/14540]  lr: 0.000056  loss: 1.48764  detection_loss: 1.3645 (cls: 0.4120, box: 0.9525)  rpn_loss: 0.1231 (cls: 0.0768, box: 0.0464)
[2025-08-07 18:38:06 train.log] INFO: Epoch: [14]  [Step 3900/14540]  lr: 0.000056  loss: 1.10997  detection_loss: 1.0089 (cls: 0.2344, box: 0.7746)  rpn_loss: 0.1010 (cls: 0.0764, box: 0.0246)
[2025-08-07 18:38:11 train.log] INFO: Epoch: [14]  [Step 4000/14540]  lr: 0.000056  loss: 0.66139  detection_loss: 0.6109 (cls: 0.1493, box: 0.4616)  rpn_loss: 0.0505 (cls: 0.0184, box: 0.0321)
[2025-08-07 18:38:16 train.log] INFO: Epoch: [14]  [Step 4100/14540]  lr: 0.000056  loss: 1.43593  detection_loss: 1.2519 (cls: 0.2175, box: 1.0344)  rpn_loss: 0.1840 (cls: 0.0292, box: 0.1549)
[2025-08-07 18:38:21 train.log] INFO: Epoch: [14]  [Step 4200/14540]  lr: 0.000056  loss: 0.56232  detection_loss: 0.5225 (cls: 0.1048, box: 0.4177)  rpn_loss: 0.0398 (cls: 0.0166, box: 0.0232)
[2025-08-07 18:38:26 train.log] INFO: Epoch: [14]  [Step 4300/14540]  lr: 0.000056  loss: 1.36435  detection_loss: 1.2193 (cls: 0.4176, box: 0.8017)  rpn_loss: 0.1450 (cls: 0.1041, box: 0.0409)
[2025-08-07 18:38:30 train.log] INFO: Epoch: [14]  [Step 4400/14540]  lr: 0.000056  loss: 0.98657  detection_loss: 0.8828 (cls: 0.1308, box: 0.7520)  rpn_loss: 0.1037 (cls: 0.0504, box: 0.0533)
[2025-08-07 18:38:35 train.log] INFO: Epoch: [14]  [Step 4500/14540]  lr: 0.000056  loss: 1.11469  detection_loss: 0.9257 (cls: 0.2923, box: 0.6334)  rpn_loss: 0.1890 (cls: 0.0616, box: 0.1274)
[2025-08-07 18:38:40 train.log] INFO: Epoch: [14]  [Step 4600/14540]  lr: 0.000056  loss: 1.38546  detection_loss: 1.2991 (cls: 0.3015, box: 0.9976)  rpn_loss: 0.0864 (cls: 0.0657, box: 0.0206)
[2025-08-07 18:38:45 train.log] INFO: Epoch: [14]  [Step 4700/14540]  lr: 0.000056  loss: 1.18977  detection_loss: 1.0403 (cls: 0.3801, box: 0.6602)  rpn_loss: 0.1495 (cls: 0.1039, box: 0.0455)
[2025-08-07 18:38:50 train.log] INFO: Epoch: [14]  [Step 4800/14540]  lr: 0.000056  loss: 0.86009  detection_loss: 0.7584 (cls: 0.1523, box: 0.6061)  rpn_loss: 0.1017 (cls: 0.0485, box: 0.0532)
[2025-08-07 18:38:55 train.log] INFO: Epoch: [14]  [Step 4900/14540]  lr: 0.000056  loss: 1.13422  detection_loss: 1.0534 (cls: 0.1335, box: 0.9199)  rpn_loss: 0.0808 (cls: 0.0550, box: 0.0258)
[2025-08-07 18:38:59 train.log] INFO: Epoch: [14]  [Step 5000/14540]  lr: 0.000056  loss: 1.22009  detection_loss: 1.0951 (cls: 0.2838, box: 0.8113)  rpn_loss: 0.1250 (cls: 0.0915, box: 0.0335)
[2025-08-07 18:39:04 train.log] INFO: Epoch: [14]  [Step 5100/14540]  lr: 0.000056  loss: 1.20251  detection_loss: 0.8813 (cls: 0.1387, box: 0.7426)  rpn_loss: 0.3213 (cls: 0.0146, box: 0.3067)
[2025-08-07 18:39:09 train.log] INFO: Epoch: [14]  [Step 5200/14540]  lr: 0.000056  loss: 1.47804  detection_loss: 1.3373 (cls: 0.3845, box: 0.9527)  rpn_loss: 0.1408 (cls: 0.0802, box: 0.0606)
[2025-08-07 18:39:14 train.log] INFO: Epoch: [14]  [Step 5300/14540]  lr: 0.000056  loss: 0.97801  detection_loss: 0.8841 (cls: 0.2828, box: 0.6013)  rpn_loss: 0.0939 (cls: 0.0536, box: 0.0403)
[2025-08-07 18:39:19 train.log] INFO: Epoch: [14]  [Step 5400/14540]  lr: 0.000056  loss: 0.94954  detection_loss: 0.6330 (cls: 0.1368, box: 0.4962)  rpn_loss: 0.3166 (cls: 0.0278, box: 0.2887)
[2025-08-07 18:39:24 train.log] INFO: Epoch: [14]  [Step 5500/14540]  lr: 0.000056  loss: 0.93363  detection_loss: 0.8288 (cls: 0.2795, box: 0.5493)  rpn_loss: 0.1048 (cls: 0.0724, box: 0.0324)
[2025-08-07 18:39:29 train.log] INFO: Epoch: [14]  [Step 5600/14540]  lr: 0.000056  loss: 1.26202  detection_loss: 1.2081 (cls: 0.1388, box: 1.0693)  rpn_loss: 0.0539 (cls: 0.0211, box: 0.0328)
[2025-08-07 18:39:34 train.log] INFO: Epoch: [14]  [Step 5700/14540]  lr: 0.000056  loss: 0.84348  detection_loss: 0.7763 (cls: 0.2119, box: 0.5644)  rpn_loss: 0.0672 (cls: 0.0195, box: 0.0477)
[2025-08-07 18:39:39 train.log] INFO: Epoch: [14]  [Step 5800/14540]  lr: 0.000056  loss: 1.15721  detection_loss: 1.0544 (cls: 0.1209, box: 0.9335)  rpn_loss: 0.1028 (cls: 0.0757, box: 0.0272)
[2025-08-07 18:39:44 train.log] INFO: Epoch: [14]  [Step 5900/14540]  lr: 0.000056  loss: 1.07090  detection_loss: 0.9927 (cls: 0.2176, box: 0.7751)  rpn_loss: 0.0782 (cls: 0.0504, box: 0.0278)
[2025-08-07 18:39:49 train.log] INFO: Epoch: [14]  [Step 6000/14540]  lr: 0.000056  loss: 0.72609  detection_loss: 0.6597 (cls: 0.1727, box: 0.4871)  rpn_loss: 0.0664 (cls: 0.0373, box: 0.0291)
[2025-08-07 18:39:54 train.log] INFO: Epoch: [14]  [Step 6100/14540]  lr: 0.000056  loss: 1.43746  detection_loss: 1.3108 (cls: 0.3055, box: 1.0053)  rpn_loss: 0.1266 (cls: 0.0947, box: 0.0320)
[2025-08-07 18:39:59 train.log] INFO: Epoch: [14]  [Step 6200/14540]  lr: 0.000056  loss: 1.01016  detection_loss: 0.8967 (cls: 0.3232, box: 0.5735)  rpn_loss: 0.1135 (cls: 0.0644, box: 0.0491)
[2025-08-07 18:40:03 train.log] INFO: Epoch: [14]  [Step 6300/14540]  lr: 0.000056  loss: 0.79698  detection_loss: 0.7236 (cls: 0.1721, box: 0.5515)  rpn_loss: 0.0734 (cls: 0.0581, box: 0.0153)
[2025-08-07 18:40:08 train.log] INFO: Epoch: [14]  [Step 6400/14540]  lr: 0.000056  loss: 0.74304  detection_loss: 0.6679 (cls: 0.1246, box: 0.5433)  rpn_loss: 0.0751 (cls: 0.0553, box: 0.0199)
[2025-08-07 18:40:13 train.log] INFO: Epoch: [14]  [Step 6500/14540]  lr: 0.000056  loss: 1.40772  detection_loss: 1.2610 (cls: 0.3846, box: 0.8764)  rpn_loss: 0.1467 (cls: 0.0984, box: 0.0483)
[2025-08-07 18:40:18 train.log] INFO: Epoch: [14]  [Step 6600/14540]  lr: 0.000056  loss: 1.28044  detection_loss: 1.1332 (cls: 0.3183, box: 0.8150)  rpn_loss: 0.1472 (cls: 0.0900, box: 0.0572)
[2025-08-07 18:40:23 train.log] INFO: Epoch: [14]  [Step 6700/14540]  lr: 0.000056  loss: 0.78131  detection_loss: 0.6838 (cls: 0.1679, box: 0.5159)  rpn_loss: 0.0975 (cls: 0.0564, box: 0.0411)
[2025-08-07 18:40:28 train.log] INFO: Epoch: [14]  [Step 6800/14540]  lr: 0.000056  loss: 0.84846  detection_loss: 0.7835 (cls: 0.1908, box: 0.5927)  rpn_loss: 0.0650 (cls: 0.0237, box: 0.0412)
[2025-08-07 18:40:33 train.log] INFO: Epoch: [14]  [Step 6900/14540]  lr: 0.000056  loss: 1.20887  detection_loss: 1.0719 (cls: 0.2934, box: 0.7784)  rpn_loss: 0.1370 (cls: 0.1044, box: 0.0326)
[2025-08-07 18:40:38 train.log] INFO: Epoch: [14]  [Step 7000/14540]  lr: 0.000056  loss: 0.85227  detection_loss: 0.7829 (cls: 0.2612, box: 0.5217)  rpn_loss: 0.0694 (cls: 0.0449, box: 0.0245)
[2025-08-07 18:40:43 train.log] INFO: Epoch: [14]  [Step 7100/14540]  lr: 0.000056  loss: 0.89163  detection_loss: 0.8204 (cls: 0.1859, box: 0.6345)  rpn_loss: 0.0713 (cls: 0.0257, box: 0.0455)
[2025-08-07 18:40:48 train.log] INFO: Epoch: [14]  [Step 7200/14540]  lr: 0.000056  loss: 1.53022  detection_loss: 1.4722 (cls: 0.5581, box: 0.9140)  rpn_loss: 0.0580 (cls: 0.0368, box: 0.0213)
[2025-08-07 18:40:52 train.log] INFO: Epoch: [14]  [Step 7300/14540]  lr: 0.000056  loss: 1.85564  detection_loss: 1.4944 (cls: 0.3676, box: 1.1268)  rpn_loss: 0.3612 (cls: 0.0829, box: 0.2783)
[2025-08-07 18:40:57 train.log] INFO: Epoch: [14]  [Step 7400/14540]  lr: 0.000056  loss: 1.26681  detection_loss: 1.1862 (cls: 0.3547, box: 0.8315)  rpn_loss: 0.0806 (cls: 0.0365, box: 0.0442)
[2025-08-07 18:41:02 train.log] INFO: Epoch: [14]  [Step 7500/14540]  lr: 0.000056  loss: 0.87352  detection_loss: 0.7975 (cls: 0.2376, box: 0.5599)  rpn_loss: 0.0760 (cls: 0.0545, box: 0.0216)
[2025-08-07 18:41:07 train.log] INFO: Epoch: [14]  [Step 7600/14540]  lr: 0.000056  loss: 0.93886  detection_loss: 0.8407 (cls: 0.2592, box: 0.5815)  rpn_loss: 0.0982 (cls: 0.0285, box: 0.0697)
[2025-08-07 18:41:12 train.log] INFO: Epoch: [14]  [Step 7700/14540]  lr: 0.000056  loss: 1.45500  detection_loss: 1.2672 (cls: 0.3968, box: 0.8704)  rpn_loss: 0.1878 (cls: 0.1180, box: 0.0698)
[2025-08-07 18:41:17 train.log] INFO: Epoch: [14]  [Step 7800/14540]  lr: 0.000056  loss: 1.52228  detection_loss: 1.4127 (cls: 0.2881, box: 1.1246)  rpn_loss: 0.1095 (cls: 0.0583, box: 0.0512)
[2025-08-07 18:41:22 train.log] INFO: Epoch: [14]  [Step 7900/14540]  lr: 0.000056  loss: 0.83401  detection_loss: 0.7395 (cls: 0.1916, box: 0.5479)  rpn_loss: 0.0945 (cls: 0.0516, box: 0.0429)
[2025-08-07 18:41:27 train.log] INFO: Epoch: [14]  [Step 8000/14540]  lr: 0.000056  loss: 1.21165  detection_loss: 1.0287 (cls: 0.2689, box: 0.7598)  rpn_loss: 0.1830 (cls: 0.0820, box: 0.1010)
[2025-08-07 18:41:32 train.log] INFO: Epoch: [14]  [Step 8100/14540]  lr: 0.000056  loss: 0.94995  detection_loss: 0.8763 (cls: 0.3126, box: 0.5637)  rpn_loss: 0.0736 (cls: 0.0500, box: 0.0237)
[2025-08-07 18:41:37 train.log] INFO: Epoch: [14]  [Step 8200/14540]  lr: 0.000056  loss: 0.97389  detection_loss: 0.6857 (cls: 0.1823, box: 0.5035)  rpn_loss: 0.2882 (cls: 0.0414, box: 0.2468)
[2025-08-07 18:41:41 train.log] INFO: Epoch: [14]  [Step 8300/14540]  lr: 0.000056  loss: 1.82148  detection_loss: 1.6971 (cls: 0.4030, box: 1.2941)  rpn_loss: 0.1244 (cls: 0.0520, box: 0.0724)
[2025-08-07 18:41:46 train.log] INFO: Epoch: [14]  [Step 8400/14540]  lr: 0.000056  loss: 1.16123  detection_loss: 0.9842 (cls: 0.2307, box: 0.7535)  rpn_loss: 0.1770 (cls: 0.1298, box: 0.0472)
[2025-08-07 18:41:51 train.log] INFO: Epoch: [14]  [Step 8500/14540]  lr: 0.000056  loss: 1.17990  detection_loss: 0.9790 (cls: 0.2321, box: 0.7468)  rpn_loss: 0.2009 (cls: 0.0405, box: 0.1605)
[2025-08-07 18:41:56 train.log] INFO: Epoch: [14]  [Step 8600/14540]  lr: 0.000056  loss: 0.67999  detection_loss: 0.6125 (cls: 0.1531, box: 0.4595)  rpn_loss: 0.0675 (cls: 0.0444, box: 0.0230)
[2025-08-07 18:42:01 train.log] INFO: Epoch: [14]  [Step 8700/14540]  lr: 0.000056  loss: 0.77538  detection_loss: 0.7123 (cls: 0.1585, box: 0.5538)  rpn_loss: 0.0631 (cls: 0.0388, box: 0.0242)
[2025-08-07 18:42:06 train.log] INFO: Epoch: [14]  [Step 8800/14540]  lr: 0.000056  loss: 1.37635  detection_loss: 1.2884 (cls: 0.2310, box: 1.0574)  rpn_loss: 0.0880 (cls: 0.0405, box: 0.0474)
[2025-08-07 18:42:11 train.log] INFO: Epoch: [14]  [Step 8900/14540]  lr: 0.000056  loss: 0.76396  detection_loss: 0.6606 (cls: 0.1925, box: 0.4681)  rpn_loss: 0.1034 (cls: 0.0422, box: 0.0612)
[2025-08-07 18:42:15 train.log] INFO: Epoch: [14]  [Step 9000/14540]  lr: 0.000056  loss: 0.97492  detection_loss: 0.9125 (cls: 0.1365, box: 0.7760)  rpn_loss: 0.0624 (cls: 0.0334, box: 0.0290)
[2025-08-07 18:42:20 train.log] INFO: Epoch: [14]  [Step 9100/14540]  lr: 0.000056  loss: 1.25153  detection_loss: 1.1082 (cls: 0.1910, box: 0.9172)  rpn_loss: 0.1433 (cls: 0.0504, box: 0.0929)
[2025-08-07 18:42:25 train.log] INFO: Epoch: [14]  [Step 9200/14540]  lr: 0.000056  loss: 1.38010  detection_loss: 1.1785 (cls: 0.1265, box: 1.0520)  rpn_loss: 0.2016 (cls: 0.0285, box: 0.1730)
[2025-08-07 18:42:30 train.log] INFO: Epoch: [14]  [Step 9300/14540]  lr: 0.000056  loss: 0.94727  detection_loss: 0.8808 (cls: 0.2243, box: 0.6564)  rpn_loss: 0.0665 (cls: 0.0282, box: 0.0383)
[2025-08-07 18:42:35 train.log] INFO: Epoch: [14]  [Step 9400/14540]  lr: 0.000056  loss: 1.28282  detection_loss: 1.1499 (cls: 0.4911, box: 0.6588)  rpn_loss: 0.1329 (cls: 0.0729, box: 0.0600)
[2025-08-07 18:42:40 train.log] INFO: Epoch: [14]  [Step 9500/14540]  lr: 0.000056  loss: 0.69238  detection_loss: 0.6114 (cls: 0.1525, box: 0.4589)  rpn_loss: 0.0809 (cls: 0.0442, box: 0.0368)
[2025-08-07 18:42:45 train.log] INFO: Epoch: [14]  [Step 9600/14540]  lr: 0.000056  loss: 0.85642  detection_loss: 0.7710 (cls: 0.1716, box: 0.5994)  rpn_loss: 0.0854 (cls: 0.0480, box: 0.0374)
[2025-08-07 18:42:50 train.log] INFO: Epoch: [14]  [Step 9700/14540]  lr: 0.000056  loss: 1.40149  detection_loss: 1.2487 (cls: 0.2731, box: 0.9755)  rpn_loss: 0.1528 (cls: 0.0861, box: 0.0667)
[2025-08-07 18:42:55 train.log] INFO: Epoch: [14]  [Step 9800/14540]  lr: 0.000056  loss: 1.18189  detection_loss: 1.0904 (cls: 0.2462, box: 0.8442)  rpn_loss: 0.0915 (cls: 0.0523, box: 0.0391)
[2025-08-07 18:43:00 train.log] INFO: Epoch: [14]  [Step 9900/14540]  lr: 0.000056  loss: 1.02479  detection_loss: 0.8968 (cls: 0.2395, box: 0.6573)  rpn_loss: 0.1280 (cls: 0.0964, box: 0.0316)
[2025-08-07 18:43:05 train.log] INFO: Epoch: [14]  [Step 10000/14540]  lr: 0.000056  loss: 1.29621  detection_loss: 1.1049 (cls: 0.1610, box: 0.9439)  rpn_loss: 0.1914 (cls: 0.0851, box: 0.1063)
[2025-08-07 18:43:09 train.log] INFO: Epoch: [14]  [Step 10100/14540]  lr: 0.000056  loss: 0.93708  detection_loss: 0.8693 (cls: 0.2427, box: 0.6266)  rpn_loss: 0.0678 (cls: 0.0268, box: 0.0410)
[2025-08-07 18:43:14 train.log] INFO: Epoch: [14]  [Step 10200/14540]  lr: 0.000056  loss: 1.13037  detection_loss: 1.0362 (cls: 0.3369, box: 0.6993)  rpn_loss: 0.0941 (cls: 0.0446, box: 0.0495)
[2025-08-07 18:43:19 train.log] INFO: Epoch: [14]  [Step 10300/14540]  lr: 0.000056  loss: 0.83395  detection_loss: 0.7710 (cls: 0.1700, box: 0.6011)  rpn_loss: 0.0629 (cls: 0.0331, box: 0.0298)
[2025-08-07 18:43:24 train.log] INFO: Epoch: [14]  [Step 10400/14540]  lr: 0.000056  loss: 1.25243  detection_loss: 1.1424 (cls: 0.2979, box: 0.8445)  rpn_loss: 0.1100 (cls: 0.0446, box: 0.0654)
[2025-08-07 18:43:29 train.log] INFO: Epoch: [14]  [Step 10500/14540]  lr: 0.000056  loss: 0.97327  detection_loss: 0.7592 (cls: 0.2547, box: 0.5045)  rpn_loss: 0.2141 (cls: 0.0425, box: 0.1715)
[2025-08-07 18:43:34 train.log] INFO: Epoch: [14]  [Step 10600/14540]  lr: 0.000056  loss: 0.94363  detection_loss: 0.8106 (cls: 0.3304, box: 0.4802)  rpn_loss: 0.1330 (cls: 0.0820, box: 0.0511)
[2025-08-07 18:43:39 train.log] INFO: Epoch: [14]  [Step 10700/14540]  lr: 0.000056  loss: 1.32833  detection_loss: 1.2303 (cls: 0.1961, box: 1.0342)  rpn_loss: 0.0980 (cls: 0.0238, box: 0.0742)
[2025-08-07 18:43:44 train.log] INFO: Epoch: [14]  [Step 10800/14540]  lr: 0.000056  loss: 1.17113  detection_loss: 1.0920 (cls: 0.1534, box: 0.9386)  rpn_loss: 0.0792 (cls: 0.0414, box: 0.0378)
[2025-08-07 18:43:49 train.log] INFO: Epoch: [14]  [Step 10900/14540]  lr: 0.000056  loss: 1.02630  detection_loss: 0.9495 (cls: 0.2165, box: 0.7329)  rpn_loss: 0.0768 (cls: 0.0318, box: 0.0451)
[2025-08-07 18:43:54 train.log] INFO: Epoch: [14]  [Step 11000/14540]  lr: 0.000056  loss: 0.97946  detection_loss: 0.9124 (cls: 0.2389, box: 0.6735)  rpn_loss: 0.0671 (cls: 0.0451, box: 0.0220)
[2025-08-07 18:43:59 train.log] INFO: Epoch: [14]  [Step 11100/14540]  lr: 0.000056  loss: 0.57883  detection_loss: 0.5130 (cls: 0.1577, box: 0.3552)  rpn_loss: 0.0659 (cls: 0.0508, box: 0.0150)
[2025-08-07 18:44:03 train.log] INFO: Epoch: [14]  [Step 11200/14540]  lr: 0.000056  loss: 1.18845  detection_loss: 1.0498 (cls: 0.2532, box: 0.7965)  rpn_loss: 0.1387 (cls: 0.1152, box: 0.0235)
[2025-08-07 18:44:08 train.log] INFO: Epoch: [14]  [Step 11300/14540]  lr: 0.000056  loss: 1.42344  detection_loss: 1.3357 (cls: 0.2805, box: 1.0551)  rpn_loss: 0.0878 (cls: 0.0398, box: 0.0480)
[2025-08-07 18:44:13 train.log] INFO: Epoch: [14]  [Step 11400/14540]  lr: 0.000056  loss: 0.73790  detection_loss: 0.6469 (cls: 0.1776, box: 0.4693)  rpn_loss: 0.0910 (cls: 0.0583, box: 0.0328)
[2025-08-07 18:44:18 train.log] INFO: Epoch: [14]  [Step 11500/14540]  lr: 0.000056  loss: 0.82205  detection_loss: 0.7798 (cls: 0.2176, box: 0.5622)  rpn_loss: 0.0422 (cls: 0.0210, box: 0.0212)
[2025-08-07 18:44:23 train.log] INFO: Epoch: [14]  [Step 11600/14540]  lr: 0.000056  loss: 0.84150  detection_loss: 0.7396 (cls: 0.2475, box: 0.4921)  rpn_loss: 0.1019 (cls: 0.0457, box: 0.0562)
[2025-08-07 18:44:28 train.log] INFO: Epoch: [14]  [Step 11700/14540]  lr: 0.000056  loss: 0.81387  detection_loss: 0.7169 (cls: 0.2708, box: 0.4461)  rpn_loss: 0.0970 (cls: 0.0565, box: 0.0405)
[2025-08-07 18:44:33 train.log] INFO: Epoch: [14]  [Step 11800/14540]  lr: 0.000056  loss: 1.05704  detection_loss: 0.9920 (cls: 0.3603, box: 0.6317)  rpn_loss: 0.0650 (cls: 0.0400, box: 0.0250)
[2025-08-07 18:44:38 train.log] INFO: Epoch: [14]  [Step 11900/14540]  lr: 0.000056  loss: 1.37184  detection_loss: 1.2224 (cls: 0.3448, box: 0.8776)  rpn_loss: 0.1495 (cls: 0.0659, box: 0.0835)
[2025-08-07 18:44:43 train.log] INFO: Epoch: [14]  [Step 12000/14540]  lr: 0.000056  loss: 0.73140  detection_loss: 0.6747 (cls: 0.1460, box: 0.5287)  rpn_loss: 0.0567 (cls: 0.0269, box: 0.0298)
[2025-08-07 18:44:47 train.log] INFO: Epoch: [14]  [Step 12100/14540]  lr: 0.000056  loss: 1.66658  detection_loss: 1.4402 (cls: 0.2036, box: 1.2366)  rpn_loss: 0.2264 (cls: 0.1201, box: 0.1063)
[2025-08-07 18:44:52 train.log] INFO: Epoch: [14]  [Step 12200/14540]  lr: 0.000056  loss: 0.87198  detection_loss: 0.7607 (cls: 0.1451, box: 0.6156)  rpn_loss: 0.1112 (cls: 0.0935, box: 0.0178)
[2025-08-07 18:44:57 train.log] INFO: Epoch: [14]  [Step 12300/14540]  lr: 0.000056  loss: 1.29646  detection_loss: 1.1875 (cls: 0.1932, box: 0.9943)  rpn_loss: 0.1090 (cls: 0.0444, box: 0.0645)
[2025-08-07 18:45:02 train.log] INFO: Epoch: [14]  [Step 12400/14540]  lr: 0.000056  loss: 1.14365  detection_loss: 1.0202 (cls: 0.2469, box: 0.7733)  rpn_loss: 0.1234 (cls: 0.0579, box: 0.0655)
[2025-08-07 18:45:07 train.log] INFO: Epoch: [14]  [Step 12500/14540]  lr: 0.000056  loss: 0.63680  detection_loss: 0.5426 (cls: 0.1496, box: 0.3930)  rpn_loss: 0.0942 (cls: 0.0363, box: 0.0579)
[2025-08-07 18:45:12 train.log] INFO: Epoch: [14]  [Step 12600/14540]  lr: 0.000056  loss: 1.26112  detection_loss: 1.1042 (cls: 0.2339, box: 0.8703)  rpn_loss: 0.1569 (cls: 0.0271, box: 0.1298)
[2025-08-07 18:45:17 train.log] INFO: Epoch: [14]  [Step 12700/14540]  lr: 0.000056  loss: 0.88620  detection_loss: 0.7610 (cls: 0.1554, box: 0.6056)  rpn_loss: 0.1251 (cls: 0.0281, box: 0.0970)
[2025-08-07 18:45:22 train.log] INFO: Epoch: [14]  [Step 12800/14540]  lr: 0.000056  loss: 1.83038  detection_loss: 1.6678 (cls: 0.4076, box: 1.2602)  rpn_loss: 0.1626 (cls: 0.1107, box: 0.0519)
[2025-08-07 18:45:26 train.log] INFO: Epoch: [14]  [Step 12900/14540]  lr: 0.000056  loss: 1.49671  detection_loss: 1.4483 (cls: 0.2480, box: 1.2003)  rpn_loss: 0.0484 (cls: 0.0153, box: 0.0331)
[2025-08-07 18:45:31 train.log] INFO: Epoch: [14]  [Step 13000/14540]  lr: 0.000056  loss: 1.28753  detection_loss: 1.2061 (cls: 0.3530, box: 0.8531)  rpn_loss: 0.0814 (cls: 0.0449, box: 0.0365)
[2025-08-07 18:45:36 train.log] INFO: Epoch: [14]  [Step 13100/14540]  lr: 0.000056  loss: 1.55424  detection_loss: 1.4464 (cls: 0.4252, box: 1.0212)  rpn_loss: 0.1079 (cls: 0.0671, box: 0.0407)
[2025-08-07 18:45:41 train.log] INFO: Epoch: [14]  [Step 13200/14540]  lr: 0.000056  loss: 0.77215  detection_loss: 0.6883 (cls: 0.1024, box: 0.5859)  rpn_loss: 0.0838 (cls: 0.0558, box: 0.0280)
[2025-08-07 18:45:46 train.log] INFO: Epoch: [14]  [Step 13300/14540]  lr: 0.000056  loss: 0.58273  detection_loss: 0.4977 (cls: 0.2139, box: 0.2838)  rpn_loss: 0.0851 (cls: 0.0658, box: 0.0192)
[2025-08-07 18:45:51 train.log] INFO: Epoch: [14]  [Step 13400/14540]  lr: 0.000056  loss: 0.67078  detection_loss: 0.5857 (cls: 0.1884, box: 0.3973)  rpn_loss: 0.0851 (cls: 0.0640, box: 0.0211)
[2025-08-07 18:45:56 train.log] INFO: Epoch: [14]  [Step 13500/14540]  lr: 0.000056  loss: 1.27711  detection_loss: 1.1380 (cls: 0.3044, box: 0.8336)  rpn_loss: 0.1391 (cls: 0.1043, box: 0.0348)
[2025-08-07 18:46:01 train.log] INFO: Epoch: [14]  [Step 13600/14540]  lr: 0.000056  loss: 1.15131  detection_loss: 1.0815 (cls: 0.2955, box: 0.7860)  rpn_loss: 0.0698 (cls: 0.0355, box: 0.0343)
[2025-08-07 18:46:05 train.log] INFO: Epoch: [14]  [Step 13700/14540]  lr: 0.000056  loss: 1.16523  detection_loss: 1.0406 (cls: 0.2742, box: 0.7663)  rpn_loss: 0.1247 (cls: 0.0689, box: 0.0557)
[2025-08-07 18:46:10 train.log] INFO: Epoch: [14]  [Step 13800/14540]  lr: 0.000056  loss: 0.69820  detection_loss: 0.6092 (cls: 0.1845, box: 0.4247)  rpn_loss: 0.0890 (cls: 0.0522, box: 0.0368)
[2025-08-07 18:46:15 train.log] INFO: Epoch: [14]  [Step 13900/14540]  lr: 0.000056  loss: 0.89730  detection_loss: 0.7989 (cls: 0.1813, box: 0.6176)  rpn_loss: 0.0984 (cls: 0.0261, box: 0.0723)
[2025-08-07 18:46:19 train.log] INFO: Epoch: [14]  [Step 14000/14540]  lr: 0.000056  loss: 1.44253  detection_loss: 1.2794 (cls: 0.3567, box: 0.9227)  rpn_loss: 0.1631 (cls: 0.0946, box: 0.0686)
[2025-08-07 18:46:24 train.log] INFO: Epoch: [14]  [Step 14100/14540]  lr: 0.000056  loss: 0.88530  detection_loss: 0.8301 (cls: 0.1382, box: 0.6919)  rpn_loss: 0.0552 (cls: 0.0300, box: 0.0251)
[2025-08-07 18:46:29 train.log] INFO: Epoch: [14]  [Step 14200/14540]  lr: 0.000056  loss: 1.15102  detection_loss: 0.9930 (cls: 0.1501, box: 0.8429)  rpn_loss: 0.1580 (cls: 0.0682, box: 0.0898)
[2025-08-07 18:46:34 train.log] INFO: Epoch: [14]  [Step 14300/14540]  lr: 0.000056  loss: 1.25522  detection_loss: 1.1106 (cls: 0.2156, box: 0.8950)  rpn_loss: 0.1446 (cls: 0.0667, box: 0.0779)
[2025-08-07 18:46:38 train.log] INFO: Epoch: [14]  [Step 14400/14540]  lr: 0.000056  loss: 1.33469  detection_loss: 1.1913 (cls: 0.2155, box: 0.9757)  rpn_loss: 0.1434 (cls: 0.0557, box: 0.0877)
[2025-08-07 18:46:43 train.log] INFO: Epoch: [14]  [Step 14500/14540]  lr: 0.000056  loss: 0.88200  detection_loss: 0.8076 (cls: 0.2662, box: 0.5415)  rpn_loss: 0.0744 (cls: 0.0556, box: 0.0188)
[2025-08-07 18:49:55 train.log] INFO: Epoch: [15]  [Step 100/14540]  lr: 0.000051  loss: 0.91516  detection_loss: 0.7833 (cls: 0.1963, box: 0.5870)  rpn_loss: 0.1319 (cls: 0.0823, box: 0.0496)
[2025-08-07 18:50:00 train.log] INFO: Epoch: [15]  [Step 200/14540]  lr: 0.000051  loss: 0.88929  detection_loss: 0.8458 (cls: 0.0949, box: 0.7510)  rpn_loss: 0.0434 (cls: 0.0181, box: 0.0254)
[2025-08-07 18:50:06 train.log] INFO: Epoch: [15]  [Step 300/14540]  lr: 0.000051  loss: 1.11715  detection_loss: 0.9853 (cls: 0.2669, box: 0.7184)  rpn_loss: 0.1318 (cls: 0.0659, box: 0.0659)
[2025-08-07 18:50:12 train.log] INFO: Epoch: [15]  [Step 400/14540]  lr: 0.000051  loss: 1.50313  detection_loss: 1.3927 (cls: 0.3897, box: 1.0030)  rpn_loss: 0.1104 (cls: 0.0311, box: 0.0793)
[2025-08-07 18:50:17 train.log] INFO: Epoch: [15]  [Step 500/14540]  lr: 0.000051  loss: 1.04079  detection_loss: 0.8968 (cls: 0.1640, box: 0.7328)  rpn_loss: 0.1440 (cls: 0.0646, box: 0.0794)
[2025-08-07 18:50:23 train.log] INFO: Epoch: [15]  [Step 600/14540]  lr: 0.000051  loss: 1.40252  detection_loss: 1.3025 (cls: 0.3804, box: 0.9221)  rpn_loss: 0.1000 (cls: 0.0705, box: 0.0295)
[2025-08-07 18:50:28 train.log] INFO: Epoch: [15]  [Step 700/14540]  lr: 0.000051  loss: 1.01702  detection_loss: 0.9408 (cls: 0.3811, box: 0.5597)  rpn_loss: 0.0762 (cls: 0.0169, box: 0.0593)
[2025-08-07 18:50:34 train.log] INFO: Epoch: [15]  [Step 800/14540]  lr: 0.000051  loss: 0.84299  detection_loss: 0.7682 (cls: 0.1745, box: 0.5937)  rpn_loss: 0.0748 (cls: 0.0506, box: 0.0242)
[2025-08-07 18:50:39 train.log] INFO: Epoch: [15]  [Step 900/14540]  lr: 0.000051  loss: 1.28964  detection_loss: 1.1919 (cls: 0.2723, box: 0.9196)  rpn_loss: 0.0977 (cls: 0.0408, box: 0.0570)
[2025-08-07 18:50:45 train.log] INFO: Epoch: [15]  [Step 1000/14540]  lr: 0.000051  loss: 1.43371  detection_loss: 1.3361 (cls: 0.2042, box: 1.1319)  rpn_loss: 0.0976 (cls: 0.0668, box: 0.0308)
[2025-08-07 18:50:50 train.log] INFO: Epoch: [15]  [Step 1100/14540]  lr: 0.000051  loss: 0.76303  detection_loss: 0.6605 (cls: 0.1966, box: 0.4639)  rpn_loss: 0.1025 (cls: 0.0209, box: 0.0816)
[2025-08-07 18:50:56 train.log] INFO: Epoch: [15]  [Step 1200/14540]  lr: 0.000051  loss: 1.09347  detection_loss: 0.9358 (cls: 0.2286, box: 0.7072)  rpn_loss: 0.1576 (cls: 0.0973, box: 0.0604)
[2025-08-07 18:51:01 train.log] INFO: Epoch: [15]  [Step 1300/14540]  lr: 0.000051  loss: 0.90903  detection_loss: 0.7281 (cls: 0.2384, box: 0.4897)  rpn_loss: 0.1809 (cls: 0.0531, box: 0.1278)
[2025-08-07 18:51:07 train.log] INFO: Epoch: [15]  [Step 1400/14540]  lr: 0.000051  loss: 1.60383  detection_loss: 1.4183 (cls: 0.3830, box: 1.0353)  rpn_loss: 0.1855 (cls: 0.0534, box: 0.1322)
[2025-08-07 18:51:13 train.log] INFO: Epoch: [15]  [Step 1500/14540]  lr: 0.000051  loss: 0.88244  detection_loss: 0.7781 (cls: 0.1992, box: 0.5789)  rpn_loss: 0.1044 (cls: 0.0772, box: 0.0272)
[2025-08-07 18:51:18 train.log] INFO: Epoch: [15]  [Step 1600/14540]  lr: 0.000051  loss: 1.65165  detection_loss: 1.4932 (cls: 0.5133, box: 0.9799)  rpn_loss: 0.1584 (cls: 0.0798, box: 0.0786)
[2025-08-07 18:51:24 train.log] INFO: Epoch: [15]  [Step 1700/14540]  lr: 0.000051  loss: 0.50803  detection_loss: 0.4638 (cls: 0.1149, box: 0.3488)  rpn_loss: 0.0442 (cls: 0.0250, box: 0.0192)
[2025-08-07 18:51:30 train.log] INFO: Epoch: [15]  [Step 1800/14540]  lr: 0.000051  loss: 0.79820  detection_loss: 0.7504 (cls: 0.1678, box: 0.5826)  rpn_loss: 0.0478 (cls: 0.0093, box: 0.0385)
[2025-08-07 18:51:35 train.log] INFO: Epoch: [15]  [Step 1900/14540]  lr: 0.000051  loss: 1.15837  detection_loss: 1.0687 (cls: 0.2717, box: 0.7970)  rpn_loss: 0.0896 (cls: 0.0494, box: 0.0403)
[2025-08-07 18:51:41 train.log] INFO: Epoch: [15]  [Step 2000/14540]  lr: 0.000051  loss: 1.57511  detection_loss: 1.4390 (cls: 0.3306, box: 1.1085)  rpn_loss: 0.1361 (cls: 0.0857, box: 0.0504)
[2025-08-07 18:51:46 train.log] INFO: Epoch: [15]  [Step 2100/14540]  lr: 0.000051  loss: 1.26465  detection_loss: 1.1701 (cls: 0.2464, box: 0.9237)  rpn_loss: 0.0945 (cls: 0.0730, box: 0.0215)
[2025-08-07 18:51:52 train.log] INFO: Epoch: [15]  [Step 2200/14540]  lr: 0.000051  loss: 0.95371  detection_loss: 0.8479 (cls: 0.2209, box: 0.6270)  rpn_loss: 0.1058 (cls: 0.0161, box: 0.0897)
[2025-08-07 18:51:57 train.log] INFO: Epoch: [15]  [Step 2300/14540]  lr: 0.000051  loss: 0.88046  detection_loss: 0.8208 (cls: 0.1714, box: 0.6493)  rpn_loss: 0.0597 (cls: 0.0311, box: 0.0286)
[2025-08-07 18:52:03 train.log] INFO: Epoch: [15]  [Step 2400/14540]  lr: 0.000051  loss: 1.70882  detection_loss: 1.5680 (cls: 0.3176, box: 1.2503)  rpn_loss: 0.1408 (cls: 0.0590, box: 0.0818)
[2025-08-07 18:52:08 train.log] INFO: Epoch: [15]  [Step 2500/14540]  lr: 0.000051  loss: 0.89320  detection_loss: 0.8221 (cls: 0.1630, box: 0.6590)  rpn_loss: 0.0711 (cls: 0.0597, box: 0.0114)
[2025-08-07 18:52:14 train.log] INFO: Epoch: [15]  [Step 2600/14540]  lr: 0.000051  loss: 1.04875  detection_loss: 1.0063 (cls: 0.1390, box: 0.8673)  rpn_loss: 0.0424 (cls: 0.0268, box: 0.0156)
[2025-08-07 18:52:19 train.log] INFO: Epoch: [15]  [Step 2700/14540]  lr: 0.000051  loss: 0.89776  detection_loss: 0.5811 (cls: 0.1423, box: 0.4388)  rpn_loss: 0.3166 (cls: 0.0604, box: 0.2562)
[2025-08-07 18:52:25 train.log] INFO: Epoch: [15]  [Step 2800/14540]  lr: 0.000051  loss: 1.14456  detection_loss: 1.0291 (cls: 0.3016, box: 0.7275)  rpn_loss: 0.1155 (cls: 0.0811, box: 0.0344)
[2025-08-07 18:52:30 train.log] INFO: Epoch: [15]  [Step 2900/14540]  lr: 0.000051  loss: 0.61279  detection_loss: 0.5238 (cls: 0.1431, box: 0.3807)  rpn_loss: 0.0890 (cls: 0.0629, box: 0.0261)
[2025-08-07 18:52:35 train.log] INFO: Epoch: [15]  [Step 3000/14540]  lr: 0.000051  loss: 0.98142  detection_loss: 0.9090 (cls: 0.1467, box: 0.7623)  rpn_loss: 0.0724 (cls: 0.0523, box: 0.0201)
[2025-08-07 18:52:41 train.log] INFO: Epoch: [15]  [Step 3100/14540]  lr: 0.000051  loss: 0.62627  detection_loss: 0.5676 (cls: 0.1545, box: 0.4132)  rpn_loss: 0.0586 (cls: 0.0368, box: 0.0218)
[2025-08-07 18:52:46 train.log] INFO: Epoch: [15]  [Step 3200/14540]  lr: 0.000051  loss: 1.29769  detection_loss: 1.1424 (cls: 0.3357, box: 0.8066)  rpn_loss: 0.1553 (cls: 0.0954, box: 0.0599)
[2025-08-07 18:52:52 train.log] INFO: Epoch: [15]  [Step 3300/14540]  lr: 0.000051  loss: 0.82233  detection_loss: 0.7352 (cls: 0.1975, box: 0.5377)  rpn_loss: 0.0872 (cls: 0.0534, box: 0.0337)
[2025-08-07 18:52:57 train.log] INFO: Epoch: [15]  [Step 3400/14540]  lr: 0.000051  loss: 1.31097  detection_loss: 1.2291 (cls: 0.2676, box: 0.9615)  rpn_loss: 0.0818 (cls: 0.0511, box: 0.0307)
[2025-08-07 18:53:03 train.log] INFO: Epoch: [15]  [Step 3500/14540]  lr: 0.000051  loss: 1.14966  detection_loss: 0.9390 (cls: 0.2583, box: 0.6807)  rpn_loss: 0.2107 (cls: 0.1780, box: 0.0326)
[2025-08-07 18:53:08 train.log] INFO: Epoch: [15]  [Step 3600/14540]  lr: 0.000051  loss: 0.88321  detection_loss: 0.8380 (cls: 0.1617, box: 0.6763)  rpn_loss: 0.0452 (cls: 0.0227, box: 0.0225)
[2025-08-07 18:53:10 train.log] INFO: Epoch: [15]  [Step 3635/14540]  lr: 0.000051  loss: 0.83180  detection_loss: 0.7408 (cls: 0.2533, box: 0.4875)  rpn_loss: 0.0910 (cls: 0.0358, box: 0.0552)
[2025-08-07 18:53:14 train.log] INFO: Epoch: [15]  [Step 3700/14540]  lr: 0.000051  loss: 1.55660  detection_loss: 1.4237 (cls: 0.2527, box: 1.1710)  rpn_loss: 0.1329 (cls: 0.0160, box: 0.1169)
[2025-08-07 18:53:20 train.log] INFO: Epoch: [15]  [Step 3800/14540]  lr: 0.000051  loss: 0.89459  detection_loss: 0.6646 (cls: 0.1964, box: 0.4682)  rpn_loss: 0.2300 (cls: 0.0320, box: 0.1980)
[2025-08-07 18:53:25 train.log] INFO: Epoch: [15]  [Step 3900/14540]  lr: 0.000051  loss: 1.13341  detection_loss: 0.9432 (cls: 0.2013, box: 0.7419)  rpn_loss: 0.1902 (cls: 0.1705, box: 0.0197)
[2025-08-07 18:53:30 train.log] INFO: Epoch: [15]  [Step 4000/14540]  lr: 0.000051  loss: 1.41917  detection_loss: 1.2563 (cls: 0.3181, box: 0.9381)  rpn_loss: 0.1629 (cls: 0.0634, box: 0.0995)
[2025-08-07 18:53:36 train.log] INFO: Epoch: [15]  [Step 4100/14540]  lr: 0.000051  loss: 1.05968  detection_loss: 1.0049 (cls: 0.3008, box: 0.7041)  rpn_loss: 0.0548 (cls: 0.0333, box: 0.0215)
[2025-08-07 18:53:42 train.log] INFO: Epoch: [15]  [Step 4200/14540]  lr: 0.000051  loss: 0.91368  detection_loss: 0.8337 (cls: 0.2278, box: 0.6059)  rpn_loss: 0.0800 (cls: 0.0438, box: 0.0362)
[2025-08-07 18:53:47 train.log] INFO: Epoch: [15]  [Step 4300/14540]  lr: 0.000051  loss: 0.64947  detection_loss: 0.5849 (cls: 0.1255, box: 0.4594)  rpn_loss: 0.0646 (cls: 0.0310, box: 0.0336)
[2025-08-07 18:53:53 train.log] INFO: Epoch: [15]  [Step 4400/14540]  lr: 0.000051  loss: 1.47069  detection_loss: 1.3044 (cls: 0.2907, box: 1.0137)  rpn_loss: 0.1663 (cls: 0.1109, box: 0.0555)
[2025-08-07 18:53:58 train.log] INFO: Epoch: [15]  [Step 4500/14540]  lr: 0.000051  loss: 1.10413  detection_loss: 0.9787 (cls: 0.3043, box: 0.6744)  rpn_loss: 0.1254 (cls: 0.0909, box: 0.0345)
[2025-08-07 18:54:03 train.log] INFO: Epoch: [15]  [Step 4600/14540]  lr: 0.000051  loss: 0.85305  detection_loss: 0.7659 (cls: 0.2031, box: 0.5628)  rpn_loss: 0.0872 (cls: 0.0455, box: 0.0417)
[2025-08-07 18:54:09 train.log] INFO: Epoch: [15]  [Step 4700/14540]  lr: 0.000051  loss: 0.95575  detection_loss: 0.8521 (cls: 0.1436, box: 0.7085)  rpn_loss: 0.1036 (cls: 0.0195, box: 0.0841)
[2025-08-07 18:54:14 train.log] INFO: Epoch: [15]  [Step 4800/14540]  lr: 0.000051  loss: 1.15449  detection_loss: 1.0794 (cls: 0.1779, box: 0.9015)  rpn_loss: 0.0751 (cls: 0.0218, box: 0.0533)
[2025-08-07 18:54:20 train.log] INFO: Epoch: [15]  [Step 4900/14540]  lr: 0.000051  loss: 0.75763  detection_loss: 0.6861 (cls: 0.0904, box: 0.5957)  rpn_loss: 0.0715 (cls: 0.0170, box: 0.0545)
[2025-08-07 18:54:25 train.log] INFO: Epoch: [15]  [Step 5000/14540]  lr: 0.000051  loss: 1.03041  detection_loss: 0.9306 (cls: 0.2555, box: 0.6751)  rpn_loss: 0.0998 (cls: 0.0494, box: 0.0504)
[2025-08-07 18:54:31 train.log] INFO: Epoch: [15]  [Step 5100/14540]  lr: 0.000051  loss: 1.31672  detection_loss: 1.1352 (cls: 0.0835, box: 1.0517)  rpn_loss: 0.1815 (cls: 0.0780, box: 0.1034)
[2025-08-07 18:54:36 train.log] INFO: Epoch: [15]  [Step 5200/14540]  lr: 0.000051  loss: 0.88581  detection_loss: 0.7936 (cls: 0.1417, box: 0.6519)  rpn_loss: 0.0922 (cls: 0.0541, box: 0.0382)
[2025-08-07 18:54:42 train.log] INFO: Epoch: [15]  [Step 5300/14540]  lr: 0.000051  loss: 1.17323  detection_loss: 1.0165 (cls: 0.3093, box: 0.7072)  rpn_loss: 0.1567 (cls: 0.0546, box: 0.1021)
[2025-08-07 18:54:47 train.log] INFO: Epoch: [15]  [Step 5400/14540]  lr: 0.000051  loss: 0.70705  detection_loss: 0.6237 (cls: 0.1612, box: 0.4626)  rpn_loss: 0.0833 (cls: 0.0615, box: 0.0218)
[2025-08-07 18:54:53 train.log] INFO: Epoch: [15]  [Step 5500/14540]  lr: 0.000051  loss: 0.90700  detection_loss: 0.8405 (cls: 0.2140, box: 0.6265)  rpn_loss: 0.0665 (cls: 0.0403, box: 0.0262)
[2025-08-07 18:54:58 train.log] INFO: Epoch: [15]  [Step 5600/14540]  lr: 0.000051  loss: 1.42082  detection_loss: 1.1248 (cls: 0.1833, box: 0.9414)  rpn_loss: 0.2961 (cls: 0.1188, box: 0.1772)
[2025-08-07 18:55:04 train.log] INFO: Epoch: [15]  [Step 5700/14540]  lr: 0.000051  loss: 0.91041  detection_loss: 0.8169 (cls: 0.1444, box: 0.6726)  rpn_loss: 0.0935 (cls: 0.0486, box: 0.0449)
[2025-08-07 18:55:09 train.log] INFO: Epoch: [15]  [Step 5800/14540]  lr: 0.000051  loss: 0.62377  detection_loss: 0.5608 (cls: 0.1151, box: 0.4457)  rpn_loss: 0.0630 (cls: 0.0342, box: 0.0287)
[2025-08-07 18:55:15 train.log] INFO: Epoch: [15]  [Step 5900/14540]  lr: 0.000051  loss: 1.46629  detection_loss: 1.3551 (cls: 0.3629, box: 0.9923)  rpn_loss: 0.1112 (cls: 0.0932, box: 0.0180)
[2025-08-07 18:55:20 train.log] INFO: Epoch: [15]  [Step 6000/14540]  lr: 0.000051  loss: 1.20838  detection_loss: 1.0691 (cls: 0.3756, box: 0.6935)  rpn_loss: 0.1393 (cls: 0.0767, box: 0.0626)
[2025-08-07 18:55:26 train.log] INFO: Epoch: [15]  [Step 6100/14540]  lr: 0.000051  loss: 1.33848  detection_loss: 1.2088 (cls: 0.2723, box: 0.9365)  rpn_loss: 0.1297 (cls: 0.0664, box: 0.0633)
[2025-08-07 18:55:31 train.log] INFO: Epoch: [15]  [Step 6200/14540]  lr: 0.000051  loss: 0.70201  detection_loss: 0.6417 (cls: 0.1213, box: 0.5204)  rpn_loss: 0.0603 (cls: 0.0206, box: 0.0397)
[2025-08-07 18:55:37 train.log] INFO: Epoch: [15]  [Step 6300/14540]  lr: 0.000051  loss: 0.65326  detection_loss: 0.6015 (cls: 0.1160, box: 0.4855)  rpn_loss: 0.0518 (cls: 0.0254, box: 0.0263)
[2025-08-07 18:55:42 train.log] INFO: Epoch: [15]  [Step 6400/14540]  lr: 0.000051  loss: 0.91834  detection_loss: 0.8066 (cls: 0.1628, box: 0.6438)  rpn_loss: 0.1117 (cls: 0.0993, box: 0.0124)
[2025-08-07 18:55:48 train.log] INFO: Epoch: [15]  [Step 6500/14540]  lr: 0.000051  loss: 0.87408  detection_loss: 0.7691 (cls: 0.1849, box: 0.5842)  rpn_loss: 0.1049 (cls: 0.0372, box: 0.0678)
[2025-08-07 18:55:54 train.log] INFO: Epoch: [15]  [Step 6600/14540]  lr: 0.000051  loss: 1.38980  detection_loss: 1.2998 (cls: 0.3575, box: 0.9423)  rpn_loss: 0.0900 (cls: 0.0171, box: 0.0728)
[2025-08-07 18:55:59 train.log] INFO: Epoch: [15]  [Step 6700/14540]  lr: 0.000051  loss: 1.24725  detection_loss: 1.1686 (cls: 0.3256, box: 0.8430)  rpn_loss: 0.0787 (cls: 0.0638, box: 0.0148)
[2025-08-07 18:56:05 train.log] INFO: Epoch: [15]  [Step 6800/14540]  lr: 0.000051  loss: 0.79472  detection_loss: 0.7369 (cls: 0.1413, box: 0.5956)  rpn_loss: 0.0578 (cls: 0.0242, box: 0.0336)
[2025-08-07 18:56:10 train.log] INFO: Epoch: [15]  [Step 6900/14540]  lr: 0.000051  loss: 0.90433  detection_loss: 0.8061 (cls: 0.3003, box: 0.5058)  rpn_loss: 0.0982 (cls: 0.0564, box: 0.0418)
[2025-08-07 18:56:16 train.log] INFO: Epoch: [15]  [Step 7000/14540]  lr: 0.000051  loss: 0.91882  detection_loss: 0.8288 (cls: 0.1654, box: 0.6633)  rpn_loss: 0.0901 (cls: 0.0783, box: 0.0117)
[2025-08-07 18:56:21 train.log] INFO: Epoch: [15]  [Step 7100/14540]  lr: 0.000051  loss: 1.23534  detection_loss: 0.9793 (cls: 0.1165, box: 0.8627)  rpn_loss: 0.2561 (cls: 0.0179, box: 0.2381)
[2025-08-07 18:56:27 train.log] INFO: Epoch: [15]  [Step 7200/14540]  lr: 0.000051  loss: 0.88879  detection_loss: 0.8212 (cls: 0.2198, box: 0.6014)  rpn_loss: 0.0676 (cls: 0.0436, box: 0.0240)
[2025-08-07 18:56:33 train.log] INFO: Epoch: [15]  [Step 7300/14540]  lr: 0.000051  loss: 0.97508  detection_loss: 0.9039 (cls: 0.1709, box: 0.7330)  rpn_loss: 0.0712 (cls: 0.0383, box: 0.0329)
[2025-08-07 18:56:38 train.log] INFO: Epoch: [15]  [Step 7400/14540]  lr: 0.000051  loss: 1.10633  detection_loss: 0.8950 (cls: 0.1922, box: 0.7029)  rpn_loss: 0.2113 (cls: 0.0790, box: 0.1323)
[2025-08-07 18:56:44 train.log] INFO: Epoch: [15]  [Step 7500/14540]  lr: 0.000051  loss: 2.05595  detection_loss: 1.7649 (cls: 0.3756, box: 1.3893)  rpn_loss: 0.2910 (cls: 0.0894, box: 0.2016)
[2025-08-07 18:56:49 train.log] INFO: Epoch: [15]  [Step 7600/14540]  lr: 0.000051  loss: 0.92630  detection_loss: 0.8649 (cls: 0.2444, box: 0.6205)  rpn_loss: 0.0614 (cls: 0.0288, box: 0.0326)
[2025-08-07 18:56:55 train.log] INFO: Epoch: [15]  [Step 7700/14540]  lr: 0.000051  loss: 1.16374  detection_loss: 1.0896 (cls: 0.1823, box: 0.9073)  rpn_loss: 0.0742 (cls: 0.0233, box: 0.0509)
[2025-08-07 18:57:00 train.log] INFO: Epoch: [15]  [Step 7800/14540]  lr: 0.000051  loss: 1.45034  detection_loss: 1.3063 (cls: 0.3056, box: 1.0007)  rpn_loss: 0.1441 (cls: 0.0748, box: 0.0693)
[2025-08-07 18:57:06 train.log] INFO: Epoch: [15]  [Step 7900/14540]  lr: 0.000051  loss: 1.62091  detection_loss: 1.4370 (cls: 0.4358, box: 1.0013)  rpn_loss: 0.1839 (cls: 0.0921, box: 0.0918)
[2025-08-07 18:57:11 train.log] INFO: Epoch: [15]  [Step 8000/14540]  lr: 0.000051  loss: 0.71904  detection_loss: 0.6167 (cls: 0.1496, box: 0.4671)  rpn_loss: 0.1023 (cls: 0.0645, box: 0.0378)
[2025-08-07 18:57:17 train.log] INFO: Epoch: [15]  [Step 8100/14540]  lr: 0.000051  loss: 1.17862  detection_loss: 1.0230 (cls: 0.1736, box: 0.8494)  rpn_loss: 0.1556 (cls: 0.0778, box: 0.0778)
[2025-08-07 18:57:23 train.log] INFO: Epoch: [15]  [Step 8200/14540]  lr: 0.000051  loss: 1.10100  detection_loss: 1.0127 (cls: 0.1601, box: 0.8526)  rpn_loss: 0.0883 (cls: 0.0251, box: 0.0632)
[2025-08-07 18:57:28 train.log] INFO: Epoch: [15]  [Step 8300/14540]  lr: 0.000051  loss: 1.14491  detection_loss: 1.0038 (cls: 0.1528, box: 0.8510)  rpn_loss: 0.1411 (cls: 0.0966, box: 0.0445)
[2025-08-07 18:57:34 train.log] INFO: Epoch: [15]  [Step 8400/14540]  lr: 0.000051  loss: 1.12200  detection_loss: 0.9465 (cls: 0.2856, box: 0.6609)  rpn_loss: 0.1755 (cls: 0.1506, box: 0.0249)
[2025-08-07 18:57:40 train.log] INFO: Epoch: [15]  [Step 8500/14540]  lr: 0.000051  loss: 1.20931  detection_loss: 1.0810 (cls: 0.2194, box: 0.8616)  rpn_loss: 0.1283 (cls: 0.0681, box: 0.0602)
[2025-08-07 18:57:45 train.log] INFO: Epoch: [15]  [Step 8600/14540]  lr: 0.000051  loss: 1.38208  detection_loss: 1.1407 (cls: 0.3464, box: 0.7943)  rpn_loss: 0.2413 (cls: 0.0645, box: 0.1768)
[2025-08-07 18:57:51 train.log] INFO: Epoch: [15]  [Step 8700/14540]  lr: 0.000051  loss: 0.94872  detection_loss: 0.8633 (cls: 0.1360, box: 0.7273)  rpn_loss: 0.0854 (cls: 0.0305, box: 0.0549)
[2025-08-07 18:57:56 train.log] INFO: Epoch: [15]  [Step 8800/14540]  lr: 0.000051  loss: 1.20841  detection_loss: 1.1436 (cls: 0.4365, box: 0.7070)  rpn_loss: 0.0648 (cls: 0.0305, box: 0.0344)
[2025-08-07 18:58:02 train.log] INFO: Epoch: [15]  [Step 8900/14540]  lr: 0.000051  loss: 1.28542  detection_loss: 1.2125 (cls: 0.2385, box: 0.9740)  rpn_loss: 0.0729 (cls: 0.0449, box: 0.0281)
[2025-08-07 18:58:07 train.log] INFO: Epoch: [15]  [Step 9000/14540]  lr: 0.000051  loss: 1.48206  detection_loss: 1.3172 (cls: 0.2874, box: 1.0298)  rpn_loss: 0.1649 (cls: 0.1371, box: 0.0278)
[2025-08-07 18:58:13 train.log] INFO: Epoch: [15]  [Step 9100/14540]  lr: 0.000051  loss: 0.86106  detection_loss: 0.7460 (cls: 0.2181, box: 0.5279)  rpn_loss: 0.1150 (cls: 0.0804, box: 0.0347)
[2025-08-07 18:58:18 train.log] INFO: Epoch: [15]  [Step 9200/14540]  lr: 0.000051  loss: 0.61946  detection_loss: 0.5436 (cls: 0.1753, box: 0.3683)  rpn_loss: 0.0759 (cls: 0.0278, box: 0.0481)
[2025-08-07 18:58:24 train.log] INFO: Epoch: [15]  [Step 9300/14540]  lr: 0.000051  loss: 0.45186  detection_loss: 0.3564 (cls: 0.0920, box: 0.2644)  rpn_loss: 0.0955 (cls: 0.0484, box: 0.0470)
[2025-08-07 18:58:29 train.log] INFO: Epoch: [15]  [Step 9400/14540]  lr: 0.000051  loss: 0.69967  detection_loss: 0.6418 (cls: 0.1774, box: 0.4644)  rpn_loss: 0.0578 (cls: 0.0326, box: 0.0252)
[2025-08-07 18:58:35 train.log] INFO: Epoch: [15]  [Step 9500/14540]  lr: 0.000051  loss: 1.29814  detection_loss: 1.1750 (cls: 0.3166, box: 0.8584)  rpn_loss: 0.1231 (cls: 0.0778, box: 0.0453)
[2025-08-07 18:58:41 train.log] INFO: Epoch: [15]  [Step 9600/14540]  lr: 0.000051  loss: 0.94771  detection_loss: 0.8310 (cls: 0.2181, box: 0.6129)  rpn_loss: 0.1167 (cls: 0.0704, box: 0.0463)
[2025-08-07 18:58:47 train.log] INFO: Epoch: [15]  [Step 9700/14540]  lr: 0.000051  loss: 0.77991  detection_loss: 0.7103 (cls: 0.1563, box: 0.5539)  rpn_loss: 0.0697 (cls: 0.0265, box: 0.0431)
[2025-08-07 18:58:53 train.log] INFO: Epoch: [15]  [Step 9800/14540]  lr: 0.000051  loss: 0.81105  detection_loss: 0.7388 (cls: 0.2468, box: 0.4919)  rpn_loss: 0.0723 (cls: 0.0237, box: 0.0486)
[2025-08-07 18:58:59 train.log] INFO: Epoch: [15]  [Step 9900/14540]  lr: 0.000051  loss: 0.82355  detection_loss: 0.7131 (cls: 0.1601, box: 0.5530)  rpn_loss: 0.1105 (cls: 0.0928, box: 0.0177)
[2025-08-07 18:59:05 train.log] INFO: Epoch: [15]  [Step 10000/14540]  lr: 0.000051  loss: 1.26585  detection_loss: 1.1438 (cls: 0.3322, box: 0.8116)  rpn_loss: 0.1220 (cls: 0.0226, box: 0.0994)
[2025-08-07 18:59:10 train.log] INFO: Epoch: [15]  [Step 10100/14540]  lr: 0.000051  loss: 0.80452  detection_loss: 0.7234 (cls: 0.2210, box: 0.5024)  rpn_loss: 0.0811 (cls: 0.0461, box: 0.0350)
[2025-08-07 18:59:16 train.log] INFO: Epoch: [15]  [Step 10200/14540]  lr: 0.000051  loss: 1.37933  detection_loss: 1.1874 (cls: 0.3185, box: 0.8689)  rpn_loss: 0.1920 (cls: 0.0926, box: 0.0994)
[2025-08-07 18:59:22 train.log] INFO: Epoch: [15]  [Step 10300/14540]  lr: 0.000051  loss: 0.62906  detection_loss: 0.5455 (cls: 0.1639, box: 0.3816)  rpn_loss: 0.0836 (cls: 0.0637, box: 0.0198)
[2025-08-07 18:59:28 train.log] INFO: Epoch: [15]  [Step 10400/14540]  lr: 0.000051  loss: 1.57459  detection_loss: 1.4062 (cls: 0.3636, box: 1.0426)  rpn_loss: 0.1684 (cls: 0.0738, box: 0.0946)
[2025-08-07 18:59:33 train.log] INFO: Epoch: [15]  [Step 10500/14540]  lr: 0.000051  loss: 1.61703  detection_loss: 1.5424 (cls: 0.1761, box: 1.3664)  rpn_loss: 0.0746 (cls: 0.0459, box: 0.0287)
[2025-08-07 18:59:39 train.log] INFO: Epoch: [15]  [Step 10600/14540]  lr: 0.000051  loss: 1.35987  detection_loss: 1.2874 (cls: 0.1869, box: 1.1005)  rpn_loss: 0.0724 (cls: 0.0302, box: 0.0422)
[2025-08-07 18:59:45 train.log] INFO: Epoch: [15]  [Step 10700/14540]  lr: 0.000051  loss: 1.20125  detection_loss: 1.0956 (cls: 0.2260, box: 0.8696)  rpn_loss: 0.1056 (cls: 0.0283, box: 0.0773)
[2025-08-07 18:59:51 train.log] INFO: Epoch: [15]  [Step 10800/14540]  lr: 0.000051  loss: 0.97247  detection_loss: 0.8652 (cls: 0.3484, box: 0.5168)  rpn_loss: 0.1073 (cls: 0.0627, box: 0.0446)
[2025-08-07 18:59:56 train.log] INFO: Epoch: [15]  [Step 10900/14540]  lr: 0.000051  loss: 2.22715  detection_loss: 2.0567 (cls: 0.5428, box: 1.5138)  rpn_loss: 0.1705 (cls: 0.1007, box: 0.0698)
[2025-08-07 19:00:02 train.log] INFO: Epoch: [15]  [Step 11000/14540]  lr: 0.000051  loss: 0.93604  detection_loss: 0.8415 (cls: 0.1980, box: 0.6435)  rpn_loss: 0.0945 (cls: 0.0287, box: 0.0658)
[2025-08-07 19:00:07 train.log] INFO: Epoch: [15]  [Step 11100/14540]  lr: 0.000051  loss: 0.88312  detection_loss: 0.7792 (cls: 0.1471, box: 0.6321)  rpn_loss: 0.1039 (cls: 0.0203, box: 0.0836)
[2025-08-07 19:00:13 train.log] INFO: Epoch: [15]  [Step 11200/14540]  lr: 0.000051  loss: 1.52179  detection_loss: 1.2220 (cls: 0.2090, box: 1.0131)  rpn_loss: 0.2998 (cls: 0.0226, box: 0.2771)
[2025-08-07 19:00:18 train.log] INFO: Epoch: [15]  [Step 11300/14540]  lr: 0.000051  loss: 0.64147  detection_loss: 0.5403 (cls: 0.1222, box: 0.4181)  rpn_loss: 0.1012 (cls: 0.0821, box: 0.0191)
[2025-08-07 19:00:23 train.log] INFO: Epoch: [15]  [Step 11400/14540]  lr: 0.000051  loss: 1.00043  detection_loss: 0.8976 (cls: 0.2213, box: 0.6763)  rpn_loss: 0.1028 (cls: 0.0591, box: 0.0437)
[2025-08-07 19:00:29 train.log] INFO: Epoch: [15]  [Step 11500/14540]  lr: 0.000051  loss: 1.13028  detection_loss: 1.0758 (cls: 0.2018, box: 0.8740)  rpn_loss: 0.0544 (cls: 0.0370, box: 0.0175)
[2025-08-07 19:00:34 train.log] INFO: Epoch: [15]  [Step 11600/14540]  lr: 0.000051  loss: 1.35776  detection_loss: 1.2791 (cls: 0.1952, box: 1.0839)  rpn_loss: 0.0786 (cls: 0.0662, box: 0.0125)
[2025-08-07 19:00:40 train.log] INFO: Epoch: [15]  [Step 11700/14540]  lr: 0.000051  loss: 1.21387  detection_loss: 1.1438 (cls: 0.3148, box: 0.8290)  rpn_loss: 0.0701 (cls: 0.0154, box: 0.0546)
[2025-08-07 19:00:46 train.log] INFO: Epoch: [15]  [Step 11800/14540]  lr: 0.000051  loss: 1.21883  detection_loss: 1.0795 (cls: 0.3411, box: 0.7384)  rpn_loss: 0.1394 (cls: 0.0901, box: 0.0492)
[2025-08-07 19:00:52 train.log] INFO: Epoch: [15]  [Step 11900/14540]  lr: 0.000051  loss: 1.11513  detection_loss: 0.9926 (cls: 0.1530, box: 0.8396)  rpn_loss: 0.1226 (cls: 0.0610, box: 0.0616)
[2025-08-07 19:00:58 train.log] INFO: Epoch: [15]  [Step 12000/14540]  lr: 0.000051  loss: 0.98545  detection_loss: 0.9448 (cls: 0.1961, box: 0.7487)  rpn_loss: 0.0407 (cls: 0.0124, box: 0.0283)
[2025-08-07 19:01:04 train.log] INFO: Epoch: [15]  [Step 12100/14540]  lr: 0.000051  loss: 0.71151  detection_loss: 0.6424 (cls: 0.1013, box: 0.5411)  rpn_loss: 0.0691 (cls: 0.0330, box: 0.0361)
[2025-08-07 19:01:09 train.log] INFO: Epoch: [15]  [Step 12200/14540]  lr: 0.000051  loss: 1.01623  detection_loss: 0.8623 (cls: 0.2622, box: 0.6001)  rpn_loss: 0.1540 (cls: 0.0606, box: 0.0934)
[2025-08-07 19:01:15 train.log] INFO: Epoch: [15]  [Step 12300/14540]  lr: 0.000051  loss: 1.12583  detection_loss: 1.0454 (cls: 0.1657, box: 0.8797)  rpn_loss: 0.0804 (cls: 0.0446, box: 0.0358)
[2025-08-07 19:01:21 train.log] INFO: Epoch: [15]  [Step 12400/14540]  lr: 0.000051  loss: 1.18052  detection_loss: 1.0631 (cls: 0.2636, box: 0.7995)  rpn_loss: 0.1175 (cls: 0.0678, box: 0.0497)
[2025-08-07 19:01:27 train.log] INFO: Epoch: [15]  [Step 12500/14540]  lr: 0.000051  loss: 0.76646  detection_loss: 0.6193 (cls: 0.2246, box: 0.3948)  rpn_loss: 0.1471 (cls: 0.0462, box: 0.1009)
[2025-08-07 19:01:32 train.log] INFO: Epoch: [15]  [Step 12600/14540]  lr: 0.000051  loss: 1.13839  detection_loss: 1.0399 (cls: 0.2031, box: 0.8369)  rpn_loss: 0.0985 (cls: 0.0324, box: 0.0661)
[2025-08-07 19:01:38 train.log] INFO: Epoch: [15]  [Step 12700/14540]  lr: 0.000051  loss: 1.02564  detection_loss: 0.9550 (cls: 0.2171, box: 0.7378)  rpn_loss: 0.0707 (cls: 0.0502, box: 0.0205)
[2025-08-07 19:01:44 train.log] INFO: Epoch: [15]  [Step 12800/14540]  lr: 0.000051  loss: 0.84585  detection_loss: 0.7714 (cls: 0.2320, box: 0.5395)  rpn_loss: 0.0744 (cls: 0.0364, box: 0.0380)
[2025-08-07 19:01:49 train.log] INFO: Epoch: [15]  [Step 12900/14540]  lr: 0.000051  loss: 0.71638  detection_loss: 0.6169 (cls: 0.1529, box: 0.4640)  rpn_loss: 0.0995 (cls: 0.0552, box: 0.0444)
[2025-08-07 19:01:55 train.log] INFO: Epoch: [15]  [Step 13000/14540]  lr: 0.000051  loss: 1.27376  detection_loss: 1.2163 (cls: 0.4393, box: 0.7770)  rpn_loss: 0.0575 (cls: 0.0312, box: 0.0263)
[2025-08-07 19:02:01 train.log] INFO: Epoch: [15]  [Step 13100/14540]  lr: 0.000051  loss: 1.83572  detection_loss: 1.7265 (cls: 0.3063, box: 1.4202)  rpn_loss: 0.1092 (cls: 0.0551, box: 0.0541)
[2025-08-07 19:02:06 train.log] INFO: Epoch: [15]  [Step 13200/14540]  lr: 0.000051  loss: 1.00696  detection_loss: 0.9278 (cls: 0.2901, box: 0.6377)  rpn_loss: 0.0791 (cls: 0.0379, box: 0.0413)
[2025-08-07 19:02:12 train.log] INFO: Epoch: [15]  [Step 13300/14540]  lr: 0.000051  loss: 1.43706  detection_loss: 1.2046 (cls: 0.4239, box: 0.7807)  rpn_loss: 0.2325 (cls: 0.0957, box: 0.1368)
[2025-08-07 19:02:17 train.log] INFO: Epoch: [15]  [Step 13400/14540]  lr: 0.000051  loss: 1.06841  detection_loss: 0.9765 (cls: 0.2286, box: 0.7479)  rpn_loss: 0.0919 (cls: 0.0499, box: 0.0420)
[2025-08-07 19:02:23 train.log] INFO: Epoch: [15]  [Step 13500/14540]  lr: 0.000051  loss: 1.31887  detection_loss: 1.2079 (cls: 0.3255, box: 0.8824)  rpn_loss: 0.1110 (cls: 0.0504, box: 0.0606)
[2025-08-07 19:02:29 train.log] INFO: Epoch: [15]  [Step 13600/14540]  lr: 0.000051  loss: 1.08533  detection_loss: 1.0099 (cls: 0.1658, box: 0.8441)  rpn_loss: 0.0755 (cls: 0.0166, box: 0.0589)
[2025-08-07 19:02:34 train.log] INFO: Epoch: [15]  [Step 13700/14540]  lr: 0.000051  loss: 1.31263  detection_loss: 1.2069 (cls: 0.4359, box: 0.7709)  rpn_loss: 0.1058 (cls: 0.0835, box: 0.0223)
[2025-08-07 19:02:40 train.log] INFO: Epoch: [15]  [Step 13800/14540]  lr: 0.000051  loss: 1.38527  detection_loss: 1.1330 (cls: 0.3101, box: 0.8229)  rpn_loss: 0.2523 (cls: 0.0874, box: 0.1648)
[2025-08-07 19:02:45 train.log] INFO: Epoch: [15]  [Step 13900/14540]  lr: 0.000051  loss: 0.93641  detection_loss: 0.7636 (cls: 0.2464, box: 0.5172)  rpn_loss: 0.1728 (cls: 0.0569, box: 0.1159)
[2025-08-07 19:02:51 train.log] INFO: Epoch: [15]  [Step 14000/14540]  lr: 0.000051  loss: 1.16789  detection_loss: 1.0795 (cls: 0.2215, box: 0.8581)  rpn_loss: 0.0884 (cls: 0.0367, box: 0.0517)
[2025-08-07 19:02:56 train.log] INFO: Epoch: [15]  [Step 14100/14540]  lr: 0.000051  loss: 0.65261  detection_loss: 0.5992 (cls: 0.1136, box: 0.4857)  rpn_loss: 0.0534 (cls: 0.0244, box: 0.0290)
[2025-08-07 19:03:02 train.log] INFO: Epoch: [15]  [Step 14200/14540]  lr: 0.000051  loss: 0.83309  detection_loss: 0.7153 (cls: 0.1962, box: 0.5191)  rpn_loss: 0.1178 (cls: 0.0872, box: 0.0307)
[2025-08-07 19:03:07 train.log] INFO: Epoch: [15]  [Step 14300/14540]  lr: 0.000051  loss: 1.61846  detection_loss: 1.5451 (cls: 0.3441, box: 1.2010)  rpn_loss: 0.0734 (cls: 0.0447, box: 0.0287)
[2025-08-07 19:03:13 train.log] INFO: Epoch: [15]  [Step 14400/14540]  lr: 0.000051  loss: 1.03688  detection_loss: 0.8920 (cls: 0.2125, box: 0.6795)  rpn_loss: 0.1449 (cls: 0.0993, box: 0.0455)
[2025-08-07 19:03:18 train.log] INFO: Epoch: [15]  [Step 14500/14540]  lr: 0.000051  loss: 1.68479  detection_loss: 1.5699 (cls: 0.3444, box: 1.2255)  rpn_loss: 0.1149 (cls: 0.0323, box: 0.0826)
[2025-08-07 19:06:37 train.log] INFO: Epoch: [16]  [Step 100/14540]  lr: 0.000045  loss: 1.43462  detection_loss: 1.2387 (cls: 0.2887, box: 0.9500)  rpn_loss: 0.1959 (cls: 0.0958, box: 0.1001)
[2025-08-07 19:06:43 train.log] INFO: Epoch: [16]  [Step 200/14540]  lr: 0.000045  loss: 1.97275  detection_loss: 1.8023 (cls: 0.2669, box: 1.5354)  rpn_loss: 0.1705 (cls: 0.1489, box: 0.0216)
[2025-08-07 19:06:48 train.log] INFO: Epoch: [16]  [Step 300/14540]  lr: 0.000045  loss: 0.64580  detection_loss: 0.5361 (cls: 0.1414, box: 0.3947)  rpn_loss: 0.1097 (cls: 0.0822, box: 0.0275)
[2025-08-07 19:06:54 train.log] INFO: Epoch: [16]  [Step 400/14540]  lr: 0.000045  loss: 1.00624  detection_loss: 0.9157 (cls: 0.1592, box: 0.7564)  rpn_loss: 0.0906 (cls: 0.0649, box: 0.0257)
[2025-08-07 19:07:00 train.log] INFO: Epoch: [16]  [Step 500/14540]  lr: 0.000045  loss: 0.88381  detection_loss: 0.7528 (cls: 0.2167, box: 0.5361)  rpn_loss: 0.1310 (cls: 0.0269, box: 0.1041)
[2025-08-07 19:07:05 train.log] INFO: Epoch: [16]  [Step 600/14540]  lr: 0.000045  loss: 1.12748  detection_loss: 1.0542 (cls: 0.2124, box: 0.8418)  rpn_loss: 0.0732 (cls: 0.0446, box: 0.0286)
[2025-08-07 19:07:10 train.log] INFO: Epoch: [16]  [Step 700/14540]  lr: 0.000045  loss: 0.70551  detection_loss: 0.6303 (cls: 0.1366, box: 0.4937)  rpn_loss: 0.0752 (cls: 0.0266, box: 0.0486)
[2025-08-07 19:07:16 train.log] INFO: Epoch: [16]  [Step 800/14540]  lr: 0.000045  loss: 0.74402  detection_loss: 0.6726 (cls: 0.2287, box: 0.4440)  rpn_loss: 0.0714 (cls: 0.0509, box: 0.0205)
[2025-08-07 19:07:22 train.log] INFO: Epoch: [16]  [Step 900/14540]  lr: 0.000045  loss: 0.57257  detection_loss: 0.4767 (cls: 0.1304, box: 0.3463)  rpn_loss: 0.0959 (cls: 0.0701, box: 0.0257)
[2025-08-07 19:07:28 train.log] INFO: Epoch: [16]  [Step 1000/14540]  lr: 0.000045  loss: 0.82746  detection_loss: 0.6795 (cls: 0.1774, box: 0.5021)  rpn_loss: 0.1480 (cls: 0.1294, box: 0.0186)
[2025-08-07 19:07:34 train.log] INFO: Epoch: [16]  [Step 1100/14540]  lr: 0.000045  loss: 1.48439  detection_loss: 1.2867 (cls: 0.4065, box: 0.8803)  rpn_loss: 0.1977 (cls: 0.0801, box: 0.1175)
[2025-08-07 19:07:39 train.log] INFO: Epoch: [16]  [Step 1200/14540]  lr: 0.000045  loss: 1.23984  detection_loss: 1.1456 (cls: 0.5507, box: 0.5949)  rpn_loss: 0.0942 (cls: 0.0603, box: 0.0339)
[2025-08-07 19:07:45 train.log] INFO: Epoch: [16]  [Step 1300/14540]  lr: 0.000045  loss: 0.79315  detection_loss: 0.7267 (cls: 0.1457, box: 0.5810)  rpn_loss: 0.0665 (cls: 0.0439, box: 0.0225)
[2025-08-07 19:07:50 train.log] INFO: Epoch: [16]  [Step 1400/14540]  lr: 0.000045  loss: 1.27775  detection_loss: 1.1573 (cls: 0.2328, box: 0.9246)  rpn_loss: 0.1204 (cls: 0.0825, box: 0.0379)
[2025-08-07 19:07:56 train.log] INFO: Epoch: [16]  [Step 1500/14540]  lr: 0.000045  loss: 0.79504  detection_loss: 0.7444 (cls: 0.1718, box: 0.5726)  rpn_loss: 0.0507 (cls: 0.0326, box: 0.0181)
[2025-08-07 19:08:02 train.log] INFO: Epoch: [16]  [Step 1600/14540]  lr: 0.000045  loss: 0.69406  detection_loss: 0.6266 (cls: 0.2002, box: 0.4264)  rpn_loss: 0.0675 (cls: 0.0385, box: 0.0290)
[2025-08-07 19:08:07 train.log] INFO: Epoch: [16]  [Step 1700/14540]  lr: 0.000045  loss: 1.42078  detection_loss: 1.3046 (cls: 0.3452, box: 0.9594)  rpn_loss: 0.1162 (cls: 0.0565, box: 0.0597)
[2025-08-07 19:08:13 train.log] INFO: Epoch: [16]  [Step 1800/14540]  lr: 0.000045  loss: 1.08414  detection_loss: 0.9665 (cls: 0.2170, box: 0.7495)  rpn_loss: 0.1176 (cls: 0.0564, box: 0.0612)
[2025-08-07 19:08:18 train.log] INFO: Epoch: [16]  [Step 1900/14540]  lr: 0.000045  loss: 0.75210  detection_loss: 0.6553 (cls: 0.1505, box: 0.5047)  rpn_loss: 0.0968 (cls: 0.0334, box: 0.0634)
[2025-08-07 19:08:24 train.log] INFO: Epoch: [16]  [Step 2000/14540]  lr: 0.000045  loss: 0.87645  detection_loss: 0.6849 (cls: 0.2029, box: 0.4820)  rpn_loss: 0.1915 (cls: 0.0636, box: 0.1279)
[2025-08-07 19:08:29 train.log] INFO: Epoch: [16]  [Step 2100/14540]  lr: 0.000045  loss: 1.34701  detection_loss: 1.1510 (cls: 0.3506, box: 0.8004)  rpn_loss: 0.1960 (cls: 0.0622, box: 0.1338)
[2025-08-07 19:08:35 train.log] INFO: Epoch: [16]  [Step 2200/14540]  lr: 0.000045  loss: 0.91367  detection_loss: 0.8650 (cls: 0.2144, box: 0.6507)  rpn_loss: 0.0486 (cls: 0.0286, box: 0.0200)
[2025-08-07 19:08:41 train.log] INFO: Epoch: [16]  [Step 2300/14540]  lr: 0.000045  loss: 1.19467  detection_loss: 1.0568 (cls: 0.1717, box: 0.8851)  rpn_loss: 0.1379 (cls: 0.0243, box: 0.1136)
[2025-08-07 19:08:47 train.log] INFO: Epoch: [16]  [Step 2400/14540]  lr: 0.000045  loss: 0.74964  detection_loss: 0.6928 (cls: 0.1233, box: 0.5695)  rpn_loss: 0.0569 (cls: 0.0307, box: 0.0261)
[2025-08-07 19:08:52 train.log] INFO: Epoch: [16]  [Step 2500/14540]  lr: 0.000045  loss: 1.07123  detection_loss: 1.0170 (cls: 0.2522, box: 0.7649)  rpn_loss: 0.0542 (cls: 0.0228, box: 0.0314)
[2025-08-07 19:08:58 train.log] INFO: Epoch: [16]  [Step 2600/14540]  lr: 0.000045  loss: 0.78565  detection_loss: 0.6948 (cls: 0.2450, box: 0.4498)  rpn_loss: 0.0909 (cls: 0.0348, box: 0.0561)
[2025-08-07 19:09:03 train.log] INFO: Epoch: [16]  [Step 2700/14540]  lr: 0.000045  loss: 0.86379  detection_loss: 0.6379 (cls: 0.1659, box: 0.4720)  rpn_loss: 0.2259 (cls: 0.0400, box: 0.1859)
[2025-08-07 19:09:09 train.log] INFO: Epoch: [16]  [Step 2800/14540]  lr: 0.000045  loss: 1.72597  detection_loss: 1.5793 (cls: 0.4963, box: 1.0830)  rpn_loss: 0.1466 (cls: 0.1001, box: 0.0465)
[2025-08-07 19:09:15 train.log] INFO: Epoch: [16]  [Step 2900/14540]  lr: 0.000045  loss: 1.17892  detection_loss: 0.7135 (cls: 0.0980, box: 0.6155)  rpn_loss: 0.4654 (cls: 0.0402, box: 0.4252)
[2025-08-07 19:09:20 train.log] INFO: Epoch: [16]  [Step 3000/14540]  lr: 0.000045  loss: 1.05352  detection_loss: 0.9309 (cls: 0.2091, box: 0.7218)  rpn_loss: 0.1226 (cls: 0.0416, box: 0.0810)
[2025-08-07 19:09:26 train.log] INFO: Epoch: [16]  [Step 3100/14540]  lr: 0.000045  loss: 0.69234  detection_loss: 0.6135 (cls: 0.1407, box: 0.4728)  rpn_loss: 0.0789 (cls: 0.0500, box: 0.0288)
[2025-08-07 19:09:31 train.log] INFO: Epoch: [16]  [Step 3200/14540]  lr: 0.000045  loss: 1.07201  detection_loss: 0.8671 (cls: 0.1957, box: 0.6714)  rpn_loss: 0.2049 (cls: 0.0365, box: 0.1684)
[2025-08-07 19:09:37 train.log] INFO: Epoch: [16]  [Step 3300/14540]  lr: 0.000045  loss: 1.04453  detection_loss: 0.9730 (cls: 0.2234, box: 0.7496)  rpn_loss: 0.0715 (cls: 0.0541, box: 0.0175)
[2025-08-07 19:09:42 train.log] INFO: Epoch: [16]  [Step 3400/14540]  lr: 0.000045  loss: 0.70777  detection_loss: 0.6287 (cls: 0.1715, box: 0.4572)  rpn_loss: 0.0791 (cls: 0.0582, box: 0.0209)
[2025-08-07 19:09:48 train.log] INFO: Epoch: [16]  [Step 3500/14540]  lr: 0.000045  loss: 1.40251  detection_loss: 1.2773 (cls: 0.2265, box: 1.0509)  rpn_loss: 0.1252 (cls: 0.0656, box: 0.0596)
[2025-08-07 19:09:54 train.log] INFO: Epoch: [16]  [Step 3600/14540]  lr: 0.000045  loss: 1.68273  detection_loss: 1.4372 (cls: 0.2270, box: 1.2102)  rpn_loss: 0.2455 (cls: 0.0301, box: 0.2154)
[2025-08-07 19:09:56 train.log] INFO: Epoch: [16]  [Step 3635/14540]  lr: 0.000045  loss: 1.00467  detection_loss: 0.8938 (cls: 0.1721, box: 0.7217)  rpn_loss: 0.1109 (cls: 0.0514, box: 0.0595)
[2025-08-07 19:09:59 train.log] INFO: Epoch: [16]  [Step 3700/14540]  lr: 0.000045  loss: 1.63311  detection_loss: 1.4379 (cls: 0.4638, box: 0.9741)  rpn_loss: 0.1952 (cls: 0.1552, box: 0.0400)
[2025-08-07 19:10:04 train.log] INFO: Epoch: [16]  [Step 3800/14540]  lr: 0.000045  loss: 1.80580  detection_loss: 1.6237 (cls: 0.3096, box: 1.3142)  rpn_loss: 0.1821 (cls: 0.1037, box: 0.0784)
[2025-08-07 19:10:10 train.log] INFO: Epoch: [16]  [Step 3900/14540]  lr: 0.000045  loss: 0.67426  detection_loss: 0.5913 (cls: 0.1252, box: 0.4661)  rpn_loss: 0.0830 (cls: 0.0175, box: 0.0655)
[2025-08-07 19:10:15 train.log] INFO: Epoch: [16]  [Step 4000/14540]  lr: 0.000045  loss: 1.00696  detection_loss: 0.8519 (cls: 0.1172, box: 0.7348)  rpn_loss: 0.1550 (cls: 0.0511, box: 0.1039)
[2025-08-07 19:10:21 train.log] INFO: Epoch: [16]  [Step 4100/14540]  lr: 0.000045  loss: 1.30738  detection_loss: 1.1913 (cls: 0.2243, box: 0.9670)  rpn_loss: 0.1161 (cls: 0.0369, box: 0.0792)
[2025-08-07 19:10:26 train.log] INFO: Epoch: [16]  [Step 4200/14540]  lr: 0.000045  loss: 1.07398  detection_loss: 0.8965 (cls: 0.2491, box: 0.6475)  rpn_loss: 0.1775 (cls: 0.1241, box: 0.0533)
[2025-08-07 19:10:32 train.log] INFO: Epoch: [16]  [Step 4300/14540]  lr: 0.000045  loss: 1.17608  detection_loss: 1.0986 (cls: 0.1982, box: 0.9005)  rpn_loss: 0.0774 (cls: 0.0391, box: 0.0383)
[2025-08-07 19:10:37 train.log] INFO: Epoch: [16]  [Step 4400/14540]  lr: 0.000045  loss: 1.19153  detection_loss: 1.0077 (cls: 0.3499, box: 0.6577)  rpn_loss: 0.1839 (cls: 0.1305, box: 0.0534)
[2025-08-07 19:10:43 train.log] INFO: Epoch: [16]  [Step 4500/14540]  lr: 0.000045  loss: 1.12667  detection_loss: 1.0628 (cls: 0.2431, box: 0.8198)  rpn_loss: 0.0638 (cls: 0.0423, box: 0.0216)
[2025-08-07 19:10:49 train.log] INFO: Epoch: [16]  [Step 4600/14540]  lr: 0.000045  loss: 1.17968  detection_loss: 1.0666 (cls: 0.2921, box: 0.7744)  rpn_loss: 0.1131 (cls: 0.0744, box: 0.0388)
[2025-08-07 19:10:54 train.log] INFO: Epoch: [16]  [Step 4700/14540]  lr: 0.000045  loss: 0.53858  detection_loss: 0.4645 (cls: 0.1366, box: 0.3279)  rpn_loss: 0.0741 (cls: 0.0520, box: 0.0221)
[2025-08-07 19:10:59 train.log] INFO: Epoch: [16]  [Step 4800/14540]  lr: 0.000045  loss: 1.01988  detection_loss: 0.8788 (cls: 0.3106, box: 0.5683)  rpn_loss: 0.1410 (cls: 0.0691, box: 0.0719)
[2025-08-07 19:11:05 train.log] INFO: Epoch: [16]  [Step 4900/14540]  lr: 0.000045  loss: 0.65656  detection_loss: 0.6108 (cls: 0.1864, box: 0.4243)  rpn_loss: 0.0458 (cls: 0.0332, box: 0.0126)
[2025-08-07 19:11:11 train.log] INFO: Epoch: [16]  [Step 5000/14540]  lr: 0.000045  loss: 1.16153  detection_loss: 0.9359 (cls: 0.3214, box: 0.6145)  rpn_loss: 0.2256 (cls: 0.0922, box: 0.1334)
[2025-08-07 19:11:16 train.log] INFO: Epoch: [16]  [Step 5100/14540]  lr: 0.000045  loss: 1.36284  detection_loss: 1.2884 (cls: 0.2739, box: 1.0145)  rpn_loss: 0.0745 (cls: 0.0483, box: 0.0261)
[2025-08-07 19:11:21 train.log] INFO: Epoch: [16]  [Step 5200/14540]  lr: 0.000045  loss: 1.02534  detection_loss: 0.9464 (cls: 0.2023, box: 0.7441)  rpn_loss: 0.0789 (cls: 0.0534, box: 0.0255)
[2025-08-07 19:11:27 train.log] INFO: Epoch: [16]  [Step 5300/14540]  lr: 0.000045  loss: 1.25541  detection_loss: 1.1031 (cls: 0.1653, box: 0.9377)  rpn_loss: 0.1524 (cls: 0.1234, box: 0.0289)
[2025-08-07 19:11:32 train.log] INFO: Epoch: [16]  [Step 5400/14540]  lr: 0.000045  loss: 1.65369  detection_loss: 1.4654 (cls: 0.1645, box: 1.3009)  rpn_loss: 0.1883 (cls: 0.0232, box: 0.1650)
[2025-08-07 19:11:37 train.log] INFO: Epoch: [16]  [Step 5500/14540]  lr: 0.000045  loss: 0.96770  detection_loss: 0.8784 (cls: 0.2610, box: 0.6174)  rpn_loss: 0.0893 (cls: 0.0576, box: 0.0317)
[2025-08-07 19:11:43 train.log] INFO: Epoch: [16]  [Step 5600/14540]  lr: 0.000045  loss: 0.86640  detection_loss: 0.6663 (cls: 0.1816, box: 0.4847)  rpn_loss: 0.2001 (cls: 0.0613, box: 0.1388)
[2025-08-07 19:11:49 train.log] INFO: Epoch: [16]  [Step 5700/14540]  lr: 0.000045  loss: 1.25308  detection_loss: 1.0110 (cls: 0.2860, box: 0.7249)  rpn_loss: 0.2421 (cls: 0.0581, box: 0.1840)
[2025-08-07 19:11:54 train.log] INFO: Epoch: [16]  [Step 5800/14540]  lr: 0.000045  loss: 1.04387  detection_loss: 0.8305 (cls: 0.2059, box: 0.6246)  rpn_loss: 0.2134 (cls: 0.0540, box: 0.1594)
[2025-08-07 19:12:00 train.log] INFO: Epoch: [16]  [Step 5900/14540]  lr: 0.000045  loss: 0.83023  detection_loss: 0.7669 (cls: 0.2443, box: 0.5227)  rpn_loss: 0.0633 (cls: 0.0206, box: 0.0427)
[2025-08-07 19:12:05 train.log] INFO: Epoch: [16]  [Step 6000/14540]  lr: 0.000045  loss: 0.88886  detection_loss: 0.7602 (cls: 0.2741, box: 0.4861)  rpn_loss: 0.1287 (cls: 0.0422, box: 0.0865)
[2025-08-07 19:12:11 train.log] INFO: Epoch: [16]  [Step 6100/14540]  lr: 0.000045  loss: 1.10500  detection_loss: 0.9301 (cls: 0.2671, box: 0.6630)  rpn_loss: 0.1749 (cls: 0.1354, box: 0.0396)
[2025-08-07 19:12:16 train.log] INFO: Epoch: [16]  [Step 6200/14540]  lr: 0.000045  loss: 0.62814  detection_loss: 0.5135 (cls: 0.1269, box: 0.3866)  rpn_loss: 0.1146 (cls: 0.0860, box: 0.0286)
[2025-08-07 19:12:21 train.log] INFO: Epoch: [16]  [Step 6300/14540]  lr: 0.000045  loss: 0.82775  detection_loss: 0.7894 (cls: 0.1495, box: 0.6399)  rpn_loss: 0.0383 (cls: 0.0082, box: 0.0302)
[2025-08-07 19:12:27 train.log] INFO: Epoch: [16]  [Step 6400/14540]  lr: 0.000045  loss: 0.93398  detection_loss: 0.8208 (cls: 0.1631, box: 0.6577)  rpn_loss: 0.1132 (cls: 0.0336, box: 0.0796)
[2025-08-07 19:12:32 train.log] INFO: Epoch: [16]  [Step 6500/14540]  lr: 0.000045  loss: 1.08212  detection_loss: 0.9815 (cls: 0.3424, box: 0.6391)  rpn_loss: 0.1006 (cls: 0.0708, box: 0.0298)
[2025-08-07 19:12:38 train.log] INFO: Epoch: [16]  [Step 6600/14540]  lr: 0.000045  loss: 0.92994  detection_loss: 0.8156 (cls: 0.2564, box: 0.5592)  rpn_loss: 0.1143 (cls: 0.0509, box: 0.0634)
[2025-08-07 19:12:44 train.log] INFO: Epoch: [16]  [Step 6700/14540]  lr: 0.000045  loss: 1.00502  detection_loss: 0.9014 (cls: 0.3215, box: 0.5799)  rpn_loss: 0.1036 (cls: 0.0677, box: 0.0359)
[2025-08-07 19:12:49 train.log] INFO: Epoch: [16]  [Step 6800/14540]  lr: 0.000045  loss: 0.86174  detection_loss: 0.7291 (cls: 0.1299, box: 0.5992)  rpn_loss: 0.1327 (cls: 0.0857, box: 0.0470)
[2025-08-07 19:12:55 train.log] INFO: Epoch: [16]  [Step 6900/14540]  lr: 0.000045  loss: 0.92373  detection_loss: 0.8382 (cls: 0.2543, box: 0.5839)  rpn_loss: 0.0855 (cls: 0.0538, box: 0.0317)
[2025-08-07 19:13:00 train.log] INFO: Epoch: [16]  [Step 7000/14540]  lr: 0.000045  loss: 1.00882  detection_loss: 0.8850 (cls: 0.2476, box: 0.6374)  rpn_loss: 0.1239 (cls: 0.1016, box: 0.0222)
[2025-08-07 19:13:06 train.log] INFO: Epoch: [16]  [Step 7100/14540]  lr: 0.000045  loss: 1.13656  detection_loss: 1.0623 (cls: 0.1502, box: 0.9121)  rpn_loss: 0.0742 (cls: 0.0129, box: 0.0613)
[2025-08-07 19:13:12 train.log] INFO: Epoch: [16]  [Step 7200/14540]  lr: 0.000045  loss: 1.20997  detection_loss: 1.0825 (cls: 0.2226, box: 0.8599)  rpn_loss: 0.1275 (cls: 0.0267, box: 0.1008)
[2025-08-07 19:13:17 train.log] INFO: Epoch: [16]  [Step 7300/14540]  lr: 0.000045  loss: 1.45346  detection_loss: 1.2730 (cls: 0.3331, box: 0.9398)  rpn_loss: 0.1805 (cls: 0.1282, box: 0.0523)
[2025-08-07 19:13:23 train.log] INFO: Epoch: [16]  [Step 7400/14540]  lr: 0.000045  loss: 0.72868  detection_loss: 0.4374 (cls: 0.1686, box: 0.2688)  rpn_loss: 0.2913 (cls: 0.0997, box: 0.1916)
[2025-08-07 19:13:29 train.log] INFO: Epoch: [16]  [Step 7500/14540]  lr: 0.000045  loss: 1.25760  detection_loss: 0.9212 (cls: 0.1774, box: 0.7437)  rpn_loss: 0.3364 (cls: 0.0398, box: 0.2967)
[2025-08-07 19:13:35 train.log] INFO: Epoch: [16]  [Step 7600/14540]  lr: 0.000045  loss: 1.11558  detection_loss: 1.0318 (cls: 0.3301, box: 0.7017)  rpn_loss: 0.0838 (cls: 0.0552, box: 0.0286)
[2025-08-07 19:13:40 train.log] INFO: Epoch: [16]  [Step 7700/14540]  lr: 0.000045  loss: 1.00948  detection_loss: 0.8921 (cls: 0.2518, box: 0.6402)  rpn_loss: 0.1174 (cls: 0.0826, box: 0.0348)
[2025-08-07 19:13:46 train.log] INFO: Epoch: [16]  [Step 7800/14540]  lr: 0.000045  loss: 0.46467  detection_loss: 0.4251 (cls: 0.1362, box: 0.2889)  rpn_loss: 0.0396 (cls: 0.0240, box: 0.0155)
[2025-08-07 19:13:52 train.log] INFO: Epoch: [16]  [Step 7900/14540]  lr: 0.000045  loss: 0.93228  detection_loss: 0.8425 (cls: 0.1350, box: 0.7075)  rpn_loss: 0.0898 (cls: 0.0418, box: 0.0480)
[2025-08-07 19:13:57 train.log] INFO: Epoch: [16]  [Step 8000/14540]  lr: 0.000045  loss: 0.43930  detection_loss: 0.3784 (cls: 0.1007, box: 0.2778)  rpn_loss: 0.0609 (cls: 0.0402, box: 0.0206)
[2025-08-07 19:14:03 train.log] INFO: Epoch: [16]  [Step 8100/14540]  lr: 0.000045  loss: 0.88431  detection_loss: 0.7689 (cls: 0.2383, box: 0.5306)  rpn_loss: 0.1154 (cls: 0.0944, box: 0.0210)
[2025-08-07 19:14:08 train.log] INFO: Epoch: [16]  [Step 8200/14540]  lr: 0.000045  loss: 1.54051  detection_loss: 1.4268 (cls: 0.3152, box: 1.1116)  rpn_loss: 0.1137 (cls: 0.0579, box: 0.0558)
[2025-08-07 19:14:14 train.log] INFO: Epoch: [16]  [Step 8300/14540]  lr: 0.000045  loss: 0.79931  detection_loss: 0.7536 (cls: 0.2059, box: 0.5477)  rpn_loss: 0.0457 (cls: 0.0159, box: 0.0298)
[2025-08-07 19:14:20 train.log] INFO: Epoch: [16]  [Step 8400/14540]  lr: 0.000045  loss: 1.29924  detection_loss: 1.2084 (cls: 0.1644, box: 1.0440)  rpn_loss: 0.0908 (cls: 0.0413, box: 0.0495)
[2025-08-07 19:14:25 train.log] INFO: Epoch: [16]  [Step 8500/14540]  lr: 0.000045  loss: 1.05541  detection_loss: 0.9694 (cls: 0.3244, box: 0.6451)  rpn_loss: 0.0860 (cls: 0.0334, box: 0.0525)
[2025-08-07 19:14:31 train.log] INFO: Epoch: [16]  [Step 8600/14540]  lr: 0.000045  loss: 0.87417  detection_loss: 0.7904 (cls: 0.1296, box: 0.6609)  rpn_loss: 0.0837 (cls: 0.0395, box: 0.0442)
[2025-08-07 19:14:37 train.log] INFO: Epoch: [16]  [Step 8700/14540]  lr: 0.000045  loss: 0.87066  detection_loss: 0.7546 (cls: 0.2507, box: 0.5039)  rpn_loss: 0.1161 (cls: 0.0770, box: 0.0390)
[2025-08-07 19:14:42 train.log] INFO: Epoch: [16]  [Step 8800/14540]  lr: 0.000045  loss: 1.20604  detection_loss: 1.1536 (cls: 0.1950, box: 0.9585)  rpn_loss: 0.0525 (cls: 0.0270, box: 0.0254)
[2025-08-07 19:14:48 train.log] INFO: Epoch: [16]  [Step 8900/14540]  lr: 0.000045  loss: 1.19349  detection_loss: 0.9170 (cls: 0.1474, box: 0.7696)  rpn_loss: 0.2765 (cls: 0.0957, box: 0.1808)
[2025-08-07 19:14:53 train.log] INFO: Epoch: [16]  [Step 9000/14540]  lr: 0.000045  loss: 1.13073  detection_loss: 1.0360 (cls: 0.2467, box: 0.7893)  rpn_loss: 0.0947 (cls: 0.0233, box: 0.0714)
[2025-08-07 19:14:58 train.log] INFO: Epoch: [16]  [Step 9100/14540]  lr: 0.000045  loss: 1.22464  detection_loss: 0.9270 (cls: 0.2372, box: 0.6899)  rpn_loss: 0.2976 (cls: 0.0380, box: 0.2596)
[2025-08-07 19:15:04 train.log] INFO: Epoch: [16]  [Step 9200/14540]  lr: 0.000045  loss: 1.39797  detection_loss: 1.2266 (cls: 0.1886, box: 1.0380)  rpn_loss: 0.1714 (cls: 0.0962, box: 0.0752)
[2025-08-07 19:15:10 train.log] INFO: Epoch: [16]  [Step 9300/14540]  lr: 0.000045  loss: 0.96618  detection_loss: 0.8189 (cls: 0.2372, box: 0.5817)  rpn_loss: 0.1473 (cls: 0.1231, box: 0.0242)
[2025-08-07 19:15:15 train.log] INFO: Epoch: [16]  [Step 9400/14540]  lr: 0.000045  loss: 0.97548  detection_loss: 0.9064 (cls: 0.1839, box: 0.7224)  rpn_loss: 0.0691 (cls: 0.0240, box: 0.0452)
[2025-08-07 19:15:21 train.log] INFO: Epoch: [16]  [Step 9500/14540]  lr: 0.000045  loss: 1.09019  detection_loss: 0.9213 (cls: 0.2420, box: 0.6793)  rpn_loss: 0.1689 (cls: 0.1069, box: 0.0620)
[2025-08-07 19:15:26 train.log] INFO: Epoch: [16]  [Step 9600/14540]  lr: 0.000045  loss: 1.39599  detection_loss: 1.1224 (cls: 0.2018, box: 0.9206)  rpn_loss: 0.2736 (cls: 0.0901, box: 0.1835)
[2025-08-07 19:15:32 train.log] INFO: Epoch: [16]  [Step 9700/14540]  lr: 0.000045  loss: 1.57836  detection_loss: 1.3952 (cls: 0.3703, box: 1.0249)  rpn_loss: 0.1831 (cls: 0.1020, box: 0.0811)
[2025-08-07 19:15:37 train.log] INFO: Epoch: [16]  [Step 9800/14540]  lr: 0.000045  loss: 1.14283  detection_loss: 1.0250 (cls: 0.2590, box: 0.7659)  rpn_loss: 0.1179 (cls: 0.0742, box: 0.0437)
[2025-08-07 19:15:43 train.log] INFO: Epoch: [16]  [Step 9900/14540]  lr: 0.000045  loss: 1.42276  detection_loss: 1.2415 (cls: 0.1836, box: 1.0579)  rpn_loss: 0.1812 (cls: 0.1437, box: 0.0375)
[2025-08-07 19:15:48 train.log] INFO: Epoch: [16]  [Step 10000/14540]  lr: 0.000045  loss: 1.36994  detection_loss: 1.2571 (cls: 0.2836, box: 0.9735)  rpn_loss: 0.1128 (cls: 0.0904, box: 0.0224)
[2025-08-07 19:15:54 train.log] INFO: Epoch: [16]  [Step 10100/14540]  lr: 0.000045  loss: 0.74336  detection_loss: 0.6391 (cls: 0.2647, box: 0.3744)  rpn_loss: 0.1043 (cls: 0.0665, box: 0.0378)
[2025-08-07 19:15:59 train.log] INFO: Epoch: [16]  [Step 10200/14540]  lr: 0.000045  loss: 0.47221  detection_loss: 0.4326 (cls: 0.0573, box: 0.3753)  rpn_loss: 0.0396 (cls: 0.0274, box: 0.0122)
[2025-08-07 19:16:05 train.log] INFO: Epoch: [16]  [Step 10300/14540]  lr: 0.000045  loss: 0.97303  detection_loss: 0.8316 (cls: 0.2411, box: 0.5905)  rpn_loss: 0.1414 (cls: 0.0357, box: 0.1057)
[2025-08-07 19:16:10 train.log] INFO: Epoch: [16]  [Step 10400/14540]  lr: 0.000045  loss: 0.91398  detection_loss: 0.8502 (cls: 0.3144, box: 0.5358)  rpn_loss: 0.0637 (cls: 0.0319, box: 0.0319)
[2025-08-07 19:16:16 train.log] INFO: Epoch: [16]  [Step 10500/14540]  lr: 0.000045  loss: 0.88755  detection_loss: 0.8289 (cls: 0.1275, box: 0.7014)  rpn_loss: 0.0587 (cls: 0.0254, box: 0.0333)
[2025-08-07 19:16:22 train.log] INFO: Epoch: [16]  [Step 10600/14540]  lr: 0.000045  loss: 0.55701  detection_loss: 0.5143 (cls: 0.1331, box: 0.3812)  rpn_loss: 0.0427 (cls: 0.0314, box: 0.0112)
[2025-08-07 19:16:27 train.log] INFO: Epoch: [16]  [Step 10700/14540]  lr: 0.000045  loss: 1.54943  detection_loss: 1.3227 (cls: 0.2196, box: 1.1031)  rpn_loss: 0.2267 (cls: 0.1409, box: 0.0858)
[2025-08-07 19:16:33 train.log] INFO: Epoch: [16]  [Step 10800/14540]  lr: 0.000045  loss: 1.34917  detection_loss: 1.0962 (cls: 0.1583, box: 0.9380)  rpn_loss: 0.2529 (cls: 0.1834, box: 0.0695)
[2025-08-07 19:16:38 train.log] INFO: Epoch: [16]  [Step 10900/14540]  lr: 0.000045  loss: 0.97774  detection_loss: 0.9314 (cls: 0.2001, box: 0.7314)  rpn_loss: 0.0463 (cls: 0.0149, box: 0.0314)
[2025-08-07 19:16:44 train.log] INFO: Epoch: [16]  [Step 11000/14540]  lr: 0.000045  loss: 0.90855  detection_loss: 0.8329 (cls: 0.1488, box: 0.6841)  rpn_loss: 0.0756 (cls: 0.0412, box: 0.0344)
[2025-08-07 19:16:49 train.log] INFO: Epoch: [16]  [Step 11100/14540]  lr: 0.000045  loss: 1.65639  detection_loss: 1.4144 (cls: 0.2373, box: 1.1771)  rpn_loss: 0.2420 (cls: 0.0765, box: 0.1655)
[2025-08-07 19:16:55 train.log] INFO: Epoch: [16]  [Step 11200/14540]  lr: 0.000045  loss: 1.37005  detection_loss: 1.2003 (cls: 0.3605, box: 0.8398)  rpn_loss: 0.1698 (cls: 0.1418, box: 0.0279)
[2025-08-07 19:17:00 train.log] INFO: Epoch: [16]  [Step 11300/14540]  lr: 0.000045  loss: 1.05835  detection_loss: 0.9916 (cls: 0.2331, box: 0.7585)  rpn_loss: 0.0667 (cls: 0.0512, box: 0.0156)
[2025-08-07 19:17:06 train.log] INFO: Epoch: [16]  [Step 11400/14540]  lr: 0.000045  loss: 1.25678  detection_loss: 1.1703 (cls: 0.2861, box: 0.8842)  rpn_loss: 0.0864 (cls: 0.0512, box: 0.0352)
[2025-08-07 19:17:12 train.log] INFO: Epoch: [16]  [Step 11500/14540]  lr: 0.000045  loss: 1.38717  detection_loss: 1.2192 (cls: 0.2690, box: 0.9502)  rpn_loss: 0.1679 (cls: 0.0819, box: 0.0860)
[2025-08-07 19:17:17 train.log] INFO: Epoch: [16]  [Step 11600/14540]  lr: 0.000045  loss: 1.06534  detection_loss: 0.9552 (cls: 0.2135, box: 0.7418)  rpn_loss: 0.1101 (cls: 0.0708, box: 0.0393)
[2025-08-07 19:17:23 train.log] INFO: Epoch: [16]  [Step 11700/14540]  lr: 0.000045  loss: 0.81030  detection_loss: 0.7459 (cls: 0.1490, box: 0.5969)  rpn_loss: 0.0644 (cls: 0.0544, box: 0.0100)
[2025-08-07 19:17:29 train.log] INFO: Epoch: [16]  [Step 11800/14540]  lr: 0.000045  loss: 1.69472  detection_loss: 1.5175 (cls: 0.5630, box: 0.9544)  rpn_loss: 0.1773 (cls: 0.0740, box: 0.1032)
[2025-08-07 19:17:34 train.log] INFO: Epoch: [16]  [Step 11900/14540]  lr: 0.000045  loss: 0.97285  detection_loss: 0.9008 (cls: 0.2208, box: 0.6800)  rpn_loss: 0.0720 (cls: 0.0445, box: 0.0276)
[2025-08-07 19:17:40 train.log] INFO: Epoch: [16]  [Step 12000/14540]  lr: 0.000045  loss: 1.52047  detection_loss: 1.2521 (cls: 0.4753, box: 0.7767)  rpn_loss: 0.2684 (cls: 0.1437, box: 0.1247)
[2025-08-07 19:17:46 train.log] INFO: Epoch: [16]  [Step 12100/14540]  lr: 0.000045  loss: 0.88307  detection_loss: 0.8138 (cls: 0.2174, box: 0.5964)  rpn_loss: 0.0693 (cls: 0.0164, box: 0.0529)
[2025-08-07 19:17:52 train.log] INFO: Epoch: [16]  [Step 12200/14540]  lr: 0.000045  loss: 0.77944  detection_loss: 0.6894 (cls: 0.2176, box: 0.4718)  rpn_loss: 0.0900 (cls: 0.0583, box: 0.0318)
[2025-08-07 19:17:57 train.log] INFO: Epoch: [16]  [Step 12300/14540]  lr: 0.000045  loss: 1.19508  detection_loss: 1.1270 (cls: 0.2223, box: 0.9046)  rpn_loss: 0.0681 (cls: 0.0241, box: 0.0440)
[2025-08-07 19:18:03 train.log] INFO: Epoch: [16]  [Step 12400/14540]  lr: 0.000045  loss: 1.28036  detection_loss: 1.2170 (cls: 0.1946, box: 1.0224)  rpn_loss: 0.0633 (cls: 0.0298, box: 0.0335)
[2025-08-07 19:18:08 train.log] INFO: Epoch: [16]  [Step 12500/14540]  lr: 0.000045  loss: 1.60685  detection_loss: 1.4066 (cls: 0.2856, box: 1.1211)  rpn_loss: 0.2002 (cls: 0.0573, box: 0.1429)
[2025-08-07 19:18:14 train.log] INFO: Epoch: [16]  [Step 12600/14540]  lr: 0.000045  loss: 1.28786  detection_loss: 0.9361 (cls: 0.3050, box: 0.6312)  rpn_loss: 0.3517 (cls: 0.0577, box: 0.2940)
[2025-08-07 19:18:19 train.log] INFO: Epoch: [16]  [Step 12700/14540]  lr: 0.000045  loss: 1.33117  detection_loss: 1.1600 (cls: 0.2602, box: 0.8999)  rpn_loss: 0.1712 (cls: 0.0404, box: 0.1308)
[2025-08-07 19:18:25 train.log] INFO: Epoch: [16]  [Step 12800/14540]  lr: 0.000045  loss: 1.30411  detection_loss: 1.1850 (cls: 0.1977, box: 0.9874)  rpn_loss: 0.1191 (cls: 0.0631, box: 0.0559)
[2025-08-07 19:18:31 train.log] INFO: Epoch: [16]  [Step 12900/14540]  lr: 0.000045  loss: 1.36378  detection_loss: 1.0882 (cls: 0.5156, box: 0.5727)  rpn_loss: 0.2756 (cls: 0.0831, box: 0.1925)
[2025-08-07 19:18:36 train.log] INFO: Epoch: [16]  [Step 13000/14540]  lr: 0.000045  loss: 0.87275  detection_loss: 0.7069 (cls: 0.1478, box: 0.5590)  rpn_loss: 0.1659 (cls: 0.0592, box: 0.1067)
[2025-08-07 19:18:42 train.log] INFO: Epoch: [16]  [Step 13100/14540]  lr: 0.000045  loss: 1.15537  detection_loss: 1.0430 (cls: 0.2757, box: 0.7673)  rpn_loss: 0.1124 (cls: 0.0724, box: 0.0400)
[2025-08-07 19:18:47 train.log] INFO: Epoch: [16]  [Step 13200/14540]  lr: 0.000045  loss: 1.01017  detection_loss: 0.7540 (cls: 0.2519, box: 0.5020)  rpn_loss: 0.2562 (cls: 0.0537, box: 0.2025)
[2025-08-07 19:18:53 train.log] INFO: Epoch: [16]  [Step 13300/14540]  lr: 0.000045  loss: 1.10203  detection_loss: 1.0346 (cls: 0.3521, box: 0.6825)  rpn_loss: 0.0674 (cls: 0.0273, box: 0.0401)
[2025-08-07 19:18:59 train.log] INFO: Epoch: [16]  [Step 13400/14540]  lr: 0.000045  loss: 0.98584  detection_loss: 0.9212 (cls: 0.1613, box: 0.7598)  rpn_loss: 0.0647 (cls: 0.0114, box: 0.0533)
[2025-08-07 19:19:04 train.log] INFO: Epoch: [16]  [Step 13500/14540]  lr: 0.000045  loss: 1.29232  detection_loss: 1.2043 (cls: 0.2801, box: 0.9242)  rpn_loss: 0.0881 (cls: 0.0688, box: 0.0192)
[2025-08-07 19:19:10 train.log] INFO: Epoch: [16]  [Step 13600/14540]  lr: 0.000045  loss: 0.99804  detection_loss: 0.9407 (cls: 0.2144, box: 0.7263)  rpn_loss: 0.0573 (cls: 0.0314, box: 0.0259)
[2025-08-07 19:19:16 train.log] INFO: Epoch: [16]  [Step 13700/14540]  lr: 0.000045  loss: 1.01991  detection_loss: 0.8997 (cls: 0.3002, box: 0.5994)  rpn_loss: 0.1202 (cls: 0.0387, box: 0.0815)
[2025-08-07 19:19:21 train.log] INFO: Epoch: [16]  [Step 13800/14540]  lr: 0.000045  loss: 1.08609  detection_loss: 0.8328 (cls: 0.1940, box: 0.6388)  rpn_loss: 0.2533 (cls: 0.0794, box: 0.1739)
[2025-08-07 19:19:27 train.log] INFO: Epoch: [16]  [Step 13900/14540]  lr: 0.000045  loss: 0.75965  detection_loss: 0.7011 (cls: 0.1313, box: 0.5697)  rpn_loss: 0.0586 (cls: 0.0332, box: 0.0253)
[2025-08-07 19:19:32 train.log] INFO: Epoch: [16]  [Step 14000/14540]  lr: 0.000045  loss: 1.08687  detection_loss: 1.0197 (cls: 0.2368, box: 0.7830)  rpn_loss: 0.0671 (cls: 0.0322, box: 0.0349)
[2025-08-07 19:19:39 train.log] INFO: Epoch: [16]  [Step 14100/14540]  lr: 0.000045  loss: 1.11760  detection_loss: 1.0132 (cls: 0.2029, box: 0.8103)  rpn_loss: 0.1044 (cls: 0.0264, box: 0.0781)
[2025-08-07 19:19:45 train.log] INFO: Epoch: [16]  [Step 14200/14540]  lr: 0.000045  loss: 1.18149  detection_loss: 0.9825 (cls: 0.1915, box: 0.7910)  rpn_loss: 0.1990 (cls: 0.1426, box: 0.0564)
[2025-08-07 19:19:51 train.log] INFO: Epoch: [16]  [Step 14300/14540]  lr: 0.000045  loss: 1.21618  detection_loss: 1.1249 (cls: 0.2515, box: 0.8733)  rpn_loss: 0.0913 (cls: 0.0733, box: 0.0180)
[2025-08-07 19:19:56 train.log] INFO: Epoch: [16]  [Step 14400/14540]  lr: 0.000045  loss: 0.83808  detection_loss: 0.6737 (cls: 0.2755, box: 0.3982)  rpn_loss: 0.1644 (cls: 0.1309, box: 0.0335)
[2025-08-07 19:20:03 train.log] INFO: Epoch: [16]  [Step 14500/14540]  lr: 0.000045  loss: 0.92315  detection_loss: 0.7941 (cls: 0.2106, box: 0.5835)  rpn_loss: 0.1290 (cls: 0.0662, box: 0.0628)
[2025-08-07 19:23:30 train.log] INFO: Epoch: [17]  [Step 100/14540]  lr: 0.000039  loss: 0.70657  detection_loss: 0.6657 (cls: 0.1521, box: 0.5137)  rpn_loss: 0.0408 (cls: 0.0228, box: 0.0180)
[2025-08-07 19:23:35 train.log] INFO: Epoch: [17]  [Step 200/14540]  lr: 0.000039  loss: 1.00027  detection_loss: 0.9102 (cls: 0.2720, box: 0.6382)  rpn_loss: 0.0901 (cls: 0.0515, box: 0.0386)
[2025-08-07 19:23:41 train.log] INFO: Epoch: [17]  [Step 300/14540]  lr: 0.000039  loss: 1.03539  detection_loss: 0.9219 (cls: 0.1401, box: 0.7818)  rpn_loss: 0.1134 (cls: 0.0401, box: 0.0733)
[2025-08-07 19:23:47 train.log] INFO: Epoch: [17]  [Step 400/14540]  lr: 0.000039  loss: 1.30278  detection_loss: 0.9461 (cls: 0.3321, box: 0.6140)  rpn_loss: 0.3567 (cls: 0.2677, box: 0.0890)
[2025-08-07 19:23:53 train.log] INFO: Epoch: [17]  [Step 500/14540]  lr: 0.000039  loss: 1.16684  detection_loss: 1.0037 (cls: 0.2263, box: 0.7774)  rpn_loss: 0.1632 (cls: 0.1141, box: 0.0491)
[2025-08-07 19:23:58 train.log] INFO: Epoch: [17]  [Step 600/14540]  lr: 0.000039  loss: 0.93170  detection_loss: 0.8639 (cls: 0.2616, box: 0.6023)  rpn_loss: 0.0678 (cls: 0.0226, box: 0.0452)
[2025-08-07 19:24:04 train.log] INFO: Epoch: [17]  [Step 700/14540]  lr: 0.000039  loss: 0.79608  detection_loss: 0.7172 (cls: 0.2099, box: 0.5074)  rpn_loss: 0.0789 (cls: 0.0413, box: 0.0376)
[2025-08-07 19:24:09 train.log] INFO: Epoch: [17]  [Step 800/14540]  lr: 0.000039  loss: 0.75176  detection_loss: 0.6681 (cls: 0.1831, box: 0.4850)  rpn_loss: 0.0837 (cls: 0.0365, box: 0.0472)
[2025-08-07 19:24:15 train.log] INFO: Epoch: [17]  [Step 900/14540]  lr: 0.000039  loss: 1.09512  detection_loss: 0.9497 (cls: 0.2066, box: 0.7431)  rpn_loss: 0.1454 (cls: 0.0266, box: 0.1188)
[2025-08-07 19:24:21 train.log] INFO: Epoch: [17]  [Step 1000/14540]  lr: 0.000039  loss: 0.54765  detection_loss: 0.4926 (cls: 0.1087, box: 0.3839)  rpn_loss: 0.0550 (cls: 0.0337, box: 0.0213)
[2025-08-07 19:24:26 train.log] INFO: Epoch: [17]  [Step 1100/14540]  lr: 0.000039  loss: 1.10237  detection_loss: 0.9303 (cls: 0.2874, box: 0.6429)  rpn_loss: 0.1721 (cls: 0.1001, box: 0.0720)
[2025-08-07 19:24:32 train.log] INFO: Epoch: [17]  [Step 1200/14540]  lr: 0.000039  loss: 1.13080  detection_loss: 1.0312 (cls: 0.3316, box: 0.6996)  rpn_loss: 0.0996 (cls: 0.0628, box: 0.0367)
[2025-08-07 19:24:37 train.log] INFO: Epoch: [17]  [Step 1300/14540]  lr: 0.000039  loss: 0.85934  detection_loss: 0.7468 (cls: 0.2168, box: 0.5301)  rpn_loss: 0.1125 (cls: 0.0461, box: 0.0664)
[2025-08-07 19:24:43 train.log] INFO: Epoch: [17]  [Step 1400/14540]  lr: 0.000039  loss: 0.87336  detection_loss: 0.7542 (cls: 0.1305, box: 0.6238)  rpn_loss: 0.1191 (cls: 0.0289, box: 0.0902)
[2025-08-07 19:24:49 train.log] INFO: Epoch: [17]  [Step 1500/14540]  lr: 0.000039  loss: 0.88575  detection_loss: 0.8363 (cls: 0.2275, box: 0.6088)  rpn_loss: 0.0495 (cls: 0.0325, box: 0.0169)
[2025-08-07 19:24:54 train.log] INFO: Epoch: [17]  [Step 1600/14540]  lr: 0.000039  loss: 0.77076  detection_loss: 0.6732 (cls: 0.1637, box: 0.5095)  rpn_loss: 0.0975 (cls: 0.0528, box: 0.0447)
[2025-08-07 19:24:59 train.log] INFO: Epoch: [17]  [Step 1700/14540]  lr: 0.000039  loss: 1.34667  detection_loss: 1.2314 (cls: 0.3148, box: 0.9166)  rpn_loss: 0.1152 (cls: 0.0606, box: 0.0546)
[2025-08-07 19:25:03 train.log] INFO: Epoch: [17]  [Step 1800/14540]  lr: 0.000039  loss: 1.25093  detection_loss: 1.1326 (cls: 0.2962, box: 0.8364)  rpn_loss: 0.1183 (cls: 0.0474, box: 0.0709)
[2025-08-07 19:25:08 train.log] INFO: Epoch: [17]  [Step 1900/14540]  lr: 0.000039  loss: 1.20479  detection_loss: 1.0326 (cls: 0.3079, box: 0.7247)  rpn_loss: 0.1722 (cls: 0.0467, box: 0.1255)
[2025-08-07 19:25:14 train.log] INFO: Epoch: [17]  [Step 2000/14540]  lr: 0.000039  loss: 1.20014  detection_loss: 1.0255 (cls: 0.3413, box: 0.6842)  rpn_loss: 0.1747 (cls: 0.1337, box: 0.0410)
[2025-08-07 19:25:19 train.log] INFO: Epoch: [17]  [Step 2100/14540]  lr: 0.000039  loss: 1.24657  detection_loss: 1.1644 (cls: 0.2771, box: 0.8873)  rpn_loss: 0.0822 (cls: 0.0317, box: 0.0505)
[2025-08-07 19:25:24 train.log] INFO: Epoch: [17]  [Step 2200/14540]  lr: 0.000039  loss: 0.75352  detection_loss: 0.7141 (cls: 0.1531, box: 0.5610)  rpn_loss: 0.0394 (cls: 0.0152, box: 0.0242)
[2025-08-07 19:25:29 train.log] INFO: Epoch: [17]  [Step 2300/14540]  lr: 0.000039  loss: 0.74400  detection_loss: 0.5843 (cls: 0.2194, box: 0.3649)  rpn_loss: 0.1597 (cls: 0.0615, box: 0.0983)
[2025-08-07 19:25:34 train.log] INFO: Epoch: [17]  [Step 2400/14540]  lr: 0.000039  loss: 0.64420  detection_loss: 0.5946 (cls: 0.1167, box: 0.4779)  rpn_loss: 0.0496 (cls: 0.0352, box: 0.0144)
[2025-08-07 19:25:39 train.log] INFO: Epoch: [17]  [Step 2500/14540]  lr: 0.000039  loss: 0.86616  detection_loss: 0.7090 (cls: 0.1453, box: 0.5637)  rpn_loss: 0.1571 (cls: 0.0283, box: 0.1288)
[2025-08-07 19:25:44 train.log] INFO: Epoch: [17]  [Step 2600/14540]  lr: 0.000039  loss: 1.27143  detection_loss: 0.7364 (cls: 0.2395, box: 0.4969)  rpn_loss: 0.5351 (cls: 0.1286, box: 0.4064)
[2025-08-07 19:25:49 train.log] INFO: Epoch: [17]  [Step 2700/14540]  lr: 0.000039  loss: 0.93991  detection_loss: 0.8657 (cls: 0.3120, box: 0.5537)  rpn_loss: 0.0742 (cls: 0.0384, box: 0.0358)
[2025-08-07 19:25:54 train.log] INFO: Epoch: [17]  [Step 2800/14540]  lr: 0.000039  loss: 1.19265  detection_loss: 1.0569 (cls: 0.3541, box: 0.7027)  rpn_loss: 0.1358 (cls: 0.0978, box: 0.0380)
[2025-08-07 19:25:59 train.log] INFO: Epoch: [17]  [Step 2900/14540]  lr: 0.000039  loss: 0.88764  detection_loss: 0.8434 (cls: 0.1680, box: 0.6755)  rpn_loss: 0.0442 (cls: 0.0074, box: 0.0368)
[2025-08-07 19:26:04 train.log] INFO: Epoch: [17]  [Step 3000/14540]  lr: 0.000039  loss: 1.14579  detection_loss: 0.8819 (cls: 0.1195, box: 0.7625)  rpn_loss: 0.2639 (cls: 0.0454, box: 0.2185)
[2025-08-07 19:26:10 train.log] INFO: Epoch: [17]  [Step 3100/14540]  lr: 0.000039  loss: 0.95007  detection_loss: 0.8543 (cls: 0.2106, box: 0.6437)  rpn_loss: 0.0958 (cls: 0.0857, box: 0.0101)
[2025-08-07 19:26:15 train.log] INFO: Epoch: [17]  [Step 3200/14540]  lr: 0.000039  loss: 1.10366  detection_loss: 0.9721 (cls: 0.2648, box: 0.7074)  rpn_loss: 0.1315 (cls: 0.1039, box: 0.0276)
[2025-08-07 19:26:21 train.log] INFO: Epoch: [17]  [Step 3300/14540]  lr: 0.000039  loss: 0.72734  detection_loss: 0.6833 (cls: 0.2085, box: 0.4749)  rpn_loss: 0.0440 (cls: 0.0278, box: 0.0162)
[2025-08-07 19:26:26 train.log] INFO: Epoch: [17]  [Step 3400/14540]  lr: 0.000039  loss: 0.69975  detection_loss: 0.6590 (cls: 0.1746, box: 0.4845)  rpn_loss: 0.0407 (cls: 0.0250, box: 0.0158)
[2025-08-07 19:26:32 train.log] INFO: Epoch: [17]  [Step 3500/14540]  lr: 0.000039  loss: 1.08189  detection_loss: 0.9334 (cls: 0.2399, box: 0.6935)  rpn_loss: 0.1485 (cls: 0.0997, box: 0.0488)
[2025-08-07 19:26:38 train.log] INFO: Epoch: [17]  [Step 3600/14540]  lr: 0.000039  loss: 1.26907  detection_loss: 1.1657 (cls: 0.1904, box: 0.9753)  rpn_loss: 0.1033 (cls: 0.0759, box: 0.0275)
[2025-08-07 19:26:40 train.log] INFO: Epoch: [17]  [Step 3635/14540]  lr: 0.000039  loss: 0.94500  detection_loss: 0.8290 (cls: 0.1031, box: 0.7260)  rpn_loss: 0.1160 (cls: 0.0168, box: 0.0992)
[2025-08-07 19:26:43 train.log] INFO: Epoch: [17]  [Step 3700/14540]  lr: 0.000039  loss: 1.24686  detection_loss: 1.1835 (cls: 0.3044, box: 0.8791)  rpn_loss: 0.0634 (cls: 0.0383, box: 0.0250)
[2025-08-07 19:26:49 train.log] INFO: Epoch: [17]  [Step 3800/14540]  lr: 0.000039  loss: 0.99947  detection_loss: 0.9103 (cls: 0.2837, box: 0.6266)  rpn_loss: 0.0892 (cls: 0.0523, box: 0.0369)
[2025-08-07 19:26:54 train.log] INFO: Epoch: [17]  [Step 3900/14540]  lr: 0.000039  loss: 0.91316  detection_loss: 0.8500 (cls: 0.1320, box: 0.7180)  rpn_loss: 0.0632 (cls: 0.0308, box: 0.0324)
[2025-08-07 19:27:00 train.log] INFO: Epoch: [17]  [Step 4000/14540]  lr: 0.000039  loss: 1.46528  detection_loss: 1.2888 (cls: 0.3736, box: 0.9152)  rpn_loss: 0.1764 (cls: 0.1483, box: 0.0281)
[2025-08-07 19:27:05 train.log] INFO: Epoch: [17]  [Step 4100/14540]  lr: 0.000039  loss: 1.24398  detection_loss: 1.1404 (cls: 0.2198, box: 0.9206)  rpn_loss: 0.1036 (cls: 0.0832, box: 0.0204)
[2025-08-07 19:27:11 train.log] INFO: Epoch: [17]  [Step 4200/14540]  lr: 0.000039  loss: 1.28759  detection_loss: 1.1478 (cls: 0.3295, box: 0.8183)  rpn_loss: 0.1398 (cls: 0.0514, box: 0.0884)
[2025-08-07 19:27:16 train.log] INFO: Epoch: [17]  [Step 4300/14540]  lr: 0.000039  loss: 1.10364  detection_loss: 0.9676 (cls: 0.3755, box: 0.5921)  rpn_loss: 0.1360 (cls: 0.0809, box: 0.0552)
[2025-08-07 19:27:22 train.log] INFO: Epoch: [17]  [Step 4400/14540]  lr: 0.000039  loss: 0.88509  detection_loss: 0.7978 (cls: 0.1708, box: 0.6270)  rpn_loss: 0.0873 (cls: 0.0606, box: 0.0266)
[2025-08-07 19:27:28 train.log] INFO: Epoch: [17]  [Step 4500/14540]  lr: 0.000039  loss: 0.75346  detection_loss: 0.7140 (cls: 0.0670, box: 0.6470)  rpn_loss: 0.0395 (cls: 0.0208, box: 0.0186)
[2025-08-07 19:27:33 train.log] INFO: Epoch: [17]  [Step 4600/14540]  lr: 0.000039  loss: 0.70883  detection_loss: 0.6394 (cls: 0.1711, box: 0.4683)  rpn_loss: 0.0694 (cls: 0.0259, box: 0.0435)
[2025-08-07 19:27:37 train.log] INFO: Epoch: [17]  [Step 4700/14540]  lr: 0.000039  loss: 0.86075  detection_loss: 0.7691 (cls: 0.1860, box: 0.5831)  rpn_loss: 0.0917 (cls: 0.0664, box: 0.0253)
[2025-08-07 19:27:42 train.log] INFO: Epoch: [17]  [Step 4800/14540]  lr: 0.000039  loss: 1.22693  detection_loss: 1.0920 (cls: 0.2189, box: 0.8731)  rpn_loss: 0.1349 (cls: 0.0616, box: 0.0734)
[2025-08-07 19:27:47 train.log] INFO: Epoch: [17]  [Step 4900/14540]  lr: 0.000039  loss: 0.75154  detection_loss: 0.6772 (cls: 0.1467, box: 0.5306)  rpn_loss: 0.0743 (cls: 0.0597, box: 0.0146)
[2025-08-07 19:27:52 train.log] INFO: Epoch: [17]  [Step 5000/14540]  lr: 0.000039  loss: 0.87059  detection_loss: 0.7991 (cls: 0.1985, box: 0.6006)  rpn_loss: 0.0715 (cls: 0.0585, box: 0.0130)
[2025-08-07 19:27:57 train.log] INFO: Epoch: [17]  [Step 5100/14540]  lr: 0.000039  loss: 0.84117  detection_loss: 0.6941 (cls: 0.1950, box: 0.4991)  rpn_loss: 0.1471 (cls: 0.0571, box: 0.0899)
[2025-08-07 19:28:02 train.log] INFO: Epoch: [17]  [Step 5200/14540]  lr: 0.000039  loss: 0.90090  detection_loss: 0.7729 (cls: 0.2928, box: 0.4801)  rpn_loss: 0.1280 (cls: 0.0282, box: 0.0998)
[2025-08-07 19:28:07 train.log] INFO: Epoch: [17]  [Step 5300/14540]  lr: 0.000039  loss: 1.25554  detection_loss: 1.1289 (cls: 0.3552, box: 0.7737)  rpn_loss: 0.1266 (cls: 0.0908, box: 0.0358)
[2025-08-07 19:28:12 train.log] INFO: Epoch: [17]  [Step 5400/14540]  lr: 0.000039  loss: 0.71543  detection_loss: 0.6238 (cls: 0.1797, box: 0.4441)  rpn_loss: 0.0916 (cls: 0.0569, box: 0.0347)
[2025-08-07 19:28:17 train.log] INFO: Epoch: [17]  [Step 5500/14540]  lr: 0.000039  loss: 1.28394  detection_loss: 1.1492 (cls: 0.4075, box: 0.7418)  rpn_loss: 0.1347 (cls: 0.0559, box: 0.0788)
[2025-08-07 19:28:22 train.log] INFO: Epoch: [17]  [Step 5600/14540]  lr: 0.000039  loss: 1.14455  detection_loss: 0.9854 (cls: 0.1554, box: 0.8300)  rpn_loss: 0.1592 (cls: 0.0950, box: 0.0641)
[2025-08-07 19:28:27 train.log] INFO: Epoch: [17]  [Step 5700/14540]  lr: 0.000039  loss: 0.68055  detection_loss: 0.6003 (cls: 0.1285, box: 0.4717)  rpn_loss: 0.0803 (cls: 0.0559, box: 0.0244)
[2025-08-07 19:28:32 train.log] INFO: Epoch: [17]  [Step 5800/14540]  lr: 0.000039  loss: 0.91257  detection_loss: 0.8440 (cls: 0.1500, box: 0.6941)  rpn_loss: 0.0685 (cls: 0.0300, box: 0.0385)
[2025-08-07 19:28:37 train.log] INFO: Epoch: [17]  [Step 5900/14540]  lr: 0.000039  loss: 0.63416  detection_loss: 0.5592 (cls: 0.1453, box: 0.4139)  rpn_loss: 0.0750 (cls: 0.0448, box: 0.0302)
[2025-08-07 19:28:42 train.log] INFO: Epoch: [17]  [Step 6000/14540]  lr: 0.000039  loss: 0.96627  detection_loss: 0.9035 (cls: 0.2017, box: 0.7018)  rpn_loss: 0.0627 (cls: 0.0346, box: 0.0282)
[2025-08-07 19:28:47 train.log] INFO: Epoch: [17]  [Step 6100/14540]  lr: 0.000039  loss: 0.97456  detection_loss: 0.8917 (cls: 0.2438, box: 0.6478)  rpn_loss: 0.0829 (cls: 0.0475, box: 0.0354)
[2025-08-07 19:28:52 train.log] INFO: Epoch: [17]  [Step 6200/14540]  lr: 0.000039  loss: 0.96992  detection_loss: 0.7696 (cls: 0.2039, box: 0.5657)  rpn_loss: 0.2003 (cls: 0.0969, box: 0.1034)
[2025-08-07 19:28:58 train.log] INFO: Epoch: [17]  [Step 6300/14540]  lr: 0.000039  loss: 0.81115  detection_loss: 0.6952 (cls: 0.1899, box: 0.5053)  rpn_loss: 0.1160 (cls: 0.0824, box: 0.0336)
[2025-08-07 19:29:03 train.log] INFO: Epoch: [17]  [Step 6400/14540]  lr: 0.000039  loss: 0.78392  detection_loss: 0.6899 (cls: 0.1679, box: 0.5220)  rpn_loss: 0.0940 (cls: 0.0549, box: 0.0391)
[2025-08-07 19:29:08 train.log] INFO: Epoch: [17]  [Step 6500/14540]  lr: 0.000039  loss: 0.42790  detection_loss: 0.3866 (cls: 0.1030, box: 0.2836)  rpn_loss: 0.0413 (cls: 0.0163, box: 0.0250)
[2025-08-07 19:29:14 train.log] INFO: Epoch: [17]  [Step 6600/14540]  lr: 0.000039  loss: 0.92779  detection_loss: 0.8122 (cls: 0.1662, box: 0.6460)  rpn_loss: 0.1156 (cls: 0.0466, box: 0.0690)
[2025-08-07 19:29:20 train.log] INFO: Epoch: [17]  [Step 6700/14540]  lr: 0.000039  loss: 0.87531  detection_loss: 0.7800 (cls: 0.1498, box: 0.6302)  rpn_loss: 0.0953 (cls: 0.0648, box: 0.0305)
[2025-08-07 19:29:26 train.log] INFO: Epoch: [17]  [Step 6800/14540]  lr: 0.000039  loss: 0.84418  detection_loss: 0.8024 (cls: 0.1368, box: 0.6656)  rpn_loss: 0.0418 (cls: 0.0222, box: 0.0196)
[2025-08-07 19:29:31 train.log] INFO: Epoch: [17]  [Step 6900/14540]  lr: 0.000039  loss: 1.39016  detection_loss: 1.1766 (cls: 0.2504, box: 0.9262)  rpn_loss: 0.2135 (cls: 0.0484, box: 0.1652)
[2025-08-07 19:29:37 train.log] INFO: Epoch: [17]  [Step 7000/14540]  lr: 0.000039  loss: 1.22137  detection_loss: 1.0969 (cls: 0.2228, box: 0.8741)  rpn_loss: 0.1244 (cls: 0.0547, box: 0.0697)
[2025-08-07 19:29:43 train.log] INFO: Epoch: [17]  [Step 7100/14540]  lr: 0.000039  loss: 0.96508  detection_loss: 0.7151 (cls: 0.1962, box: 0.5189)  rpn_loss: 0.2500 (cls: 0.0402, box: 0.2097)
[2025-08-07 19:29:49 train.log] INFO: Epoch: [17]  [Step 7200/14540]  lr: 0.000039  loss: 1.64472  detection_loss: 1.5168 (cls: 0.4659, box: 1.0509)  rpn_loss: 0.1279 (cls: 0.0954, box: 0.0325)
[2025-08-07 19:29:55 train.log] INFO: Epoch: [17]  [Step 7300/14540]  lr: 0.000039  loss: 1.70197  detection_loss: 1.5241 (cls: 0.3482, box: 1.1759)  rpn_loss: 0.1779 (cls: 0.1168, box: 0.0611)
[2025-08-07 19:30:01 train.log] INFO: Epoch: [17]  [Step 7400/14540]  lr: 0.000039  loss: 1.17643  detection_loss: 1.0376 (cls: 0.2246, box: 0.8130)  rpn_loss: 0.1389 (cls: 0.0538, box: 0.0850)
[2025-08-07 19:30:06 train.log] INFO: Epoch: [17]  [Step 7500/14540]  lr: 0.000039  loss: 1.47316  detection_loss: 1.3958 (cls: 0.3779, box: 1.0179)  rpn_loss: 0.0773 (cls: 0.0534, box: 0.0240)
[2025-08-07 19:30:12 train.log] INFO: Epoch: [17]  [Step 7600/14540]  lr: 0.000039  loss: 0.98588  detection_loss: 0.8256 (cls: 0.2151, box: 0.6105)  rpn_loss: 0.1603 (cls: 0.0353, box: 0.1250)
[2025-08-07 19:30:16 train.log] INFO: Epoch: [17]  [Step 7700/14540]  lr: 0.000039  loss: 0.67902  detection_loss: 0.6450 (cls: 0.0848, box: 0.5602)  rpn_loss: 0.0340 (cls: 0.0101, box: 0.0239)
[2025-08-07 19:30:21 train.log] INFO: Epoch: [17]  [Step 7800/14540]  lr: 0.000039  loss: 1.47162  detection_loss: 1.3444 (cls: 0.6238, box: 0.7206)  rpn_loss: 0.1272 (cls: 0.0587, box: 0.0685)
[2025-08-07 19:30:26 train.log] INFO: Epoch: [17]  [Step 7900/14540]  lr: 0.000039  loss: 0.97097  detection_loss: 0.8255 (cls: 0.2250, box: 0.6005)  rpn_loss: 0.1455 (cls: 0.0975, box: 0.0480)
[2025-08-07 19:30:31 train.log] INFO: Epoch: [17]  [Step 8000/14540]  lr: 0.000039  loss: 0.77028  detection_loss: 0.6400 (cls: 0.1449, box: 0.4950)  rpn_loss: 0.1303 (cls: 0.0638, box: 0.0665)
[2025-08-07 19:30:36 train.log] INFO: Epoch: [17]  [Step 8100/14540]  lr: 0.000039  loss: 0.65801  detection_loss: 0.5589 (cls: 0.1555, box: 0.4034)  rpn_loss: 0.0991 (cls: 0.0579, box: 0.0412)
[2025-08-07 19:30:41 train.log] INFO: Epoch: [17]  [Step 8200/14540]  lr: 0.000039  loss: 1.63002  detection_loss: 1.5146 (cls: 0.4193, box: 1.0952)  rpn_loss: 0.1154 (cls: 0.0881, box: 0.0274)
[2025-08-07 19:30:46 train.log] INFO: Epoch: [17]  [Step 8300/14540]  lr: 0.000039  loss: 0.72634  detection_loss: 0.7016 (cls: 0.1804, box: 0.5212)  rpn_loss: 0.0247 (cls: 0.0124, box: 0.0123)
[2025-08-07 19:30:51 train.log] INFO: Epoch: [17]  [Step 8400/14540]  lr: 0.000039  loss: 1.31969  detection_loss: 1.1214 (cls: 0.2559, box: 0.8655)  rpn_loss: 0.1983 (cls: 0.0768, box: 0.1215)
[2025-08-07 19:30:56 train.log] INFO: Epoch: [17]  [Step 8500/14540]  lr: 0.000039  loss: 1.01578  detection_loss: 0.9022 (cls: 0.2661, box: 0.6361)  rpn_loss: 0.1136 (cls: 0.0686, box: 0.0450)
[2025-08-07 19:31:01 train.log] INFO: Epoch: [17]  [Step 8600/14540]  lr: 0.000039  loss: 0.82465  detection_loss: 0.7522 (cls: 0.1493, box: 0.6029)  rpn_loss: 0.0724 (cls: 0.0507, box: 0.0217)
[2025-08-07 19:31:07 train.log] INFO: Epoch: [17]  [Step 8700/14540]  lr: 0.000039  loss: 1.04797  detection_loss: 0.8914 (cls: 0.1793, box: 0.7121)  rpn_loss: 0.1566 (cls: 0.1284, box: 0.0282)
[2025-08-07 19:31:12 train.log] INFO: Epoch: [17]  [Step 8800/14540]  lr: 0.000039  loss: 0.79199  detection_loss: 0.6815 (cls: 0.1645, box: 0.5169)  rpn_loss: 0.1105 (cls: 0.0571, box: 0.0534)
[2025-08-07 19:31:18 train.log] INFO: Epoch: [17]  [Step 8900/14540]  lr: 0.000039  loss: 1.94426  detection_loss: 1.7109 (cls: 0.4654, box: 1.2454)  rpn_loss: 0.2334 (cls: 0.0593, box: 0.1741)
[2025-08-07 19:31:23 train.log] INFO: Epoch: [17]  [Step 9000/14540]  lr: 0.000039  loss: 1.35467  detection_loss: 1.2509 (cls: 0.2980, box: 0.9529)  rpn_loss: 0.1038 (cls: 0.0405, box: 0.0633)
[2025-08-07 19:31:28 train.log] INFO: Epoch: [17]  [Step 9100/14540]  lr: 0.000039  loss: 1.59178  detection_loss: 1.4983 (cls: 0.4896, box: 1.0087)  rpn_loss: 0.0935 (cls: 0.0721, box: 0.0215)
[2025-08-07 19:31:33 train.log] INFO: Epoch: [17]  [Step 9200/14540]  lr: 0.000039  loss: 0.73984  detection_loss: 0.6930 (cls: 0.1163, box: 0.5767)  rpn_loss: 0.0468 (cls: 0.0246, box: 0.0223)
[2025-08-07 19:31:38 train.log] INFO: Epoch: [17]  [Step 9300/14540]  lr: 0.000039  loss: 1.36361  detection_loss: 1.1763 (cls: 0.2481, box: 0.9282)  rpn_loss: 0.1873 (cls: 0.0518, box: 0.1354)
[2025-08-07 19:31:44 train.log] INFO: Epoch: [17]  [Step 9400/14540]  lr: 0.000039  loss: 1.10997  detection_loss: 0.9824 (cls: 0.2180, box: 0.7644)  rpn_loss: 0.1275 (cls: 0.1019, box: 0.0256)
[2025-08-07 19:31:49 train.log] INFO: Epoch: [17]  [Step 9500/14540]  lr: 0.000039  loss: 0.90635  detection_loss: 0.8149 (cls: 0.2104, box: 0.6046)  rpn_loss: 0.0914 (cls: 0.0507, box: 0.0407)
[2025-08-07 19:31:54 train.log] INFO: Epoch: [17]  [Step 9600/14540]  lr: 0.000039  loss: 1.24683  detection_loss: 1.1378 (cls: 0.2831, box: 0.8547)  rpn_loss: 0.1090 (cls: 0.0884, box: 0.0206)
[2025-08-07 19:31:59 train.log] INFO: Epoch: [17]  [Step 9700/14540]  lr: 0.000039  loss: 0.63413  detection_loss: 0.5471 (cls: 0.1700, box: 0.3771)  rpn_loss: 0.0871 (cls: 0.0761, box: 0.0110)
[2025-08-07 19:32:05 train.log] INFO: Epoch: [17]  [Step 9800/14540]  lr: 0.000039  loss: 1.26112  detection_loss: 1.1586 (cls: 0.2529, box: 0.9058)  rpn_loss: 0.1025 (cls: 0.0752, box: 0.0272)
[2025-08-07 19:32:10 train.log] INFO: Epoch: [17]  [Step 9900/14540]  lr: 0.000039  loss: 1.01733  detection_loss: 0.8804 (cls: 0.2058, box: 0.6745)  rpn_loss: 0.1369 (cls: 0.0625, box: 0.0745)
[2025-08-07 19:32:15 train.log] INFO: Epoch: [17]  [Step 10000/14540]  lr: 0.000039  loss: 0.72832  detection_loss: 0.6617 (cls: 0.1978, box: 0.4639)  rpn_loss: 0.0666 (cls: 0.0278, box: 0.0388)
[2025-08-07 19:32:20 train.log] INFO: Epoch: [17]  [Step 10100/14540]  lr: 0.000039  loss: 0.81824  detection_loss: 0.7470 (cls: 0.1919, box: 0.5551)  rpn_loss: 0.0712 (cls: 0.0320, box: 0.0392)
[2025-08-07 19:32:25 train.log] INFO: Epoch: [17]  [Step 10200/14540]  lr: 0.000039  loss: 0.51631  detection_loss: 0.4794 (cls: 0.1174, box: 0.3620)  rpn_loss: 0.0369 (cls: 0.0140, box: 0.0229)
[2025-08-07 19:32:31 train.log] INFO: Epoch: [17]  [Step 10300/14540]  lr: 0.000039  loss: 0.90752  detection_loss: 0.8472 (cls: 0.2466, box: 0.6005)  rpn_loss: 0.0604 (cls: 0.0294, box: 0.0309)
[2025-08-07 19:32:37 train.log] INFO: Epoch: [17]  [Step 10400/14540]  lr: 0.000039  loss: 1.09254  detection_loss: 0.9349 (cls: 0.1306, box: 0.8042)  rpn_loss: 0.1577 (cls: 0.0266, box: 0.1310)
[2025-08-07 19:32:43 train.log] INFO: Epoch: [17]  [Step 10500/14540]  lr: 0.000039  loss: 0.45182  detection_loss: 0.4213 (cls: 0.1036, box: 0.3177)  rpn_loss: 0.0305 (cls: 0.0232, box: 0.0073)
[2025-08-07 19:32:49 train.log] INFO: Epoch: [17]  [Step 10600/14540]  lr: 0.000039  loss: 0.77289  detection_loss: 0.7201 (cls: 0.2093, box: 0.5108)  rpn_loss: 0.0528 (cls: 0.0382, box: 0.0146)
[2025-08-07 19:32:54 train.log] INFO: Epoch: [17]  [Step 10700/14540]  lr: 0.000039  loss: 0.52823  detection_loss: 0.3678 (cls: 0.0815, box: 0.2864)  rpn_loss: 0.1604 (cls: 0.0248, box: 0.1356)
[2025-08-07 19:33:00 train.log] INFO: Epoch: [17]  [Step 10800/14540]  lr: 0.000039  loss: 1.25110  detection_loss: 1.0221 (cls: 0.2740, box: 0.7481)  rpn_loss: 0.2290 (cls: 0.0643, box: 0.1647)
[2025-08-07 19:33:05 train.log] INFO: Epoch: [17]  [Step 10900/14540]  lr: 0.000039  loss: 1.04902  detection_loss: 0.9792 (cls: 0.3180, box: 0.6612)  rpn_loss: 0.0698 (cls: 0.0241, box: 0.0458)
[2025-08-07 19:33:10 train.log] INFO: Epoch: [17]  [Step 11000/14540]  lr: 0.000039  loss: 0.91803  detection_loss: 0.7843 (cls: 0.3300, box: 0.4544)  rpn_loss: 0.1337 (cls: 0.1122, box: 0.0215)
[2025-08-07 19:33:15 train.log] INFO: Epoch: [17]  [Step 11100/14540]  lr: 0.000039  loss: 1.18268  detection_loss: 1.0181 (cls: 0.3006, box: 0.7175)  rpn_loss: 0.1645 (cls: 0.1168, box: 0.0477)
[2025-08-07 19:33:20 train.log] INFO: Epoch: [17]  [Step 11200/14540]  lr: 0.000039  loss: 1.33904  detection_loss: 1.2101 (cls: 0.1679, box: 1.0422)  rpn_loss: 0.1289 (cls: 0.0698, box: 0.0591)
[2025-08-07 19:33:25 train.log] INFO: Epoch: [17]  [Step 11300/14540]  lr: 0.000039  loss: 0.74047  detection_loss: 0.6750 (cls: 0.1587, box: 0.5163)  rpn_loss: 0.0654 (cls: 0.0402, box: 0.0252)
[2025-08-07 19:33:30 train.log] INFO: Epoch: [17]  [Step 11400/14540]  lr: 0.000039  loss: 0.79417  detection_loss: 0.7292 (cls: 0.1376, box: 0.5916)  rpn_loss: 0.0650 (cls: 0.0135, box: 0.0515)
[2025-08-07 19:33:35 train.log] INFO: Epoch: [17]  [Step 11500/14540]  lr: 0.000039  loss: 0.88261  detection_loss: 0.6943 (cls: 0.1231, box: 0.5711)  rpn_loss: 0.1883 (cls: 0.0541, box: 0.1342)
[2025-08-07 19:33:40 train.log] INFO: Epoch: [17]  [Step 11600/14540]  lr: 0.000039  loss: 0.76175  detection_loss: 0.6469 (cls: 0.2348, box: 0.4121)  rpn_loss: 0.1149 (cls: 0.0707, box: 0.0442)
[2025-08-07 19:33:45 train.log] INFO: Epoch: [17]  [Step 11700/14540]  lr: 0.000039  loss: 0.40403  detection_loss: 0.3751 (cls: 0.0881, box: 0.2869)  rpn_loss: 0.0289 (cls: 0.0180, box: 0.0109)
[2025-08-07 19:33:50 train.log] INFO: Epoch: [17]  [Step 11800/14540]  lr: 0.000039  loss: 0.92763  detection_loss: 0.8581 (cls: 0.2252, box: 0.6329)  rpn_loss: 0.0696 (cls: 0.0515, box: 0.0180)
[2025-08-07 19:33:55 train.log] INFO: Epoch: [17]  [Step 11900/14540]  lr: 0.000039  loss: 0.87866  detection_loss: 0.7835 (cls: 0.2000, box: 0.5836)  rpn_loss: 0.0951 (cls: 0.0570, box: 0.0382)
[2025-08-07 19:34:00 train.log] INFO: Epoch: [17]  [Step 12000/14540]  lr: 0.000039  loss: 1.20026  detection_loss: 1.1086 (cls: 0.2683, box: 0.8403)  rpn_loss: 0.0917 (cls: 0.0545, box: 0.0371)
[2025-08-07 19:34:05 train.log] INFO: Epoch: [17]  [Step 12100/14540]  lr: 0.000039  loss: 1.17703  detection_loss: 1.0150 (cls: 0.3159, box: 0.6992)  rpn_loss: 0.1620 (cls: 0.0956, box: 0.0664)
[2025-08-07 19:34:10 train.log] INFO: Epoch: [17]  [Step 12200/14540]  lr: 0.000039  loss: 1.11542  detection_loss: 1.0139 (cls: 0.2650, box: 0.7488)  rpn_loss: 0.1015 (cls: 0.0601, box: 0.0414)
[2025-08-07 19:34:15 train.log] INFO: Epoch: [17]  [Step 12300/14540]  lr: 0.000039  loss: 0.70669  detection_loss: 0.6300 (cls: 0.1964, box: 0.4336)  rpn_loss: 0.0767 (cls: 0.0566, box: 0.0201)
[2025-08-07 19:34:20 train.log] INFO: Epoch: [17]  [Step 12400/14540]  lr: 0.000039  loss: 0.56361  detection_loss: 0.5105 (cls: 0.1099, box: 0.4007)  rpn_loss: 0.0531 (cls: 0.0392, box: 0.0139)
[2025-08-07 19:34:25 train.log] INFO: Epoch: [17]  [Step 12500/14540]  lr: 0.000039  loss: 1.12939  detection_loss: 1.0611 (cls: 0.2807, box: 0.7804)  rpn_loss: 0.0683 (cls: 0.0396, box: 0.0287)
[2025-08-07 19:34:30 train.log] INFO: Epoch: [17]  [Step 12600/14540]  lr: 0.000039  loss: 0.78767  detection_loss: 0.7088 (cls: 0.1913, box: 0.5175)  rpn_loss: 0.0789 (cls: 0.0504, box: 0.0285)
[2025-08-07 19:34:35 train.log] INFO: Epoch: [17]  [Step 12700/14540]  lr: 0.000039  loss: 0.85650  detection_loss: 0.7042 (cls: 0.0949, box: 0.6093)  rpn_loss: 0.1523 (cls: 0.0383, box: 0.1140)
[2025-08-07 19:34:41 train.log] INFO: Epoch: [17]  [Step 12800/14540]  lr: 0.000039  loss: 0.85908  detection_loss: 0.7614 (cls: 0.1807, box: 0.5807)  rpn_loss: 0.0977 (cls: 0.0596, box: 0.0381)
[2025-08-07 19:34:46 train.log] INFO: Epoch: [17]  [Step 12900/14540]  lr: 0.000039  loss: 0.74610  detection_loss: 0.5179 (cls: 0.0689, box: 0.4489)  rpn_loss: 0.2282 (cls: 0.0120, box: 0.2163)
[2025-08-07 19:34:51 train.log] INFO: Epoch: [17]  [Step 13000/14540]  lr: 0.000039  loss: 1.24881  detection_loss: 1.1827 (cls: 0.2389, box: 0.9438)  rpn_loss: 0.0661 (cls: 0.0430, box: 0.0231)
[2025-08-07 19:34:55 train.log] INFO: Epoch: [17]  [Step 13100/14540]  lr: 0.000039  loss: 1.19643  detection_loss: 1.0846 (cls: 0.3705, box: 0.7141)  rpn_loss: 0.1119 (cls: 0.0908, box: 0.0211)
[2025-08-07 19:35:00 train.log] INFO: Epoch: [17]  [Step 13200/14540]  lr: 0.000039  loss: 0.92142  detection_loss: 0.8443 (cls: 0.1820, box: 0.6623)  rpn_loss: 0.0771 (cls: 0.0372, box: 0.0399)
[2025-08-07 19:35:05 train.log] INFO: Epoch: [17]  [Step 13300/14540]  lr: 0.000039  loss: 1.03091  detection_loss: 0.8922 (cls: 0.1784, box: 0.7138)  rpn_loss: 0.1387 (cls: 0.0371, box: 0.1016)
[2025-08-07 19:35:10 train.log] INFO: Epoch: [17]  [Step 13400/14540]  lr: 0.000039  loss: 0.60622  detection_loss: 0.5604 (cls: 0.1881, box: 0.3723)  rpn_loss: 0.0458 (cls: 0.0313, box: 0.0145)
[2025-08-07 19:35:16 train.log] INFO: Epoch: [17]  [Step 13500/14540]  lr: 0.000039  loss: 0.94213  detection_loss: 0.8097 (cls: 0.2440, box: 0.5657)  rpn_loss: 0.1324 (cls: 0.0910, box: 0.0414)
[2025-08-07 19:35:21 train.log] INFO: Epoch: [17]  [Step 13600/14540]  lr: 0.000039  loss: 1.33636  detection_loss: 1.2161 (cls: 0.1985, box: 1.0176)  rpn_loss: 0.1203 (cls: 0.0874, box: 0.0328)
[2025-08-07 19:35:26 train.log] INFO: Epoch: [17]  [Step 13700/14540]  lr: 0.000039  loss: 0.76987  detection_loss: 0.7097 (cls: 0.1664, box: 0.5433)  rpn_loss: 0.0602 (cls: 0.0171, box: 0.0431)
[2025-08-07 19:35:31 train.log] INFO: Epoch: [17]  [Step 13800/14540]  lr: 0.000039  loss: 0.55480  detection_loss: 0.4294 (cls: 0.1704, box: 0.2591)  rpn_loss: 0.1254 (cls: 0.0697, box: 0.0557)
[2025-08-07 19:35:36 train.log] INFO: Epoch: [17]  [Step 13900/14540]  lr: 0.000039  loss: 1.80318  detection_loss: 1.6153 (cls: 0.5063, box: 1.1091)  rpn_loss: 0.1878 (cls: 0.1166, box: 0.0713)
[2025-08-07 19:35:41 train.log] INFO: Epoch: [17]  [Step 14000/14540]  lr: 0.000039  loss: 0.81318  detection_loss: 0.7109 (cls: 0.2314, box: 0.4795)  rpn_loss: 0.1023 (cls: 0.0623, box: 0.0399)
[2025-08-07 19:35:47 train.log] INFO: Epoch: [17]  [Step 14100/14540]  lr: 0.000039  loss: 0.64773  detection_loss: 0.5675 (cls: 0.1368, box: 0.4307)  rpn_loss: 0.0802 (cls: 0.0659, box: 0.0143)
[2025-08-07 19:35:52 train.log] INFO: Epoch: [17]  [Step 14200/14540]  lr: 0.000039  loss: 1.32879  detection_loss: 1.2130 (cls: 0.2486, box: 0.9644)  rpn_loss: 0.1158 (cls: 0.0295, box: 0.0863)
[2025-08-07 19:35:57 train.log] INFO: Epoch: [17]  [Step 14300/14540]  lr: 0.000039  loss: 1.12801  detection_loss: 0.9677 (cls: 0.2243, box: 0.7434)  rpn_loss: 0.1603 (cls: 0.0700, box: 0.0903)
[2025-08-07 19:36:02 train.log] INFO: Epoch: [17]  [Step 14400/14540]  lr: 0.000039  loss: 1.58642  detection_loss: 1.4711 (cls: 0.3744, box: 1.0967)  rpn_loss: 0.1154 (cls: 0.0635, box: 0.0519)
[2025-08-07 19:36:07 train.log] INFO: Epoch: [17]  [Step 14500/14540]  lr: 0.000039  loss: 1.02214  detection_loss: 0.8230 (cls: 0.1690, box: 0.6540)  rpn_loss: 0.1992 (cls: 0.0456, box: 0.1536)
[2025-08-07 19:39:11 train.log] INFO: Epoch: [18]  [Step 100/14540]  lr: 0.000034  loss: 1.02834  detection_loss: 0.9361 (cls: 0.2871, box: 0.6490)  rpn_loss: 0.0922 (cls: 0.0696, box: 0.0227)
[2025-08-07 19:39:16 train.log] INFO: Epoch: [18]  [Step 200/14540]  lr: 0.000034  loss: 0.77888  detection_loss: 0.7040 (cls: 0.1508, box: 0.5532)  rpn_loss: 0.0749 (cls: 0.0223, box: 0.0525)
[2025-08-07 19:39:21 train.log] INFO: Epoch: [18]  [Step 300/14540]  lr: 0.000034  loss: 0.92407  detection_loss: 0.8717 (cls: 0.2304, box: 0.6413)  rpn_loss: 0.0523 (cls: 0.0246, box: 0.0277)
[2025-08-07 19:39:27 train.log] INFO: Epoch: [18]  [Step 400/14540]  lr: 0.000034  loss: 0.95417  detection_loss: 0.9079 (cls: 0.1415, box: 0.7664)  rpn_loss: 0.0462 (cls: 0.0211, box: 0.0252)
[2025-08-07 19:39:32 train.log] INFO: Epoch: [18]  [Step 500/14540]  lr: 0.000034  loss: 1.11991  detection_loss: 1.0395 (cls: 0.2688, box: 0.7706)  rpn_loss: 0.0804 (cls: 0.0551, box: 0.0253)
[2025-08-07 19:39:37 train.log] INFO: Epoch: [18]  [Step 600/14540]  lr: 0.000034  loss: 0.75924  detection_loss: 0.6328 (cls: 0.1583, box: 0.4745)  rpn_loss: 0.1264 (cls: 0.0386, box: 0.0878)
[2025-08-07 19:39:42 train.log] INFO: Epoch: [18]  [Step 700/14540]  lr: 0.000034  loss: 1.13309  detection_loss: 1.0452 (cls: 0.2864, box: 0.7588)  rpn_loss: 0.0879 (cls: 0.0441, box: 0.0438)
[2025-08-07 19:39:47 train.log] INFO: Epoch: [18]  [Step 800/14540]  lr: 0.000034  loss: 0.69806  detection_loss: 0.6183 (cls: 0.1307, box: 0.4877)  rpn_loss: 0.0797 (cls: 0.0626, box: 0.0171)
[2025-08-07 19:39:52 train.log] INFO: Epoch: [18]  [Step 900/14540]  lr: 0.000034  loss: 0.90029  detection_loss: 0.8150 (cls: 0.1649, box: 0.6501)  rpn_loss: 0.0853 (cls: 0.0610, box: 0.0243)
[2025-08-07 19:39:58 train.log] INFO: Epoch: [18]  [Step 1000/14540]  lr: 0.000034  loss: 0.65648  detection_loss: 0.5866 (cls: 0.1625, box: 0.4241)  rpn_loss: 0.0699 (cls: 0.0378, box: 0.0321)
[2025-08-07 19:40:04 train.log] INFO: Epoch: [18]  [Step 1100/14540]  lr: 0.000034  loss: 0.51654  detection_loss: 0.4581 (cls: 0.1165, box: 0.3416)  rpn_loss: 0.0584 (cls: 0.0403, box: 0.0181)
[2025-08-07 19:40:10 train.log] INFO: Epoch: [18]  [Step 1200/14540]  lr: 0.000034  loss: 1.10992  detection_loss: 0.9282 (cls: 0.2938, box: 0.6344)  rpn_loss: 0.1818 (cls: 0.0605, box: 0.1213)
[2025-08-07 19:40:16 train.log] INFO: Epoch: [18]  [Step 1300/14540]  lr: 0.000034  loss: 1.31640  detection_loss: 1.1949 (cls: 0.2953, box: 0.8997)  rpn_loss: 0.1215 (cls: 0.0599, box: 0.0615)
[2025-08-07 19:40:22 train.log] INFO: Epoch: [18]  [Step 1400/14540]  lr: 0.000034  loss: 0.82808  detection_loss: 0.6631 (cls: 0.2325, box: 0.4306)  rpn_loss: 0.1650 (cls: 0.0702, box: 0.0948)
[2025-08-07 19:40:28 train.log] INFO: Epoch: [18]  [Step 1500/14540]  lr: 0.000034  loss: 0.80063  detection_loss: 0.6990 (cls: 0.1185, box: 0.5805)  rpn_loss: 0.1016 (cls: 0.0527, box: 0.0489)
[2025-08-07 19:40:33 train.log] INFO: Epoch: [18]  [Step 1600/14540]  lr: 0.000034  loss: 1.16000  detection_loss: 1.0020 (cls: 0.2804, box: 0.7215)  rpn_loss: 0.1580 (cls: 0.1312, box: 0.0268)
[2025-08-07 19:40:39 train.log] INFO: Epoch: [18]  [Step 1700/14540]  lr: 0.000034  loss: 0.82384  detection_loss: 0.7292 (cls: 0.1812, box: 0.5480)  rpn_loss: 0.0946 (cls: 0.0758, box: 0.0188)
[2025-08-07 19:40:45 train.log] INFO: Epoch: [18]  [Step 1800/14540]  lr: 0.000034  loss: 0.96966  detection_loss: 0.8846 (cls: 0.1218, box: 0.7628)  rpn_loss: 0.0850 (cls: 0.0407, box: 0.0443)
[2025-08-07 19:40:51 train.log] INFO: Epoch: [18]  [Step 1900/14540]  lr: 0.000034  loss: 1.40438  detection_loss: 1.3170 (cls: 0.3781, box: 0.9389)  rpn_loss: 0.0874 (cls: 0.0515, box: 0.0359)
[2025-08-07 19:40:57 train.log] INFO: Epoch: [18]  [Step 2000/14540]  lr: 0.000034  loss: 1.20228  detection_loss: 1.0813 (cls: 0.3696, box: 0.7117)  rpn_loss: 0.1209 (cls: 0.0657, box: 0.0552)
[2025-08-07 19:41:03 train.log] INFO: Epoch: [18]  [Step 2100/14540]  lr: 0.000034  loss: 0.84174  detection_loss: 0.7645 (cls: 0.0779, box: 0.6867)  rpn_loss: 0.0772 (cls: 0.0184, box: 0.0588)
[2025-08-07 19:41:09 train.log] INFO: Epoch: [18]  [Step 2200/14540]  lr: 0.000034  loss: 0.76653  detection_loss: 0.6987 (cls: 0.1213, box: 0.5774)  rpn_loss: 0.0678 (cls: 0.0429, box: 0.0249)
[2025-08-07 19:41:15 train.log] INFO: Epoch: [18]  [Step 2300/14540]  lr: 0.000034  loss: 0.67992  detection_loss: 0.6352 (cls: 0.1262, box: 0.5090)  rpn_loss: 0.0447 (cls: 0.0118, box: 0.0330)
[2025-08-07 19:41:21 train.log] INFO: Epoch: [18]  [Step 2400/14540]  lr: 0.000034  loss: 1.40377  detection_loss: 1.2860 (cls: 0.2407, box: 1.0454)  rpn_loss: 0.1177 (cls: 0.0832, box: 0.0346)
[2025-08-07 19:41:27 train.log] INFO: Epoch: [18]  [Step 2500/14540]  lr: 0.000034  loss: 0.53555  detection_loss: 0.4557 (cls: 0.1185, box: 0.3372)  rpn_loss: 0.0799 (cls: 0.0452, box: 0.0346)
[2025-08-07 19:41:32 train.log] INFO: Epoch: [18]  [Step 2600/14540]  lr: 0.000034  loss: 0.89365  detection_loss: 0.8316 (cls: 0.1604, box: 0.6712)  rpn_loss: 0.0621 (cls: 0.0467, box: 0.0154)
[2025-08-07 19:41:38 train.log] INFO: Epoch: [18]  [Step 2700/14540]  lr: 0.000034  loss: 1.14590  detection_loss: 1.0277 (cls: 0.2180, box: 0.8097)  rpn_loss: 0.1182 (cls: 0.0824, box: 0.0358)
[2025-08-07 19:41:43 train.log] INFO: Epoch: [18]  [Step 2800/14540]  lr: 0.000034  loss: 0.89465  detection_loss: 0.7717 (cls: 0.1465, box: 0.6252)  rpn_loss: 0.1229 (cls: 0.0361, box: 0.0869)
[2025-08-07 19:41:49 train.log] INFO: Epoch: [18]  [Step 2900/14540]  lr: 0.000034  loss: 1.07739  detection_loss: 0.9687 (cls: 0.2574, box: 0.7113)  rpn_loss: 0.1087 (cls: 0.0524, box: 0.0563)
[2025-08-07 19:41:55 train.log] INFO: Epoch: [18]  [Step 3000/14540]  lr: 0.000034  loss: 0.91417  detection_loss: 0.8265 (cls: 0.1418, box: 0.6846)  rpn_loss: 0.0877 (cls: 0.0463, box: 0.0414)
[2025-08-07 19:42:01 train.log] INFO: Epoch: [18]  [Step 3100/14540]  lr: 0.000034  loss: 1.43603  detection_loss: 1.2426 (cls: 0.2200, box: 1.0226)  rpn_loss: 0.1934 (cls: 0.1075, box: 0.0859)
[2025-08-07 19:42:06 train.log] INFO: Epoch: [18]  [Step 3200/14540]  lr: 0.000034  loss: 0.82879  detection_loss: 0.7120 (cls: 0.1880, box: 0.5240)  rpn_loss: 0.1168 (cls: 0.1012, box: 0.0156)
[2025-08-07 19:42:12 train.log] INFO: Epoch: [18]  [Step 3300/14540]  lr: 0.000034  loss: 1.60657  detection_loss: 1.4875 (cls: 0.3756, box: 1.1119)  rpn_loss: 0.1191 (cls: 0.0573, box: 0.0618)
[2025-08-07 19:42:18 train.log] INFO: Epoch: [18]  [Step 3400/14540]  lr: 0.000034  loss: 0.78425  detection_loss: 0.6812 (cls: 0.2314, box: 0.4498)  rpn_loss: 0.1031 (cls: 0.0729, box: 0.0302)
[2025-08-07 19:42:23 train.log] INFO: Epoch: [18]  [Step 3500/14540]  lr: 0.000034  loss: 1.53794  detection_loss: 1.3483 (cls: 0.3401, box: 1.0083)  rpn_loss: 0.1896 (cls: 0.0450, box: 0.1446)
[2025-08-07 19:42:29 train.log] INFO: Epoch: [18]  [Step 3600/14540]  lr: 0.000034  loss: 1.15442  detection_loss: 0.9214 (cls: 0.1479, box: 0.7735)  rpn_loss: 0.2330 (cls: 0.1110, box: 0.1220)
[2025-08-07 19:42:31 train.log] INFO: Epoch: [18]  [Step 3635/14540]  lr: 0.000034  loss: 0.64733  detection_loss: 0.6026 (cls: 0.1564, box: 0.4462)  rpn_loss: 0.0447 (cls: 0.0280, box: 0.0168)
[2025-08-07 19:42:34 train.log] INFO: Epoch: [18]  [Step 3700/14540]  lr: 0.000034  loss: 0.44617  detection_loss: 0.3879 (cls: 0.1087, box: 0.2791)  rpn_loss: 0.0583 (cls: 0.0252, box: 0.0331)
[2025-08-07 19:42:40 train.log] INFO: Epoch: [18]  [Step 3800/14540]  lr: 0.000034  loss: 1.35886  detection_loss: 1.3086 (cls: 0.4185, box: 0.8901)  rpn_loss: 0.0502 (cls: 0.0349, box: 0.0154)
[2025-08-07 19:42:45 train.log] INFO: Epoch: [18]  [Step 3900/14540]  lr: 0.000034  loss: 1.24764  detection_loss: 1.1713 (cls: 0.2962, box: 0.8751)  rpn_loss: 0.0763 (cls: 0.0391, box: 0.0373)
[2025-08-07 19:42:51 train.log] INFO: Epoch: [18]  [Step 4000/14540]  lr: 0.000034  loss: 0.81911  detection_loss: 0.7409 (cls: 0.2410, box: 0.4999)  rpn_loss: 0.0782 (cls: 0.0397, box: 0.0385)
[2025-08-07 19:42:56 train.log] INFO: Epoch: [18]  [Step 4100/14540]  lr: 0.000034  loss: 1.50635  detection_loss: 1.3458 (cls: 0.3327, box: 1.0130)  rpn_loss: 0.1606 (cls: 0.0888, box: 0.0717)
[2025-08-07 19:43:02 train.log] INFO: Epoch: [18]  [Step 4200/14540]  lr: 0.000034  loss: 1.32199  detection_loss: 1.1810 (cls: 0.4131, box: 0.7678)  rpn_loss: 0.1410 (cls: 0.0970, box: 0.0440)
[2025-08-07 19:43:07 train.log] INFO: Epoch: [18]  [Step 4300/14540]  lr: 0.000034  loss: 0.95242  detection_loss: 0.8400 (cls: 0.1856, box: 0.6543)  rpn_loss: 0.1125 (cls: 0.0525, box: 0.0599)
[2025-08-07 19:43:13 train.log] INFO: Epoch: [18]  [Step 4400/14540]  lr: 0.000034  loss: 0.84515  detection_loss: 0.7824 (cls: 0.2327, box: 0.5498)  rpn_loss: 0.0627 (cls: 0.0344, box: 0.0283)
[2025-08-07 19:43:19 train.log] INFO: Epoch: [18]  [Step 4500/14540]  lr: 0.000034  loss: 0.99239  detection_loss: 0.8644 (cls: 0.2382, box: 0.6262)  rpn_loss: 0.1280 (cls: 0.0676, box: 0.0604)
[2025-08-07 19:43:24 train.log] INFO: Epoch: [18]  [Step 4600/14540]  lr: 0.000034  loss: 0.86984  detection_loss: 0.8234 (cls: 0.2148, box: 0.6087)  rpn_loss: 0.0464 (cls: 0.0177, box: 0.0287)
[2025-08-07 19:43:30 train.log] INFO: Epoch: [18]  [Step 4700/14540]  lr: 0.000034  loss: 1.33886  detection_loss: 1.2380 (cls: 0.1307, box: 1.1073)  rpn_loss: 0.1008 (cls: 0.0741, box: 0.0268)
[2025-08-07 19:43:35 train.log] INFO: Epoch: [18]  [Step 4800/14540]  lr: 0.000034  loss: 0.81962  detection_loss: 0.4677 (cls: 0.1355, box: 0.3322)  rpn_loss: 0.3519 (cls: 0.0397, box: 0.3123)
[2025-08-07 19:43:41 train.log] INFO: Epoch: [18]  [Step 4900/14540]  lr: 0.000034  loss: 0.56545  detection_loss: 0.4257 (cls: 0.1327, box: 0.2930)  rpn_loss: 0.1397 (cls: 0.1084, box: 0.0313)
[2025-08-07 19:43:46 train.log] INFO: Epoch: [18]  [Step 5000/14540]  lr: 0.000034  loss: 0.94377  detection_loss: 0.8635 (cls: 0.3029, box: 0.5607)  rpn_loss: 0.0802 (cls: 0.0474, box: 0.0328)
[2025-08-07 19:43:52 train.log] INFO: Epoch: [18]  [Step 5100/14540]  lr: 0.000034  loss: 1.06480  detection_loss: 0.9343 (cls: 0.1808, box: 0.7535)  rpn_loss: 0.1305 (cls: 0.0498, box: 0.0806)
[2025-08-07 19:43:57 train.log] INFO: Epoch: [18]  [Step 5200/14540]  lr: 0.000034  loss: 0.86979  detection_loss: 0.7587 (cls: 0.1539, box: 0.6048)  rpn_loss: 0.1111 (cls: 0.0848, box: 0.0263)
[2025-08-07 19:44:03 train.log] INFO: Epoch: [18]  [Step 5300/14540]  lr: 0.000034  loss: 1.52402  detection_loss: 1.3226 (cls: 0.2281, box: 1.0945)  rpn_loss: 0.2015 (cls: 0.1022, box: 0.0992)
[2025-08-07 19:44:09 train.log] INFO: Epoch: [18]  [Step 5400/14540]  lr: 0.000034  loss: 0.81908  detection_loss: 0.7289 (cls: 0.1729, box: 0.5560)  rpn_loss: 0.0902 (cls: 0.0317, box: 0.0585)
[2025-08-07 19:44:15 train.log] INFO: Epoch: [18]  [Step 5500/14540]  lr: 0.000034  loss: 1.03218  detection_loss: 0.9592 (cls: 0.2390, box: 0.7202)  rpn_loss: 0.0730 (cls: 0.0379, box: 0.0351)
[2025-08-07 19:44:21 train.log] INFO: Epoch: [18]  [Step 5600/14540]  lr: 0.000034  loss: 0.96546  detection_loss: 0.7544 (cls: 0.1180, box: 0.6365)  rpn_loss: 0.2110 (cls: 0.0632, box: 0.1478)
[2025-08-07 19:44:27 train.log] INFO: Epoch: [18]  [Step 5700/14540]  lr: 0.000034  loss: 0.66113  detection_loss: 0.5797 (cls: 0.1634, box: 0.4163)  rpn_loss: 0.0814 (cls: 0.0395, box: 0.0420)
[2025-08-07 19:44:32 train.log] INFO: Epoch: [18]  [Step 5800/14540]  lr: 0.000034  loss: 0.87808  detection_loss: 0.7879 (cls: 0.1987, box: 0.5892)  rpn_loss: 0.0902 (cls: 0.0222, box: 0.0680)
[2025-08-07 19:44:38 train.log] INFO: Epoch: [18]  [Step 5900/14540]  lr: 0.000034  loss: 0.60432  detection_loss: 0.5206 (cls: 0.1526, box: 0.3679)  rpn_loss: 0.0838 (cls: 0.0630, box: 0.0208)
[2025-08-07 19:44:43 train.log] INFO: Epoch: [18]  [Step 6000/14540]  lr: 0.000034  loss: 1.62349  detection_loss: 1.4703 (cls: 0.2813, box: 1.1890)  rpn_loss: 0.1532 (cls: 0.0705, box: 0.0827)
[2025-08-07 19:44:49 train.log] INFO: Epoch: [18]  [Step 6100/14540]  lr: 0.000034  loss: 0.86140  detection_loss: 0.7574 (cls: 0.1812, box: 0.5763)  rpn_loss: 0.1040 (cls: 0.0527, box: 0.0513)
[2025-08-07 19:44:55 train.log] INFO: Epoch: [18]  [Step 6200/14540]  lr: 0.000034  loss: 1.13292  detection_loss: 1.0624 (cls: 0.1553, box: 0.9070)  rpn_loss: 0.0705 (cls: 0.0398, box: 0.0307)
[2025-08-07 19:45:00 train.log] INFO: Epoch: [18]  [Step 6300/14540]  lr: 0.000034  loss: 0.97687  detection_loss: 0.9322 (cls: 0.2078, box: 0.7244)  rpn_loss: 0.0447 (cls: 0.0154, box: 0.0292)
[2025-08-07 19:45:06 train.log] INFO: Epoch: [18]  [Step 6400/14540]  lr: 0.000034  loss: 0.88903  detection_loss: 0.7648 (cls: 0.2201, box: 0.5447)  rpn_loss: 0.1242 (cls: 0.1005, box: 0.0237)
[2025-08-07 19:45:12 train.log] INFO: Epoch: [18]  [Step 6500/14540]  lr: 0.000034  loss: 1.28247  detection_loss: 1.1734 (cls: 0.2825, box: 0.8909)  rpn_loss: 0.1091 (cls: 0.0555, box: 0.0536)
[2025-08-07 19:45:17 train.log] INFO: Epoch: [18]  [Step 6600/14540]  lr: 0.000034  loss: 1.01288  detection_loss: 0.9000 (cls: 0.3772, box: 0.5228)  rpn_loss: 0.1129 (cls: 0.0824, box: 0.0305)
[2025-08-07 19:45:23 train.log] INFO: Epoch: [18]  [Step 6700/14540]  lr: 0.000034  loss: 0.84195  detection_loss: 0.7989 (cls: 0.1788, box: 0.6200)  rpn_loss: 0.0431 (cls: 0.0258, box: 0.0173)
[2025-08-07 19:45:29 train.log] INFO: Epoch: [18]  [Step 6800/14540]  lr: 0.000034  loss: 1.53595  detection_loss: 1.3437 (cls: 0.3687, box: 0.9750)  rpn_loss: 0.1923 (cls: 0.1330, box: 0.0593)
[2025-08-07 19:45:34 train.log] INFO: Epoch: [18]  [Step 6900/14540]  lr: 0.000034  loss: 1.02995  detection_loss: 0.9176 (cls: 0.2188, box: 0.6988)  rpn_loss: 0.1123 (cls: 0.0725, box: 0.0399)
[2025-08-07 19:45:40 train.log] INFO: Epoch: [18]  [Step 7000/14540]  lr: 0.000034  loss: 0.75332  detection_loss: 0.7224 (cls: 0.1733, box: 0.5491)  rpn_loss: 0.0310 (cls: 0.0114, box: 0.0195)
[2025-08-07 19:45:46 train.log] INFO: Epoch: [18]  [Step 7100/14540]  lr: 0.000034  loss: 1.09140  detection_loss: 0.9375 (cls: 0.1763, box: 0.7612)  rpn_loss: 0.1539 (cls: 0.1076, box: 0.0463)
[2025-08-07 19:45:51 train.log] INFO: Epoch: [18]  [Step 7200/14540]  lr: 0.000034  loss: 0.83889  detection_loss: 0.6597 (cls: 0.1704, box: 0.4893)  rpn_loss: 0.1792 (cls: 0.1069, box: 0.0723)
[2025-08-07 19:45:57 train.log] INFO: Epoch: [18]  [Step 7300/14540]  lr: 0.000034  loss: 1.05354  detection_loss: 0.9165 (cls: 0.2300, box: 0.6865)  rpn_loss: 0.1371 (cls: 0.1065, box: 0.0306)
[2025-08-07 19:46:03 train.log] INFO: Epoch: [18]  [Step 7400/14540]  lr: 0.000034  loss: 0.86581  detection_loss: 0.7896 (cls: 0.1215, box: 0.6681)  rpn_loss: 0.0762 (cls: 0.0260, box: 0.0502)
[2025-08-07 19:46:08 train.log] INFO: Epoch: [18]  [Step 7500/14540]  lr: 0.000034  loss: 1.29811  detection_loss: 1.0165 (cls: 0.1450, box: 0.8715)  rpn_loss: 0.2816 (cls: 0.2378, box: 0.0438)
[2025-08-07 19:46:14 train.log] INFO: Epoch: [18]  [Step 7600/14540]  lr: 0.000034  loss: 1.42633  detection_loss: 1.3211 (cls: 0.3242, box: 0.9969)  rpn_loss: 0.1052 (cls: 0.0518, box: 0.0534)
[2025-08-07 19:46:20 train.log] INFO: Epoch: [18]  [Step 7700/14540]  lr: 0.000034  loss: 1.69434  detection_loss: 1.5653 (cls: 0.5460, box: 1.0193)  rpn_loss: 0.1291 (cls: 0.0971, box: 0.0320)
[2025-08-07 19:46:25 train.log] INFO: Epoch: [18]  [Step 7800/14540]  lr: 0.000034  loss: 0.79840  detection_loss: 0.6822 (cls: 0.2310, box: 0.4513)  rpn_loss: 0.1161 (cls: 0.0515, box: 0.0647)
[2025-08-07 19:46:31 train.log] INFO: Epoch: [18]  [Step 7900/14540]  lr: 0.000034  loss: 0.67580  detection_loss: 0.5799 (cls: 0.1461, box: 0.4338)  rpn_loss: 0.0959 (cls: 0.0326, box: 0.0632)
[2025-08-07 19:46:37 train.log] INFO: Epoch: [18]  [Step 8000/14540]  lr: 0.000034  loss: 0.90261  detection_loss: 0.6403 (cls: 0.2368, box: 0.4035)  rpn_loss: 0.2623 (cls: 0.0353, box: 0.2270)
[2025-08-07 19:46:42 train.log] INFO: Epoch: [18]  [Step 8100/14540]  lr: 0.000034  loss: 1.10595  detection_loss: 0.8752 (cls: 0.2025, box: 0.6727)  rpn_loss: 0.2308 (cls: 0.0411, box: 0.1896)
[2025-08-07 19:46:48 train.log] INFO: Epoch: [18]  [Step 8200/14540]  lr: 0.000034  loss: 1.50232  detection_loss: 1.3275 (cls: 0.2855, box: 1.0420)  rpn_loss: 0.1748 (cls: 0.0518, box: 0.1230)
[2025-08-07 19:46:54 train.log] INFO: Epoch: [18]  [Step 8300/14540]  lr: 0.000034  loss: 0.90797  detection_loss: 0.8424 (cls: 0.3134, box: 0.5290)  rpn_loss: 0.0656 (cls: 0.0504, box: 0.0151)
[2025-08-07 19:47:00 train.log] INFO: Epoch: [18]  [Step 8400/14540]  lr: 0.000034  loss: 1.53686  detection_loss: 1.3846 (cls: 0.5557, box: 0.8289)  rpn_loss: 0.1523 (cls: 0.0953, box: 0.0570)
[2025-08-07 19:47:06 train.log] INFO: Epoch: [18]  [Step 8500/14540]  lr: 0.000034  loss: 1.23744  detection_loss: 1.1311 (cls: 0.1450, box: 0.9861)  rpn_loss: 0.1063 (cls: 0.0137, box: 0.0927)
[2025-08-07 19:47:11 train.log] INFO: Epoch: [18]  [Step 8600/14540]  lr: 0.000034  loss: 1.12109  detection_loss: 1.0633 (cls: 0.1799, box: 0.8834)  rpn_loss: 0.0578 (cls: 0.0324, box: 0.0254)
[2025-08-07 19:47:17 train.log] INFO: Epoch: [18]  [Step 8700/14540]  lr: 0.000034  loss: 1.81167  detection_loss: 1.6926 (cls: 0.5612, box: 1.1314)  rpn_loss: 0.1191 (cls: 0.0816, box: 0.0375)
[2025-08-07 19:47:23 train.log] INFO: Epoch: [18]  [Step 8800/14540]  lr: 0.000034  loss: 0.92500  detection_loss: 0.8545 (cls: 0.1798, box: 0.6747)  rpn_loss: 0.0705 (cls: 0.0540, box: 0.0165)
[2025-08-07 19:47:28 train.log] INFO: Epoch: [18]  [Step 8900/14540]  lr: 0.000034  loss: 0.62888  detection_loss: 0.5294 (cls: 0.1521, box: 0.3773)  rpn_loss: 0.0995 (cls: 0.0554, box: 0.0441)
[2025-08-07 19:47:34 train.log] INFO: Epoch: [18]  [Step 9000/14540]  lr: 0.000034  loss: 1.11473  detection_loss: 0.6974 (cls: 0.1672, box: 0.5302)  rpn_loss: 0.4173 (cls: 0.0438, box: 0.3736)
[2025-08-07 19:47:40 train.log] INFO: Epoch: [18]  [Step 9100/14540]  lr: 0.000034  loss: 0.90006  detection_loss: 0.8286 (cls: 0.2611, box: 0.5675)  rpn_loss: 0.0714 (cls: 0.0465, box: 0.0249)
[2025-08-07 19:47:46 train.log] INFO: Epoch: [18]  [Step 9200/14540]  lr: 0.000034  loss: 0.75537  detection_loss: 0.6423 (cls: 0.1212, box: 0.5211)  rpn_loss: 0.1131 (cls: 0.0438, box: 0.0693)
[2025-08-07 19:47:52 train.log] INFO: Epoch: [18]  [Step 9300/14540]  lr: 0.000034  loss: 0.86436  detection_loss: 0.7866 (cls: 0.1583, box: 0.6284)  rpn_loss: 0.0778 (cls: 0.0377, box: 0.0401)
[2025-08-07 19:47:57 train.log] INFO: Epoch: [18]  [Step 9400/14540]  lr: 0.000034  loss: 2.05473  detection_loss: 1.9513 (cls: 0.3802, box: 1.5711)  rpn_loss: 0.1034 (cls: 0.0568, box: 0.0466)
[2025-08-07 19:48:03 train.log] INFO: Epoch: [18]  [Step 9500/14540]  lr: 0.000034  loss: 1.49601  detection_loss: 1.3561 (cls: 0.3478, box: 1.0082)  rpn_loss: 0.1400 (cls: 0.0866, box: 0.0533)
[2025-08-07 19:48:09 train.log] INFO: Epoch: [18]  [Step 9600/14540]  lr: 0.000034  loss: 1.35163  detection_loss: 1.2236 (cls: 0.2277, box: 0.9959)  rpn_loss: 0.1280 (cls: 0.0558, box: 0.0722)
[2025-08-07 19:48:14 train.log] INFO: Epoch: [18]  [Step 9700/14540]  lr: 0.000034  loss: 0.99060  detection_loss: 0.9253 (cls: 0.1903, box: 0.7350)  rpn_loss: 0.0653 (cls: 0.0360, box: 0.0294)
[2025-08-07 19:48:20 train.log] INFO: Epoch: [18]  [Step 9800/14540]  lr: 0.000034  loss: 0.43296  detection_loss: 0.3767 (cls: 0.0712, box: 0.3055)  rpn_loss: 0.0563 (cls: 0.0339, box: 0.0223)
[2025-08-07 19:48:26 train.log] INFO: Epoch: [18]  [Step 9900/14540]  lr: 0.000034  loss: 0.68283  detection_loss: 0.6391 (cls: 0.2262, box: 0.4129)  rpn_loss: 0.0438 (cls: 0.0253, box: 0.0184)
[2025-08-07 19:48:32 train.log] INFO: Epoch: [18]  [Step 10000/14540]  lr: 0.000034  loss: 1.44259  detection_loss: 1.3225 (cls: 0.3837, box: 0.9388)  rpn_loss: 0.1201 (cls: 0.0825, box: 0.0376)
[2025-08-07 19:48:38 train.log] INFO: Epoch: [18]  [Step 10100/14540]  lr: 0.000034  loss: 1.10918  detection_loss: 0.9391 (cls: 0.2197, box: 0.7194)  rpn_loss: 0.1701 (cls: 0.0308, box: 0.1393)
[2025-08-07 19:48:44 train.log] INFO: Epoch: [18]  [Step 10200/14540]  lr: 0.000034  loss: 0.56028  detection_loss: 0.5032 (cls: 0.1458, box: 0.3574)  rpn_loss: 0.0571 (cls: 0.0481, box: 0.0089)
[2025-08-07 19:48:50 train.log] INFO: Epoch: [18]  [Step 10300/14540]  lr: 0.000034  loss: 1.19699  detection_loss: 1.0838 (cls: 0.3360, box: 0.7478)  rpn_loss: 0.1132 (cls: 0.0619, box: 0.0513)
[2025-08-07 19:48:56 train.log] INFO: Epoch: [18]  [Step 10400/14540]  lr: 0.000034  loss: 0.96679  detection_loss: 0.8678 (cls: 0.1811, box: 0.6867)  rpn_loss: 0.0990 (cls: 0.0377, box: 0.0612)
[2025-08-07 19:49:01 train.log] INFO: Epoch: [18]  [Step 10500/14540]  lr: 0.000034  loss: 0.69251  detection_loss: 0.6257 (cls: 0.1279, box: 0.4978)  rpn_loss: 0.0668 (cls: 0.0229, box: 0.0440)
[2025-08-07 19:49:07 train.log] INFO: Epoch: [18]  [Step 10600/14540]  lr: 0.000034  loss: 1.04429  detection_loss: 0.9056 (cls: 0.2432, box: 0.6624)  rpn_loss: 0.1387 (cls: 0.0844, box: 0.0543)
[2025-08-07 19:49:12 train.log] INFO: Epoch: [18]  [Step 10700/14540]  lr: 0.000034  loss: 0.91829  detection_loss: 0.5817 (cls: 0.1999, box: 0.3818)  rpn_loss: 0.3365 (cls: 0.0574, box: 0.2792)
[2025-08-07 19:49:18 train.log] INFO: Epoch: [18]  [Step 10800/14540]  lr: 0.000034  loss: 0.79726  detection_loss: 0.7276 (cls: 0.1393, box: 0.5883)  rpn_loss: 0.0697 (cls: 0.0372, box: 0.0325)
[2025-08-07 19:49:23 train.log] INFO: Epoch: [18]  [Step 10900/14540]  lr: 0.000034  loss: 0.76604  detection_loss: 0.6450 (cls: 0.1847, box: 0.4603)  rpn_loss: 0.1210 (cls: 0.0543, box: 0.0667)
[2025-08-07 19:49:29 train.log] INFO: Epoch: [18]  [Step 11000/14540]  lr: 0.000034  loss: 0.65197  detection_loss: 0.5574 (cls: 0.1520, box: 0.4054)  rpn_loss: 0.0945 (cls: 0.0481, box: 0.0464)
[2025-08-07 19:49:35 train.log] INFO: Epoch: [18]  [Step 11100/14540]  lr: 0.000034  loss: 0.91640  detection_loss: 0.8451 (cls: 0.1761, box: 0.6689)  rpn_loss: 0.0714 (cls: 0.0293, box: 0.0420)
[2025-08-07 19:49:41 train.log] INFO: Epoch: [18]  [Step 11200/14540]  lr: 0.000034  loss: 1.40956  detection_loss: 1.3081 (cls: 0.3874, box: 0.9207)  rpn_loss: 0.1015 (cls: 0.0358, box: 0.0656)
[2025-08-07 19:49:47 train.log] INFO: Epoch: [18]  [Step 11300/14540]  lr: 0.000034  loss: 1.14322  detection_loss: 1.0418 (cls: 0.2669, box: 0.7749)  rpn_loss: 0.1014 (cls: 0.0677, box: 0.0338)
[2025-08-07 19:49:52 train.log] INFO: Epoch: [18]  [Step 11400/14540]  lr: 0.000034  loss: 0.61719  detection_loss: 0.5322 (cls: 0.1503, box: 0.3820)  rpn_loss: 0.0849 (cls: 0.0642, box: 0.0207)
[2025-08-07 19:49:58 train.log] INFO: Epoch: [18]  [Step 11500/14540]  lr: 0.000034  loss: 0.85367  detection_loss: 0.7698 (cls: 0.2691, box: 0.5007)  rpn_loss: 0.0838 (cls: 0.0703, box: 0.0135)
[2025-08-07 19:50:04 train.log] INFO: Epoch: [18]  [Step 11600/14540]  lr: 0.000034  loss: 0.86710  detection_loss: 0.7484 (cls: 0.2616, box: 0.4868)  rpn_loss: 0.1187 (cls: 0.0684, box: 0.0503)
[2025-08-07 19:50:10 train.log] INFO: Epoch: [18]  [Step 11700/14540]  lr: 0.000034  loss: 1.34097  detection_loss: 0.9366 (cls: 0.1876, box: 0.7490)  rpn_loss: 0.4043 (cls: 0.0893, box: 0.3150)
[2025-08-07 19:50:16 train.log] INFO: Epoch: [18]  [Step 11800/14540]  lr: 0.000034  loss: 1.09190  detection_loss: 1.0192 (cls: 0.2467, box: 0.7725)  rpn_loss: 0.0727 (cls: 0.0376, box: 0.0351)
[2025-08-07 19:50:22 train.log] INFO: Epoch: [18]  [Step 11900/14540]  lr: 0.000034  loss: 0.93946  detection_loss: 0.8178 (cls: 0.1933, box: 0.6246)  rpn_loss: 0.1216 (cls: 0.0931, box: 0.0285)
[2025-08-07 19:50:28 train.log] INFO: Epoch: [18]  [Step 12000/14540]  lr: 0.000034  loss: 0.55061  detection_loss: 0.5068 (cls: 0.1230, box: 0.3839)  rpn_loss: 0.0438 (cls: 0.0207, box: 0.0231)
[2025-08-07 19:50:34 train.log] INFO: Epoch: [18]  [Step 12100/14540]  lr: 0.000034  loss: 1.39543  detection_loss: 1.1692 (cls: 0.3786, box: 0.7906)  rpn_loss: 0.2262 (cls: 0.1001, box: 0.1261)
[2025-08-07 19:50:39 train.log] INFO: Epoch: [18]  [Step 12200/14540]  lr: 0.000034  loss: 0.95718  detection_loss: 0.8942 (cls: 0.2754, box: 0.6188)  rpn_loss: 0.0630 (cls: 0.0297, box: 0.0333)
[2025-08-07 19:50:45 train.log] INFO: Epoch: [18]  [Step 12300/14540]  lr: 0.000034  loss: 0.92710  detection_loss: 0.8402 (cls: 0.2485, box: 0.5917)  rpn_loss: 0.0869 (cls: 0.0431, box: 0.0438)
[2025-08-07 19:50:51 train.log] INFO: Epoch: [18]  [Step 12400/14540]  lr: 0.000034  loss: 0.89631  detection_loss: 0.7906 (cls: 0.2324, box: 0.5582)  rpn_loss: 0.1057 (cls: 0.0416, box: 0.0641)
[2025-08-07 19:50:57 train.log] INFO: Epoch: [18]  [Step 12500/14540]  lr: 0.000034  loss: 1.53699  detection_loss: 1.4072 (cls: 0.2617, box: 1.1455)  rpn_loss: 0.1298 (cls: 0.0960, box: 0.0338)
[2025-08-07 19:51:02 train.log] INFO: Epoch: [18]  [Step 12600/14540]  lr: 0.000034  loss: 1.17066  detection_loss: 1.0890 (cls: 0.4336, box: 0.6554)  rpn_loss: 0.0816 (cls: 0.0353, box: 0.0463)
[2025-08-07 19:51:08 train.log] INFO: Epoch: [18]  [Step 12700/14540]  lr: 0.000034  loss: 1.03759  detection_loss: 0.9673 (cls: 0.2088, box: 0.7586)  rpn_loss: 0.0703 (cls: 0.0411, box: 0.0292)
[2025-08-07 19:51:14 train.log] INFO: Epoch: [18]  [Step 12800/14540]  lr: 0.000034  loss: 1.02090  detection_loss: 0.8677 (cls: 0.1556, box: 0.7121)  rpn_loss: 0.1533 (cls: 0.1132, box: 0.0401)
[2025-08-07 19:51:19 train.log] INFO: Epoch: [18]  [Step 12900/14540]  lr: 0.000034  loss: 1.24742  detection_loss: 1.1224 (cls: 0.2172, box: 0.9052)  rpn_loss: 0.1250 (cls: 0.0866, box: 0.0385)
[2025-08-07 19:51:25 train.log] INFO: Epoch: [18]  [Step 13000/14540]  lr: 0.000034  loss: 0.90093  detection_loss: 0.8243 (cls: 0.1914, box: 0.6329)  rpn_loss: 0.0766 (cls: 0.0342, box: 0.0424)
[2025-08-07 19:51:30 train.log] INFO: Epoch: [18]  [Step 13100/14540]  lr: 0.000034  loss: 1.01041  detection_loss: 0.8728 (cls: 0.2889, box: 0.5839)  rpn_loss: 0.1376 (cls: 0.0395, box: 0.0981)
[2025-08-07 19:51:36 train.log] INFO: Epoch: [18]  [Step 13200/14540]  lr: 0.000034  loss: 0.73829  detection_loss: 0.6871 (cls: 0.2562, box: 0.4310)  rpn_loss: 0.0512 (cls: 0.0282, box: 0.0229)
[2025-08-07 19:51:42 train.log] INFO: Epoch: [18]  [Step 13300/14540]  lr: 0.000034  loss: 1.12841  detection_loss: 1.0294 (cls: 0.3028, box: 0.7265)  rpn_loss: 0.0991 (cls: 0.0142, box: 0.0848)
[2025-08-07 19:51:47 train.log] INFO: Epoch: [18]  [Step 13400/14540]  lr: 0.000034  loss: 0.40494  detection_loss: 0.3604 (cls: 0.1144, box: 0.2460)  rpn_loss: 0.0445 (cls: 0.0245, box: 0.0200)
[2025-08-07 19:51:53 train.log] INFO: Epoch: [18]  [Step 13500/14540]  lr: 0.000034  loss: 1.62315  detection_loss: 1.3200 (cls: 0.2837, box: 1.0363)  rpn_loss: 0.3031 (cls: 0.0621, box: 0.2410)
[2025-08-07 19:51:59 train.log] INFO: Epoch: [18]  [Step 13600/14540]  lr: 0.000034  loss: 0.84050  detection_loss: 0.7230 (cls: 0.1170, box: 0.6060)  rpn_loss: 0.1175 (cls: 0.0362, box: 0.0814)
[2025-08-07 19:52:04 train.log] INFO: Epoch: [18]  [Step 13700/14540]  lr: 0.000034  loss: 0.53420  detection_loss: 0.4645 (cls: 0.1462, box: 0.3182)  rpn_loss: 0.0697 (cls: 0.0533, box: 0.0164)
[2025-08-07 19:52:10 train.log] INFO: Epoch: [18]  [Step 13800/14540]  lr: 0.000034  loss: 1.68599  detection_loss: 1.5743 (cls: 0.5108, box: 1.0635)  rpn_loss: 0.1116 (cls: 0.0457, box: 0.0660)
[2025-08-07 19:52:15 train.log] INFO: Epoch: [18]  [Step 13900/14540]  lr: 0.000034  loss: 0.93102  detection_loss: 0.8128 (cls: 0.1628, box: 0.6500)  rpn_loss: 0.1183 (cls: 0.0927, box: 0.0255)
[2025-08-07 19:52:21 train.log] INFO: Epoch: [18]  [Step 14000/14540]  lr: 0.000034  loss: 0.56802  detection_loss: 0.5167 (cls: 0.0914, box: 0.4253)  rpn_loss: 0.0513 (cls: 0.0353, box: 0.0160)
[2025-08-07 19:52:27 train.log] INFO: Epoch: [18]  [Step 14100/14540]  lr: 0.000034  loss: 1.82917  detection_loss: 1.5848 (cls: 0.3075, box: 1.2774)  rpn_loss: 0.2443 (cls: 0.1861, box: 0.0583)
[2025-08-07 19:52:33 train.log] INFO: Epoch: [18]  [Step 14200/14540]  lr: 0.000034  loss: 0.47753  detection_loss: 0.4270 (cls: 0.1112, box: 0.3158)  rpn_loss: 0.0505 (cls: 0.0145, box: 0.0361)
[2025-08-07 19:52:38 train.log] INFO: Epoch: [18]  [Step 14300/14540]  lr: 0.000034  loss: 1.22724  detection_loss: 1.0798 (cls: 0.3023, box: 0.7775)  rpn_loss: 0.1474 (cls: 0.0208, box: 0.1267)
[2025-08-07 19:52:44 train.log] INFO: Epoch: [18]  [Step 14400/14540]  lr: 0.000034  loss: 0.57038  detection_loss: 0.4938 (cls: 0.1475, box: 0.3463)  rpn_loss: 0.0765 (cls: 0.0627, box: 0.0138)
[2025-08-07 19:52:50 train.log] INFO: Epoch: [18]  [Step 14500/14540]  lr: 0.000034  loss: 0.97633  detection_loss: 0.8613 (cls: 0.2776, box: 0.5838)  rpn_loss: 0.1150 (cls: 0.0687, box: 0.0463)
[2025-08-07 19:56:33 train.log] INFO: Epoch: [19]  [Step 100/14540]  lr: 0.000028  loss: 1.02792  detection_loss: 0.6771 (cls: 0.1046, box: 0.5726)  rpn_loss: 0.3508 (cls: 0.0647, box: 0.2861)
[2025-08-07 19:56:39 train.log] INFO: Epoch: [19]  [Step 200/14540]  lr: 0.000028  loss: 0.99959  detection_loss: 0.9455 (cls: 0.1855, box: 0.7600)  rpn_loss: 0.0541 (cls: 0.0332, box: 0.0209)
[2025-08-07 19:56:44 train.log] INFO: Epoch: [19]  [Step 300/14540]  lr: 0.000028  loss: 1.13099  detection_loss: 0.9428 (cls: 0.1848, box: 0.7580)  rpn_loss: 0.1881 (cls: 0.0425, box: 0.1457)
[2025-08-07 19:56:49 train.log] INFO: Epoch: [19]  [Step 400/14540]  lr: 0.000028  loss: 0.78360  detection_loss: 0.7217 (cls: 0.1216, box: 0.6001)  rpn_loss: 0.0619 (cls: 0.0261, box: 0.0358)
[2025-08-07 19:56:54 train.log] INFO: Epoch: [19]  [Step 500/14540]  lr: 0.000028  loss: 0.94330  detection_loss: 0.8493 (cls: 0.1981, box: 0.6512)  rpn_loss: 0.0940 (cls: 0.0424, box: 0.0516)
[2025-08-07 19:56:59 train.log] INFO: Epoch: [19]  [Step 600/14540]  lr: 0.000028  loss: 1.00489  detection_loss: 0.8812 (cls: 0.2692, box: 0.6120)  rpn_loss: 0.1237 (cls: 0.0874, box: 0.0364)
[2025-08-07 19:57:05 train.log] INFO: Epoch: [19]  [Step 700/14540]  lr: 0.000028  loss: 0.95589  detection_loss: 0.8730 (cls: 0.3412, box: 0.5318)  rpn_loss: 0.0829 (cls: 0.0700, box: 0.0128)
[2025-08-07 19:57:10 train.log] INFO: Epoch: [19]  [Step 800/14540]  lr: 0.000028  loss: 0.65863  detection_loss: 0.3790 (cls: 0.1040, box: 0.2750)  rpn_loss: 0.2796 (cls: 0.0633, box: 0.2163)
[2025-08-07 19:57:15 train.log] INFO: Epoch: [19]  [Step 900/14540]  lr: 0.000028  loss: 0.98313  detection_loss: 0.8325 (cls: 0.2091, box: 0.6233)  rpn_loss: 0.1507 (cls: 0.0808, box: 0.0699)
[2025-08-07 19:57:20 train.log] INFO: Epoch: [19]  [Step 1000/14540]  lr: 0.000028  loss: 0.92921  detection_loss: 0.8731 (cls: 0.3474, box: 0.5258)  rpn_loss: 0.0561 (cls: 0.0357, box: 0.0204)
[2025-08-07 19:57:25 train.log] INFO: Epoch: [19]  [Step 1100/14540]  lr: 0.000028  loss: 1.04323  detection_loss: 0.8869 (cls: 0.1876, box: 0.6993)  rpn_loss: 0.1563 (cls: 0.0388, box: 0.1175)
[2025-08-07 19:57:30 train.log] INFO: Epoch: [19]  [Step 1200/14540]  lr: 0.000028  loss: 0.91406  detection_loss: 0.8461 (cls: 0.2129, box: 0.6333)  rpn_loss: 0.0679 (cls: 0.0279, box: 0.0400)
[2025-08-07 19:57:35 train.log] INFO: Epoch: [19]  [Step 1300/14540]  lr: 0.000028  loss: 1.09568  detection_loss: 0.9066 (cls: 0.2437, box: 0.6629)  rpn_loss: 0.1891 (cls: 0.1294, box: 0.0597)
[2025-08-07 19:57:40 train.log] INFO: Epoch: [19]  [Step 1400/14540]  lr: 0.000028  loss: 0.88707  detection_loss: 0.7974 (cls: 0.3242, box: 0.4733)  rpn_loss: 0.0896 (cls: 0.0408, box: 0.0489)
[2025-08-07 19:57:45 train.log] INFO: Epoch: [19]  [Step 1500/14540]  lr: 0.000028  loss: 1.71301  detection_loss: 1.5154 (cls: 0.3105, box: 1.2049)  rpn_loss: 0.1977 (cls: 0.1170, box: 0.0807)
[2025-08-07 19:57:50 train.log] INFO: Epoch: [19]  [Step 1600/14540]  lr: 0.000028  loss: 0.73369  detection_loss: 0.5558 (cls: 0.1095, box: 0.4463)  rpn_loss: 0.1779 (cls: 0.0401, box: 0.1378)
[2025-08-07 19:57:55 train.log] INFO: Epoch: [19]  [Step 1700/14540]  lr: 0.000028  loss: 0.62993  detection_loss: 0.5656 (cls: 0.1391, box: 0.4265)  rpn_loss: 0.0643 (cls: 0.0346, box: 0.0297)
[2025-08-07 19:58:00 train.log] INFO: Epoch: [19]  [Step 1800/14540]  lr: 0.000028  loss: 1.04700  detection_loss: 0.9867 (cls: 0.1340, box: 0.8527)  rpn_loss: 0.0603 (cls: 0.0158, box: 0.0445)
[2025-08-07 19:58:05 train.log] INFO: Epoch: [19]  [Step 1900/14540]  lr: 0.000028  loss: 1.21961  detection_loss: 1.0613 (cls: 0.3808, box: 0.6805)  rpn_loss: 0.1583 (cls: 0.0993, box: 0.0591)
[2025-08-07 19:58:10 train.log] INFO: Epoch: [19]  [Step 2000/14540]  lr: 0.000028  loss: 0.99922  detection_loss: 0.9260 (cls: 0.2652, box: 0.6608)  rpn_loss: 0.0732 (cls: 0.0439, box: 0.0293)
[2025-08-07 19:58:15 train.log] INFO: Epoch: [19]  [Step 2100/14540]  lr: 0.000028  loss: 1.21476  detection_loss: 1.1067 (cls: 0.2710, box: 0.8357)  rpn_loss: 0.1081 (cls: 0.0250, box: 0.0831)
[2025-08-07 19:58:20 train.log] INFO: Epoch: [19]  [Step 2200/14540]  lr: 0.000028  loss: 0.86267  detection_loss: 0.7174 (cls: 0.1412, box: 0.5761)  rpn_loss: 0.1453 (cls: 0.1137, box: 0.0316)
[2025-08-07 19:58:25 train.log] INFO: Epoch: [19]  [Step 2300/14540]  lr: 0.000028  loss: 0.83966  detection_loss: 0.7432 (cls: 0.1276, box: 0.6156)  rpn_loss: 0.0965 (cls: 0.0435, box: 0.0530)
[2025-08-07 19:58:30 train.log] INFO: Epoch: [19]  [Step 2400/14540]  lr: 0.000028  loss: 0.63275  detection_loss: 0.5873 (cls: 0.1362, box: 0.4511)  rpn_loss: 0.0455 (cls: 0.0284, box: 0.0171)
[2025-08-07 19:58:35 train.log] INFO: Epoch: [19]  [Step 2500/14540]  lr: 0.000028  loss: 1.15745  detection_loss: 1.0643 (cls: 0.2053, box: 0.8590)  rpn_loss: 0.0931 (cls: 0.0147, box: 0.0784)
[2025-08-07 19:58:40 train.log] INFO: Epoch: [19]  [Step 2600/14540]  lr: 0.000028  loss: 1.45055  detection_loss: 1.3063 (cls: 0.2098, box: 1.0965)  rpn_loss: 0.1443 (cls: 0.0896, box: 0.0547)
[2025-08-07 19:58:45 train.log] INFO: Epoch: [19]  [Step 2700/14540]  lr: 0.000028  loss: 1.13979  detection_loss: 1.0636 (cls: 0.1986, box: 0.8651)  rpn_loss: 0.0762 (cls: 0.0321, box: 0.0441)
[2025-08-07 19:58:50 train.log] INFO: Epoch: [19]  [Step 2800/14540]  lr: 0.000028  loss: 0.94576  detection_loss: 0.8134 (cls: 0.1715, box: 0.6419)  rpn_loss: 0.1323 (cls: 0.0405, box: 0.0918)
[2025-08-07 19:58:55 train.log] INFO: Epoch: [19]  [Step 2900/14540]  lr: 0.000028  loss: 0.78176  detection_loss: 0.7051 (cls: 0.1905, box: 0.5146)  rpn_loss: 0.0767 (cls: 0.0462, box: 0.0305)
[2025-08-07 19:59:00 train.log] INFO: Epoch: [19]  [Step 3000/14540]  lr: 0.000028  loss: 1.05591  detection_loss: 0.9481 (cls: 0.2961, box: 0.6520)  rpn_loss: 0.1078 (cls: 0.0390, box: 0.0688)
[2025-08-07 19:59:05 train.log] INFO: Epoch: [19]  [Step 3100/14540]  lr: 0.000028  loss: 0.91798  detection_loss: 0.8283 (cls: 0.2512, box: 0.5772)  rpn_loss: 0.0897 (cls: 0.0517, box: 0.0380)
[2025-08-07 19:59:09 train.log] INFO: Epoch: [19]  [Step 3200/14540]  lr: 0.000028  loss: 1.27066  detection_loss: 1.2064 (cls: 0.2888, box: 0.9176)  rpn_loss: 0.0643 (cls: 0.0307, box: 0.0336)
[2025-08-07 19:59:14 train.log] INFO: Epoch: [19]  [Step 3300/14540]  lr: 0.000028  loss: 1.73478  detection_loss: 1.5475 (cls: 0.3151, box: 1.2324)  rpn_loss: 0.1873 (cls: 0.0598, box: 0.1275)
[2025-08-07 19:59:19 train.log] INFO: Epoch: [19]  [Step 3400/14540]  lr: 0.000028  loss: 0.86542  detection_loss: 0.7845 (cls: 0.2067, box: 0.5778)  rpn_loss: 0.0809 (cls: 0.0508, box: 0.0301)
[2025-08-07 19:59:24 train.log] INFO: Epoch: [19]  [Step 3500/14540]  lr: 0.000028  loss: 1.13485  detection_loss: 1.0240 (cls: 0.2590, box: 0.7651)  rpn_loss: 0.1108 (cls: 0.0821, box: 0.0287)
[2025-08-07 19:59:29 train.log] INFO: Epoch: [19]  [Step 3600/14540]  lr: 0.000028  loss: 0.97347  detection_loss: 0.8412 (cls: 0.1747, box: 0.6665)  rpn_loss: 0.1323 (cls: 0.0588, box: 0.0735)
[2025-08-07 19:59:31 train.log] INFO: Epoch: [19]  [Step 3635/14540]  lr: 0.000028  loss: 0.51156  detection_loss: 0.4300 (cls: 0.1577, box: 0.2723)  rpn_loss: 0.0815 (cls: 0.0623, box: 0.0193)
[2025-08-07 19:59:35 train.log] INFO: Epoch: [19]  [Step 3700/14540]  lr: 0.000028  loss: 0.77270  detection_loss: 0.6439 (cls: 0.1799, box: 0.4641)  rpn_loss: 0.1288 (cls: 0.0375, box: 0.0913)
[2025-08-07 19:59:40 train.log] INFO: Epoch: [19]  [Step 3800/14540]  lr: 0.000028  loss: 0.77375  detection_loss: 0.7168 (cls: 0.1388, box: 0.5780)  rpn_loss: 0.0570 (cls: 0.0319, box: 0.0250)
[2025-08-07 19:59:45 train.log] INFO: Epoch: [19]  [Step 3900/14540]  lr: 0.000028  loss: 0.68525  detection_loss: 0.4819 (cls: 0.1156, box: 0.3663)  rpn_loss: 0.2034 (cls: 0.0169, box: 0.1865)
[2025-08-07 19:59:49 train.log] INFO: Epoch: [19]  [Step 4000/14540]  lr: 0.000028  loss: 0.93616  detection_loss: 0.8228 (cls: 0.2285, box: 0.5943)  rpn_loss: 0.1134 (cls: 0.0575, box: 0.0559)
[2025-08-07 19:59:54 train.log] INFO: Epoch: [19]  [Step 4100/14540]  lr: 0.000028  loss: 1.06804  detection_loss: 0.6704 (cls: 0.1480, box: 0.5225)  rpn_loss: 0.3976 (cls: 0.0463, box: 0.3513)
[2025-08-07 19:59:59 train.log] INFO: Epoch: [19]  [Step 4200/14540]  lr: 0.000028  loss: 1.36411  detection_loss: 1.2467 (cls: 0.3140, box: 0.9328)  rpn_loss: 0.1174 (cls: 0.0715, box: 0.0459)
[2025-08-07 20:00:04 train.log] INFO: Epoch: [19]  [Step 4300/14540]  lr: 0.000028  loss: 0.87846  detection_loss: 0.8375 (cls: 0.1967, box: 0.6408)  rpn_loss: 0.0410 (cls: 0.0156, box: 0.0254)
[2025-08-07 20:00:09 train.log] INFO: Epoch: [19]  [Step 4400/14540]  lr: 0.000028  loss: 0.65215  detection_loss: 0.4210 (cls: 0.0961, box: 0.3249)  rpn_loss: 0.2312 (cls: 0.0334, box: 0.1977)
[2025-08-07 20:00:14 train.log] INFO: Epoch: [19]  [Step 4500/14540]  lr: 0.000028  loss: 0.77658  detection_loss: 0.7248 (cls: 0.1509, box: 0.5740)  rpn_loss: 0.0517 (cls: 0.0239, box: 0.0279)
[2025-08-07 20:00:19 train.log] INFO: Epoch: [19]  [Step 4600/14540]  lr: 0.000028  loss: 1.43147  detection_loss: 1.2932 (cls: 0.2844, box: 1.0088)  rpn_loss: 0.1382 (cls: 0.0375, box: 0.1007)
[2025-08-07 20:00:24 train.log] INFO: Epoch: [19]  [Step 4700/14540]  lr: 0.000028  loss: 0.89023  detection_loss: 0.8057 (cls: 0.2958, box: 0.5099)  rpn_loss: 0.0845 (cls: 0.0363, box: 0.0482)
[2025-08-07 20:00:28 train.log] INFO: Epoch: [19]  [Step 4800/14540]  lr: 0.000028  loss: 0.95996  detection_loss: 0.8501 (cls: 0.2438, box: 0.6062)  rpn_loss: 0.1099 (cls: 0.0612, box: 0.0487)
[2025-08-07 20:00:33 train.log] INFO: Epoch: [19]  [Step 4900/14540]  lr: 0.000028  loss: 1.03782  detection_loss: 0.8772 (cls: 0.2181, box: 0.6591)  rpn_loss: 0.1607 (cls: 0.0555, box: 0.1052)
[2025-08-07 20:00:38 train.log] INFO: Epoch: [19]  [Step 5000/14540]  lr: 0.000028  loss: 0.67414  detection_loss: 0.6306 (cls: 0.1332, box: 0.4974)  rpn_loss: 0.0435 (cls: 0.0170, box: 0.0265)
[2025-08-07 20:00:43 train.log] INFO: Epoch: [19]  [Step 5100/14540]  lr: 0.000028  loss: 0.89734  detection_loss: 0.8258 (cls: 0.1777, box: 0.6480)  rpn_loss: 0.0716 (cls: 0.0438, box: 0.0278)
[2025-08-07 20:00:48 train.log] INFO: Epoch: [19]  [Step 5200/14540]  lr: 0.000028  loss: 0.61671  detection_loss: 0.5648 (cls: 0.1480, box: 0.4168)  rpn_loss: 0.0519 (cls: 0.0149, box: 0.0370)
[2025-08-07 20:00:53 train.log] INFO: Epoch: [19]  [Step 5300/14540]  lr: 0.000028  loss: 0.52711  detection_loss: 0.4414 (cls: 0.1469, box: 0.2945)  rpn_loss: 0.0857 (cls: 0.0614, box: 0.0243)
[2025-08-07 20:00:58 train.log] INFO: Epoch: [19]  [Step 5400/14540]  lr: 0.000028  loss: 1.01797  detection_loss: 0.9527 (cls: 0.2349, box: 0.7178)  rpn_loss: 0.0653 (cls: 0.0433, box: 0.0220)
[2025-08-07 20:01:03 train.log] INFO: Epoch: [19]  [Step 5500/14540]  lr: 0.000028  loss: 1.04905  detection_loss: 0.9129 (cls: 0.2522, box: 0.6607)  rpn_loss: 0.1361 (cls: 0.0223, box: 0.1138)
[2025-08-07 20:01:08 train.log] INFO: Epoch: [19]  [Step 5600/14540]  lr: 0.000028  loss: 1.42365  detection_loss: 1.0101 (cls: 0.3422, box: 0.6680)  rpn_loss: 0.4135 (cls: 0.1348, box: 0.2787)
[2025-08-07 20:01:13 train.log] INFO: Epoch: [19]  [Step 5700/14540]  lr: 0.000028  loss: 1.15184  detection_loss: 1.1147 (cls: 0.1812, box: 0.9334)  rpn_loss: 0.0372 (cls: 0.0139, box: 0.0233)
[2025-08-07 20:01:18 train.log] INFO: Epoch: [19]  [Step 5800/14540]  lr: 0.000028  loss: 0.85522  detection_loss: 0.7993 (cls: 0.2170, box: 0.5822)  rpn_loss: 0.0560 (cls: 0.0381, box: 0.0179)
[2025-08-07 20:01:22 train.log] INFO: Epoch: [19]  [Step 5900/14540]  lr: 0.000028  loss: 0.77223  detection_loss: 0.7324 (cls: 0.1763, box: 0.5560)  rpn_loss: 0.0399 (cls: 0.0172, box: 0.0226)
[2025-08-07 20:01:27 train.log] INFO: Epoch: [19]  [Step 6000/14540]  lr: 0.000028  loss: 1.09103  detection_loss: 0.9337 (cls: 0.1467, box: 0.7870)  rpn_loss: 0.1573 (cls: 0.0636, box: 0.0937)
[2025-08-07 20:01:32 train.log] INFO: Epoch: [19]  [Step 6100/14540]  lr: 0.000028  loss: 0.74554  detection_loss: 0.7006 (cls: 0.1240, box: 0.5766)  rpn_loss: 0.0450 (cls: 0.0267, box: 0.0183)
[2025-08-07 20:01:37 train.log] INFO: Epoch: [19]  [Step 6200/14540]  lr: 0.000028  loss: 1.26502  detection_loss: 1.1367 (cls: 0.2800, box: 0.8567)  rpn_loss: 0.1283 (cls: 0.0741, box: 0.0543)
[2025-08-07 20:01:42 train.log] INFO: Epoch: [19]  [Step 6300/14540]  lr: 0.000028  loss: 1.11901  detection_loss: 0.9994 (cls: 0.2451, box: 0.7544)  rpn_loss: 0.1196 (cls: 0.0854, box: 0.0342)
[2025-08-07 20:01:47 train.log] INFO: Epoch: [19]  [Step 6400/14540]  lr: 0.000028  loss: 1.56144  detection_loss: 1.3846 (cls: 0.3411, box: 1.0435)  rpn_loss: 0.1768 (cls: 0.1123, box: 0.0645)
[2025-08-07 20:01:52 train.log] INFO: Epoch: [19]  [Step 6500/14540]  lr: 0.000028  loss: 0.74876  detection_loss: 0.6984 (cls: 0.1482, box: 0.5501)  rpn_loss: 0.0504 (cls: 0.0275, box: 0.0229)
[2025-08-07 20:01:57 train.log] INFO: Epoch: [19]  [Step 6600/14540]  lr: 0.000028  loss: 0.60998  detection_loss: 0.5335 (cls: 0.1348, box: 0.3988)  rpn_loss: 0.0764 (cls: 0.0283, box: 0.0482)
[2025-08-07 20:02:01 train.log] INFO: Epoch: [19]  [Step 6700/14540]  lr: 0.000028  loss: 0.67978  detection_loss: 0.6227 (cls: 0.1989, box: 0.4238)  rpn_loss: 0.0571 (cls: 0.0461, box: 0.0110)
[2025-08-07 20:02:06 train.log] INFO: Epoch: [19]  [Step 6800/14540]  lr: 0.000028  loss: 1.07301  detection_loss: 0.9071 (cls: 0.2153, box: 0.6918)  rpn_loss: 0.1659 (cls: 0.0675, box: 0.0984)
[2025-08-07 20:02:11 train.log] INFO: Epoch: [19]  [Step 6900/14540]  lr: 0.000028  loss: 1.00133  detection_loss: 0.8599 (cls: 0.2280, box: 0.6320)  rpn_loss: 0.1414 (cls: 0.1191, box: 0.0223)
[2025-08-07 20:02:16 train.log] INFO: Epoch: [19]  [Step 7000/14540]  lr: 0.000028  loss: 0.58226  detection_loss: 0.4816 (cls: 0.1184, box: 0.3631)  rpn_loss: 0.1007 (cls: 0.0811, box: 0.0196)
[2025-08-07 20:02:21 train.log] INFO: Epoch: [19]  [Step 7100/14540]  lr: 0.000028  loss: 0.70829  detection_loss: 0.6713 (cls: 0.1704, box: 0.5008)  rpn_loss: 0.0370 (cls: 0.0157, box: 0.0213)
[2025-08-07 20:02:26 train.log] INFO: Epoch: [19]  [Step 7200/14540]  lr: 0.000028  loss: 0.55403  detection_loss: 0.4990 (cls: 0.1399, box: 0.3591)  rpn_loss: 0.0550 (cls: 0.0248, box: 0.0302)
[2025-08-07 20:02:31 train.log] INFO: Epoch: [19]  [Step 7300/14540]  lr: 0.000028  loss: 0.94817  detection_loss: 0.8453 (cls: 0.1390, box: 0.7063)  rpn_loss: 0.1029 (cls: 0.0489, box: 0.0540)
[2025-08-07 20:02:36 train.log] INFO: Epoch: [19]  [Step 7400/14540]  lr: 0.000028  loss: 1.58112  detection_loss: 1.3221 (cls: 0.2956, box: 1.0265)  rpn_loss: 0.2590 (cls: 0.0501, box: 0.2089)
[2025-08-07 20:02:40 train.log] INFO: Epoch: [19]  [Step 7500/14540]  lr: 0.000028  loss: 1.17764  detection_loss: 0.9662 (cls: 0.1885, box: 0.7777)  rpn_loss: 0.2115 (cls: 0.0410, box: 0.1704)
[2025-08-07 20:02:45 train.log] INFO: Epoch: [19]  [Step 7600/14540]  lr: 0.000028  loss: 0.58080  detection_loss: 0.5344 (cls: 0.1019, box: 0.4325)  rpn_loss: 0.0464 (cls: 0.0349, box: 0.0114)
[2025-08-07 20:02:50 train.log] INFO: Epoch: [19]  [Step 7700/14540]  lr: 0.000028  loss: 0.52092  detection_loss: 0.4525 (cls: 0.1283, box: 0.3242)  rpn_loss: 0.0685 (cls: 0.0426, box: 0.0259)
[2025-08-07 20:02:55 train.log] INFO: Epoch: [19]  [Step 7800/14540]  lr: 0.000028  loss: 1.28951  detection_loss: 1.1433 (cls: 0.2534, box: 0.8899)  rpn_loss: 0.1462 (cls: 0.1125, box: 0.0338)
[2025-08-07 20:03:00 train.log] INFO: Epoch: [19]  [Step 7900/14540]  lr: 0.000028  loss: 0.91967  detection_loss: 0.8481 (cls: 0.1399, box: 0.7082)  rpn_loss: 0.0715 (cls: 0.0384, box: 0.0331)
[2025-08-07 20:03:05 train.log] INFO: Epoch: [19]  [Step 8000/14540]  lr: 0.000028  loss: 0.86105  detection_loss: 0.7247 (cls: 0.2264, box: 0.4982)  rpn_loss: 0.1364 (cls: 0.0470, box: 0.0894)
[2025-08-07 20:03:10 train.log] INFO: Epoch: [19]  [Step 8100/14540]  lr: 0.000028  loss: 0.66326  detection_loss: 0.5665 (cls: 0.1827, box: 0.3838)  rpn_loss: 0.0967 (cls: 0.0284, box: 0.0684)
[2025-08-07 20:03:15 train.log] INFO: Epoch: [19]  [Step 8200/14540]  lr: 0.000028  loss: 0.65557  detection_loss: 0.5900 (cls: 0.1355, box: 0.4546)  rpn_loss: 0.0656 (cls: 0.0141, box: 0.0515)
[2025-08-07 20:03:19 train.log] INFO: Epoch: [19]  [Step 8300/14540]  lr: 0.000028  loss: 0.58018  detection_loss: 0.4863 (cls: 0.1085, box: 0.3778)  rpn_loss: 0.0939 (cls: 0.0585, box: 0.0354)
[2025-08-07 20:03:24 train.log] INFO: Epoch: [19]  [Step 8400/14540]  lr: 0.000028  loss: 0.90518  detection_loss: 0.8625 (cls: 0.1588, box: 0.7037)  rpn_loss: 0.0427 (cls: 0.0232, box: 0.0194)
[2025-08-07 20:03:29 train.log] INFO: Epoch: [19]  [Step 8500/14540]  lr: 0.000028  loss: 0.68661  detection_loss: 0.6301 (cls: 0.2048, box: 0.4253)  rpn_loss: 0.0565 (cls: 0.0365, box: 0.0200)
[2025-08-07 20:03:34 train.log] INFO: Epoch: [19]  [Step 8600/14540]  lr: 0.000028  loss: 0.74308  detection_loss: 0.7056 (cls: 0.1265, box: 0.5791)  rpn_loss: 0.0375 (cls: 0.0150, box: 0.0225)
[2025-08-07 20:03:39 train.log] INFO: Epoch: [19]  [Step 8700/14540]  lr: 0.000028  loss: 1.38839  detection_loss: 1.2606 (cls: 0.3076, box: 0.9530)  rpn_loss: 0.1278 (cls: 0.0940, box: 0.0338)
[2025-08-07 20:03:44 train.log] INFO: Epoch: [19]  [Step 8800/14540]  lr: 0.000028  loss: 0.91510  detection_loss: 0.7864 (cls: 0.1498, box: 0.6366)  rpn_loss: 0.1287 (cls: 0.0674, box: 0.0614)
[2025-08-07 20:03:48 train.log] INFO: Epoch: [19]  [Step 8900/14540]  lr: 0.000028  loss: 1.00841  detection_loss: 0.8792 (cls: 0.2171, box: 0.6621)  rpn_loss: 0.1292 (cls: 0.0615, box: 0.0677)
[2025-08-07 20:03:53 train.log] INFO: Epoch: [19]  [Step 9000/14540]  lr: 0.000028  loss: 1.02132  detection_loss: 0.9185 (cls: 0.3123, box: 0.6063)  rpn_loss: 0.1028 (cls: 0.0811, box: 0.0217)
[2025-08-07 20:03:58 train.log] INFO: Epoch: [19]  [Step 9100/14540]  lr: 0.000028  loss: 1.05378  detection_loss: 0.9280 (cls: 0.2196, box: 0.7084)  rpn_loss: 0.1258 (cls: 0.0415, box: 0.0843)
[2025-08-07 20:04:03 train.log] INFO: Epoch: [19]  [Step 9200/14540]  lr: 0.000028  loss: 0.92718  detection_loss: 0.8677 (cls: 0.1975, box: 0.6702)  rpn_loss: 0.0595 (cls: 0.0458, box: 0.0136)
[2025-08-07 20:04:08 train.log] INFO: Epoch: [19]  [Step 9300/14540]  lr: 0.000028  loss: 1.19930  detection_loss: 1.1032 (cls: 0.2614, box: 0.8418)  rpn_loss: 0.0961 (cls: 0.0648, box: 0.0313)
[2025-08-07 20:04:13 train.log] INFO: Epoch: [19]  [Step 9400/14540]  lr: 0.000028  loss: 0.57050  detection_loss: 0.5122 (cls: 0.1396, box: 0.3726)  rpn_loss: 0.0583 (cls: 0.0414, box: 0.0169)
[2025-08-07 20:04:18 train.log] INFO: Epoch: [19]  [Step 9500/14540]  lr: 0.000028  loss: 1.68007  detection_loss: 1.4974 (cls: 0.3742, box: 1.1231)  rpn_loss: 0.1827 (cls: 0.0448, box: 0.1379)
[2025-08-07 20:04:22 train.log] INFO: Epoch: [19]  [Step 9600/14540]  lr: 0.000028  loss: 0.72352  detection_loss: 0.6712 (cls: 0.1105, box: 0.5607)  rpn_loss: 0.0523 (cls: 0.0168, box: 0.0355)
[2025-08-07 20:04:27 train.log] INFO: Epoch: [19]  [Step 9700/14540]  lr: 0.000028  loss: 0.80958  detection_loss: 0.7226 (cls: 0.1559, box: 0.5667)  rpn_loss: 0.0870 (cls: 0.0411, box: 0.0459)
[2025-08-07 20:04:32 train.log] INFO: Epoch: [19]  [Step 9800/14540]  lr: 0.000028  loss: 0.94017  detection_loss: 0.8338 (cls: 0.2037, box: 0.6301)  rpn_loss: 0.1064 (cls: 0.0203, box: 0.0861)
[2025-08-07 20:04:37 train.log] INFO: Epoch: [19]  [Step 9900/14540]  lr: 0.000028  loss: 0.80496  detection_loss: 0.7085 (cls: 0.1826, box: 0.5259)  rpn_loss: 0.0965 (cls: 0.0617, box: 0.0348)
[2025-08-07 20:04:42 train.log] INFO: Epoch: [19]  [Step 10000/14540]  lr: 0.000028  loss: 0.99093  detection_loss: 0.8867 (cls: 0.1634, box: 0.7233)  rpn_loss: 0.1042 (cls: 0.0622, box: 0.0420)
[2025-08-07 20:04:47 train.log] INFO: Epoch: [19]  [Step 10100/14540]  lr: 0.000028  loss: 0.88013  detection_loss: 0.8107 (cls: 0.1261, box: 0.6846)  rpn_loss: 0.0694 (cls: 0.0379, box: 0.0316)
[2025-08-07 20:04:51 train.log] INFO: Epoch: [19]  [Step 10200/14540]  lr: 0.000028  loss: 0.67138  detection_loss: 0.6193 (cls: 0.2084, box: 0.4109)  rpn_loss: 0.0520 (cls: 0.0352, box: 0.0169)
[2025-08-07 20:04:56 train.log] INFO: Epoch: [19]  [Step 10300/14540]  lr: 0.000028  loss: 1.06847  detection_loss: 0.8196 (cls: 0.2128, box: 0.6068)  rpn_loss: 0.2488 (cls: 0.0640, box: 0.1848)
[2025-08-07 20:05:01 train.log] INFO: Epoch: [19]  [Step 10400/14540]  lr: 0.000028  loss: 1.55121  detection_loss: 1.3467 (cls: 0.2424, box: 1.1043)  rpn_loss: 0.2045 (cls: 0.1330, box: 0.0715)
[2025-08-07 20:05:06 train.log] INFO: Epoch: [19]  [Step 10500/14540]  lr: 0.000028  loss: 1.13804  detection_loss: 1.0224 (cls: 0.3614, box: 0.6610)  rpn_loss: 0.1156 (cls: 0.0625, box: 0.0532)
[2025-08-07 20:05:11 train.log] INFO: Epoch: [19]  [Step 10600/14540]  lr: 0.000028  loss: 1.14625  detection_loss: 1.0869 (cls: 0.2332, box: 0.8538)  rpn_loss: 0.0593 (cls: 0.0407, box: 0.0186)
[2025-08-07 20:05:16 train.log] INFO: Epoch: [19]  [Step 10700/14540]  lr: 0.000028  loss: 0.98749  detection_loss: 0.8115 (cls: 0.1900, box: 0.6215)  rpn_loss: 0.1760 (cls: 0.0189, box: 0.1570)
[2025-08-07 20:05:21 train.log] INFO: Epoch: [19]  [Step 10800/14540]  lr: 0.000028  loss: 1.19480  detection_loss: 1.1116 (cls: 0.1742, box: 0.9374)  rpn_loss: 0.0832 (cls: 0.0546, box: 0.0286)
[2025-08-07 20:05:25 train.log] INFO: Epoch: [19]  [Step 10900/14540]  lr: 0.000028  loss: 0.49515  detection_loss: 0.4226 (cls: 0.1086, box: 0.3140)  rpn_loss: 0.0726 (cls: 0.0211, box: 0.0515)
[2025-08-07 20:05:30 train.log] INFO: Epoch: [19]  [Step 11000/14540]  lr: 0.000028  loss: 0.64884  detection_loss: 0.5884 (cls: 0.1559, box: 0.4325)  rpn_loss: 0.0605 (cls: 0.0358, box: 0.0246)
[2025-08-07 20:05:35 train.log] INFO: Epoch: [19]  [Step 11100/14540]  lr: 0.000028  loss: 0.72816  detection_loss: 0.6891 (cls: 0.1854, box: 0.5037)  rpn_loss: 0.0391 (cls: 0.0264, box: 0.0127)
[2025-08-07 20:05:40 train.log] INFO: Epoch: [19]  [Step 11200/14540]  lr: 0.000028  loss: 1.43091  detection_loss: 1.2506 (cls: 0.4963, box: 0.7543)  rpn_loss: 0.1803 (cls: 0.0810, box: 0.0992)
[2025-08-07 20:05:45 train.log] INFO: Epoch: [19]  [Step 11300/14540]  lr: 0.000028  loss: 0.41412  detection_loss: 0.3668 (cls: 0.0902, box: 0.2766)  rpn_loss: 0.0473 (cls: 0.0371, box: 0.0103)
[2025-08-07 20:05:50 train.log] INFO: Epoch: [19]  [Step 11400/14540]  lr: 0.000028  loss: 0.63809  detection_loss: 0.5321 (cls: 0.1765, box: 0.3556)  rpn_loss: 0.1060 (cls: 0.0742, box: 0.0317)
[2025-08-07 20:05:55 train.log] INFO: Epoch: [19]  [Step 11500/14540]  lr: 0.000028  loss: 1.37114  detection_loss: 1.2958 (cls: 0.2823, box: 1.0135)  rpn_loss: 0.0753 (cls: 0.0411, box: 0.0342)
[2025-08-07 20:06:00 train.log] INFO: Epoch: [19]  [Step 11600/14540]  lr: 0.000028  loss: 1.03137  detection_loss: 0.9394 (cls: 0.2374, box: 0.7019)  rpn_loss: 0.0920 (cls: 0.0489, box: 0.0431)
[2025-08-07 20:06:04 train.log] INFO: Epoch: [19]  [Step 11700/14540]  lr: 0.000028  loss: 0.83410  detection_loss: 0.6785 (cls: 0.1900, box: 0.4885)  rpn_loss: 0.1556 (cls: 0.0426, box: 0.1130)
[2025-08-07 20:06:09 train.log] INFO: Epoch: [19]  [Step 11800/14540]  lr: 0.000028  loss: 0.96536  detection_loss: 0.7819 (cls: 0.1695, box: 0.6124)  rpn_loss: 0.1835 (cls: 0.0289, box: 0.1546)
[2025-08-07 20:06:14 train.log] INFO: Epoch: [19]  [Step 11900/14540]  lr: 0.000028  loss: 1.02216  detection_loss: 0.9761 (cls: 0.2138, box: 0.7623)  rpn_loss: 0.0460 (cls: 0.0247, box: 0.0214)
[2025-08-07 20:06:19 train.log] INFO: Epoch: [19]  [Step 12000/14540]  lr: 0.000028  loss: 0.55933  detection_loss: 0.4945 (cls: 0.1111, box: 0.3834)  rpn_loss: 0.0649 (cls: 0.0390, box: 0.0259)
[2025-08-07 20:06:24 train.log] INFO: Epoch: [19]  [Step 12100/14540]  lr: 0.000028  loss: 0.85453  detection_loss: 0.7357 (cls: 0.1611, box: 0.5746)  rpn_loss: 0.1188 (cls: 0.0289, box: 0.0899)
[2025-08-07 20:06:29 train.log] INFO: Epoch: [19]  [Step 12200/14540]  lr: 0.000028  loss: 0.71898  detection_loss: 0.6684 (cls: 0.1220, box: 0.5464)  rpn_loss: 0.0506 (cls: 0.0338, box: 0.0168)
[2025-08-07 20:06:34 train.log] INFO: Epoch: [19]  [Step 12300/14540]  lr: 0.000028  loss: 0.82050  detection_loss: 0.7310 (cls: 0.2526, box: 0.4784)  rpn_loss: 0.0895 (cls: 0.0275, box: 0.0620)
[2025-08-07 20:06:38 train.log] INFO: Epoch: [19]  [Step 12400/14540]  lr: 0.000028  loss: 0.66944  detection_loss: 0.6021 (cls: 0.1493, box: 0.4528)  rpn_loss: 0.0674 (cls: 0.0284, box: 0.0390)
[2025-08-07 20:06:43 train.log] INFO: Epoch: [19]  [Step 12500/14540]  lr: 0.000028  loss: 0.43928  detection_loss: 0.4064 (cls: 0.1012, box: 0.3053)  rpn_loss: 0.0329 (cls: 0.0174, box: 0.0154)
[2025-08-07 20:06:48 train.log] INFO: Epoch: [19]  [Step 12600/14540]  lr: 0.000028  loss: 0.81348  detection_loss: 0.7620 (cls: 0.1226, box: 0.6394)  rpn_loss: 0.0514 (cls: 0.0304, box: 0.0211)
[2025-08-07 20:06:53 train.log] INFO: Epoch: [19]  [Step 12700/14540]  lr: 0.000028  loss: 1.22216  detection_loss: 1.1236 (cls: 0.1145, box: 1.0091)  rpn_loss: 0.0986 (cls: 0.0301, box: 0.0685)
[2025-08-07 20:06:58 train.log] INFO: Epoch: [19]  [Step 12800/14540]  lr: 0.000028  loss: 0.78015  detection_loss: 0.7005 (cls: 0.2252, box: 0.4753)  rpn_loss: 0.0797 (cls: 0.0463, box: 0.0334)
[2025-08-07 20:07:02 train.log] INFO: Epoch: [19]  [Step 12900/14540]  lr: 0.000028  loss: 0.87165  detection_loss: 0.7290 (cls: 0.1848, box: 0.5442)  rpn_loss: 0.1426 (cls: 0.1142, box: 0.0284)
[2025-08-07 20:07:07 train.log] INFO: Epoch: [19]  [Step 13000/14540]  lr: 0.000028  loss: 1.31559  detection_loss: 1.1776 (cls: 0.2328, box: 0.9449)  rpn_loss: 0.1380 (cls: 0.1026, box: 0.0354)
[2025-08-07 20:07:12 train.log] INFO: Epoch: [19]  [Step 13100/14540]  lr: 0.000028  loss: 1.12624  detection_loss: 1.0339 (cls: 0.2438, box: 0.7901)  rpn_loss: 0.0923 (cls: 0.0643, box: 0.0281)
[2025-08-07 20:07:17 train.log] INFO: Epoch: [19]  [Step 13200/14540]  lr: 0.000028  loss: 0.98266  detection_loss: 0.5143 (cls: 0.1773, box: 0.3370)  rpn_loss: 0.4683 (cls: 0.0758, box: 0.3925)
[2025-08-07 20:07:22 train.log] INFO: Epoch: [19]  [Step 13300/14540]  lr: 0.000028  loss: 1.06076  detection_loss: 0.9544 (cls: 0.1848, box: 0.7696)  rpn_loss: 0.1063 (cls: 0.0328, box: 0.0736)
[2025-08-07 20:07:27 train.log] INFO: Epoch: [19]  [Step 13400/14540]  lr: 0.000028  loss: 1.02084  detection_loss: 0.9351 (cls: 0.2987, box: 0.6364)  rpn_loss: 0.0857 (cls: 0.0628, box: 0.0229)
[2025-08-07 20:07:32 train.log] INFO: Epoch: [19]  [Step 13500/14540]  lr: 0.000028  loss: 0.67183  detection_loss: 0.5789 (cls: 0.1646, box: 0.4143)  rpn_loss: 0.0929 (cls: 0.0592, box: 0.0337)
[2025-08-07 20:07:36 train.log] INFO: Epoch: [19]  [Step 13600/14540]  lr: 0.000028  loss: 0.73271  detection_loss: 0.6751 (cls: 0.2415, box: 0.4336)  rpn_loss: 0.0576 (cls: 0.0305, box: 0.0271)
[2025-08-07 20:07:41 train.log] INFO: Epoch: [19]  [Step 13700/14540]  lr: 0.000028  loss: 0.51712  detection_loss: 0.4818 (cls: 0.0718, box: 0.4100)  rpn_loss: 0.0353 (cls: 0.0175, box: 0.0178)
[2025-08-07 20:07:46 train.log] INFO: Epoch: [19]  [Step 13800/14540]  lr: 0.000028  loss: 0.95861  detection_loss: 0.8607 (cls: 0.2601, box: 0.6006)  rpn_loss: 0.0979 (cls: 0.0630, box: 0.0349)
[2025-08-07 20:07:51 train.log] INFO: Epoch: [19]  [Step 13900/14540]  lr: 0.000028  loss: 0.96547  detection_loss: 0.8153 (cls: 0.2376, box: 0.5777)  rpn_loss: 0.1502 (cls: 0.0854, box: 0.0647)
[2025-08-07 20:07:56 train.log] INFO: Epoch: [19]  [Step 14000/14540]  lr: 0.000028  loss: 1.12776  detection_loss: 0.9779 (cls: 0.2856, box: 0.6923)  rpn_loss: 0.1498 (cls: 0.0493, box: 0.1005)
[2025-08-07 20:08:01 train.log] INFO: Epoch: [19]  [Step 14100/14540]  lr: 0.000028  loss: 0.70700  detection_loss: 0.6175 (cls: 0.1499, box: 0.4677)  rpn_loss: 0.0895 (cls: 0.0679, box: 0.0215)
[2025-08-07 20:08:05 train.log] INFO: Epoch: [19]  [Step 14200/14540]  lr: 0.000028  loss: 1.63608  detection_loss: 1.5403 (cls: 0.4376, box: 1.1027)  rpn_loss: 0.0958 (cls: 0.0421, box: 0.0537)
[2025-08-07 20:08:10 train.log] INFO: Epoch: [19]  [Step 14300/14540]  lr: 0.000028  loss: 0.81645  detection_loss: 0.7422 (cls: 0.1634, box: 0.5788)  rpn_loss: 0.0743 (cls: 0.0499, box: 0.0244)
[2025-08-07 20:08:15 train.log] INFO: Epoch: [19]  [Step 14400/14540]  lr: 0.000028  loss: 0.81452  detection_loss: 0.7376 (cls: 0.2210, box: 0.5166)  rpn_loss: 0.0769 (cls: 0.0595, box: 0.0174)
[2025-08-07 20:08:20 train.log] INFO: Epoch: [19]  [Step 14500/14540]  lr: 0.000028  loss: 0.48922  detection_loss: 0.4423 (cls: 0.0867, box: 0.3556)  rpn_loss: 0.0469 (cls: 0.0132, box: 0.0337)
[2025-08-07 20:11:17 train.log] INFO: Epoch: [20]  [Step 100/14540]  lr: 0.000023  loss: 0.77906  detection_loss: 0.7365 (cls: 0.1724, box: 0.5642)  rpn_loss: 0.0425 (cls: 0.0242, box: 0.0183)
[2025-08-07 20:11:22 train.log] INFO: Epoch: [20]  [Step 200/14540]  lr: 0.000023  loss: 0.53873  detection_loss: 0.4861 (cls: 0.0870, box: 0.3991)  rpn_loss: 0.0526 (cls: 0.0258, box: 0.0269)
[2025-08-07 20:11:27 train.log] INFO: Epoch: [20]  [Step 300/14540]  lr: 0.000023  loss: 0.64757  detection_loss: 0.5243 (cls: 0.0800, box: 0.4442)  rpn_loss: 0.1233 (cls: 0.0304, box: 0.0929)
[2025-08-07 20:11:32 train.log] INFO: Epoch: [20]  [Step 400/14540]  lr: 0.000023  loss: 0.91818  detection_loss: 0.8520 (cls: 0.1780, box: 0.6740)  rpn_loss: 0.0662 (cls: 0.0222, box: 0.0440)
[2025-08-07 20:11:36 train.log] INFO: Epoch: [20]  [Step 500/14540]  lr: 0.000023  loss: 1.01575  detection_loss: 0.9050 (cls: 0.1118, box: 0.7932)  rpn_loss: 0.1108 (cls: 0.0258, box: 0.0850)
[2025-08-07 20:11:41 train.log] INFO: Epoch: [20]  [Step 600/14540]  lr: 0.000023  loss: 1.05866  detection_loss: 0.9607 (cls: 0.3039, box: 0.6568)  rpn_loss: 0.0979 (cls: 0.0719, box: 0.0261)
[2025-08-07 20:11:46 train.log] INFO: Epoch: [20]  [Step 700/14540]  lr: 0.000023  loss: 1.30906  detection_loss: 1.2354 (cls: 0.3738, box: 0.8616)  rpn_loss: 0.0736 (cls: 0.0423, box: 0.0313)
[2025-08-07 20:11:51 train.log] INFO: Epoch: [20]  [Step 800/14540]  lr: 0.000023  loss: 0.48218  detection_loss: 0.4465 (cls: 0.0559, box: 0.3906)  rpn_loss: 0.0357 (cls: 0.0195, box: 0.0162)
[2025-08-07 20:11:56 train.log] INFO: Epoch: [20]  [Step 900/14540]  lr: 0.000023  loss: 0.66241  detection_loss: 0.5020 (cls: 0.1309, box: 0.3711)  rpn_loss: 0.1604 (cls: 0.1406, box: 0.0197)
[2025-08-07 20:12:01 train.log] INFO: Epoch: [20]  [Step 1000/14540]  lr: 0.000023  loss: 1.07411  detection_loss: 0.9860 (cls: 0.3981, box: 0.5879)  rpn_loss: 0.0881 (cls: 0.0399, box: 0.0482)
[2025-08-07 20:12:06 train.log] INFO: Epoch: [20]  [Step 1100/14540]  lr: 0.000023  loss: 0.74881  detection_loss: 0.6730 (cls: 0.1798, box: 0.4932)  rpn_loss: 0.0758 (cls: 0.0219, box: 0.0539)
[2025-08-07 20:12:11 train.log] INFO: Epoch: [20]  [Step 1200/14540]  lr: 0.000023  loss: 0.75193  detection_loss: 0.7118 (cls: 0.1619, box: 0.5499)  rpn_loss: 0.0401 (cls: 0.0105, box: 0.0297)
[2025-08-07 20:12:16 train.log] INFO: Epoch: [20]  [Step 1300/14540]  lr: 0.000023  loss: 0.64872  detection_loss: 0.5978 (cls: 0.1396, box: 0.4582)  rpn_loss: 0.0509 (cls: 0.0188, box: 0.0321)
[2025-08-07 20:12:21 train.log] INFO: Epoch: [20]  [Step 1400/14540]  lr: 0.000023  loss: 0.56077  detection_loss: 0.5270 (cls: 0.1395, box: 0.3875)  rpn_loss: 0.0337 (cls: 0.0092, box: 0.0246)
[2025-08-07 20:12:26 train.log] INFO: Epoch: [20]  [Step 1500/14540]  lr: 0.000023  loss: 1.09555  detection_loss: 1.0331 (cls: 0.1599, box: 0.8732)  rpn_loss: 0.0625 (cls: 0.0339, box: 0.0286)
[2025-08-07 20:12:31 train.log] INFO: Epoch: [20]  [Step 1600/14540]  lr: 0.000023  loss: 1.26720  detection_loss: 1.1792 (cls: 0.3229, box: 0.8564)  rpn_loss: 0.0880 (cls: 0.0593, box: 0.0287)
[2025-08-07 20:12:36 train.log] INFO: Epoch: [20]  [Step 1700/14540]  lr: 0.000023  loss: 1.18621  detection_loss: 1.0365 (cls: 0.1931, box: 0.8434)  rpn_loss: 0.1497 (cls: 0.0413, box: 0.1084)
[2025-08-07 20:12:41 train.log] INFO: Epoch: [20]  [Step 1800/14540]  lr: 0.000023  loss: 0.69350  detection_loss: 0.6226 (cls: 0.1738, box: 0.4488)  rpn_loss: 0.0709 (cls: 0.0235, box: 0.0474)
[2025-08-07 20:12:46 train.log] INFO: Epoch: [20]  [Step 1900/14540]  lr: 0.000023  loss: 1.48128  detection_loss: 1.3201 (cls: 0.2220, box: 1.0981)  rpn_loss: 0.1612 (cls: 0.0580, box: 0.1031)
[2025-08-07 20:12:51 train.log] INFO: Epoch: [20]  [Step 2000/14540]  lr: 0.000023  loss: 0.51987  detection_loss: 0.2787 (cls: 0.0833, box: 0.1955)  rpn_loss: 0.2411 (cls: 0.0160, box: 0.2251)
[2025-08-07 20:12:56 train.log] INFO: Epoch: [20]  [Step 2100/14540]  lr: 0.000023  loss: 1.06550  detection_loss: 0.8952 (cls: 0.3676, box: 0.5276)  rpn_loss: 0.1703 (cls: 0.1410, box: 0.0293)
[2025-08-07 20:13:01 train.log] INFO: Epoch: [20]  [Step 2200/14540]  lr: 0.000023  loss: 1.17178  detection_loss: 1.1013 (cls: 0.3163, box: 0.7850)  rpn_loss: 0.0705 (cls: 0.0433, box: 0.0272)
[2025-08-07 20:13:06 train.log] INFO: Epoch: [20]  [Step 2300/14540]  lr: 0.000023  loss: 0.49267  detection_loss: 0.4552 (cls: 0.1927, box: 0.2625)  rpn_loss: 0.0375 (cls: 0.0227, box: 0.0148)
[2025-08-07 20:13:10 train.log] INFO: Epoch: [20]  [Step 2400/14540]  lr: 0.000023  loss: 0.90880  detection_loss: 0.8265 (cls: 0.1872, box: 0.6392)  rpn_loss: 0.0823 (cls: 0.0374, box: 0.0450)
[2025-08-07 20:13:15 train.log] INFO: Epoch: [20]  [Step 2500/14540]  lr: 0.000023  loss: 0.82368  detection_loss: 0.7212 (cls: 0.2034, box: 0.5178)  rpn_loss: 0.1025 (cls: 0.0722, box: 0.0302)
[2025-08-07 20:13:20 train.log] INFO: Epoch: [20]  [Step 2600/14540]  lr: 0.000023  loss: 0.70257  detection_loss: 0.5783 (cls: 0.1890, box: 0.3893)  rpn_loss: 0.1243 (cls: 0.0404, box: 0.0838)
[2025-08-07 20:13:25 train.log] INFO: Epoch: [20]  [Step 2700/14540]  lr: 0.000023  loss: 0.67004  detection_loss: 0.5698 (cls: 0.1526, box: 0.4172)  rpn_loss: 0.1003 (cls: 0.0550, box: 0.0452)
[2025-08-07 20:13:30 train.log] INFO: Epoch: [20]  [Step 2800/14540]  lr: 0.000023  loss: 1.17340  detection_loss: 1.0375 (cls: 0.2218, box: 0.8157)  rpn_loss: 0.1359 (cls: 0.1048, box: 0.0311)
[2025-08-07 20:13:35 train.log] INFO: Epoch: [20]  [Step 2900/14540]  lr: 0.000023  loss: 1.42741  detection_loss: 1.3462 (cls: 0.0784, box: 1.2678)  rpn_loss: 0.0812 (cls: 0.0344, box: 0.0469)
[2025-08-07 20:13:40 train.log] INFO: Epoch: [20]  [Step 3000/14540]  lr: 0.000023  loss: 0.63608  detection_loss: 0.5471 (cls: 0.1548, box: 0.3923)  rpn_loss: 0.0890 (cls: 0.0492, box: 0.0398)
[2025-08-07 20:13:45 train.log] INFO: Epoch: [20]  [Step 3100/14540]  lr: 0.000023  loss: 0.82691  detection_loss: 0.7510 (cls: 0.1906, box: 0.5604)  rpn_loss: 0.0759 (cls: 0.0250, box: 0.0509)
[2025-08-07 20:13:49 train.log] INFO: Epoch: [20]  [Step 3200/14540]  lr: 0.000023  loss: 0.50787  detection_loss: 0.4159 (cls: 0.1181, box: 0.2977)  rpn_loss: 0.0920 (cls: 0.0327, box: 0.0594)
[2025-08-07 20:13:54 train.log] INFO: Epoch: [20]  [Step 3300/14540]  lr: 0.000023  loss: 1.26826  detection_loss: 1.1588 (cls: 0.2868, box: 0.8719)  rpn_loss: 0.1095 (cls: 0.0307, box: 0.0788)
[2025-08-07 20:13:59 train.log] INFO: Epoch: [20]  [Step 3400/14540]  lr: 0.000023  loss: 0.93170  detection_loss: 0.8173 (cls: 0.2051, box: 0.6122)  rpn_loss: 0.1145 (cls: 0.0572, box: 0.0573)
[2025-08-07 20:14:04 train.log] INFO: Epoch: [20]  [Step 3500/14540]  lr: 0.000023  loss: 0.46328  detection_loss: 0.4107 (cls: 0.1809, box: 0.2298)  rpn_loss: 0.0526 (cls: 0.0306, box: 0.0220)
[2025-08-07 20:14:09 train.log] INFO: Epoch: [20]  [Step 3600/14540]  lr: 0.000023  loss: 0.76546  detection_loss: 0.6858 (cls: 0.1973, box: 0.4885)  rpn_loss: 0.0797 (cls: 0.0413, box: 0.0384)
[2025-08-07 20:14:11 train.log] INFO: Epoch: [20]  [Step 3635/14540]  lr: 0.000023  loss: 1.05946  detection_loss: 0.7253 (cls: 0.1029, box: 0.6224)  rpn_loss: 0.3341 (cls: 0.0601, box: 0.2741)
[2025-08-07 20:14:14 train.log] INFO: Epoch: [20]  [Step 3700/14540]  lr: 0.000023  loss: 1.02707  detection_loss: 0.8971 (cls: 0.2601, box: 0.6369)  rpn_loss: 0.1300 (cls: 0.1031, box: 0.0269)
[2025-08-07 20:14:19 train.log] INFO: Epoch: [20]  [Step 3800/14540]  lr: 0.000023  loss: 0.76159  detection_loss: 0.7255 (cls: 0.1557, box: 0.5698)  rpn_loss: 0.0361 (cls: 0.0180, box: 0.0181)
[2025-08-07 20:14:24 train.log] INFO: Epoch: [20]  [Step 3900/14540]  lr: 0.000023  loss: 0.80586  detection_loss: 0.7306 (cls: 0.2633, box: 0.4673)  rpn_loss: 0.0752 (cls: 0.0598, box: 0.0154)
[2025-08-07 20:14:29 train.log] INFO: Epoch: [20]  [Step 4000/14540]  lr: 0.000023  loss: 1.29349  detection_loss: 1.1858 (cls: 0.2376, box: 0.9482)  rpn_loss: 0.1076 (cls: 0.0374, box: 0.0702)
[2025-08-07 20:14:33 train.log] INFO: Epoch: [20]  [Step 4100/14540]  lr: 0.000023  loss: 0.74726  detection_loss: 0.6893 (cls: 0.1179, box: 0.5713)  rpn_loss: 0.0580 (cls: 0.0158, box: 0.0422)
[2025-08-07 20:14:38 train.log] INFO: Epoch: [20]  [Step 4200/14540]  lr: 0.000023  loss: 1.30235  detection_loss: 1.0817 (cls: 0.2086, box: 0.8732)  rpn_loss: 0.2206 (cls: 0.0240, box: 0.1966)
[2025-08-07 20:14:43 train.log] INFO: Epoch: [20]  [Step 4300/14540]  lr: 0.000023  loss: 0.71271  detection_loss: 0.6575 (cls: 0.1437, box: 0.5138)  rpn_loss: 0.0552 (cls: 0.0313, box: 0.0239)
[2025-08-07 20:14:48 train.log] INFO: Epoch: [20]  [Step 4400/14540]  lr: 0.000023  loss: 1.42234  detection_loss: 1.2643 (cls: 0.2205, box: 1.0437)  rpn_loss: 0.1581 (cls: 0.1242, box: 0.0338)
[2025-08-07 20:14:53 train.log] INFO: Epoch: [20]  [Step 4500/14540]  lr: 0.000023  loss: 0.85631  detection_loss: 0.7404 (cls: 0.2232, box: 0.5172)  rpn_loss: 0.1159 (cls: 0.0407, box: 0.0751)
[2025-08-07 20:14:58 train.log] INFO: Epoch: [20]  [Step 4600/14540]  lr: 0.000023  loss: 0.75682  detection_loss: 0.6655 (cls: 0.1972, box: 0.4683)  rpn_loss: 0.0913 (cls: 0.0762, box: 0.0151)
[2025-08-07 20:15:03 train.log] INFO: Epoch: [20]  [Step 4700/14540]  lr: 0.000023  loss: 0.97833  detection_loss: 0.4483 (cls: 0.1625, box: 0.2858)  rpn_loss: 0.5300 (cls: 0.0540, box: 0.4760)
[2025-08-07 20:15:08 train.log] INFO: Epoch: [20]  [Step 4800/14540]  lr: 0.000023  loss: 0.77597  detection_loss: 0.7114 (cls: 0.1573, box: 0.5541)  rpn_loss: 0.0646 (cls: 0.0285, box: 0.0361)
[2025-08-07 20:15:12 train.log] INFO: Epoch: [20]  [Step 4900/14540]  lr: 0.000023  loss: 0.71222  detection_loss: 0.6122 (cls: 0.1738, box: 0.4384)  rpn_loss: 0.1000 (cls: 0.0825, box: 0.0176)
[2025-08-07 20:15:17 train.log] INFO: Epoch: [20]  [Step 5000/14540]  lr: 0.000023  loss: 0.95021  detection_loss: 0.8719 (cls: 0.1790, box: 0.6928)  rpn_loss: 0.0783 (cls: 0.0600, box: 0.0183)
[2025-08-07 20:15:22 train.log] INFO: Epoch: [20]  [Step 5100/14540]  lr: 0.000023  loss: 0.42869  detection_loss: 0.3917 (cls: 0.0867, box: 0.3050)  rpn_loss: 0.0370 (cls: 0.0097, box: 0.0274)
[2025-08-07 20:15:27 train.log] INFO: Epoch: [20]  [Step 5200/14540]  lr: 0.000023  loss: 0.60844  detection_loss: 0.5483 (cls: 0.2047, box: 0.3436)  rpn_loss: 0.0602 (cls: 0.0327, box: 0.0275)
[2025-08-07 20:15:32 train.log] INFO: Epoch: [20]  [Step 5300/14540]  lr: 0.000023  loss: 0.95216  detection_loss: 0.8520 (cls: 0.1688, box: 0.6832)  rpn_loss: 0.1002 (cls: 0.0266, box: 0.0736)
[2025-08-07 20:15:37 train.log] INFO: Epoch: [20]  [Step 5400/14540]  lr: 0.000023  loss: 1.14094  detection_loss: 0.9618 (cls: 0.3148, box: 0.6470)  rpn_loss: 0.1792 (cls: 0.0750, box: 0.1042)
[2025-08-07 20:15:42 train.log] INFO: Epoch: [20]  [Step 5500/14540]  lr: 0.000023  loss: 0.73164  detection_loss: 0.6559 (cls: 0.1749, box: 0.4810)  rpn_loss: 0.0757 (cls: 0.0379, box: 0.0378)
[2025-08-07 20:15:47 train.log] INFO: Epoch: [20]  [Step 5600/14540]  lr: 0.000023  loss: 0.98757  detection_loss: 0.7442 (cls: 0.1752, box: 0.5690)  rpn_loss: 0.2434 (cls: 0.1664, box: 0.0770)
[2025-08-07 20:15:51 train.log] INFO: Epoch: [20]  [Step 5700/14540]  lr: 0.000023  loss: 0.67430  detection_loss: 0.5366 (cls: 0.1639, box: 0.3727)  rpn_loss: 0.1377 (cls: 0.1223, box: 0.0154)
[2025-08-07 20:15:56 train.log] INFO: Epoch: [20]  [Step 5800/14540]  lr: 0.000023  loss: 0.69229  detection_loss: 0.6055 (cls: 0.2004, box: 0.4051)  rpn_loss: 0.0868 (cls: 0.0728, box: 0.0140)
[2025-08-07 20:16:01 train.log] INFO: Epoch: [20]  [Step 5900/14540]  lr: 0.000023  loss: 1.12872  detection_loss: 1.0408 (cls: 0.3562, box: 0.6845)  rpn_loss: 0.0880 (cls: 0.0636, box: 0.0243)
[2025-08-07 20:16:06 train.log] INFO: Epoch: [20]  [Step 6000/14540]  lr: 0.000023  loss: 1.14035  detection_loss: 0.9926 (cls: 0.2136, box: 0.7789)  rpn_loss: 0.1478 (cls: 0.1008, box: 0.0469)
[2025-08-07 20:16:11 train.log] INFO: Epoch: [20]  [Step 6100/14540]  lr: 0.000023  loss: 0.86210  detection_loss: 0.7783 (cls: 0.2609, box: 0.5173)  rpn_loss: 0.0838 (cls: 0.0426, box: 0.0413)
[2025-08-07 20:16:16 train.log] INFO: Epoch: [20]  [Step 6200/14540]  lr: 0.000023  loss: 0.96111  detection_loss: 0.7848 (cls: 0.2139, box: 0.5709)  rpn_loss: 0.1763 (cls: 0.0320, box: 0.1443)
[2025-08-07 20:16:21 train.log] INFO: Epoch: [20]  [Step 6300/14540]  lr: 0.000023  loss: 1.00729  detection_loss: 0.8784 (cls: 0.2675, box: 0.6110)  rpn_loss: 0.1288 (cls: 0.0877, box: 0.0412)
[2025-08-07 20:16:26 train.log] INFO: Epoch: [20]  [Step 6400/14540]  lr: 0.000023  loss: 0.49439  detection_loss: 0.4503 (cls: 0.0946, box: 0.3557)  rpn_loss: 0.0441 (cls: 0.0278, box: 0.0163)
[2025-08-07 20:16:30 train.log] INFO: Epoch: [20]  [Step 6500/14540]  lr: 0.000023  loss: 0.83966  detection_loss: 0.7587 (cls: 0.0886, box: 0.6701)  rpn_loss: 0.0810 (cls: 0.0160, box: 0.0650)
[2025-08-07 20:16:35 train.log] INFO: Epoch: [20]  [Step 6600/14540]  lr: 0.000023  loss: 0.93962  detection_loss: 0.8988 (cls: 0.1262, box: 0.7726)  rpn_loss: 0.0408 (cls: 0.0159, box: 0.0249)
[2025-08-07 20:16:40 train.log] INFO: Epoch: [20]  [Step 6700/14540]  lr: 0.000023  loss: 0.92916  detection_loss: 0.8324 (cls: 0.2256, box: 0.6068)  rpn_loss: 0.0967 (cls: 0.0529, box: 0.0439)
[2025-08-07 20:16:45 train.log] INFO: Epoch: [20]  [Step 6800/14540]  lr: 0.000023  loss: 0.88602  detection_loss: 0.8471 (cls: 0.1714, box: 0.6756)  rpn_loss: 0.0389 (cls: 0.0293, box: 0.0097)
[2025-08-07 20:16:50 train.log] INFO: Epoch: [20]  [Step 6900/14540]  lr: 0.000023  loss: 1.29005  detection_loss: 1.1817 (cls: 0.4371, box: 0.7446)  rpn_loss: 0.1083 (cls: 0.0734, box: 0.0350)
[2025-08-07 20:16:55 train.log] INFO: Epoch: [20]  [Step 7000/14540]  lr: 0.000023  loss: 1.17191  detection_loss: 1.0415 (cls: 0.1779, box: 0.8636)  rpn_loss: 0.1304 (cls: 0.1174, box: 0.0131)
[2025-08-07 20:17:00 train.log] INFO: Epoch: [20]  [Step 7100/14540]  lr: 0.000023  loss: 1.01351  detection_loss: 0.9207 (cls: 0.3832, box: 0.5375)  rpn_loss: 0.0928 (cls: 0.0415, box: 0.0512)
[2025-08-07 20:17:05 train.log] INFO: Epoch: [20]  [Step 7200/14540]  lr: 0.000023  loss: 1.15173  detection_loss: 0.8842 (cls: 0.2057, box: 0.6785)  rpn_loss: 0.2676 (cls: 0.0548, box: 0.2128)
[2025-08-07 20:17:09 train.log] INFO: Epoch: [20]  [Step 7300/14540]  lr: 0.000023  loss: 1.28721  detection_loss: 1.1426 (cls: 0.2925, box: 0.8501)  rpn_loss: 0.1447 (cls: 0.1157, box: 0.0289)
[2025-08-07 20:17:14 train.log] INFO: Epoch: [20]  [Step 7400/14540]  lr: 0.000023  loss: 1.35275  detection_loss: 1.2920 (cls: 0.3376, box: 0.9544)  rpn_loss: 0.0608 (cls: 0.0184, box: 0.0424)
[2025-08-07 20:17:19 train.log] INFO: Epoch: [20]  [Step 7500/14540]  lr: 0.000023  loss: 0.42662  detection_loss: 0.3448 (cls: 0.1206, box: 0.2241)  rpn_loss: 0.0818 (cls: 0.0481, box: 0.0338)
[2025-08-07 20:17:24 train.log] INFO: Epoch: [20]  [Step 7600/14540]  lr: 0.000023  loss: 0.83975  detection_loss: 0.5768 (cls: 0.1585, box: 0.4183)  rpn_loss: 0.2629 (cls: 0.0272, box: 0.2358)
[2025-08-07 20:17:28 train.log] INFO: Epoch: [20]  [Step 7700/14540]  lr: 0.000023  loss: 0.93385  detection_loss: 0.9135 (cls: 0.1085, box: 0.8050)  rpn_loss: 0.0203 (cls: 0.0094, box: 0.0109)
[2025-08-07 20:17:33 train.log] INFO: Epoch: [20]  [Step 7800/14540]  lr: 0.000023  loss: 1.48704  detection_loss: 1.3766 (cls: 0.4478, box: 0.9288)  rpn_loss: 0.1104 (cls: 0.0510, box: 0.0594)
[2025-08-07 20:17:38 train.log] INFO: Epoch: [20]  [Step 7900/14540]  lr: 0.000023  loss: 0.95995  detection_loss: 0.9173 (cls: 0.1484, box: 0.7689)  rpn_loss: 0.0426 (cls: 0.0172, box: 0.0255)
[2025-08-07 20:17:44 train.log] INFO: Epoch: [20]  [Step 8000/14540]  lr: 0.000023  loss: 0.89631  detection_loss: 0.8413 (cls: 0.2705, box: 0.5708)  rpn_loss: 0.0550 (cls: 0.0210, box: 0.0340)
[2025-08-07 20:17:49 train.log] INFO: Epoch: [20]  [Step 8100/14540]  lr: 0.000023  loss: 0.69213  detection_loss: 0.6530 (cls: 0.1925, box: 0.4605)  rpn_loss: 0.0392 (cls: 0.0137, box: 0.0254)
[2025-08-07 20:17:55 train.log] INFO: Epoch: [20]  [Step 8200/14540]  lr: 0.000023  loss: 1.45952  detection_loss: 1.3471 (cls: 0.3013, box: 1.0458)  rpn_loss: 0.1124 (cls: 0.0399, box: 0.0725)
[2025-08-07 20:18:00 train.log] INFO: Epoch: [20]  [Step 8300/14540]  lr: 0.000023  loss: 0.62281  detection_loss: 0.5862 (cls: 0.1952, box: 0.3910)  rpn_loss: 0.0366 (cls: 0.0114, box: 0.0253)
[2025-08-07 20:18:06 train.log] INFO: Epoch: [20]  [Step 8400/14540]  lr: 0.000023  loss: 1.17765  detection_loss: 1.0365 (cls: 0.1961, box: 0.8404)  rpn_loss: 0.1412 (cls: 0.1078, box: 0.0334)
[2025-08-07 20:18:12 train.log] INFO: Epoch: [20]  [Step 8500/14540]  lr: 0.000023  loss: 0.90274  detection_loss: 0.7962 (cls: 0.2184, box: 0.5778)  rpn_loss: 0.1065 (cls: 0.0224, box: 0.0842)
[2025-08-07 20:18:17 train.log] INFO: Epoch: [20]  [Step 8600/14540]  lr: 0.000023  loss: 0.71525  detection_loss: 0.5465 (cls: 0.1437, box: 0.4027)  rpn_loss: 0.1688 (cls: 0.0194, box: 0.1494)
[2025-08-07 20:18:23 train.log] INFO: Epoch: [20]  [Step 8700/14540]  lr: 0.000023  loss: 1.37269  detection_loss: 1.2274 (cls: 0.2747, box: 0.9527)  rpn_loss: 0.1453 (cls: 0.0863, box: 0.0590)
[2025-08-07 20:18:29 train.log] INFO: Epoch: [20]  [Step 8800/14540]  lr: 0.000023  loss: 1.16379  detection_loss: 1.0776 (cls: 0.1129, box: 0.9647)  rpn_loss: 0.0862 (cls: 0.0232, box: 0.0631)
[2025-08-07 20:18:34 train.log] INFO: Epoch: [20]  [Step 8900/14540]  lr: 0.000023  loss: 1.31431  detection_loss: 1.0817 (cls: 0.2472, box: 0.8346)  rpn_loss: 0.2326 (cls: 0.1118, box: 0.1208)
[2025-08-07 20:18:40 train.log] INFO: Epoch: [20]  [Step 9000/14540]  lr: 0.000023  loss: 0.89534  detection_loss: 0.8145 (cls: 0.2064, box: 0.6082)  rpn_loss: 0.0808 (cls: 0.0369, box: 0.0438)
[2025-08-07 20:18:45 train.log] INFO: Epoch: [20]  [Step 9100/14540]  lr: 0.000023  loss: 0.51304  detection_loss: 0.4541 (cls: 0.1288, box: 0.3253)  rpn_loss: 0.0589 (cls: 0.0340, box: 0.0249)
[2025-08-07 20:18:51 train.log] INFO: Epoch: [20]  [Step 9200/14540]  lr: 0.000023  loss: 0.89470  detection_loss: 0.8380 (cls: 0.2254, box: 0.6125)  rpn_loss: 0.0567 (cls: 0.0236, box: 0.0331)
[2025-08-07 20:18:57 train.log] INFO: Epoch: [20]  [Step 9300/14540]  lr: 0.000023  loss: 0.86044  detection_loss: 0.6948 (cls: 0.1863, box: 0.5084)  rpn_loss: 0.1657 (cls: 0.0326, box: 0.1331)
[2025-08-07 20:19:02 train.log] INFO: Epoch: [20]  [Step 9400/14540]  lr: 0.000023  loss: 1.11225  detection_loss: 1.0242 (cls: 0.1754, box: 0.8488)  rpn_loss: 0.0880 (cls: 0.0319, box: 0.0561)
[2025-08-07 20:19:08 train.log] INFO: Epoch: [20]  [Step 9500/14540]  lr: 0.000023  loss: 1.37857  detection_loss: 1.1733 (cls: 0.2164, box: 0.9570)  rpn_loss: 0.2052 (cls: 0.0826, box: 0.1226)
[2025-08-07 20:19:13 train.log] INFO: Epoch: [20]  [Step 9600/14540]  lr: 0.000023  loss: 1.26381  detection_loss: 1.1555 (cls: 0.3726, box: 0.7829)  rpn_loss: 0.1083 (cls: 0.0625, box: 0.0458)
[2025-08-07 20:19:19 train.log] INFO: Epoch: [20]  [Step 9700/14540]  lr: 0.000023  loss: 0.80956  detection_loss: 0.7414 (cls: 0.1926, box: 0.5488)  rpn_loss: 0.0681 (cls: 0.0332, box: 0.0349)
[2025-08-07 20:19:24 train.log] INFO: Epoch: [20]  [Step 9800/14540]  lr: 0.000023  loss: 0.70773  detection_loss: 0.5187 (cls: 0.0969, box: 0.4217)  rpn_loss: 0.1891 (cls: 0.0274, box: 0.1616)
[2025-08-07 20:19:30 train.log] INFO: Epoch: [20]  [Step 9900/14540]  lr: 0.000023  loss: 0.66625  detection_loss: 0.5945 (cls: 0.1643, box: 0.4303)  rpn_loss: 0.0717 (cls: 0.0610, box: 0.0107)
[2025-08-07 20:19:35 train.log] INFO: Epoch: [20]  [Step 10000/14540]  lr: 0.000023  loss: 0.67893  detection_loss: 0.6272 (cls: 0.1092, box: 0.5180)  rpn_loss: 0.0517 (cls: 0.0156, box: 0.0361)
[2025-08-07 20:19:41 train.log] INFO: Epoch: [20]  [Step 10100/14540]  lr: 0.000023  loss: 0.67221  detection_loss: 0.5639 (cls: 0.1434, box: 0.4205)  rpn_loss: 0.1083 (cls: 0.0620, box: 0.0463)
[2025-08-07 20:19:46 train.log] INFO: Epoch: [20]  [Step 10200/14540]  lr: 0.000023  loss: 0.88052  detection_loss: 0.7903 (cls: 0.1961, box: 0.5942)  rpn_loss: 0.0902 (cls: 0.0591, box: 0.0310)
[2025-08-07 20:19:52 train.log] INFO: Epoch: [20]  [Step 10300/14540]  lr: 0.000023  loss: 0.66242  detection_loss: 0.6130 (cls: 0.2436, box: 0.3693)  rpn_loss: 0.0495 (cls: 0.0189, box: 0.0305)
[2025-08-07 20:19:57 train.log] INFO: Epoch: [20]  [Step 10400/14540]  lr: 0.000023  loss: 0.72143  detection_loss: 0.6198 (cls: 0.1247, box: 0.4950)  rpn_loss: 0.1017 (cls: 0.0369, box: 0.0648)
[2025-08-07 20:20:03 train.log] INFO: Epoch: [20]  [Step 10500/14540]  lr: 0.000023  loss: 1.05809  detection_loss: 0.9654 (cls: 0.2207, box: 0.7447)  rpn_loss: 0.0927 (cls: 0.0685, box: 0.0241)
[2025-08-07 20:20:09 train.log] INFO: Epoch: [20]  [Step 10600/14540]  lr: 0.000023  loss: 1.26052  detection_loss: 1.0897 (cls: 0.4278, box: 0.6619)  rpn_loss: 0.1708 (cls: 0.1276, box: 0.0432)
[2025-08-07 20:20:14 train.log] INFO: Epoch: [20]  [Step 10700/14540]  lr: 0.000023  loss: 0.72748  detection_loss: 0.6304 (cls: 0.2246, box: 0.4059)  rpn_loss: 0.0970 (cls: 0.0459, box: 0.0512)
[2025-08-07 20:20:20 train.log] INFO: Epoch: [20]  [Step 10800/14540]  lr: 0.000023  loss: 1.06036  detection_loss: 0.9876 (cls: 0.2542, box: 0.7333)  rpn_loss: 0.0728 (cls: 0.0339, box: 0.0389)
[2025-08-07 20:20:25 train.log] INFO: Epoch: [20]  [Step 10900/14540]  lr: 0.000023  loss: 0.59996  detection_loss: 0.4742 (cls: 0.0798, box: 0.3944)  rpn_loss: 0.1257 (cls: 0.0701, box: 0.0556)
[2025-08-07 20:20:31 train.log] INFO: Epoch: [20]  [Step 11000/14540]  lr: 0.000023  loss: 0.77386  detection_loss: 0.7164 (cls: 0.1881, box: 0.5283)  rpn_loss: 0.0574 (cls: 0.0352, box: 0.0223)
[2025-08-07 20:20:36 train.log] INFO: Epoch: [20]  [Step 11100/14540]  lr: 0.000023  loss: 1.13920  detection_loss: 1.0082 (cls: 0.1825, box: 0.8257)  rpn_loss: 0.1310 (cls: 0.0710, box: 0.0601)
[2025-08-07 20:20:42 train.log] INFO: Epoch: [20]  [Step 11200/14540]  lr: 0.000023  loss: 1.09256  detection_loss: 0.9580 (cls: 0.2084, box: 0.7495)  rpn_loss: 0.1346 (cls: 0.0527, box: 0.0819)
[2025-08-07 20:20:48 train.log] INFO: Epoch: [20]  [Step 11300/14540]  lr: 0.000023  loss: 0.94594  detection_loss: 0.8037 (cls: 0.1567, box: 0.6470)  rpn_loss: 0.1423 (cls: 0.1011, box: 0.0412)
[2025-08-07 20:20:53 train.log] INFO: Epoch: [20]  [Step 11400/14540]  lr: 0.000023  loss: 0.94355  detection_loss: 0.8639 (cls: 0.1325, box: 0.7314)  rpn_loss: 0.0796 (cls: 0.0418, box: 0.0379)
[2025-08-07 20:20:58 train.log] INFO: Epoch: [20]  [Step 11500/14540]  lr: 0.000023  loss: 0.84067  detection_loss: 0.7587 (cls: 0.3456, box: 0.4131)  rpn_loss: 0.0819 (cls: 0.0543, box: 0.0276)
[2025-08-07 20:21:04 train.log] INFO: Epoch: [20]  [Step 11600/14540]  lr: 0.000023  loss: 0.67874  detection_loss: 0.6572 (cls: 0.1739, box: 0.4833)  rpn_loss: 0.0216 (cls: 0.0095, box: 0.0120)
[2025-08-07 20:21:09 train.log] INFO: Epoch: [20]  [Step 11700/14540]  lr: 0.000023  loss: 0.98122  detection_loss: 0.8932 (cls: 0.1966, box: 0.6966)  rpn_loss: 0.0880 (cls: 0.0306, box: 0.0574)
[2025-08-07 20:21:15 train.log] INFO: Epoch: [20]  [Step 11800/14540]  lr: 0.000023  loss: 0.57740  detection_loss: 0.5137 (cls: 0.1192, box: 0.3945)  rpn_loss: 0.0637 (cls: 0.0424, box: 0.0213)
[2025-08-07 20:21:20 train.log] INFO: Epoch: [20]  [Step 11900/14540]  lr: 0.000023  loss: 1.19114  detection_loss: 1.0776 (cls: 0.2235, box: 0.8541)  rpn_loss: 0.1136 (cls: 0.0971, box: 0.0165)
[2025-08-07 20:21:26 train.log] INFO: Epoch: [20]  [Step 12000/14540]  lr: 0.000023  loss: 0.75749  detection_loss: 0.6887 (cls: 0.1400, box: 0.5488)  rpn_loss: 0.0688 (cls: 0.0340, box: 0.0348)
[2025-08-07 20:21:32 train.log] INFO: Epoch: [20]  [Step 12100/14540]  lr: 0.000023  loss: 1.14154  detection_loss: 1.0221 (cls: 0.2421, box: 0.7800)  rpn_loss: 0.1195 (cls: 0.0315, box: 0.0880)
[2025-08-07 20:21:37 train.log] INFO: Epoch: [20]  [Step 12200/14540]  lr: 0.000023  loss: 1.22257  detection_loss: 1.1439 (cls: 0.3920, box: 0.7519)  rpn_loss: 0.0787 (cls: 0.0493, box: 0.0294)
[2025-08-07 20:21:43 train.log] INFO: Epoch: [20]  [Step 12300/14540]  lr: 0.000023  loss: 0.94187  detection_loss: 0.8473 (cls: 0.1820, box: 0.6654)  rpn_loss: 0.0945 (cls: 0.0381, box: 0.0565)
[2025-08-07 20:21:48 train.log] INFO: Epoch: [20]  [Step 12400/14540]  lr: 0.000023  loss: 1.81760  detection_loss: 1.6354 (cls: 0.4476, box: 1.1877)  rpn_loss: 0.1822 (cls: 0.0859, box: 0.0964)
[2025-08-07 20:21:54 train.log] INFO: Epoch: [20]  [Step 12500/14540]  lr: 0.000023  loss: 0.64814  detection_loss: 0.5995 (cls: 0.1195, box: 0.4800)  rpn_loss: 0.0486 (cls: 0.0220, box: 0.0266)
[2025-08-07 20:21:59 train.log] INFO: Epoch: [20]  [Step 12600/14540]  lr: 0.000023  loss: 1.12203  detection_loss: 0.8784 (cls: 0.2448, box: 0.6336)  rpn_loss: 0.2436 (cls: 0.0489, box: 0.1947)
[2025-08-07 20:22:05 train.log] INFO: Epoch: [20]  [Step 12700/14540]  lr: 0.000023  loss: 1.11928  detection_loss: 0.9003 (cls: 0.2678, box: 0.6326)  rpn_loss: 0.2190 (cls: 0.0700, box: 0.1490)
[2025-08-07 20:22:11 train.log] INFO: Epoch: [20]  [Step 12800/14540]  lr: 0.000023  loss: 0.97757  detection_loss: 0.8754 (cls: 0.2825, box: 0.5929)  rpn_loss: 0.1021 (cls: 0.0564, box: 0.0458)
[2025-08-07 20:22:16 train.log] INFO: Epoch: [20]  [Step 12900/14540]  lr: 0.000023  loss: 0.74976  detection_loss: 0.5090 (cls: 0.1446, box: 0.3644)  rpn_loss: 0.2408 (cls: 0.0262, box: 0.2145)
[2025-08-07 20:22:22 train.log] INFO: Epoch: [20]  [Step 13000/14540]  lr: 0.000023  loss: 1.40822  detection_loss: 1.2759 (cls: 0.3846, box: 0.8913)  rpn_loss: 0.1323 (cls: 0.0653, box: 0.0670)
[2025-08-07 20:22:27 train.log] INFO: Epoch: [20]  [Step 13100/14540]  lr: 0.000023  loss: 1.03541  detection_loss: 0.8964 (cls: 0.3125, box: 0.5839)  rpn_loss: 0.1390 (cls: 0.0875, box: 0.0515)
[2025-08-07 20:22:33 train.log] INFO: Epoch: [20]  [Step 13200/14540]  lr: 0.000023  loss: 0.85857  detection_loss: 0.6452 (cls: 0.1144, box: 0.5308)  rpn_loss: 0.2133 (cls: 0.0236, box: 0.1897)
[2025-08-07 20:22:39 train.log] INFO: Epoch: [20]  [Step 13300/14540]  lr: 0.000023  loss: 1.34782  detection_loss: 1.2448 (cls: 0.1588, box: 1.0861)  rpn_loss: 0.1030 (cls: 0.0706, box: 0.0325)
[2025-08-07 20:22:44 train.log] INFO: Epoch: [20]  [Step 13400/14540]  lr: 0.000023  loss: 1.61838  detection_loss: 1.4777 (cls: 0.2595, box: 1.2183)  rpn_loss: 0.1406 (cls: 0.0292, box: 0.1115)
[2025-08-07 20:22:50 train.log] INFO: Epoch: [20]  [Step 13500/14540]  lr: 0.000023  loss: 0.96932  detection_loss: 0.8215 (cls: 0.2291, box: 0.5924)  rpn_loss: 0.1479 (cls: 0.0887, box: 0.0592)
[2025-08-07 20:22:55 train.log] INFO: Epoch: [20]  [Step 13600/14540]  lr: 0.000023  loss: 0.66364  detection_loss: 0.6004 (cls: 0.1443, box: 0.4562)  rpn_loss: 0.0632 (cls: 0.0403, box: 0.0229)
[2025-08-07 20:23:01 train.log] INFO: Epoch: [20]  [Step 13700/14540]  lr: 0.000023  loss: 0.66124  detection_loss: 0.6024 (cls: 0.1644, box: 0.4380)  rpn_loss: 0.0589 (cls: 0.0337, box: 0.0251)
[2025-08-07 20:23:07 train.log] INFO: Epoch: [20]  [Step 13800/14540]  lr: 0.000023  loss: 0.50416  detection_loss: 0.4520 (cls: 0.1561, box: 0.2959)  rpn_loss: 0.0522 (cls: 0.0390, box: 0.0132)
[2025-08-07 20:23:12 train.log] INFO: Epoch: [20]  [Step 13900/14540]  lr: 0.000023  loss: 1.09107  detection_loss: 0.9962 (cls: 0.2114, box: 0.7848)  rpn_loss: 0.0949 (cls: 0.0384, box: 0.0565)
[2025-08-07 20:23:17 train.log] INFO: Epoch: [20]  [Step 14000/14540]  lr: 0.000023  loss: 0.56848  detection_loss: 0.4950 (cls: 0.1853, box: 0.3097)  rpn_loss: 0.0735 (cls: 0.0502, box: 0.0233)
[2025-08-07 20:23:23 train.log] INFO: Epoch: [20]  [Step 14100/14540]  lr: 0.000023  loss: 0.48873  detection_loss: 0.4206 (cls: 0.1018, box: 0.3188)  rpn_loss: 0.0682 (cls: 0.0329, box: 0.0353)
[2025-08-07 20:23:28 train.log] INFO: Epoch: [20]  [Step 14200/14540]  lr: 0.000023  loss: 0.81233  detection_loss: 0.7705 (cls: 0.1706, box: 0.5998)  rpn_loss: 0.0419 (cls: 0.0171, box: 0.0247)
[2025-08-07 20:23:34 train.log] INFO: Epoch: [20]  [Step 14300/14540]  lr: 0.000023  loss: 1.10787  detection_loss: 0.9126 (cls: 0.1770, box: 0.7356)  rpn_loss: 0.1953 (cls: 0.0900, box: 0.1053)
[2025-08-07 20:23:40 train.log] INFO: Epoch: [20]  [Step 14400/14540]  lr: 0.000023  loss: 1.21835  detection_loss: 0.9502 (cls: 0.2771, box: 0.6732)  rpn_loss: 0.2681 (cls: 0.0467, box: 0.2215)
[2025-08-07 20:23:45 train.log] INFO: Epoch: [20]  [Step 14500/14540]  lr: 0.000023  loss: 1.42758  detection_loss: 1.2071 (cls: 0.3313, box: 0.8758)  rpn_loss: 0.2205 (cls: 0.0587, box: 0.1618)
[2025-08-07 20:27:10 train.log] INFO: Epoch: [21]  [Step 100/14540]  lr: 0.000019  loss: 0.71608  detection_loss: 0.6069 (cls: 0.2422, box: 0.3647)  rpn_loss: 0.1092 (cls: 0.0665, box: 0.0428)
[2025-08-07 20:27:16 train.log] INFO: Epoch: [21]  [Step 200/14540]  lr: 0.000019  loss: 0.84658  detection_loss: 0.7546 (cls: 0.2042, box: 0.5503)  rpn_loss: 0.0920 (cls: 0.0589, box: 0.0332)
[2025-08-07 20:27:21 train.log] INFO: Epoch: [21]  [Step 300/14540]  lr: 0.000019  loss: 1.34990  detection_loss: 0.9027 (cls: 0.2254, box: 0.6773)  rpn_loss: 0.4472 (cls: 0.0463, box: 0.4009)
[2025-08-07 20:27:27 train.log] INFO: Epoch: [21]  [Step 400/14540]  lr: 0.000019  loss: 0.94940  detection_loss: 0.7847 (cls: 0.1912, box: 0.5935)  rpn_loss: 0.1647 (cls: 0.1378, box: 0.0270)
[2025-08-07 20:27:33 train.log] INFO: Epoch: [21]  [Step 500/14540]  lr: 0.000019  loss: 0.89905  detection_loss: 0.7358 (cls: 0.1822, box: 0.5536)  rpn_loss: 0.1632 (cls: 0.1222, box: 0.0410)
[2025-08-07 20:27:38 train.log] INFO: Epoch: [21]  [Step 600/14540]  lr: 0.000019  loss: 1.29006  detection_loss: 1.1660 (cls: 0.2821, box: 0.8839)  rpn_loss: 0.1240 (cls: 0.0699, box: 0.0541)
[2025-08-07 20:27:44 train.log] INFO: Epoch: [21]  [Step 700/14540]  lr: 0.000019  loss: 0.77250  detection_loss: 0.6431 (cls: 0.1833, box: 0.4598)  rpn_loss: 0.1294 (cls: 0.1007, box: 0.0287)
[2025-08-07 20:27:49 train.log] INFO: Epoch: [21]  [Step 800/14540]  lr: 0.000019  loss: 0.57350  detection_loss: 0.4989 (cls: 0.1146, box: 0.3843)  rpn_loss: 0.0746 (cls: 0.0579, box: 0.0166)
[2025-08-07 20:27:55 train.log] INFO: Epoch: [21]  [Step 900/14540]  lr: 0.000019  loss: 1.29573  detection_loss: 1.2199 (cls: 0.2928, box: 0.9271)  rpn_loss: 0.0758 (cls: 0.0272, box: 0.0486)
[2025-08-07 20:28:01 train.log] INFO: Epoch: [21]  [Step 1000/14540]  lr: 0.000019  loss: 0.72567  detection_loss: 0.6417 (cls: 0.2052, box: 0.4366)  rpn_loss: 0.0839 (cls: 0.0477, box: 0.0362)
[2025-08-07 20:28:06 train.log] INFO: Epoch: [21]  [Step 1100/14540]  lr: 0.000019  loss: 1.45439  detection_loss: 1.3104 (cls: 0.2914, box: 1.0190)  rpn_loss: 0.1440 (cls: 0.0538, box: 0.0903)
[2025-08-07 20:28:12 train.log] INFO: Epoch: [21]  [Step 1200/14540]  lr: 0.000019  loss: 0.72696  detection_loss: 0.6390 (cls: 0.1649, box: 0.4741)  rpn_loss: 0.0879 (cls: 0.0545, box: 0.0335)
[2025-08-07 20:28:17 train.log] INFO: Epoch: [21]  [Step 1300/14540]  lr: 0.000019  loss: 1.15071  detection_loss: 0.9667 (cls: 0.2615, box: 0.7052)  rpn_loss: 0.1840 (cls: 0.1518, box: 0.0322)
[2025-08-07 20:28:23 train.log] INFO: Epoch: [21]  [Step 1400/14540]  lr: 0.000019  loss: 0.63418  detection_loss: 0.5719 (cls: 0.1190, box: 0.4529)  rpn_loss: 0.0622 (cls: 0.0236, box: 0.0386)
[2025-08-07 20:28:28 train.log] INFO: Epoch: [21]  [Step 1500/14540]  lr: 0.000019  loss: 1.10746  detection_loss: 0.9871 (cls: 0.2187, box: 0.7684)  rpn_loss: 0.1204 (cls: 0.0393, box: 0.0810)
[2025-08-07 20:28:34 train.log] INFO: Epoch: [21]  [Step 1600/14540]  lr: 0.000019  loss: 0.66312  detection_loss: 0.4640 (cls: 0.2021, box: 0.2619)  rpn_loss: 0.1991 (cls: 0.0657, box: 0.1335)
[2025-08-07 20:28:39 train.log] INFO: Epoch: [21]  [Step 1700/14540]  lr: 0.000019  loss: 0.88858  detection_loss: 0.8204 (cls: 0.1617, box: 0.6587)  rpn_loss: 0.0682 (cls: 0.0150, box: 0.0532)
[2025-08-07 20:28:44 train.log] INFO: Epoch: [21]  [Step 1800/14540]  lr: 0.000019  loss: 0.61468  detection_loss: 0.5116 (cls: 0.1799, box: 0.3317)  rpn_loss: 0.1031 (cls: 0.0194, box: 0.0837)
[2025-08-07 20:28:50 train.log] INFO: Epoch: [21]  [Step 1900/14540]  lr: 0.000019  loss: 0.74672  detection_loss: 0.6291 (cls: 0.1913, box: 0.4378)  rpn_loss: 0.1177 (cls: 0.0286, box: 0.0890)
[2025-08-07 20:28:56 train.log] INFO: Epoch: [21]  [Step 2000/14540]  lr: 0.000019  loss: 0.78220  detection_loss: 0.7100 (cls: 0.1271, box: 0.5829)  rpn_loss: 0.0722 (cls: 0.0451, box: 0.0271)
[2025-08-07 20:29:01 train.log] INFO: Epoch: [21]  [Step 2100/14540]  lr: 0.000019  loss: 0.68380  detection_loss: 0.6419 (cls: 0.1078, box: 0.5341)  rpn_loss: 0.0419 (cls: 0.0106, box: 0.0313)
[2025-08-07 20:29:07 train.log] INFO: Epoch: [21]  [Step 2200/14540]  lr: 0.000019  loss: 0.62961  detection_loss: 0.5513 (cls: 0.1381, box: 0.4131)  rpn_loss: 0.0784 (cls: 0.0441, box: 0.0342)
[2025-08-07 20:29:13 train.log] INFO: Epoch: [21]  [Step 2300/14540]  lr: 0.000019  loss: 0.58499  detection_loss: 0.4824 (cls: 0.1170, box: 0.3654)  rpn_loss: 0.1026 (cls: 0.0295, box: 0.0732)
[2025-08-07 20:29:18 train.log] INFO: Epoch: [21]  [Step 2400/14540]  lr: 0.000019  loss: 0.81668  detection_loss: 0.7505 (cls: 0.1174, box: 0.6331)  rpn_loss: 0.0662 (cls: 0.0453, box: 0.0208)
[2025-08-07 20:29:24 train.log] INFO: Epoch: [21]  [Step 2500/14540]  lr: 0.000019  loss: 0.68898  detection_loss: 0.6124 (cls: 0.1466, box: 0.4659)  rpn_loss: 0.0765 (cls: 0.0366, box: 0.0400)
[2025-08-07 20:29:29 train.log] INFO: Epoch: [21]  [Step 2600/14540]  lr: 0.000019  loss: 1.29461  detection_loss: 1.1454 (cls: 0.3308, box: 0.8146)  rpn_loss: 0.1492 (cls: 0.0344, box: 0.1148)
[2025-08-07 20:29:35 train.log] INFO: Epoch: [21]  [Step 2700/14540]  lr: 0.000019  loss: 1.20076  detection_loss: 0.9606 (cls: 0.3143, box: 0.6463)  rpn_loss: 0.2402 (cls: 0.0467, box: 0.1935)
[2025-08-07 20:29:40 train.log] INFO: Epoch: [21]  [Step 2800/14540]  lr: 0.000019  loss: 1.59195  detection_loss: 1.3710 (cls: 0.2582, box: 1.1127)  rpn_loss: 0.2210 (cls: 0.0734, box: 0.1475)
[2025-08-07 20:29:46 train.log] INFO: Epoch: [21]  [Step 2900/14540]  lr: 0.000019  loss: 0.93966  detection_loss: 0.8818 (cls: 0.1519, box: 0.7299)  rpn_loss: 0.0579 (cls: 0.0385, box: 0.0194)
[2025-08-07 20:29:51 train.log] INFO: Epoch: [21]  [Step 3000/14540]  lr: 0.000019  loss: 0.73282  detection_loss: 0.6356 (cls: 0.1582, box: 0.4774)  rpn_loss: 0.0972 (cls: 0.0742, box: 0.0230)
[2025-08-07 20:29:57 train.log] INFO: Epoch: [21]  [Step 3100/14540]  lr: 0.000019  loss: 0.60624  detection_loss: 0.5200 (cls: 0.1130, box: 0.4070)  rpn_loss: 0.0863 (cls: 0.0683, box: 0.0179)
[2025-08-07 20:30:03 train.log] INFO: Epoch: [21]  [Step 3200/14540]  lr: 0.000019  loss: 0.98060  detection_loss: 0.9034 (cls: 0.1705, box: 0.7329)  rpn_loss: 0.0772 (cls: 0.0441, box: 0.0331)
[2025-08-07 20:30:08 train.log] INFO: Epoch: [21]  [Step 3300/14540]  lr: 0.000019  loss: 0.70937  detection_loss: 0.6261 (cls: 0.2001, box: 0.4260)  rpn_loss: 0.0833 (cls: 0.0466, box: 0.0367)
[2025-08-07 20:30:14 train.log] INFO: Epoch: [21]  [Step 3400/14540]  lr: 0.000019  loss: 1.25790  detection_loss: 1.1275 (cls: 0.4413, box: 0.6862)  rpn_loss: 0.1304 (cls: 0.1060, box: 0.0244)
[2025-08-07 20:30:19 train.log] INFO: Epoch: [21]  [Step 3500/14540]  lr: 0.000019  loss: 0.52846  detection_loss: 0.4202 (cls: 0.1144, box: 0.3058)  rpn_loss: 0.1083 (cls: 0.0831, box: 0.0251)
[2025-08-07 20:30:25 train.log] INFO: Epoch: [21]  [Step 3600/14540]  lr: 0.000019  loss: 0.83940  detection_loss: 0.7279 (cls: 0.1446, box: 0.5833)  rpn_loss: 0.1115 (cls: 0.0267, box: 0.0848)
[2025-08-07 20:30:27 train.log] INFO: Epoch: [21]  [Step 3635/14540]  lr: 0.000019  loss: 0.94225  detection_loss: 0.8218 (cls: 0.2166, box: 0.6053)  rpn_loss: 0.1204 (cls: 0.0248, box: 0.0956)
[2025-08-07 20:30:30 train.log] INFO: Epoch: [21]  [Step 3700/14540]  lr: 0.000019  loss: 0.82229  detection_loss: 0.6986 (cls: 0.2080, box: 0.4905)  rpn_loss: 0.1237 (cls: 0.0967, box: 0.0271)
[2025-08-07 20:30:36 train.log] INFO: Epoch: [21]  [Step 3800/14540]  lr: 0.000019  loss: 0.62599  detection_loss: 0.5424 (cls: 0.1263, box: 0.4160)  rpn_loss: 0.0836 (cls: 0.0619, box: 0.0217)
[2025-08-07 20:30:41 train.log] INFO: Epoch: [21]  [Step 3900/14540]  lr: 0.000019  loss: 0.99640  detection_loss: 0.8603 (cls: 0.2412, box: 0.6190)  rpn_loss: 0.1361 (cls: 0.0347, box: 0.1014)
[2025-08-07 20:30:47 train.log] INFO: Epoch: [21]  [Step 4000/14540]  lr: 0.000019  loss: 0.89981  detection_loss: 0.7548 (cls: 0.2145, box: 0.5403)  rpn_loss: 0.1450 (cls: 0.0256, box: 0.1194)
[2025-08-07 20:30:52 train.log] INFO: Epoch: [21]  [Step 4100/14540]  lr: 0.000019  loss: 0.44126  detection_loss: 0.3902 (cls: 0.1115, box: 0.2787)  rpn_loss: 0.0510 (cls: 0.0380, box: 0.0130)
[2025-08-07 20:30:58 train.log] INFO: Epoch: [21]  [Step 4200/14540]  lr: 0.000019  loss: 1.21889  detection_loss: 1.1201 (cls: 0.3804, box: 0.7397)  rpn_loss: 0.0988 (cls: 0.0614, box: 0.0374)
[2025-08-07 20:31:03 train.log] INFO: Epoch: [21]  [Step 4300/14540]  lr: 0.000019  loss: 0.80304  detection_loss: 0.7357 (cls: 0.2355, box: 0.5003)  rpn_loss: 0.0673 (cls: 0.0346, box: 0.0328)
[2025-08-07 20:31:09 train.log] INFO: Epoch: [21]  [Step 4400/14540]  lr: 0.000019  loss: 0.73698  detection_loss: 0.6973 (cls: 0.1163, box: 0.5809)  rpn_loss: 0.0397 (cls: 0.0275, box: 0.0122)
[2025-08-07 20:31:14 train.log] INFO: Epoch: [21]  [Step 4500/14540]  lr: 0.000019  loss: 0.32255  detection_loss: 0.2933 (cls: 0.0940, box: 0.1993)  rpn_loss: 0.0292 (cls: 0.0166, box: 0.0127)
[2025-08-07 20:31:20 train.log] INFO: Epoch: [21]  [Step 4600/14540]  lr: 0.000019  loss: 0.94089  detection_loss: 0.8738 (cls: 0.1429, box: 0.7310)  rpn_loss: 0.0671 (cls: 0.0255, box: 0.0415)
[2025-08-07 20:31:25 train.log] INFO: Epoch: [21]  [Step 4700/14540]  lr: 0.000019  loss: 0.73634  detection_loss: 0.7111 (cls: 0.1554, box: 0.5557)  rpn_loss: 0.0252 (cls: 0.0107, box: 0.0145)
[2025-08-07 20:31:31 train.log] INFO: Epoch: [21]  [Step 4800/14540]  lr: 0.000019  loss: 1.95005  detection_loss: 1.7869 (cls: 0.3628, box: 1.4242)  rpn_loss: 0.1631 (cls: 0.0882, box: 0.0749)
[2025-08-07 20:31:37 train.log] INFO: Epoch: [21]  [Step 4900/14540]  lr: 0.000019  loss: 0.96067  detection_loss: 0.6255 (cls: 0.1522, box: 0.4732)  rpn_loss: 0.3352 (cls: 0.0598, box: 0.2754)
[2025-08-07 20:31:42 train.log] INFO: Epoch: [21]  [Step 5000/14540]  lr: 0.000019  loss: 0.88419  detection_loss: 0.8199 (cls: 0.2940, box: 0.5259)  rpn_loss: 0.0643 (cls: 0.0324, box: 0.0319)
[2025-08-07 20:31:47 train.log] INFO: Epoch: [21]  [Step 5100/14540]  lr: 0.000019  loss: 0.93803  detection_loss: 0.8301 (cls: 0.1630, box: 0.6671)  rpn_loss: 0.1080 (cls: 0.0390, box: 0.0690)
[2025-08-07 20:31:53 train.log] INFO: Epoch: [21]  [Step 5200/14540]  lr: 0.000019  loss: 0.90191  detection_loss: 0.8323 (cls: 0.1805, box: 0.6518)  rpn_loss: 0.0696 (cls: 0.0356, box: 0.0340)
[2025-08-07 20:31:58 train.log] INFO: Epoch: [21]  [Step 5300/14540]  lr: 0.000019  loss: 0.79862  detection_loss: 0.7374 (cls: 0.1631, box: 0.5743)  rpn_loss: 0.0612 (cls: 0.0265, box: 0.0347)
[2025-08-07 20:32:04 train.log] INFO: Epoch: [21]  [Step 5400/14540]  lr: 0.000019  loss: 1.39314  detection_loss: 1.2541 (cls: 0.1836, box: 1.0705)  rpn_loss: 0.1391 (cls: 0.0393, box: 0.0997)
[2025-08-07 20:32:09 train.log] INFO: Epoch: [21]  [Step 5500/14540]  lr: 0.000019  loss: 0.59286  detection_loss: 0.5197 (cls: 0.1117, box: 0.4080)  rpn_loss: 0.0732 (cls: 0.0467, box: 0.0264)
[2025-08-07 20:32:15 train.log] INFO: Epoch: [21]  [Step 5600/14540]  lr: 0.000019  loss: 1.48793  detection_loss: 1.2484 (cls: 0.2729, box: 0.9756)  rpn_loss: 0.2395 (cls: 0.0588, box: 0.1807)
[2025-08-07 20:32:20 train.log] INFO: Epoch: [21]  [Step 5700/14540]  lr: 0.000019  loss: 0.58912  detection_loss: 0.4240 (cls: 0.1690, box: 0.2550)  rpn_loss: 0.1651 (cls: 0.0360, box: 0.1291)
[2025-08-07 20:32:26 train.log] INFO: Epoch: [21]  [Step 5800/14540]  lr: 0.000019  loss: 1.25961  detection_loss: 1.1841 (cls: 0.2300, box: 0.9541)  rpn_loss: 0.0755 (cls: 0.0178, box: 0.0578)
[2025-08-07 20:32:31 train.log] INFO: Epoch: [21]  [Step 5900/14540]  lr: 0.000019  loss: 0.70712  detection_loss: 0.6283 (cls: 0.1439, box: 0.4845)  rpn_loss: 0.0788 (cls: 0.0455, box: 0.0333)
[2025-08-07 20:32:37 train.log] INFO: Epoch: [21]  [Step 6000/14540]  lr: 0.000019  loss: 0.98961  detection_loss: 0.9076 (cls: 0.3239, box: 0.5837)  rpn_loss: 0.0820 (cls: 0.0540, box: 0.0279)
[2025-08-07 20:32:42 train.log] INFO: Epoch: [21]  [Step 6100/14540]  lr: 0.000019  loss: 0.86462  detection_loss: 0.7682 (cls: 0.2639, box: 0.5044)  rpn_loss: 0.0964 (cls: 0.0434, box: 0.0530)
[2025-08-07 20:32:48 train.log] INFO: Epoch: [21]  [Step 6200/14540]  lr: 0.000019  loss: 1.30768  detection_loss: 1.0075 (cls: 0.2344, box: 0.7731)  rpn_loss: 0.3002 (cls: 0.0413, box: 0.2589)
[2025-08-07 20:32:53 train.log] INFO: Epoch: [21]  [Step 6300/14540]  lr: 0.000019  loss: 1.12867  detection_loss: 0.9394 (cls: 0.1020, box: 0.8374)  rpn_loss: 0.1892 (cls: 0.0667, box: 0.1225)
[2025-08-07 20:32:59 train.log] INFO: Epoch: [21]  [Step 6400/14540]  lr: 0.000019  loss: 0.91499  detection_loss: 0.6889 (cls: 0.1405, box: 0.5484)  rpn_loss: 0.2260 (cls: 0.0335, box: 0.1926)
[2025-08-07 20:33:04 train.log] INFO: Epoch: [21]  [Step 6500/14540]  lr: 0.000019  loss: 0.67676  detection_loss: 0.6313 (cls: 0.1469, box: 0.4843)  rpn_loss: 0.0455 (cls: 0.0158, box: 0.0296)
[2025-08-07 20:33:10 train.log] INFO: Epoch: [21]  [Step 6600/14540]  lr: 0.000019  loss: 0.85981  detection_loss: 0.7427 (cls: 0.1245, box: 0.6182)  rpn_loss: 0.1172 (cls: 0.0531, box: 0.0641)
[2025-08-07 20:33:15 train.log] INFO: Epoch: [21]  [Step 6700/14540]  lr: 0.000019  loss: 0.78104  detection_loss: 0.6961 (cls: 0.1054, box: 0.5907)  rpn_loss: 0.0849 (cls: 0.0087, box: 0.0762)
[2025-08-07 20:33:21 train.log] INFO: Epoch: [21]  [Step 6800/14540]  lr: 0.000019  loss: 1.13324  detection_loss: 0.9386 (cls: 0.2149, box: 0.7237)  rpn_loss: 0.1947 (cls: 0.0865, box: 0.1081)
[2025-08-07 20:33:27 train.log] INFO: Epoch: [21]  [Step 6900/14540]  lr: 0.000019  loss: 1.06438  detection_loss: 0.9267 (cls: 0.2442, box: 0.6826)  rpn_loss: 0.1377 (cls: 0.0571, box: 0.0805)
[2025-08-07 20:33:32 train.log] INFO: Epoch: [21]  [Step 7000/14540]  lr: 0.000019  loss: 1.04140  detection_loss: 0.9140 (cls: 0.1478, box: 0.7662)  rpn_loss: 0.1274 (cls: 0.0597, box: 0.0677)
[2025-08-07 20:33:38 train.log] INFO: Epoch: [21]  [Step 7100/14540]  lr: 0.000019  loss: 1.20452  detection_loss: 1.0670 (cls: 0.2417, box: 0.8253)  rpn_loss: 0.1375 (cls: 0.0769, box: 0.0606)
[2025-08-07 20:33:43 train.log] INFO: Epoch: [21]  [Step 7200/14540]  lr: 0.000019  loss: 1.15554  detection_loss: 1.0999 (cls: 0.3270, box: 0.7730)  rpn_loss: 0.0556 (cls: 0.0306, box: 0.0251)
[2025-08-07 20:33:49 train.log] INFO: Epoch: [21]  [Step 7300/14540]  lr: 0.000019  loss: 0.70284  detection_loss: 0.5909 (cls: 0.1141, box: 0.4768)  rpn_loss: 0.1119 (cls: 0.0769, box: 0.0350)
[2025-08-07 20:33:54 train.log] INFO: Epoch: [21]  [Step 7400/14540]  lr: 0.000019  loss: 0.84618  detection_loss: 0.7794 (cls: 0.2188, box: 0.5606)  rpn_loss: 0.0668 (cls: 0.0414, box: 0.0253)
[2025-08-07 20:33:59 train.log] INFO: Epoch: [21]  [Step 7500/14540]  lr: 0.000019  loss: 1.09151  detection_loss: 0.9597 (cls: 0.2289, box: 0.7308)  rpn_loss: 0.1318 (cls: 0.0409, box: 0.0909)
[2025-08-07 20:34:05 train.log] INFO: Epoch: [21]  [Step 7600/14540]  lr: 0.000019  loss: 1.06372  detection_loss: 0.8851 (cls: 0.2052, box: 0.6799)  rpn_loss: 0.1786 (cls: 0.1241, box: 0.0545)
[2025-08-07 20:34:10 train.log] INFO: Epoch: [21]  [Step 7700/14540]  lr: 0.000019  loss: 0.75084  detection_loss: 0.6523 (cls: 0.1554, box: 0.4969)  rpn_loss: 0.0985 (cls: 0.0390, box: 0.0595)
[2025-08-07 20:34:16 train.log] INFO: Epoch: [21]  [Step 7800/14540]  lr: 0.000019  loss: 1.11827  detection_loss: 0.9068 (cls: 0.1797, box: 0.7271)  rpn_loss: 0.2115 (cls: 0.1721, box: 0.0394)
[2025-08-07 20:34:22 train.log] INFO: Epoch: [21]  [Step 7900/14540]  lr: 0.000019  loss: 1.05711  detection_loss: 0.8696 (cls: 0.1702, box: 0.6995)  rpn_loss: 0.1875 (cls: 0.0170, box: 0.1705)
[2025-08-07 20:34:27 train.log] INFO: Epoch: [21]  [Step 8000/14540]  lr: 0.000019  loss: 1.06619  detection_loss: 0.9484 (cls: 0.2134, box: 0.7350)  rpn_loss: 0.1178 (cls: 0.0688, box: 0.0490)
[2025-08-07 20:34:33 train.log] INFO: Epoch: [21]  [Step 8100/14540]  lr: 0.000019  loss: 0.77176  detection_loss: 0.7098 (cls: 0.1784, box: 0.5314)  rpn_loss: 0.0619 (cls: 0.0392, box: 0.0227)
[2025-08-07 20:34:38 train.log] INFO: Epoch: [21]  [Step 8200/14540]  lr: 0.000019  loss: 0.66544  detection_loss: 0.6294 (cls: 0.1332, box: 0.4963)  rpn_loss: 0.0360 (cls: 0.0217, box: 0.0143)
[2025-08-07 20:34:43 train.log] INFO: Epoch: [21]  [Step 8300/14540]  lr: 0.000019  loss: 0.63978  detection_loss: 0.5822 (cls: 0.1291, box: 0.4531)  rpn_loss: 0.0576 (cls: 0.0127, box: 0.0448)
[2025-08-07 20:34:49 train.log] INFO: Epoch: [21]  [Step 8400/14540]  lr: 0.000019  loss: 0.50100  detection_loss: 0.4277 (cls: 0.1158, box: 0.3119)  rpn_loss: 0.0733 (cls: 0.0271, box: 0.0462)
[2025-08-07 20:34:55 train.log] INFO: Epoch: [21]  [Step 8500/14540]  lr: 0.000019  loss: 0.86725  detection_loss: 0.7268 (cls: 0.1519, box: 0.5749)  rpn_loss: 0.1405 (cls: 0.0521, box: 0.0883)
[2025-08-07 20:35:00 train.log] INFO: Epoch: [21]  [Step 8600/14540]  lr: 0.000019  loss: 0.80475  detection_loss: 0.7427 (cls: 0.1767, box: 0.5659)  rpn_loss: 0.0621 (cls: 0.0296, box: 0.0325)
[2025-08-07 20:35:06 train.log] INFO: Epoch: [21]  [Step 8700/14540]  lr: 0.000019  loss: 0.55673  detection_loss: 0.5112 (cls: 0.1210, box: 0.3902)  rpn_loss: 0.0455 (cls: 0.0373, box: 0.0082)
[2025-08-07 20:35:11 train.log] INFO: Epoch: [21]  [Step 8800/14540]  lr: 0.000019  loss: 1.19545  detection_loss: 1.1231 (cls: 0.3252, box: 0.7979)  rpn_loss: 0.0724 (cls: 0.0262, box: 0.0462)
[2025-08-07 20:35:17 train.log] INFO: Epoch: [21]  [Step 8900/14540]  lr: 0.000019  loss: 1.25944  detection_loss: 1.0904 (cls: 0.3408, box: 0.7496)  rpn_loss: 0.1691 (cls: 0.1406, box: 0.0285)
[2025-08-07 20:35:23 train.log] INFO: Epoch: [21]  [Step 9000/14540]  lr: 0.000019  loss: 1.63721  detection_loss: 1.4417 (cls: 0.4384, box: 1.0034)  rpn_loss: 0.1955 (cls: 0.1480, box: 0.0475)
[2025-08-07 20:35:28 train.log] INFO: Epoch: [21]  [Step 9100/14540]  lr: 0.000019  loss: 0.90720  detection_loss: 0.7646 (cls: 0.1806, box: 0.5839)  rpn_loss: 0.1426 (cls: 0.1008, box: 0.0418)
[2025-08-07 20:35:34 train.log] INFO: Epoch: [21]  [Step 9200/14540]  lr: 0.000019  loss: 0.66119  detection_loss: 0.5409 (cls: 0.1506, box: 0.3903)  rpn_loss: 0.1202 (cls: 0.0932, box: 0.0270)
[2025-08-07 20:35:39 train.log] INFO: Epoch: [21]  [Step 9300/14540]  lr: 0.000019  loss: 1.29595  detection_loss: 1.1702 (cls: 0.3176, box: 0.8526)  rpn_loss: 0.1257 (cls: 0.0751, box: 0.0506)
[2025-08-07 20:35:45 train.log] INFO: Epoch: [21]  [Step 9400/14540]  lr: 0.000019  loss: 0.95823  detection_loss: 0.8883 (cls: 0.2193, box: 0.6689)  rpn_loss: 0.0700 (cls: 0.0376, box: 0.0324)
[2025-08-07 20:35:50 train.log] INFO: Epoch: [21]  [Step 9500/14540]  lr: 0.000019  loss: 0.82692  detection_loss: 0.6881 (cls: 0.1329, box: 0.5552)  rpn_loss: 0.1389 (cls: 0.0268, box: 0.1121)
[2025-08-07 20:35:56 train.log] INFO: Epoch: [21]  [Step 9600/14540]  lr: 0.000019  loss: 0.89872  detection_loss: 0.8462 (cls: 0.1527, box: 0.6936)  rpn_loss: 0.0525 (cls: 0.0110, box: 0.0415)
[2025-08-07 20:36:01 train.log] INFO: Epoch: [21]  [Step 9700/14540]  lr: 0.000019  loss: 0.71189  detection_loss: 0.6101 (cls: 0.1240, box: 0.4861)  rpn_loss: 0.1018 (cls: 0.0329, box: 0.0689)
[2025-08-07 20:36:07 train.log] INFO: Epoch: [21]  [Step 9800/14540]  lr: 0.000019  loss: 1.03598  detection_loss: 0.9259 (cls: 0.2270, box: 0.6990)  rpn_loss: 0.1101 (cls: 0.0461, box: 0.0639)
[2025-08-07 20:36:12 train.log] INFO: Epoch: [21]  [Step 9900/14540]  lr: 0.000019  loss: 1.15813  detection_loss: 1.1015 (cls: 0.1931, box: 0.9085)  rpn_loss: 0.0566 (cls: 0.0416, box: 0.0150)
[2025-08-07 20:36:18 train.log] INFO: Epoch: [21]  [Step 10000/14540]  lr: 0.000019  loss: 0.88683  detection_loss: 0.7146 (cls: 0.1277, box: 0.5868)  rpn_loss: 0.1722 (cls: 0.0317, box: 0.1406)
[2025-08-07 20:36:24 train.log] INFO: Epoch: [21]  [Step 10100/14540]  lr: 0.000019  loss: 0.87763  detection_loss: 0.7880 (cls: 0.2042, box: 0.5838)  rpn_loss: 0.0896 (cls: 0.0450, box: 0.0447)
[2025-08-07 20:36:29 train.log] INFO: Epoch: [21]  [Step 10200/14540]  lr: 0.000019  loss: 0.58932  detection_loss: 0.4657 (cls: 0.1494, box: 0.3163)  rpn_loss: 0.1236 (cls: 0.0489, box: 0.0747)
[2025-08-07 20:36:35 train.log] INFO: Epoch: [21]  [Step 10300/14540]  lr: 0.000019  loss: 1.08743  detection_loss: 0.9043 (cls: 0.1904, box: 0.7139)  rpn_loss: 0.1831 (cls: 0.0640, box: 0.1192)
[2025-08-07 20:36:40 train.log] INFO: Epoch: [21]  [Step 10400/14540]  lr: 0.000019  loss: 1.26988  detection_loss: 1.1350 (cls: 0.2271, box: 0.9079)  rpn_loss: 0.1349 (cls: 0.0444, box: 0.0905)
[2025-08-07 20:36:46 train.log] INFO: Epoch: [21]  [Step 10500/14540]  lr: 0.000019  loss: 0.71332  detection_loss: 0.4830 (cls: 0.0964, box: 0.3866)  rpn_loss: 0.2303 (cls: 0.0494, box: 0.1809)
[2025-08-07 20:36:52 train.log] INFO: Epoch: [21]  [Step 10600/14540]  lr: 0.000019  loss: 0.77708  detection_loss: 0.7033 (cls: 0.2034, box: 0.4999)  rpn_loss: 0.0738 (cls: 0.0477, box: 0.0261)
[2025-08-07 20:36:58 train.log] INFO: Epoch: [21]  [Step 10700/14540]  lr: 0.000019  loss: 0.71921  detection_loss: 0.6421 (cls: 0.1960, box: 0.4462)  rpn_loss: 0.0771 (cls: 0.0308, box: 0.0462)
[2025-08-07 20:37:04 train.log] INFO: Epoch: [21]  [Step 10800/14540]  lr: 0.000019  loss: 1.08812  detection_loss: 0.9610 (cls: 0.1771, box: 0.7838)  rpn_loss: 0.1271 (cls: 0.0406, box: 0.0865)
[2025-08-07 20:37:10 train.log] INFO: Epoch: [21]  [Step 10900/14540]  lr: 0.000019  loss: 1.43260  detection_loss: 1.2910 (cls: 0.3816, box: 0.9094)  rpn_loss: 0.1416 (cls: 0.0908, box: 0.0508)
[2025-08-07 20:37:16 train.log] INFO: Epoch: [21]  [Step 11000/14540]  lr: 0.000019  loss: 0.56428  detection_loss: 0.5171 (cls: 0.1221, box: 0.3951)  rpn_loss: 0.0471 (cls: 0.0290, box: 0.0181)
[2025-08-07 20:37:21 train.log] INFO: Epoch: [21]  [Step 11100/14540]  lr: 0.000019  loss: 1.30718  detection_loss: 1.1646 (cls: 0.2459, box: 0.9187)  rpn_loss: 0.1426 (cls: 0.1232, box: 0.0194)
[2025-08-07 20:37:27 train.log] INFO: Epoch: [21]  [Step 11200/14540]  lr: 0.000019  loss: 1.10877  detection_loss: 0.9787 (cls: 0.2504, box: 0.7283)  rpn_loss: 0.1301 (cls: 0.0929, box: 0.0372)
[2025-08-07 20:37:33 train.log] INFO: Epoch: [21]  [Step 11300/14540]  lr: 0.000019  loss: 1.52301  detection_loss: 1.3651 (cls: 0.2044, box: 1.1606)  rpn_loss: 0.1579 (cls: 0.1265, box: 0.0315)
[2025-08-07 20:37:39 train.log] INFO: Epoch: [21]  [Step 11400/14540]  lr: 0.000019  loss: 0.69876  detection_loss: 0.6344 (cls: 0.1280, box: 0.5065)  rpn_loss: 0.0643 (cls: 0.0380, box: 0.0263)
[2025-08-07 20:37:44 train.log] INFO: Epoch: [21]  [Step 11500/14540]  lr: 0.000019  loss: 1.00014  detection_loss: 0.8838 (cls: 0.1856, box: 0.6982)  rpn_loss: 0.1164 (cls: 0.0721, box: 0.0442)
[2025-08-07 20:37:50 train.log] INFO: Epoch: [21]  [Step 11600/14540]  lr: 0.000019  loss: 0.75100  detection_loss: 0.6929 (cls: 0.1944, box: 0.4985)  rpn_loss: 0.0581 (cls: 0.0363, box: 0.0219)
[2025-08-07 20:37:56 train.log] INFO: Epoch: [21]  [Step 11700/14540]  lr: 0.000019  loss: 1.13138  detection_loss: 1.0545 (cls: 0.3467, box: 0.7078)  rpn_loss: 0.0769 (cls: 0.0266, box: 0.0502)
[2025-08-07 20:38:01 train.log] INFO: Epoch: [21]  [Step 11800/14540]  lr: 0.000019  loss: 0.83965  detection_loss: 0.7582 (cls: 0.1901, box: 0.5681)  rpn_loss: 0.0815 (cls: 0.0635, box: 0.0180)
[2025-08-07 20:38:07 train.log] INFO: Epoch: [21]  [Step 11900/14540]  lr: 0.000019  loss: 0.86093  detection_loss: 0.7962 (cls: 0.1160, box: 0.6802)  rpn_loss: 0.0647 (cls: 0.0194, box: 0.0453)
[2025-08-07 20:38:12 train.log] INFO: Epoch: [21]  [Step 12000/14540]  lr: 0.000019  loss: 1.06558  detection_loss: 0.8771 (cls: 0.1418, box: 0.7353)  rpn_loss: 0.1885 (cls: 0.0331, box: 0.1554)
[2025-08-07 20:38:18 train.log] INFO: Epoch: [21]  [Step 12100/14540]  lr: 0.000019  loss: 1.30456  detection_loss: 1.1630 (cls: 0.3445, box: 0.8185)  rpn_loss: 0.1415 (cls: 0.0376, box: 0.1040)
[2025-08-07 20:38:24 train.log] INFO: Epoch: [21]  [Step 12200/14540]  lr: 0.000019  loss: 0.52928  detection_loss: 0.4414 (cls: 0.1334, box: 0.3080)  rpn_loss: 0.0879 (cls: 0.0763, box: 0.0117)
[2025-08-07 20:38:29 train.log] INFO: Epoch: [21]  [Step 12300/14540]  lr: 0.000019  loss: 1.26978  detection_loss: 1.1440 (cls: 0.3199, box: 0.8241)  rpn_loss: 0.1258 (cls: 0.0536, box: 0.0722)
[2025-08-07 20:38:35 train.log] INFO: Epoch: [21]  [Step 12400/14540]  lr: 0.000019  loss: 0.92174  detection_loss: 0.8563 (cls: 0.1823, box: 0.6739)  rpn_loss: 0.0655 (cls: 0.0242, box: 0.0412)
[2025-08-07 20:38:40 train.log] INFO: Epoch: [21]  [Step 12500/14540]  lr: 0.000019  loss: 1.22598  detection_loss: 1.0968 (cls: 0.2822, box: 0.8146)  rpn_loss: 0.1292 (cls: 0.0709, box: 0.0583)
[2025-08-07 20:38:46 train.log] INFO: Epoch: [21]  [Step 12600/14540]  lr: 0.000019  loss: 0.86271  detection_loss: 0.8105 (cls: 0.1356, box: 0.6749)  rpn_loss: 0.0522 (cls: 0.0378, box: 0.0144)
[2025-08-07 20:38:52 train.log] INFO: Epoch: [21]  [Step 12700/14540]  lr: 0.000019  loss: 0.85529  detection_loss: 0.7761 (cls: 0.2371, box: 0.5390)  rpn_loss: 0.0792 (cls: 0.0275, box: 0.0516)
[2025-08-07 20:38:58 train.log] INFO: Epoch: [21]  [Step 12800/14540]  lr: 0.000019  loss: 0.96767  detection_loss: 0.8778 (cls: 0.2986, box: 0.5792)  rpn_loss: 0.0899 (cls: 0.0412, box: 0.0487)
[2025-08-07 20:39:03 train.log] INFO: Epoch: [21]  [Step 12900/14540]  lr: 0.000019  loss: 1.27705  detection_loss: 1.2165 (cls: 0.2290, box: 0.9875)  rpn_loss: 0.0606 (cls: 0.0402, box: 0.0204)
[2025-08-07 20:39:09 train.log] INFO: Epoch: [21]  [Step 13000/14540]  lr: 0.000019  loss: 1.01970  detection_loss: 0.9392 (cls: 0.2967, box: 0.6425)  rpn_loss: 0.0805 (cls: 0.0232, box: 0.0573)
[2025-08-07 20:39:14 train.log] INFO: Epoch: [21]  [Step 13100/14540]  lr: 0.000019  loss: 1.23641  detection_loss: 1.1374 (cls: 0.2414, box: 0.8960)  rpn_loss: 0.0990 (cls: 0.0263, box: 0.0727)
[2025-08-07 20:39:20 train.log] INFO: Epoch: [21]  [Step 13200/14540]  lr: 0.000019  loss: 0.96198  detection_loss: 0.8836 (cls: 0.2637, box: 0.6199)  rpn_loss: 0.0784 (cls: 0.0550, box: 0.0234)
[2025-08-07 20:39:26 train.log] INFO: Epoch: [21]  [Step 13300/14540]  lr: 0.000019  loss: 0.86614  detection_loss: 0.7926 (cls: 0.2948, box: 0.4978)  rpn_loss: 0.0735 (cls: 0.0434, box: 0.0301)
[2025-08-07 20:39:31 train.log] INFO: Epoch: [21]  [Step 13400/14540]  lr: 0.000019  loss: 0.76469  detection_loss: 0.7132 (cls: 0.1284, box: 0.5848)  rpn_loss: 0.0515 (cls: 0.0136, box: 0.0379)
[2025-08-07 20:39:37 train.log] INFO: Epoch: [21]  [Step 13500/14540]  lr: 0.000019  loss: 0.92052  detection_loss: 0.7493 (cls: 0.1586, box: 0.5907)  rpn_loss: 0.1713 (cls: 0.0623, box: 0.1090)
[2025-08-07 20:39:43 train.log] INFO: Epoch: [21]  [Step 13600/14540]  lr: 0.000019  loss: 1.00843  detection_loss: 0.7370 (cls: 0.2453, box: 0.4917)  rpn_loss: 0.2714 (cls: 0.0794, box: 0.1920)
[2025-08-07 20:39:48 train.log] INFO: Epoch: [21]  [Step 13700/14540]  lr: 0.000019  loss: 0.88662  detection_loss: 0.8069 (cls: 0.1489, box: 0.6580)  rpn_loss: 0.0797 (cls: 0.0207, box: 0.0590)
[2025-08-07 20:39:54 train.log] INFO: Epoch: [21]  [Step 13800/14540]  lr: 0.000019  loss: 0.76279  detection_loss: 0.6722 (cls: 0.1567, box: 0.5155)  rpn_loss: 0.0906 (cls: 0.0416, box: 0.0490)
[2025-08-07 20:39:59 train.log] INFO: Epoch: [21]  [Step 13900/14540]  lr: 0.000019  loss: 0.48525  detection_loss: 0.4356 (cls: 0.1587, box: 0.2769)  rpn_loss: 0.0497 (cls: 0.0169, box: 0.0328)
[2025-08-07 20:40:05 train.log] INFO: Epoch: [21]  [Step 14000/14540]  lr: 0.000019  loss: 0.84576  detection_loss: 0.7964 (cls: 0.2456, box: 0.5508)  rpn_loss: 0.0494 (cls: 0.0297, box: 0.0197)
[2025-08-07 20:40:11 train.log] INFO: Epoch: [21]  [Step 14100/14540]  lr: 0.000019  loss: 0.73864  detection_loss: 0.6544 (cls: 0.1502, box: 0.5043)  rpn_loss: 0.0842 (cls: 0.0444, box: 0.0398)
[2025-08-07 20:40:17 train.log] INFO: Epoch: [21]  [Step 14200/14540]  lr: 0.000019  loss: 0.72399  detection_loss: 0.6527 (cls: 0.1557, box: 0.4969)  rpn_loss: 0.0713 (cls: 0.0451, box: 0.0262)
[2025-08-07 20:40:23 train.log] INFO: Epoch: [21]  [Step 14300/14540]  lr: 0.000019  loss: 1.07574  detection_loss: 0.9596 (cls: 0.3619, box: 0.5977)  rpn_loss: 0.1161 (cls: 0.0431, box: 0.0730)
[2025-08-07 20:40:28 train.log] INFO: Epoch: [21]  [Step 14400/14540]  lr: 0.000019  loss: 0.57004  detection_loss: 0.5061 (cls: 0.1303, box: 0.3758)  rpn_loss: 0.0640 (cls: 0.0326, box: 0.0313)
[2025-08-07 20:40:34 train.log] INFO: Epoch: [21]  [Step 14500/14540]  lr: 0.000019  loss: 1.72246  detection_loss: 1.4094 (cls: 0.2540, box: 1.1553)  rpn_loss: 0.3131 (cls: 0.1479, box: 0.1652)
[2025-08-07 20:43:58 train.log] INFO: Epoch: [22]  [Step 100/14540]  lr: 0.000014  loss: 1.18467  detection_loss: 1.0122 (cls: 0.2913, box: 0.7209)  rpn_loss: 0.1724 (cls: 0.0865, box: 0.0859)
[2025-08-07 20:44:04 train.log] INFO: Epoch: [22]  [Step 200/14540]  lr: 0.000014  loss: 1.19180  detection_loss: 1.0743 (cls: 0.4414, box: 0.6329)  rpn_loss: 0.1175 (cls: 0.0671, box: 0.0504)
[2025-08-07 20:44:09 train.log] INFO: Epoch: [22]  [Step 300/14540]  lr: 0.000014  loss: 0.79783  detection_loss: 0.6865 (cls: 0.2379, box: 0.4486)  rpn_loss: 0.1114 (cls: 0.0646, box: 0.0468)
[2025-08-07 20:44:15 train.log] INFO: Epoch: [22]  [Step 400/14540]  lr: 0.000014  loss: 0.97836  detection_loss: 0.8927 (cls: 0.2710, box: 0.6217)  rpn_loss: 0.0857 (cls: 0.0358, box: 0.0499)
[2025-08-07 20:44:21 train.log] INFO: Epoch: [22]  [Step 500/14540]  lr: 0.000014  loss: 1.38027  detection_loss: 1.1478 (cls: 0.2591, box: 0.8887)  rpn_loss: 0.2325 (cls: 0.0739, box: 0.1586)
[2025-08-07 20:44:27 train.log] INFO: Epoch: [22]  [Step 600/14540]  lr: 0.000014  loss: 0.65085  detection_loss: 0.5473 (cls: 0.1549, box: 0.3924)  rpn_loss: 0.1035 (cls: 0.0549, box: 0.0486)
[2025-08-07 20:44:32 train.log] INFO: Epoch: [22]  [Step 700/14540]  lr: 0.000014  loss: 0.99988  detection_loss: 0.9257 (cls: 0.1970, box: 0.7287)  rpn_loss: 0.0742 (cls: 0.0456, box: 0.0286)
[2025-08-07 20:44:38 train.log] INFO: Epoch: [22]  [Step 800/14540]  lr: 0.000014  loss: 0.49339  detection_loss: 0.4132 (cls: 0.1121, box: 0.3011)  rpn_loss: 0.0802 (cls: 0.0690, box: 0.0111)
[2025-08-07 20:44:43 train.log] INFO: Epoch: [22]  [Step 900/14540]  lr: 0.000014  loss: 0.93788  detection_loss: 0.8757 (cls: 0.2733, box: 0.6024)  rpn_loss: 0.0622 (cls: 0.0307, box: 0.0315)
[2025-08-07 20:44:49 train.log] INFO: Epoch: [22]  [Step 1000/14540]  lr: 0.000014  loss: 0.56997  detection_loss: 0.5060 (cls: 0.0972, box: 0.4088)  rpn_loss: 0.0639 (cls: 0.0326, box: 0.0313)
[2025-08-07 20:44:54 train.log] INFO: Epoch: [22]  [Step 1100/14540]  lr: 0.000014  loss: 1.12297  detection_loss: 1.0534 (cls: 0.2721, box: 0.7813)  rpn_loss: 0.0695 (cls: 0.0290, box: 0.0405)
[2025-08-07 20:45:00 train.log] INFO: Epoch: [22]  [Step 1200/14540]  lr: 0.000014  loss: 0.84022  detection_loss: 0.7731 (cls: 0.1674, box: 0.6057)  rpn_loss: 0.0671 (cls: 0.0416, box: 0.0255)
[2025-08-07 20:45:05 train.log] INFO: Epoch: [22]  [Step 1300/14540]  lr: 0.000014  loss: 1.59510  detection_loss: 1.4899 (cls: 0.2880, box: 1.2019)  rpn_loss: 0.1052 (cls: 0.0563, box: 0.0490)
[2025-08-07 20:45:11 train.log] INFO: Epoch: [22]  [Step 1400/14540]  lr: 0.000014  loss: 0.89261  detection_loss: 0.8195 (cls: 0.1981, box: 0.6214)  rpn_loss: 0.0731 (cls: 0.0354, box: 0.0377)
[2025-08-07 20:45:16 train.log] INFO: Epoch: [22]  [Step 1500/14540]  lr: 0.000014  loss: 1.04190  detection_loss: 0.8979 (cls: 0.2344, box: 0.6635)  rpn_loss: 0.1440 (cls: 0.1293, box: 0.0147)
[2025-08-07 20:45:22 train.log] INFO: Epoch: [22]  [Step 1600/14540]  lr: 0.000014  loss: 0.63870  detection_loss: 0.5642 (cls: 0.1053, box: 0.4589)  rpn_loss: 0.0745 (cls: 0.0219, box: 0.0526)
[2025-08-07 20:45:28 train.log] INFO: Epoch: [22]  [Step 1700/14540]  lr: 0.000014  loss: 1.22097  detection_loss: 1.0533 (cls: 0.2952, box: 0.7581)  rpn_loss: 0.1677 (cls: 0.1055, box: 0.0622)
[2025-08-07 20:45:33 train.log] INFO: Epoch: [22]  [Step 1800/14540]  lr: 0.000014  loss: 0.90248  detection_loss: 0.7730 (cls: 0.2555, box: 0.5175)  rpn_loss: 0.1295 (cls: 0.0636, box: 0.0659)
[2025-08-07 20:45:39 train.log] INFO: Epoch: [22]  [Step 1900/14540]  lr: 0.000014  loss: 0.72694  detection_loss: 0.6481 (cls: 0.1737, box: 0.4743)  rpn_loss: 0.0789 (cls: 0.0214, box: 0.0575)
[2025-08-07 20:45:44 train.log] INFO: Epoch: [22]  [Step 2000/14540]  lr: 0.000014  loss: 0.78986  detection_loss: 0.7194 (cls: 0.1683, box: 0.5511)  rpn_loss: 0.0705 (cls: 0.0481, box: 0.0224)
[2025-08-07 20:45:50 train.log] INFO: Epoch: [22]  [Step 2100/14540]  lr: 0.000014  loss: 1.22963  detection_loss: 1.0966 (cls: 0.3338, box: 0.7628)  rpn_loss: 0.1331 (cls: 0.0923, box: 0.0407)
[2025-08-07 20:45:56 train.log] INFO: Epoch: [22]  [Step 2200/14540]  lr: 0.000014  loss: 0.86949  detection_loss: 0.6891 (cls: 0.1589, box: 0.5302)  rpn_loss: 0.1804 (cls: 0.1146, box: 0.0658)
[2025-08-07 20:46:01 train.log] INFO: Epoch: [22]  [Step 2300/14540]  lr: 0.000014  loss: 0.73447  detection_loss: 0.6380 (cls: 0.1816, box: 0.4563)  rpn_loss: 0.0965 (cls: 0.0501, box: 0.0464)
[2025-08-07 20:46:07 train.log] INFO: Epoch: [22]  [Step 2400/14540]  lr: 0.000014  loss: 0.46649  detection_loss: 0.3353 (cls: 0.0843, box: 0.2510)  rpn_loss: 0.1312 (cls: 0.0554, box: 0.0757)
[2025-08-07 20:46:12 train.log] INFO: Epoch: [22]  [Step 2500/14540]  lr: 0.000014  loss: 0.69124  detection_loss: 0.6013 (cls: 0.2131, box: 0.3882)  rpn_loss: 0.0900 (cls: 0.0407, box: 0.0493)
[2025-08-07 20:46:18 train.log] INFO: Epoch: [22]  [Step 2600/14540]  lr: 0.000014  loss: 0.83062  detection_loss: 0.6798 (cls: 0.2569, box: 0.4229)  rpn_loss: 0.1508 (cls: 0.0433, box: 0.1075)
[2025-08-07 20:46:23 train.log] INFO: Epoch: [22]  [Step 2700/14540]  lr: 0.000014  loss: 1.13825  detection_loss: 1.0172 (cls: 0.3079, box: 0.7093)  rpn_loss: 0.1210 (cls: 0.0757, box: 0.0453)
[2025-08-07 20:46:29 train.log] INFO: Epoch: [22]  [Step 2800/14540]  lr: 0.000014  loss: 1.10909  detection_loss: 1.0159 (cls: 0.3232, box: 0.6927)  rpn_loss: 0.0932 (cls: 0.0440, box: 0.0492)
[2025-08-07 20:46:34 train.log] INFO: Epoch: [22]  [Step 2900/14540]  lr: 0.000014  loss: 0.54508  detection_loss: 0.4708 (cls: 0.1272, box: 0.3435)  rpn_loss: 0.0743 (cls: 0.0524, box: 0.0219)
[2025-08-07 20:46:39 train.log] INFO: Epoch: [22]  [Step 3000/14540]  lr: 0.000014  loss: 0.82439  detection_loss: 0.7314 (cls: 0.1706, box: 0.5609)  rpn_loss: 0.0930 (cls: 0.0382, box: 0.0548)
[2025-08-07 20:46:45 train.log] INFO: Epoch: [22]  [Step 3100/14540]  lr: 0.000014  loss: 0.88617  detection_loss: 0.7974 (cls: 0.2507, box: 0.5468)  rpn_loss: 0.0887 (cls: 0.0494, box: 0.0393)
[2025-08-07 20:46:50 train.log] INFO: Epoch: [22]  [Step 3200/14540]  lr: 0.000014  loss: 1.01675  detection_loss: 0.9377 (cls: 0.2106, box: 0.7271)  rpn_loss: 0.0791 (cls: 0.0572, box: 0.0219)
[2025-08-07 20:46:56 train.log] INFO: Epoch: [22]  [Step 3300/14540]  lr: 0.000014  loss: 0.68806  detection_loss: 0.6068 (cls: 0.1444, box: 0.4624)  rpn_loss: 0.0812 (cls: 0.0550, box: 0.0262)
[2025-08-07 20:47:01 train.log] INFO: Epoch: [22]  [Step 3400/14540]  lr: 0.000014  loss: 0.73844  detection_loss: 0.6551 (cls: 0.1198, box: 0.5353)  rpn_loss: 0.0833 (cls: 0.0712, box: 0.0121)
[2025-08-07 20:47:07 train.log] INFO: Epoch: [22]  [Step 3500/14540]  lr: 0.000014  loss: 0.86958  detection_loss: 0.7447 (cls: 0.2244, box: 0.5203)  rpn_loss: 0.1249 (cls: 0.0300, box: 0.0949)
[2025-08-07 20:47:13 train.log] INFO: Epoch: [22]  [Step 3600/14540]  lr: 0.000014  loss: 1.82522  detection_loss: 1.6419 (cls: 0.5664, box: 1.0755)  rpn_loss: 0.1833 (cls: 0.0965, box: 0.0868)
[2025-08-07 20:47:15 train.log] INFO: Epoch: [22]  [Step 3635/14540]  lr: 0.000014  loss: 1.00869  detection_loss: 0.8620 (cls: 0.2416, box: 0.6204)  rpn_loss: 0.1467 (cls: 0.0409, box: 0.1058)
[2025-08-07 20:47:18 train.log] INFO: Epoch: [22]  [Step 3700/14540]  lr: 0.000014  loss: 1.12105  detection_loss: 0.9723 (cls: 0.3198, box: 0.6525)  rpn_loss: 0.1487 (cls: 0.1226, box: 0.0261)
[2025-08-07 20:47:24 train.log] INFO: Epoch: [22]  [Step 3800/14540]  lr: 0.000014  loss: 0.97081  detection_loss: 0.8877 (cls: 0.2169, box: 0.6709)  rpn_loss: 0.0831 (cls: 0.0347, box: 0.0484)
[2025-08-07 20:47:29 train.log] INFO: Epoch: [22]  [Step 3900/14540]  lr: 0.000014  loss: 1.38687  detection_loss: 1.2923 (cls: 0.4523, box: 0.8400)  rpn_loss: 0.0946 (cls: 0.0606, box: 0.0339)
[2025-08-07 20:47:35 train.log] INFO: Epoch: [22]  [Step 4000/14540]  lr: 0.000014  loss: 0.63441  detection_loss: 0.5289 (cls: 0.1223, box: 0.4067)  rpn_loss: 0.1055 (cls: 0.0822, box: 0.0233)
[2025-08-07 20:47:40 train.log] INFO: Epoch: [22]  [Step 4100/14540]  lr: 0.000014  loss: 0.77686  detection_loss: 0.7270 (cls: 0.2264, box: 0.5006)  rpn_loss: 0.0499 (cls: 0.0344, box: 0.0155)
[2025-08-07 20:47:46 train.log] INFO: Epoch: [22]  [Step 4200/14540]  lr: 0.000014  loss: 0.92248  detection_loss: 0.8226 (cls: 0.1872, box: 0.6354)  rpn_loss: 0.0999 (cls: 0.0486, box: 0.0513)
[2025-08-07 20:47:51 train.log] INFO: Epoch: [22]  [Step 4300/14540]  lr: 0.000014  loss: 0.71264  detection_loss: 0.6490 (cls: 0.1548, box: 0.4942)  rpn_loss: 0.0637 (cls: 0.0278, box: 0.0358)
[2025-08-07 20:47:57 train.log] INFO: Epoch: [22]  [Step 4400/14540]  lr: 0.000014  loss: 1.12872  detection_loss: 1.0296 (cls: 0.1306, box: 0.8990)  rpn_loss: 0.0991 (cls: 0.0181, box: 0.0810)
[2025-08-07 20:48:02 train.log] INFO: Epoch: [22]  [Step 4500/14540]  lr: 0.000014  loss: 1.44567  detection_loss: 1.2972 (cls: 0.2676, box: 1.0296)  rpn_loss: 0.1485 (cls: 0.0327, box: 0.1158)
[2025-08-07 20:48:08 train.log] INFO: Epoch: [22]  [Step 4600/14540]  lr: 0.000014  loss: 0.85384  detection_loss: 0.7746 (cls: 0.2297, box: 0.5449)  rpn_loss: 0.0792 (cls: 0.0274, box: 0.0519)
[2025-08-07 20:48:13 train.log] INFO: Epoch: [22]  [Step 4700/14540]  lr: 0.000014  loss: 1.23252  detection_loss: 1.0062 (cls: 0.2822, box: 0.7240)  rpn_loss: 0.2263 (cls: 0.0690, box: 0.1573)
[2025-08-07 20:48:19 train.log] INFO: Epoch: [22]  [Step 4800/14540]  lr: 0.000014  loss: 1.38523  detection_loss: 1.2650 (cls: 0.3660, box: 0.8989)  rpn_loss: 0.1203 (cls: 0.0717, box: 0.0485)
[2025-08-07 20:48:24 train.log] INFO: Epoch: [22]  [Step 4900/14540]  lr: 0.000014  loss: 1.27871  detection_loss: 1.1928 (cls: 0.2935, box: 0.8993)  rpn_loss: 0.0859 (cls: 0.0545, box: 0.0315)
[2025-08-07 20:48:30 train.log] INFO: Epoch: [22]  [Step 5000/14540]  lr: 0.000014  loss: 1.14092  detection_loss: 1.0615 (cls: 0.2905, box: 0.7710)  rpn_loss: 0.0794 (cls: 0.0618, box: 0.0176)
[2025-08-07 20:48:35 train.log] INFO: Epoch: [22]  [Step 5100/14540]  lr: 0.000014  loss: 0.93906  detection_loss: 0.8104 (cls: 0.2124, box: 0.5980)  rpn_loss: 0.1286 (cls: 0.0275, box: 0.1012)
[2025-08-07 20:48:41 train.log] INFO: Epoch: [22]  [Step 5200/14540]  lr: 0.000014  loss: 1.06145  detection_loss: 0.9249 (cls: 0.2365, box: 0.6885)  rpn_loss: 0.1365 (cls: 0.0229, box: 0.1136)
[2025-08-07 20:48:46 train.log] INFO: Epoch: [22]  [Step 5300/14540]  lr: 0.000014  loss: 0.57133  detection_loss: 0.5087 (cls: 0.1257, box: 0.3829)  rpn_loss: 0.0626 (cls: 0.0265, box: 0.0362)
[2025-08-07 20:48:52 train.log] INFO: Epoch: [22]  [Step 5400/14540]  lr: 0.000014  loss: 0.85934  detection_loss: 0.7667 (cls: 0.2114, box: 0.5553)  rpn_loss: 0.0927 (cls: 0.0712, box: 0.0215)
[2025-08-07 20:48:57 train.log] INFO: Epoch: [22]  [Step 5500/14540]  lr: 0.000014  loss: 1.27667  detection_loss: 1.1450 (cls: 0.2446, box: 0.9004)  rpn_loss: 0.1317 (cls: 0.0480, box: 0.0837)
[2025-08-07 20:49:03 train.log] INFO: Epoch: [22]  [Step 5600/14540]  lr: 0.000014  loss: 0.77185  detection_loss: 0.6765 (cls: 0.1602, box: 0.5164)  rpn_loss: 0.0953 (cls: 0.0478, box: 0.0475)
[2025-08-07 20:49:09 train.log] INFO: Epoch: [22]  [Step 5700/14540]  lr: 0.000014  loss: 1.46768  detection_loss: 1.3079 (cls: 0.2653, box: 1.0426)  rpn_loss: 0.1597 (cls: 0.0880, box: 0.0717)
[2025-08-07 20:49:14 train.log] INFO: Epoch: [22]  [Step 5800/14540]  lr: 0.000014  loss: 1.11265  detection_loss: 1.0193 (cls: 0.3933, box: 0.6260)  rpn_loss: 0.0934 (cls: 0.0632, box: 0.0302)
[2025-08-07 20:49:20 train.log] INFO: Epoch: [22]  [Step 5900/14540]  lr: 0.000014  loss: 0.98830  detection_loss: 0.8833 (cls: 0.2963, box: 0.5870)  rpn_loss: 0.1050 (cls: 0.0872, box: 0.0178)
[2025-08-07 20:49:25 train.log] INFO: Epoch: [22]  [Step 6000/14540]  lr: 0.000014  loss: 0.61210  detection_loss: 0.5624 (cls: 0.1840, box: 0.3784)  rpn_loss: 0.0497 (cls: 0.0332, box: 0.0165)
[2025-08-07 20:49:31 train.log] INFO: Epoch: [22]  [Step 6100/14540]  lr: 0.000014  loss: 0.67974  detection_loss: 0.4959 (cls: 0.1352, box: 0.3607)  rpn_loss: 0.1838 (cls: 0.0545, box: 0.1293)
[2025-08-07 20:49:36 train.log] INFO: Epoch: [22]  [Step 6200/14540]  lr: 0.000014  loss: 0.98080  detection_loss: 0.6244 (cls: 0.2229, box: 0.4015)  rpn_loss: 0.3564 (cls: 0.0427, box: 0.3136)
[2025-08-07 20:49:42 train.log] INFO: Epoch: [22]  [Step 6300/14540]  lr: 0.000014  loss: 0.69647  detection_loss: 0.6223 (cls: 0.1867, box: 0.4357)  rpn_loss: 0.0741 (cls: 0.0444, box: 0.0298)
[2025-08-07 20:49:47 train.log] INFO: Epoch: [22]  [Step 6400/14540]  lr: 0.000014  loss: 0.94233  detection_loss: 0.8074 (cls: 0.2441, box: 0.5633)  rpn_loss: 0.1350 (cls: 0.0568, box: 0.0781)
[2025-08-07 20:49:53 train.log] INFO: Epoch: [22]  [Step 6500/14540]  lr: 0.000014  loss: 0.87186  detection_loss: 0.8126 (cls: 0.2348, box: 0.5778)  rpn_loss: 0.0593 (cls: 0.0204, box: 0.0389)
[2025-08-07 20:49:59 train.log] INFO: Epoch: [22]  [Step 6600/14540]  lr: 0.000014  loss: 0.75676  detection_loss: 0.7151 (cls: 0.1410, box: 0.5741)  rpn_loss: 0.0417 (cls: 0.0184, box: 0.0233)
[2025-08-07 20:50:04 train.log] INFO: Epoch: [22]  [Step 6700/14540]  lr: 0.000014  loss: 0.71835  detection_loss: 0.6236 (cls: 0.0934, box: 0.5301)  rpn_loss: 0.0948 (cls: 0.0380, box: 0.0568)
[2025-08-07 20:50:10 train.log] INFO: Epoch: [22]  [Step 6800/14540]  lr: 0.000014  loss: 0.55709  detection_loss: 0.5088 (cls: 0.1554, box: 0.3535)  rpn_loss: 0.0482 (cls: 0.0259, box: 0.0223)
[2025-08-07 20:50:15 train.log] INFO: Epoch: [22]  [Step 6900/14540]  lr: 0.000014  loss: 0.66151  detection_loss: 0.5905 (cls: 0.2180, box: 0.3725)  rpn_loss: 0.0710 (cls: 0.0293, box: 0.0418)
[2025-08-07 20:50:21 train.log] INFO: Epoch: [22]  [Step 7000/14540]  lr: 0.000014  loss: 0.44942  detection_loss: 0.4072 (cls: 0.0840, box: 0.3232)  rpn_loss: 0.0422 (cls: 0.0164, box: 0.0258)
[2025-08-07 20:50:26 train.log] INFO: Epoch: [22]  [Step 7100/14540]  lr: 0.000014  loss: 0.70236  detection_loss: 0.6321 (cls: 0.2079, box: 0.4241)  rpn_loss: 0.0703 (cls: 0.0447, box: 0.0257)
[2025-08-07 20:50:32 train.log] INFO: Epoch: [22]  [Step 7200/14540]  lr: 0.000014  loss: 1.11678  detection_loss: 0.9996 (cls: 0.1841, box: 0.8155)  rpn_loss: 0.1172 (cls: 0.0406, box: 0.0765)
[2025-08-07 20:50:38 train.log] INFO: Epoch: [22]  [Step 7300/14540]  lr: 0.000014  loss: 1.29831  detection_loss: 1.1921 (cls: 0.3681, box: 0.8239)  rpn_loss: 0.1062 (cls: 0.0569, box: 0.0493)
[2025-08-07 20:50:43 train.log] INFO: Epoch: [22]  [Step 7400/14540]  lr: 0.000014  loss: 1.13507  detection_loss: 0.9863 (cls: 0.1727, box: 0.8136)  rpn_loss: 0.1488 (cls: 0.0108, box: 0.1380)
[2025-08-07 20:50:49 train.log] INFO: Epoch: [22]  [Step 7500/14540]  lr: 0.000014  loss: 1.44979  detection_loss: 1.2157 (cls: 0.3672, box: 0.8485)  rpn_loss: 0.2341 (cls: 0.0979, box: 0.1362)
[2025-08-07 20:50:54 train.log] INFO: Epoch: [22]  [Step 7600/14540]  lr: 0.000014  loss: 1.09560  detection_loss: 0.8804 (cls: 0.1878, box: 0.6926)  rpn_loss: 0.2152 (cls: 0.0991, box: 0.1161)
[2025-08-07 20:51:00 train.log] INFO: Epoch: [22]  [Step 7700/14540]  lr: 0.000014  loss: 1.01247  detection_loss: 0.9454 (cls: 0.2251, box: 0.7203)  rpn_loss: 0.0671 (cls: 0.0288, box: 0.0382)
[2025-08-07 20:51:05 train.log] INFO: Epoch: [22]  [Step 7800/14540]  lr: 0.000014  loss: 0.85448  detection_loss: 0.7479 (cls: 0.1790, box: 0.5689)  rpn_loss: 0.1066 (cls: 0.0689, box: 0.0377)
[2025-08-07 20:51:11 train.log] INFO: Epoch: [22]  [Step 7900/14540]  lr: 0.000014  loss: 1.14888  detection_loss: 0.9992 (cls: 0.3204, box: 0.6788)  rpn_loss: 0.1497 (cls: 0.0494, box: 0.1003)
[2025-08-07 20:51:16 train.log] INFO: Epoch: [22]  [Step 8000/14540]  lr: 0.000014  loss: 0.59806  detection_loss: 0.5001 (cls: 0.1046, box: 0.3955)  rpn_loss: 0.0980 (cls: 0.0760, box: 0.0219)
[2025-08-07 20:51:22 train.log] INFO: Epoch: [22]  [Step 8100/14540]  lr: 0.000014  loss: 1.13886  detection_loss: 1.0202 (cls: 0.2443, box: 0.7759)  rpn_loss: 0.1186 (cls: 0.0374, box: 0.0812)
[2025-08-07 20:51:28 train.log] INFO: Epoch: [22]  [Step 8200/14540]  lr: 0.000014  loss: 1.22183  detection_loss: 1.0944 (cls: 0.3360, box: 0.7584)  rpn_loss: 0.1274 (cls: 0.0868, box: 0.0406)
[2025-08-07 20:51:33 train.log] INFO: Epoch: [22]  [Step 8300/14540]  lr: 0.000014  loss: 1.35731  detection_loss: 1.2625 (cls: 0.3702, box: 0.8923)  rpn_loss: 0.0948 (cls: 0.0694, box: 0.0254)
[2025-08-07 20:51:39 train.log] INFO: Epoch: [22]  [Step 8400/14540]  lr: 0.000014  loss: 1.13360  detection_loss: 1.0297 (cls: 0.1772, box: 0.8525)  rpn_loss: 0.1039 (cls: 0.0628, box: 0.0410)
[2025-08-07 20:51:44 train.log] INFO: Epoch: [22]  [Step 8500/14540]  lr: 0.000014  loss: 1.32369  detection_loss: 1.2216 (cls: 0.2215, box: 1.0001)  rpn_loss: 0.1021 (cls: 0.0746, box: 0.0276)
[2025-08-07 20:51:50 train.log] INFO: Epoch: [22]  [Step 8600/14540]  lr: 0.000014  loss: 1.25611  detection_loss: 1.1597 (cls: 0.2562, box: 0.9035)  rpn_loss: 0.0964 (cls: 0.0481, box: 0.0484)
[2025-08-07 20:51:55 train.log] INFO: Epoch: [22]  [Step 8700/14540]  lr: 0.000014  loss: 1.02241  detection_loss: 0.8753 (cls: 0.2228, box: 0.6525)  rpn_loss: 0.1471 (cls: 0.1178, box: 0.0293)
[2025-08-07 20:52:01 train.log] INFO: Epoch: [22]  [Step 8800/14540]  lr: 0.000014  loss: 0.82181  detection_loss: 0.7620 (cls: 0.1516, box: 0.6103)  rpn_loss: 0.0598 (cls: 0.0320, box: 0.0278)
[2025-08-07 20:52:06 train.log] INFO: Epoch: [22]  [Step 8900/14540]  lr: 0.000014  loss: 0.75655  detection_loss: 0.5451 (cls: 0.1267, box: 0.4183)  rpn_loss: 0.2115 (cls: 0.0253, box: 0.1862)
[2025-08-07 20:52:12 train.log] INFO: Epoch: [22]  [Step 9000/14540]  lr: 0.000014  loss: 0.82904  detection_loss: 0.7151 (cls: 0.1787, box: 0.5364)  rpn_loss: 0.1140 (cls: 0.0343, box: 0.0797)
[2025-08-07 20:52:18 train.log] INFO: Epoch: [22]  [Step 9100/14540]  lr: 0.000014  loss: 0.91705  detection_loss: 0.8178 (cls: 0.1863, box: 0.6315)  rpn_loss: 0.0993 (cls: 0.0402, box: 0.0591)
[2025-08-07 20:52:23 train.log] INFO: Epoch: [22]  [Step 9200/14540]  lr: 0.000014  loss: 0.69109  detection_loss: 0.6269 (cls: 0.1614, box: 0.4656)  rpn_loss: 0.0642 (cls: 0.0414, box: 0.0228)
[2025-08-07 20:52:29 train.log] INFO: Epoch: [22]  [Step 9300/14540]  lr: 0.000014  loss: 1.28674  detection_loss: 1.1370 (cls: 0.2437, box: 0.8933)  rpn_loss: 0.1498 (cls: 0.0389, box: 0.1108)
[2025-08-07 20:52:34 train.log] INFO: Epoch: [22]  [Step 9400/14540]  lr: 0.000014  loss: 1.40354  detection_loss: 1.0982 (cls: 0.2783, box: 0.8199)  rpn_loss: 0.3053 (cls: 0.0464, box: 0.2590)
[2025-08-07 20:52:40 train.log] INFO: Epoch: [22]  [Step 9500/14540]  lr: 0.000014  loss: 0.60301  detection_loss: 0.5581 (cls: 0.1173, box: 0.4408)  rpn_loss: 0.0449 (cls: 0.0284, box: 0.0165)
[2025-08-07 20:52:46 train.log] INFO: Epoch: [22]  [Step 9600/14540]  lr: 0.000014  loss: 0.48266  detection_loss: 0.3757 (cls: 0.1113, box: 0.2644)  rpn_loss: 0.1070 (cls: 0.0248, box: 0.0822)
[2025-08-07 20:52:51 train.log] INFO: Epoch: [22]  [Step 9700/14540]  lr: 0.000014  loss: 0.68350  detection_loss: 0.5635 (cls: 0.1800, box: 0.3835)  rpn_loss: 0.1200 (cls: 0.0645, box: 0.0555)
[2025-08-07 20:52:57 train.log] INFO: Epoch: [22]  [Step 9800/14540]  lr: 0.000014  loss: 0.85636  detection_loss: 0.8027 (cls: 0.1858, box: 0.6170)  rpn_loss: 0.0536 (cls: 0.0356, box: 0.0180)
[2025-08-07 20:53:02 train.log] INFO: Epoch: [22]  [Step 9900/14540]  lr: 0.000014  loss: 1.32748  detection_loss: 1.2408 (cls: 0.3290, box: 0.9118)  rpn_loss: 0.0867 (cls: 0.0562, box: 0.0304)
[2025-08-07 20:53:08 train.log] INFO: Epoch: [22]  [Step 10000/14540]  lr: 0.000014  loss: 1.02426  detection_loss: 0.9157 (cls: 0.1750, box: 0.7407)  rpn_loss: 0.1085 (cls: 0.0595, box: 0.0491)
[2025-08-07 20:53:14 train.log] INFO: Epoch: [22]  [Step 10100/14540]  lr: 0.000014  loss: 0.82199  detection_loss: 0.7737 (cls: 0.2174, box: 0.5562)  rpn_loss: 0.0483 (cls: 0.0202, box: 0.0281)
[2025-08-07 20:53:20 train.log] INFO: Epoch: [22]  [Step 10200/14540]  lr: 0.000014  loss: 0.67636  detection_loss: 0.6369 (cls: 0.1297, box: 0.5072)  rpn_loss: 0.0395 (cls: 0.0227, box: 0.0167)
[2025-08-07 20:53:25 train.log] INFO: Epoch: [22]  [Step 10300/14540]  lr: 0.000014  loss: 1.09240  detection_loss: 0.9741 (cls: 0.1548, box: 0.8192)  rpn_loss: 0.1183 (cls: 0.0286, box: 0.0897)
[2025-08-07 20:53:31 train.log] INFO: Epoch: [22]  [Step 10400/14540]  lr: 0.000014  loss: 0.58342  detection_loss: 0.5322 (cls: 0.1271, box: 0.4051)  rpn_loss: 0.0512 (cls: 0.0347, box: 0.0165)
[2025-08-07 20:53:37 train.log] INFO: Epoch: [22]  [Step 10500/14540]  lr: 0.000014  loss: 0.75453  detection_loss: 0.6964 (cls: 0.1955, box: 0.5009)  rpn_loss: 0.0581 (cls: 0.0443, box: 0.0138)
[2025-08-07 20:53:43 train.log] INFO: Epoch: [22]  [Step 10600/14540]  lr: 0.000014  loss: 0.89571  detection_loss: 0.8070 (cls: 0.2525, box: 0.5545)  rpn_loss: 0.0887 (cls: 0.0633, box: 0.0254)
[2025-08-07 20:53:48 train.log] INFO: Epoch: [22]  [Step 10700/14540]  lr: 0.000014  loss: 0.74127  detection_loss: 0.6567 (cls: 0.2080, box: 0.4487)  rpn_loss: 0.0845 (cls: 0.0304, box: 0.0542)
[2025-08-07 20:53:54 train.log] INFO: Epoch: [22]  [Step 10800/14540]  lr: 0.000014  loss: 0.67939  detection_loss: 0.5913 (cls: 0.1376, box: 0.4537)  rpn_loss: 0.0881 (cls: 0.0532, box: 0.0349)
[2025-08-07 20:54:00 train.log] INFO: Epoch: [22]  [Step 10900/14540]  lr: 0.000014  loss: 1.07433  detection_loss: 0.9772 (cls: 0.3214, box: 0.6558)  rpn_loss: 0.0971 (cls: 0.0549, box: 0.0422)
[2025-08-07 20:54:05 train.log] INFO: Epoch: [22]  [Step 11000/14540]  lr: 0.000014  loss: 1.18675  detection_loss: 0.9713 (cls: 0.1612, box: 0.8101)  rpn_loss: 0.2155 (cls: 0.1008, box: 0.1147)
[2025-08-07 20:54:11 train.log] INFO: Epoch: [22]  [Step 11100/14540]  lr: 0.000014  loss: 0.52216  detection_loss: 0.4635 (cls: 0.0857, box: 0.3778)  rpn_loss: 0.0586 (cls: 0.0287, box: 0.0299)
[2025-08-07 20:54:16 train.log] INFO: Epoch: [22]  [Step 11200/14540]  lr: 0.000014  loss: 0.87751  detection_loss: 0.7807 (cls: 0.1850, box: 0.5957)  rpn_loss: 0.0968 (cls: 0.0428, box: 0.0539)
[2025-08-07 20:54:22 train.log] INFO: Epoch: [22]  [Step 11300/14540]  lr: 0.000014  loss: 1.02618  detection_loss: 0.8842 (cls: 0.3299, box: 0.5543)  rpn_loss: 0.1419 (cls: 0.0584, box: 0.0836)
[2025-08-07 20:54:27 train.log] INFO: Epoch: [22]  [Step 11400/14540]  lr: 0.000014  loss: 1.07133  detection_loss: 0.9701 (cls: 0.2257, box: 0.7444)  rpn_loss: 0.1012 (cls: 0.0523, box: 0.0489)
[2025-08-07 20:54:33 train.log] INFO: Epoch: [22]  [Step 11500/14540]  lr: 0.000014  loss: 0.91106  detection_loss: 0.7802 (cls: 0.2148, box: 0.5654)  rpn_loss: 0.1308 (cls: 0.0891, box: 0.0417)
[2025-08-07 20:54:38 train.log] INFO: Epoch: [22]  [Step 11600/14540]  lr: 0.000014  loss: 1.02585  detection_loss: 0.8864 (cls: 0.2670, box: 0.6194)  rpn_loss: 0.1394 (cls: 0.0617, box: 0.0777)
[2025-08-07 20:54:44 train.log] INFO: Epoch: [22]  [Step 11700/14540]  lr: 0.000014  loss: 0.75072  detection_loss: 0.6520 (cls: 0.1859, box: 0.4661)  rpn_loss: 0.0988 (cls: 0.0731, box: 0.0257)
[2025-08-07 20:54:49 train.log] INFO: Epoch: [22]  [Step 11800/14540]  lr: 0.000014  loss: 0.60754  detection_loss: 0.5534 (cls: 0.0915, box: 0.4620)  rpn_loss: 0.0541 (cls: 0.0358, box: 0.0183)
[2025-08-07 20:54:55 train.log] INFO: Epoch: [22]  [Step 11900/14540]  lr: 0.000014  loss: 0.86506  detection_loss: 0.7910 (cls: 0.1265, box: 0.6645)  rpn_loss: 0.0741 (cls: 0.0210, box: 0.0531)
[2025-08-07 20:55:01 train.log] INFO: Epoch: [22]  [Step 12000/14540]  lr: 0.000014  loss: 0.97693  detection_loss: 0.9091 (cls: 0.2197, box: 0.6894)  rpn_loss: 0.0679 (cls: 0.0420, box: 0.0259)
[2025-08-07 20:55:06 train.log] INFO: Epoch: [22]  [Step 12100/14540]  lr: 0.000014  loss: 1.05518  detection_loss: 0.9105 (cls: 0.1915, box: 0.7190)  rpn_loss: 0.1447 (cls: 0.0526, box: 0.0922)
[2025-08-07 20:55:12 train.log] INFO: Epoch: [22]  [Step 12200/14540]  lr: 0.000014  loss: 0.68485  detection_loss: 0.6223 (cls: 0.3251, box: 0.2973)  rpn_loss: 0.0625 (cls: 0.0490, box: 0.0135)
[2025-08-07 20:55:17 train.log] INFO: Epoch: [22]  [Step 12300/14540]  lr: 0.000014  loss: 0.53519  detection_loss: 0.4800 (cls: 0.1467, box: 0.3333)  rpn_loss: 0.0552 (cls: 0.0283, box: 0.0269)
[2025-08-07 20:55:23 train.log] INFO: Epoch: [22]  [Step 12400/14540]  lr: 0.000014  loss: 0.71134  detection_loss: 0.6521 (cls: 0.1112, box: 0.5409)  rpn_loss: 0.0592 (cls: 0.0126, box: 0.0467)
[2025-08-07 20:55:28 train.log] INFO: Epoch: [22]  [Step 12500/14540]  lr: 0.000014  loss: 0.81917  detection_loss: 0.7100 (cls: 0.2037, box: 0.5064)  rpn_loss: 0.1091 (cls: 0.0532, box: 0.0560)
[2025-08-07 20:55:34 train.log] INFO: Epoch: [22]  [Step 12600/14540]  lr: 0.000014  loss: 0.68607  detection_loss: 0.6598 (cls: 0.1347, box: 0.5251)  rpn_loss: 0.0263 (cls: 0.0168, box: 0.0095)
[2025-08-07 20:55:39 train.log] INFO: Epoch: [22]  [Step 12700/14540]  lr: 0.000014  loss: 1.42706  detection_loss: 1.3718 (cls: 0.3255, box: 1.0462)  rpn_loss: 0.0553 (cls: 0.0257, box: 0.0296)
[2025-08-07 20:55:44 train.log] INFO: Epoch: [22]  [Step 12800/14540]  lr: 0.000014  loss: 0.80422  detection_loss: 0.7353 (cls: 0.2434, box: 0.4919)  rpn_loss: 0.0690 (cls: 0.0325, box: 0.0365)
[2025-08-07 20:55:50 train.log] INFO: Epoch: [22]  [Step 12900/14540]  lr: 0.000014  loss: 1.41496  detection_loss: 1.0970 (cls: 0.3084, box: 0.7886)  rpn_loss: 0.3180 (cls: 0.0563, box: 0.2617)
[2025-08-07 20:55:55 train.log] INFO: Epoch: [22]  [Step 13000/14540]  lr: 0.000014  loss: 0.50929  detection_loss: 0.3961 (cls: 0.1007, box: 0.2954)  rpn_loss: 0.1132 (cls: 0.0111, box: 0.1021)
[2025-08-07 20:56:01 train.log] INFO: Epoch: [22]  [Step 13100/14540]  lr: 0.000014  loss: 0.91083  detection_loss: 0.8420 (cls: 0.1556, box: 0.6864)  rpn_loss: 0.0689 (cls: 0.0211, box: 0.0478)
[2025-08-07 20:56:06 train.log] INFO: Epoch: [22]  [Step 13200/14540]  lr: 0.000014  loss: 0.58085  detection_loss: 0.5280 (cls: 0.1469, box: 0.3811)  rpn_loss: 0.0528 (cls: 0.0234, box: 0.0294)
[2025-08-07 20:56:12 train.log] INFO: Epoch: [22]  [Step 13300/14540]  lr: 0.000014  loss: 0.85963  detection_loss: 0.7814 (cls: 0.2683, box: 0.5131)  rpn_loss: 0.0782 (cls: 0.0319, box: 0.0463)
[2025-08-07 20:56:17 train.log] INFO: Epoch: [22]  [Step 13400/14540]  lr: 0.000014  loss: 1.23106  detection_loss: 1.0829 (cls: 0.3862, box: 0.6967)  rpn_loss: 0.1481 (cls: 0.1235, box: 0.0247)
[2025-08-07 20:56:23 train.log] INFO: Epoch: [22]  [Step 13500/14540]  lr: 0.000014  loss: 1.52902  detection_loss: 1.4454 (cls: 0.4450, box: 1.0004)  rpn_loss: 0.0836 (cls: 0.0517, box: 0.0319)
[2025-08-07 20:56:28 train.log] INFO: Epoch: [22]  [Step 13600/14540]  lr: 0.000014  loss: 0.78533  detection_loss: 0.7285 (cls: 0.1296, box: 0.5988)  rpn_loss: 0.0569 (cls: 0.0182, box: 0.0386)
[2025-08-07 20:56:34 train.log] INFO: Epoch: [22]  [Step 13700/14540]  lr: 0.000014  loss: 0.80118  detection_loss: 0.7401 (cls: 0.2567, box: 0.4834)  rpn_loss: 0.0611 (cls: 0.0427, box: 0.0183)
[2025-08-07 20:56:39 train.log] INFO: Epoch: [22]  [Step 13800/14540]  lr: 0.000014  loss: 0.89513  detection_loss: 0.7885 (cls: 0.2124, box: 0.5761)  rpn_loss: 0.1066 (cls: 0.0662, box: 0.0405)
[2025-08-07 20:56:44 train.log] INFO: Epoch: [22]  [Step 13900/14540]  lr: 0.000014  loss: 1.01059  detection_loss: 0.8578 (cls: 0.2188, box: 0.6389)  rpn_loss: 0.1528 (cls: 0.0623, box: 0.0905)
[2025-08-07 20:56:50 train.log] INFO: Epoch: [22]  [Step 14000/14540]  lr: 0.000014  loss: 1.02678  detection_loss: 0.9407 (cls: 0.1957, box: 0.7451)  rpn_loss: 0.0861 (cls: 0.0471, box: 0.0390)
[2025-08-07 20:56:55 train.log] INFO: Epoch: [22]  [Step 14100/14540]  lr: 0.000014  loss: 0.91754  detection_loss: 0.8341 (cls: 0.2632, box: 0.5708)  rpn_loss: 0.0835 (cls: 0.0570, box: 0.0265)
[2025-08-07 20:57:01 train.log] INFO: Epoch: [22]  [Step 14200/14540]  lr: 0.000014  loss: 0.70185  detection_loss: 0.5854 (cls: 0.1840, box: 0.4015)  rpn_loss: 0.1164 (cls: 0.0840, box: 0.0324)
[2025-08-07 20:57:06 train.log] INFO: Epoch: [22]  [Step 14300/14540]  lr: 0.000014  loss: 0.71469  detection_loss: 0.6500 (cls: 0.1899, box: 0.4601)  rpn_loss: 0.0647 (cls: 0.0311, box: 0.0336)
[2025-08-07 20:57:12 train.log] INFO: Epoch: [22]  [Step 14400/14540]  lr: 0.000014  loss: 0.88754  detection_loss: 0.8220 (cls: 0.1896, box: 0.6324)  rpn_loss: 0.0655 (cls: 0.0222, box: 0.0433)
[2025-08-07 20:57:17 train.log] INFO: Epoch: [22]  [Step 14500/14540]  lr: 0.000014  loss: 1.01947  detection_loss: 0.7246 (cls: 0.2344, box: 0.4902)  rpn_loss: 0.2949 (cls: 0.0948, box: 0.2001)
[2025-08-07 21:00:41 train.log] INFO: Epoch: [23]  [Step 100/14540]  lr: 0.000011  loss: 0.67660  detection_loss: 0.6127 (cls: 0.1518, box: 0.4609)  rpn_loss: 0.0639 (cls: 0.0283, box: 0.0356)
[2025-08-07 21:00:47 train.log] INFO: Epoch: [23]  [Step 200/14540]  lr: 0.000011  loss: 0.50976  detection_loss: 0.4474 (cls: 0.1087, box: 0.3388)  rpn_loss: 0.0623 (cls: 0.0492, box: 0.0131)
[2025-08-07 21:00:52 train.log] INFO: Epoch: [23]  [Step 300/14540]  lr: 0.000011  loss: 0.68772  detection_loss: 0.5934 (cls: 0.1607, box: 0.4327)  rpn_loss: 0.0944 (cls: 0.0342, box: 0.0602)
[2025-08-07 21:00:58 train.log] INFO: Epoch: [23]  [Step 400/14540]  lr: 0.000011  loss: 1.11703  detection_loss: 0.8226 (cls: 0.2645, box: 0.5580)  rpn_loss: 0.2945 (cls: 0.0681, box: 0.2264)
[2025-08-07 21:01:04 train.log] INFO: Epoch: [23]  [Step 500/14540]  lr: 0.000011  loss: 0.82646  detection_loss: 0.7802 (cls: 0.1610, box: 0.6191)  rpn_loss: 0.0463 (cls: 0.0107, box: 0.0356)
[2025-08-07 21:01:10 train.log] INFO: Epoch: [23]  [Step 600/14540]  lr: 0.000011  loss: 0.84800  detection_loss: 0.8058 (cls: 0.1843, box: 0.6214)  rpn_loss: 0.0422 (cls: 0.0247, box: 0.0175)
[2025-08-07 21:01:15 train.log] INFO: Epoch: [23]  [Step 700/14540]  lr: 0.000011  loss: 0.66964  detection_loss: 0.6162 (cls: 0.1278, box: 0.4884)  rpn_loss: 0.0535 (cls: 0.0236, box: 0.0299)
[2025-08-07 21:01:21 train.log] INFO: Epoch: [23]  [Step 800/14540]  lr: 0.000011  loss: 0.71774  detection_loss: 0.6234 (cls: 0.1154, box: 0.5080)  rpn_loss: 0.0944 (cls: 0.0615, box: 0.0329)
[2025-08-07 21:01:26 train.log] INFO: Epoch: [23]  [Step 900/14540]  lr: 0.000011  loss: 0.55227  detection_loss: 0.3848 (cls: 0.1129, box: 0.2719)  rpn_loss: 0.1675 (cls: 0.0341, box: 0.1334)
[2025-08-07 21:01:32 train.log] INFO: Epoch: [23]  [Step 1000/14540]  lr: 0.000011  loss: 0.97121  detection_loss: 0.8856 (cls: 0.2308, box: 0.6548)  rpn_loss: 0.0856 (cls: 0.0446, box: 0.0410)
[2025-08-07 21:01:37 train.log] INFO: Epoch: [23]  [Step 1100/14540]  lr: 0.000011  loss: 0.56617  detection_loss: 0.5130 (cls: 0.1644, box: 0.3486)  rpn_loss: 0.0532 (cls: 0.0237, box: 0.0295)
[2025-08-07 21:01:43 train.log] INFO: Epoch: [23]  [Step 1200/14540]  lr: 0.000011  loss: 1.23376  detection_loss: 0.9914 (cls: 0.1430, box: 0.8484)  rpn_loss: 0.2424 (cls: 0.0256, box: 0.2168)
[2025-08-07 21:01:49 train.log] INFO: Epoch: [23]  [Step 1300/14540]  lr: 0.000011  loss: 0.86395  detection_loss: 0.8403 (cls: 0.1237, box: 0.7166)  rpn_loss: 0.0236 (cls: 0.0085, box: 0.0152)
[2025-08-07 21:01:54 train.log] INFO: Epoch: [23]  [Step 1400/14540]  lr: 0.000011  loss: 1.05351  detection_loss: 0.9820 (cls: 0.2084, box: 0.7736)  rpn_loss: 0.0715 (cls: 0.0351, box: 0.0364)
[2025-08-07 21:01:59 train.log] INFO: Epoch: [23]  [Step 1500/14540]  lr: 0.000011  loss: 1.00335  detection_loss: 0.9205 (cls: 0.1755, box: 0.7450)  rpn_loss: 0.0829 (cls: 0.0365, box: 0.0464)
[2025-08-07 21:02:05 train.log] INFO: Epoch: [23]  [Step 1600/14540]  lr: 0.000011  loss: 1.17389  detection_loss: 1.0821 (cls: 0.2767, box: 0.8054)  rpn_loss: 0.0918 (cls: 0.0393, box: 0.0524)
[2025-08-07 21:02:11 train.log] INFO: Epoch: [23]  [Step 1700/14540]  lr: 0.000011  loss: 0.61144  detection_loss: 0.5442 (cls: 0.1539, box: 0.3903)  rpn_loss: 0.0672 (cls: 0.0376, box: 0.0296)
[2025-08-07 21:02:16 train.log] INFO: Epoch: [23]  [Step 1800/14540]  lr: 0.000011  loss: 0.69318  detection_loss: 0.5189 (cls: 0.1802, box: 0.3387)  rpn_loss: 0.1743 (cls: 0.0394, box: 0.1349)
[2025-08-07 21:02:22 train.log] INFO: Epoch: [23]  [Step 1900/14540]  lr: 0.000011  loss: 1.07743  detection_loss: 0.9528 (cls: 0.1065, box: 0.8462)  rpn_loss: 0.1247 (cls: 0.0313, box: 0.0934)
[2025-08-07 21:02:28 train.log] INFO: Epoch: [23]  [Step 2000/14540]  lr: 0.000011  loss: 0.55711  detection_loss: 0.4625 (cls: 0.1423, box: 0.3201)  rpn_loss: 0.0946 (cls: 0.0284, box: 0.0662)
[2025-08-07 21:02:33 train.log] INFO: Epoch: [23]  [Step 2100/14540]  lr: 0.000011  loss: 1.04710  detection_loss: 0.8163 (cls: 0.2318, box: 0.5844)  rpn_loss: 0.2308 (cls: 0.0307, box: 0.2001)
[2025-08-07 21:02:39 train.log] INFO: Epoch: [23]  [Step 2200/14540]  lr: 0.000011  loss: 0.52722  detection_loss: 0.4496 (cls: 0.1197, box: 0.3299)  rpn_loss: 0.0776 (cls: 0.0520, box: 0.0256)
[2025-08-07 21:02:44 train.log] INFO: Epoch: [23]  [Step 2300/14540]  lr: 0.000011  loss: 0.55036  detection_loss: 0.5167 (cls: 0.1256, box: 0.3911)  rpn_loss: 0.0336 (cls: 0.0170, box: 0.0167)
[2025-08-07 21:02:50 train.log] INFO: Epoch: [23]  [Step 2400/14540]  lr: 0.000011  loss: 0.89684  detection_loss: 0.8099 (cls: 0.2551, box: 0.5548)  rpn_loss: 0.0870 (cls: 0.0573, box: 0.0296)
[2025-08-07 21:02:55 train.log] INFO: Epoch: [23]  [Step 2500/14540]  lr: 0.000011  loss: 0.94840  detection_loss: 0.8185 (cls: 0.1643, box: 0.6542)  rpn_loss: 0.1299 (cls: 0.0526, box: 0.0773)
[2025-08-07 21:03:01 train.log] INFO: Epoch: [23]  [Step 2600/14540]  lr: 0.000011  loss: 0.84056  detection_loss: 0.7527 (cls: 0.1757, box: 0.5770)  rpn_loss: 0.0879 (cls: 0.0635, box: 0.0244)
[2025-08-07 21:03:07 train.log] INFO: Epoch: [23]  [Step 2700/14540]  lr: 0.000011  loss: 0.58038  detection_loss: 0.5222 (cls: 0.1359, box: 0.3863)  rpn_loss: 0.0582 (cls: 0.0178, box: 0.0404)
[2025-08-07 21:03:12 train.log] INFO: Epoch: [23]  [Step 2800/14540]  lr: 0.000011  loss: 0.50055  detection_loss: 0.4119 (cls: 0.1021, box: 0.3098)  rpn_loss: 0.0887 (cls: 0.0222, box: 0.0664)
[2025-08-07 21:03:18 train.log] INFO: Epoch: [23]  [Step 2900/14540]  lr: 0.000011  loss: 0.58025  detection_loss: 0.5042 (cls: 0.1354, box: 0.3689)  rpn_loss: 0.0760 (cls: 0.0579, box: 0.0181)
[2025-08-07 21:03:23 train.log] INFO: Epoch: [23]  [Step 3000/14540]  lr: 0.000011  loss: 1.06110  detection_loss: 0.9500 (cls: 0.3498, box: 0.6002)  rpn_loss: 0.1112 (cls: 0.0760, box: 0.0352)
[2025-08-07 21:03:29 train.log] INFO: Epoch: [23]  [Step 3100/14540]  lr: 0.000011  loss: 1.44527  detection_loss: 1.3090 (cls: 0.2762, box: 1.0328)  rpn_loss: 0.1363 (cls: 0.0551, box: 0.0812)
[2025-08-07 21:03:35 train.log] INFO: Epoch: [23]  [Step 3200/14540]  lr: 0.000011  loss: 0.76058  detection_loss: 0.6780 (cls: 0.1415, box: 0.5365)  rpn_loss: 0.0826 (cls: 0.0239, box: 0.0587)
[2025-08-07 21:03:40 train.log] INFO: Epoch: [23]  [Step 3300/14540]  lr: 0.000011  loss: 0.79757  detection_loss: 0.7115 (cls: 0.2572, box: 0.4543)  rpn_loss: 0.0861 (cls: 0.0616, box: 0.0245)
[2025-08-07 21:03:46 train.log] INFO: Epoch: [23]  [Step 3400/14540]  lr: 0.000011  loss: 1.33947  detection_loss: 1.2181 (cls: 0.2961, box: 0.9221)  rpn_loss: 0.1213 (cls: 0.0404, box: 0.0809)
[2025-08-07 21:03:51 train.log] INFO: Epoch: [23]  [Step 3500/14540]  lr: 0.000011  loss: 1.03130  detection_loss: 0.8020 (cls: 0.1991, box: 0.6029)  rpn_loss: 0.2293 (cls: 0.0564, box: 0.1729)
[2025-08-07 21:03:57 train.log] INFO: Epoch: [23]  [Step 3600/14540]  lr: 0.000011  loss: 1.02059  detection_loss: 0.9119 (cls: 0.1810, box: 0.7310)  rpn_loss: 0.1087 (cls: 0.0227, box: 0.0860)
[2025-08-07 21:03:59 train.log] INFO: Epoch: [23]  [Step 3635/14540]  lr: 0.000011  loss: 0.66549  detection_loss: 0.5679 (cls: 0.2184, box: 0.3495)  rpn_loss: 0.0976 (cls: 0.0820, box: 0.0156)
[2025-08-07 21:04:02 train.log] INFO: Epoch: [23]  [Step 3700/14540]  lr: 0.000011  loss: 0.75771  detection_loss: 0.6451 (cls: 0.1720, box: 0.4731)  rpn_loss: 0.1126 (cls: 0.1025, box: 0.0101)
[2025-08-07 21:04:08 train.log] INFO: Epoch: [23]  [Step 3800/14540]  lr: 0.000011  loss: 0.73631  detection_loss: 0.6353 (cls: 0.1128, box: 0.5226)  rpn_loss: 0.1010 (cls: 0.0154, box: 0.0856)
[2025-08-07 21:04:13 train.log] INFO: Epoch: [23]  [Step 3900/14540]  lr: 0.000011  loss: 0.37643  detection_loss: 0.2941 (cls: 0.1043, box: 0.1898)  rpn_loss: 0.0824 (cls: 0.0443, box: 0.0381)
[2025-08-07 21:04:19 train.log] INFO: Epoch: [23]  [Step 4000/14540]  lr: 0.000011  loss: 0.97403  detection_loss: 0.8341 (cls: 0.2146, box: 0.6195)  rpn_loss: 0.1399 (cls: 0.0416, box: 0.0984)
[2025-08-07 21:04:25 train.log] INFO: Epoch: [23]  [Step 4100/14540]  lr: 0.000011  loss: 1.01400  detection_loss: 0.8788 (cls: 0.2910, box: 0.5878)  rpn_loss: 0.1352 (cls: 0.1063, box: 0.0289)
[2025-08-07 21:04:30 train.log] INFO: Epoch: [23]  [Step 4200/14540]  lr: 0.000011  loss: 0.68016  detection_loss: 0.5273 (cls: 0.1910, box: 0.3363)  rpn_loss: 0.1528 (cls: 0.0695, box: 0.0834)
[2025-08-07 21:04:36 train.log] INFO: Epoch: [23]  [Step 4300/14540]  lr: 0.000011  loss: 0.64446  detection_loss: 0.5730 (cls: 0.0908, box: 0.4821)  rpn_loss: 0.0715 (cls: 0.0163, box: 0.0552)
[2025-08-07 21:04:42 train.log] INFO: Epoch: [23]  [Step 4400/14540]  lr: 0.000011  loss: 1.17818  detection_loss: 1.1005 (cls: 0.1355, box: 0.9650)  rpn_loss: 0.0777 (cls: 0.0285, box: 0.0492)
[2025-08-07 21:04:47 train.log] INFO: Epoch: [23]  [Step 4500/14540]  lr: 0.000011  loss: 1.11221  detection_loss: 0.9994 (cls: 0.1804, box: 0.8190)  rpn_loss: 0.1128 (cls: 0.0558, box: 0.0570)
[2025-08-07 21:04:53 train.log] INFO: Epoch: [23]  [Step 4600/14540]  lr: 0.000011  loss: 0.90980  detection_loss: 0.7542 (cls: 0.1678, box: 0.5863)  rpn_loss: 0.1556 (cls: 0.1039, box: 0.0518)
[2025-08-07 21:04:58 train.log] INFO: Epoch: [23]  [Step 4700/14540]  lr: 0.000011  loss: 0.92259  detection_loss: 0.8363 (cls: 0.3185, box: 0.5177)  rpn_loss: 0.0863 (cls: 0.0693, box: 0.0170)
[2025-08-07 21:05:04 train.log] INFO: Epoch: [23]  [Step 4800/14540]  lr: 0.000011  loss: 0.69516  detection_loss: 0.4597 (cls: 0.1179, box: 0.3418)  rpn_loss: 0.2355 (cls: 0.1279, box: 0.1076)
[2025-08-07 21:05:09 train.log] INFO: Epoch: [23]  [Step 4900/14540]  lr: 0.000011  loss: 0.96508  detection_loss: 0.8919 (cls: 0.1775, box: 0.7144)  rpn_loss: 0.0732 (cls: 0.0354, box: 0.0378)
[2025-08-07 21:05:15 train.log] INFO: Epoch: [23]  [Step 5000/14540]  lr: 0.000011  loss: 0.69805  detection_loss: 0.6158 (cls: 0.1422, box: 0.4736)  rpn_loss: 0.0823 (cls: 0.0590, box: 0.0233)
[2025-08-07 21:05:20 train.log] INFO: Epoch: [23]  [Step 5100/14540]  lr: 0.000011  loss: 0.79037  detection_loss: 0.7036 (cls: 0.1641, box: 0.5395)  rpn_loss: 0.0868 (cls: 0.0190, box: 0.0678)
[2025-08-07 21:05:26 train.log] INFO: Epoch: [23]  [Step 5200/14540]  lr: 0.000011  loss: 0.81346  detection_loss: 0.7183 (cls: 0.1733, box: 0.5451)  rpn_loss: 0.0951 (cls: 0.0204, box: 0.0747)
[2025-08-07 21:05:31 train.log] INFO: Epoch: [23]  [Step 5300/14540]  lr: 0.000011  loss: 0.33604  detection_loss: 0.3004 (cls: 0.0785, box: 0.2219)  rpn_loss: 0.0356 (cls: 0.0130, box: 0.0227)
[2025-08-07 21:05:37 train.log] INFO: Epoch: [23]  [Step 5400/14540]  lr: 0.000011  loss: 0.94455  detection_loss: 0.8248 (cls: 0.2411, box: 0.5837)  rpn_loss: 0.1198 (cls: 0.0301, box: 0.0897)
[2025-08-07 21:05:42 train.log] INFO: Epoch: [23]  [Step 5500/14540]  lr: 0.000011  loss: 1.52906  detection_loss: 1.3019 (cls: 0.2280, box: 1.0739)  rpn_loss: 0.2271 (cls: 0.1228, box: 0.1043)
[2025-08-07 21:05:48 train.log] INFO: Epoch: [23]  [Step 5600/14540]  lr: 0.000011  loss: 0.36726  detection_loss: 0.3155 (cls: 0.0908, box: 0.2247)  rpn_loss: 0.0518 (cls: 0.0464, box: 0.0054)
[2025-08-07 21:05:53 train.log] INFO: Epoch: [23]  [Step 5700/14540]  lr: 0.000011  loss: 0.92160  detection_loss: 0.8214 (cls: 0.2583, box: 0.5631)  rpn_loss: 0.1002 (cls: 0.0311, box: 0.0691)
[2025-08-07 21:05:59 train.log] INFO: Epoch: [23]  [Step 5800/14540]  lr: 0.000011  loss: 0.63180  detection_loss: 0.5706 (cls: 0.1380, box: 0.4326)  rpn_loss: 0.0612 (cls: 0.0496, box: 0.0116)
[2025-08-07 21:06:04 train.log] INFO: Epoch: [23]  [Step 5900/14540]  lr: 0.000011  loss: 0.91030  detection_loss: 0.8402 (cls: 0.2299, box: 0.6103)  rpn_loss: 0.0701 (cls: 0.0332, box: 0.0369)
[2025-08-07 21:06:10 train.log] INFO: Epoch: [23]  [Step 6000/14540]  lr: 0.000011  loss: 0.78668  detection_loss: 0.6746 (cls: 0.1289, box: 0.5457)  rpn_loss: 0.1121 (cls: 0.0774, box: 0.0347)
[2025-08-07 21:06:16 train.log] INFO: Epoch: [23]  [Step 6100/14540]  lr: 0.000011  loss: 0.58524  detection_loss: 0.5206 (cls: 0.1233, box: 0.3973)  rpn_loss: 0.0646 (cls: 0.0389, box: 0.0258)
[2025-08-07 21:06:21 train.log] INFO: Epoch: [23]  [Step 6200/14540]  lr: 0.000011  loss: 0.88850  detection_loss: 0.8305 (cls: 0.1361, box: 0.6945)  rpn_loss: 0.0580 (cls: 0.0233, box: 0.0347)
[2025-08-07 21:06:27 train.log] INFO: Epoch: [23]  [Step 6300/14540]  lr: 0.000011  loss: 1.01442  detection_loss: 0.9671 (cls: 0.1953, box: 0.7718)  rpn_loss: 0.0473 (cls: 0.0256, box: 0.0217)
[2025-08-07 21:06:32 train.log] INFO: Epoch: [23]  [Step 6400/14540]  lr: 0.000011  loss: 0.83549  detection_loss: 0.7368 (cls: 0.1827, box: 0.5541)  rpn_loss: 0.0987 (cls: 0.0608, box: 0.0378)
[2025-08-07 21:06:38 train.log] INFO: Epoch: [23]  [Step 6500/14540]  lr: 0.000011  loss: 0.88164  detection_loss: 0.7904 (cls: 0.2637, box: 0.5267)  rpn_loss: 0.0912 (cls: 0.0368, box: 0.0544)
[2025-08-07 21:06:43 train.log] INFO: Epoch: [23]  [Step 6600/14540]  lr: 0.000011  loss: 1.10334  detection_loss: 0.9732 (cls: 0.3034, box: 0.6698)  rpn_loss: 0.1302 (cls: 0.1124, box: 0.0178)
[2025-08-07 21:06:49 train.log] INFO: Epoch: [23]  [Step 6700/14540]  lr: 0.000011  loss: 1.37929  detection_loss: 1.3020 (cls: 0.3376, box: 0.9644)  rpn_loss: 0.0773 (cls: 0.0407, box: 0.0366)
[2025-08-07 21:06:54 train.log] INFO: Epoch: [23]  [Step 6800/14540]  lr: 0.000011  loss: 0.84022  detection_loss: 0.7681 (cls: 0.2374, box: 0.5306)  rpn_loss: 0.0722 (cls: 0.0553, box: 0.0168)
[2025-08-07 21:07:00 train.log] INFO: Epoch: [23]  [Step 6900/14540]  lr: 0.000011  loss: 1.30147  detection_loss: 1.2114 (cls: 0.4161, box: 0.7953)  rpn_loss: 0.0901 (cls: 0.0354, box: 0.0547)
[2025-08-07 21:07:05 train.log] INFO: Epoch: [23]  [Step 7000/14540]  lr: 0.000011  loss: 0.80731  detection_loss: 0.6662 (cls: 0.2891, box: 0.3771)  rpn_loss: 0.1412 (cls: 0.1237, box: 0.0175)
[2025-08-07 21:07:11 train.log] INFO: Epoch: [23]  [Step 7100/14540]  lr: 0.000011  loss: 0.65081  detection_loss: 0.5935 (cls: 0.1689, box: 0.4246)  rpn_loss: 0.0573 (cls: 0.0397, box: 0.0176)
[2025-08-07 21:07:16 train.log] INFO: Epoch: [23]  [Step 7200/14540]  lr: 0.000011  loss: 0.76766  detection_loss: 0.6808 (cls: 0.1624, box: 0.5184)  rpn_loss: 0.0869 (cls: 0.0327, box: 0.0541)
[2025-08-07 21:07:22 train.log] INFO: Epoch: [23]  [Step 7300/14540]  lr: 0.000011  loss: 0.67316  detection_loss: 0.6133 (cls: 0.1455, box: 0.4678)  rpn_loss: 0.0598 (cls: 0.0383, box: 0.0216)
[2025-08-07 21:07:28 train.log] INFO: Epoch: [23]  [Step 7400/14540]  lr: 0.000011  loss: 0.76238  detection_loss: 0.6254 (cls: 0.1627, box: 0.4627)  rpn_loss: 0.1370 (cls: 0.0993, box: 0.0377)
[2025-08-07 21:07:33 train.log] INFO: Epoch: [23]  [Step 7500/14540]  lr: 0.000011  loss: 0.96119  detection_loss: 0.8288 (cls: 0.1487, box: 0.6801)  rpn_loss: 0.1324 (cls: 0.0284, box: 0.1040)
[2025-08-07 21:07:38 train.log] INFO: Epoch: [23]  [Step 7600/14540]  lr: 0.000011  loss: 0.67212  detection_loss: 0.6159 (cls: 0.1450, box: 0.4709)  rpn_loss: 0.0563 (cls: 0.0182, box: 0.0381)
[2025-08-07 21:07:44 train.log] INFO: Epoch: [23]  [Step 7700/14540]  lr: 0.000011  loss: 1.35680  detection_loss: 1.1523 (cls: 0.2392, box: 0.9131)  rpn_loss: 0.2045 (cls: 0.1643, box: 0.0402)
[2025-08-07 21:07:50 train.log] INFO: Epoch: [23]  [Step 7800/14540]  lr: 0.000011  loss: 1.10299  detection_loss: 0.8885 (cls: 0.2106, box: 0.6778)  rpn_loss: 0.2145 (cls: 0.1796, box: 0.0349)
[2025-08-07 21:07:55 train.log] INFO: Epoch: [23]  [Step 7900/14540]  lr: 0.000011  loss: 0.37267  detection_loss: 0.3155 (cls: 0.1049, box: 0.2106)  rpn_loss: 0.0572 (cls: 0.0246, box: 0.0325)
[2025-08-07 21:08:01 train.log] INFO: Epoch: [23]  [Step 8000/14540]  lr: 0.000011  loss: 0.60297  detection_loss: 0.5435 (cls: 0.1283, box: 0.4151)  rpn_loss: 0.0595 (cls: 0.0252, box: 0.0343)
[2025-08-07 21:08:07 train.log] INFO: Epoch: [23]  [Step 8100/14540]  lr: 0.000011  loss: 0.98610  detection_loss: 0.9382 (cls: 0.1163, box: 0.8219)  rpn_loss: 0.0479 (cls: 0.0308, box: 0.0171)
[2025-08-07 21:08:12 train.log] INFO: Epoch: [23]  [Step 8200/14540]  lr: 0.000011  loss: 0.82397  detection_loss: 0.7109 (cls: 0.1577, box: 0.5532)  rpn_loss: 0.1131 (cls: 0.0378, box: 0.0753)
[2025-08-07 21:08:18 train.log] INFO: Epoch: [23]  [Step 8300/14540]  lr: 0.000011  loss: 0.71693  detection_loss: 0.6378 (cls: 0.2140, box: 0.4238)  rpn_loss: 0.0791 (cls: 0.0662, box: 0.0129)
[2025-08-07 21:08:24 train.log] INFO: Epoch: [23]  [Step 8400/14540]  lr: 0.000011  loss: 1.13563  detection_loss: 0.9353 (cls: 0.2207, box: 0.7146)  rpn_loss: 0.2003 (cls: 0.1710, box: 0.0293)
[2025-08-07 21:08:29 train.log] INFO: Epoch: [23]  [Step 8500/14540]  lr: 0.000011  loss: 0.57626  detection_loss: 0.5078 (cls: 0.2336, box: 0.2742)  rpn_loss: 0.0685 (cls: 0.0337, box: 0.0348)
[2025-08-07 21:08:35 train.log] INFO: Epoch: [23]  [Step 8600/14540]  lr: 0.000011  loss: 1.35586  detection_loss: 1.1672 (cls: 0.2907, box: 0.8765)  rpn_loss: 0.1887 (cls: 0.1727, box: 0.0160)
[2025-08-07 21:08:40 train.log] INFO: Epoch: [23]  [Step 8700/14540]  lr: 0.000011  loss: 1.08072  detection_loss: 0.9980 (cls: 0.2369, box: 0.7611)  rpn_loss: 0.0827 (cls: 0.0371, box: 0.0456)
[2025-08-07 21:08:45 train.log] INFO: Epoch: [23]  [Step 8800/14540]  lr: 0.000011  loss: 1.27934  detection_loss: 1.1250 (cls: 0.3456, box: 0.7794)  rpn_loss: 0.1543 (cls: 0.0334, box: 0.1209)
[2025-08-07 21:08:51 train.log] INFO: Epoch: [23]  [Step 8900/14540]  lr: 0.000011  loss: 0.72039  detection_loss: 0.6012 (cls: 0.2004, box: 0.4008)  rpn_loss: 0.1192 (cls: 0.0760, box: 0.0432)
[2025-08-07 21:08:56 train.log] INFO: Epoch: [23]  [Step 9000/14540]  lr: 0.000011  loss: 0.65863  detection_loss: 0.6103 (cls: 0.1358, box: 0.4746)  rpn_loss: 0.0483 (cls: 0.0324, box: 0.0159)
[2025-08-07 21:09:02 train.log] INFO: Epoch: [23]  [Step 9100/14540]  lr: 0.000011  loss: 0.55964  detection_loss: 0.4738 (cls: 0.1160, box: 0.3577)  rpn_loss: 0.0859 (cls: 0.0631, box: 0.0228)
[2025-08-07 21:09:07 train.log] INFO: Epoch: [23]  [Step 9200/14540]  lr: 0.000011  loss: 1.14082  detection_loss: 1.0162 (cls: 0.3244, box: 0.6918)  rpn_loss: 0.1246 (cls: 0.0233, box: 0.1013)
[2025-08-07 21:09:13 train.log] INFO: Epoch: [23]  [Step 9300/14540]  lr: 0.000011  loss: 0.55359  detection_loss: 0.4938 (cls: 0.1394, box: 0.3544)  rpn_loss: 0.0598 (cls: 0.0356, box: 0.0242)
[2025-08-07 21:09:18 train.log] INFO: Epoch: [23]  [Step 9400/14540]  lr: 0.000011  loss: 0.98925  detection_loss: 0.4792 (cls: 0.1555, box: 0.3237)  rpn_loss: 0.5100 (cls: 0.0457, box: 0.4643)
[2025-08-07 21:09:24 train.log] INFO: Epoch: [23]  [Step 9500/14540]  lr: 0.000011  loss: 1.80022  detection_loss: 1.6196 (cls: 0.5341, box: 1.0855)  rpn_loss: 0.1806 (cls: 0.1160, box: 0.0646)
[2025-08-07 21:09:29 train.log] INFO: Epoch: [23]  [Step 9600/14540]  lr: 0.000011  loss: 1.15052  detection_loss: 1.1006 (cls: 0.4118, box: 0.6888)  rpn_loss: 0.0499 (cls: 0.0258, box: 0.0242)
[2025-08-07 21:09:34 train.log] INFO: Epoch: [23]  [Step 9700/14540]  lr: 0.000011  loss: 1.43089  detection_loss: 1.3352 (cls: 0.3297, box: 1.0055)  rpn_loss: 0.0957 (cls: 0.0667, box: 0.0290)
[2025-08-07 21:09:40 train.log] INFO: Epoch: [23]  [Step 9800/14540]  lr: 0.000011  loss: 0.66396  detection_loss: 0.5960 (cls: 0.1593, box: 0.4367)  rpn_loss: 0.0679 (cls: 0.0434, box: 0.0245)
[2025-08-07 21:09:45 train.log] INFO: Epoch: [23]  [Step 9900/14540]  lr: 0.000011  loss: 0.85190  detection_loss: 0.7051 (cls: 0.1585, box: 0.5466)  rpn_loss: 0.1468 (cls: 0.0218, box: 0.1250)
[2025-08-07 21:09:50 train.log] INFO: Epoch: [23]  [Step 10000/14540]  lr: 0.000011  loss: 0.71391  detection_loss: 0.5622 (cls: 0.1555, box: 0.4066)  rpn_loss: 0.1517 (cls: 0.1134, box: 0.0383)
[2025-08-07 21:09:56 train.log] INFO: Epoch: [23]  [Step 10100/14540]  lr: 0.000011  loss: 0.74990  detection_loss: 0.6818 (cls: 0.1675, box: 0.5144)  rpn_loss: 0.0681 (cls: 0.0489, box: 0.0192)
[2025-08-07 21:10:01 train.log] INFO: Epoch: [23]  [Step 10200/14540]  lr: 0.000011  loss: 0.96898  detection_loss: 0.8867 (cls: 0.2923, box: 0.5944)  rpn_loss: 0.0823 (cls: 0.0531, box: 0.0292)
[2025-08-07 21:10:07 train.log] INFO: Epoch: [23]  [Step 10300/14540]  lr: 0.000011  loss: 1.29041  detection_loss: 1.1717 (cls: 0.2320, box: 0.9397)  rpn_loss: 0.1187 (cls: 0.0924, box: 0.0264)
[2025-08-07 21:10:12 train.log] INFO: Epoch: [23]  [Step 10400/14540]  lr: 0.000011  loss: 0.55438  detection_loss: 0.4729 (cls: 0.1591, box: 0.3138)  rpn_loss: 0.0815 (cls: 0.0452, box: 0.0363)
[2025-08-07 21:10:18 train.log] INFO: Epoch: [23]  [Step 10500/14540]  lr: 0.000011  loss: 0.67460  detection_loss: 0.6357 (cls: 0.1432, box: 0.4925)  rpn_loss: 0.0389 (cls: 0.0213, box: 0.0177)
[2025-08-07 21:10:23 train.log] INFO: Epoch: [23]  [Step 10600/14540]  lr: 0.000011  loss: 0.73401  detection_loss: 0.6132 (cls: 0.1273, box: 0.4860)  rpn_loss: 0.1208 (cls: 0.0182, box: 0.1026)
[2025-08-07 21:10:29 train.log] INFO: Epoch: [23]  [Step 10700/14540]  lr: 0.000011  loss: 0.54127  detection_loss: 0.4581 (cls: 0.0917, box: 0.3665)  rpn_loss: 0.0832 (cls: 0.0303, box: 0.0529)
[2025-08-07 21:10:35 train.log] INFO: Epoch: [23]  [Step 10800/14540]  lr: 0.000011  loss: 0.68090  detection_loss: 0.5674 (cls: 0.1765, box: 0.3909)  rpn_loss: 0.1135 (cls: 0.0499, box: 0.0636)
[2025-08-07 21:10:40 train.log] INFO: Epoch: [23]  [Step 10900/14540]  lr: 0.000011  loss: 0.72537  detection_loss: 0.6528 (cls: 0.1677, box: 0.4851)  rpn_loss: 0.0726 (cls: 0.0199, box: 0.0526)
[2025-08-07 21:10:46 train.log] INFO: Epoch: [23]  [Step 11000/14540]  lr: 0.000011  loss: 1.06405  detection_loss: 0.9672 (cls: 0.1206, box: 0.8466)  rpn_loss: 0.0968 (cls: 0.0500, box: 0.0468)
[2025-08-07 21:10:51 train.log] INFO: Epoch: [23]  [Step 11100/14540]  lr: 0.000011  loss: 1.15729  detection_loss: 0.9418 (cls: 0.3017, box: 0.6400)  rpn_loss: 0.2155 (cls: 0.0984, box: 0.1171)
[2025-08-07 21:10:56 train.log] INFO: Epoch: [23]  [Step 11200/14540]  lr: 0.000011  loss: 0.82290  detection_loss: 0.6918 (cls: 0.1676, box: 0.5242)  rpn_loss: 0.1311 (cls: 0.0875, box: 0.0436)
[2025-08-07 21:11:02 train.log] INFO: Epoch: [23]  [Step 11300/14540]  lr: 0.000011  loss: 0.72111  detection_loss: 0.6336 (cls: 0.2271, box: 0.4066)  rpn_loss: 0.0875 (cls: 0.0610, box: 0.0265)
[2025-08-07 21:11:07 train.log] INFO: Epoch: [23]  [Step 11400/14540]  lr: 0.000011  loss: 0.51319  detection_loss: 0.4462 (cls: 0.1351, box: 0.3111)  rpn_loss: 0.0670 (cls: 0.0402, box: 0.0268)
[2025-08-07 21:11:13 train.log] INFO: Epoch: [23]  [Step 11500/14540]  lr: 0.000011  loss: 0.72854  detection_loss: 0.6316 (cls: 0.2253, box: 0.4063)  rpn_loss: 0.0970 (cls: 0.0363, box: 0.0607)
[2025-08-07 21:11:18 train.log] INFO: Epoch: [23]  [Step 11600/14540]  lr: 0.000011  loss: 0.94412  detection_loss: 0.8732 (cls: 0.2141, box: 0.6591)  rpn_loss: 0.0710 (cls: 0.0388, box: 0.0322)
[2025-08-07 21:11:24 train.log] INFO: Epoch: [23]  [Step 11700/14540]  lr: 0.000011  loss: 1.04995  detection_loss: 0.9112 (cls: 0.2584, box: 0.6528)  rpn_loss: 0.1388 (cls: 0.1164, box: 0.0224)
[2025-08-07 21:11:29 train.log] INFO: Epoch: [23]  [Step 11800/14540]  lr: 0.000011  loss: 0.61598  detection_loss: 0.5034 (cls: 0.1330, box: 0.3704)  rpn_loss: 0.1126 (cls: 0.0335, box: 0.0791)
[2025-08-07 21:11:35 train.log] INFO: Epoch: [23]  [Step 11900/14540]  lr: 0.000011  loss: 1.26524  detection_loss: 1.0554 (cls: 0.1925, box: 0.8629)  rpn_loss: 0.2098 (cls: 0.1517, box: 0.0581)
[2025-08-07 21:11:40 train.log] INFO: Epoch: [23]  [Step 12000/14540]  lr: 0.000011  loss: 1.02638  detection_loss: 0.9159 (cls: 0.2169, box: 0.6990)  rpn_loss: 0.1104 (cls: 0.0400, box: 0.0704)
[2025-08-07 21:11:46 train.log] INFO: Epoch: [23]  [Step 12100/14540]  lr: 0.000011  loss: 1.10036  detection_loss: 0.9971 (cls: 0.4113, box: 0.5859)  rpn_loss: 0.1032 (cls: 0.0497, box: 0.0535)
[2025-08-07 21:11:51 train.log] INFO: Epoch: [23]  [Step 12200/14540]  lr: 0.000011  loss: 0.57245  detection_loss: 0.4889 (cls: 0.1039, box: 0.3850)  rpn_loss: 0.0835 (cls: 0.0239, box: 0.0596)
[2025-08-07 21:11:57 train.log] INFO: Epoch: [23]  [Step 12300/14540]  lr: 0.000011  loss: 0.88495  detection_loss: 0.7527 (cls: 0.3110, box: 0.4418)  rpn_loss: 0.1322 (cls: 0.0226, box: 0.1096)
[2025-08-07 21:12:02 train.log] INFO: Epoch: [23]  [Step 12400/14540]  lr: 0.000011  loss: 0.66928  detection_loss: 0.6077 (cls: 0.1327, box: 0.4750)  rpn_loss: 0.0615 (cls: 0.0443, box: 0.0173)
[2025-08-07 21:12:07 train.log] INFO: Epoch: [23]  [Step 12500/14540]  lr: 0.000011  loss: 0.69790  detection_loss: 0.6283 (cls: 0.1164, box: 0.5119)  rpn_loss: 0.0696 (cls: 0.0332, box: 0.0364)
[2025-08-07 21:12:13 train.log] INFO: Epoch: [23]  [Step 12600/14540]  lr: 0.000011  loss: 0.89321  detection_loss: 0.7769 (cls: 0.2170, box: 0.5599)  rpn_loss: 0.1163 (cls: 0.0938, box: 0.0225)
[2025-08-07 21:12:18 train.log] INFO: Epoch: [23]  [Step 12700/14540]  lr: 0.000011  loss: 0.70145  detection_loss: 0.6560 (cls: 0.1725, box: 0.4836)  rpn_loss: 0.0454 (cls: 0.0281, box: 0.0173)
[2025-08-07 21:12:24 train.log] INFO: Epoch: [23]  [Step 12800/14540]  lr: 0.000011  loss: 1.30095  detection_loss: 1.1510 (cls: 0.3794, box: 0.7716)  rpn_loss: 0.1500 (cls: 0.0797, box: 0.0703)
[2025-08-07 21:12:29 train.log] INFO: Epoch: [23]  [Step 12900/14540]  lr: 0.000011  loss: 1.00297  detection_loss: 0.8972 (cls: 0.3226, box: 0.5746)  rpn_loss: 0.1058 (cls: 0.0828, box: 0.0230)
[2025-08-07 21:12:34 train.log] INFO: Epoch: [23]  [Step 13000/14540]  lr: 0.000011  loss: 0.86189  detection_loss: 0.7198 (cls: 0.2953, box: 0.4245)  rpn_loss: 0.1421 (cls: 0.0969, box: 0.0452)
[2025-08-07 21:12:40 train.log] INFO: Epoch: [23]  [Step 13100/14540]  lr: 0.000011  loss: 1.54601  detection_loss: 1.4107 (cls: 0.3350, box: 1.0757)  rpn_loss: 0.1353 (cls: 0.0876, box: 0.0477)
[2025-08-07 21:12:45 train.log] INFO: Epoch: [23]  [Step 13200/14540]  lr: 0.000011  loss: 1.13967  detection_loss: 1.0496 (cls: 0.2323, box: 0.8173)  rpn_loss: 0.0901 (cls: 0.0426, box: 0.0475)
[2025-08-07 21:12:51 train.log] INFO: Epoch: [23]  [Step 13300/14540]  lr: 0.000011  loss: 0.46542  detection_loss: 0.3432 (cls: 0.0883, box: 0.2549)  rpn_loss: 0.1223 (cls: 0.0167, box: 0.1055)
[2025-08-07 21:12:56 train.log] INFO: Epoch: [23]  [Step 13400/14540]  lr: 0.000011  loss: 0.84159  detection_loss: 0.7446 (cls: 0.1442, box: 0.6004)  rpn_loss: 0.0970 (cls: 0.0080, box: 0.0890)
[2025-08-07 21:13:02 train.log] INFO: Epoch: [23]  [Step 13500/14540]  lr: 0.000011  loss: 0.61362  detection_loss: 0.5062 (cls: 0.1762, box: 0.3300)  rpn_loss: 0.1074 (cls: 0.0855, box: 0.0219)
[2025-08-07 21:13:07 train.log] INFO: Epoch: [23]  [Step 13600/14540]  lr: 0.000011  loss: 0.86822  detection_loss: 0.6848 (cls: 0.2259, box: 0.4589)  rpn_loss: 0.1834 (cls: 0.0366, box: 0.1468)
[2025-08-07 21:13:13 train.log] INFO: Epoch: [23]  [Step 13700/14540]  lr: 0.000011  loss: 0.79614  detection_loss: 0.7041 (cls: 0.1330, box: 0.5711)  rpn_loss: 0.0920 (cls: 0.0447, box: 0.0473)
[2025-08-07 21:13:18 train.log] INFO: Epoch: [23]  [Step 13800/14540]  lr: 0.000011  loss: 0.90037  detection_loss: 0.8070 (cls: 0.1837, box: 0.6233)  rpn_loss: 0.0933 (cls: 0.0607, box: 0.0326)
[2025-08-07 21:13:24 train.log] INFO: Epoch: [23]  [Step 13900/14540]  lr: 0.000011  loss: 0.69532  detection_loss: 0.5955 (cls: 0.1410, box: 0.4545)  rpn_loss: 0.0998 (cls: 0.0426, box: 0.0572)
[2025-08-07 21:13:29 train.log] INFO: Epoch: [23]  [Step 14000/14540]  lr: 0.000011  loss: 0.53603  detection_loss: 0.4681 (cls: 0.0781, box: 0.3901)  rpn_loss: 0.0679 (cls: 0.0180, box: 0.0499)
[2025-08-07 21:13:35 train.log] INFO: Epoch: [23]  [Step 14100/14540]  lr: 0.000011  loss: 0.54642  detection_loss: 0.5112 (cls: 0.1740, box: 0.3372)  rpn_loss: 0.0352 (cls: 0.0216, box: 0.0136)
[2025-08-07 21:13:40 train.log] INFO: Epoch: [23]  [Step 14200/14540]  lr: 0.000011  loss: 0.77510  detection_loss: 0.7199 (cls: 0.1602, box: 0.5597)  rpn_loss: 0.0552 (cls: 0.0129, box: 0.0423)
[2025-08-07 21:13:45 train.log] INFO: Epoch: [23]  [Step 14300/14540]  lr: 0.000011  loss: 1.24894  detection_loss: 1.1357 (cls: 0.2870, box: 0.8487)  rpn_loss: 0.1132 (cls: 0.0404, box: 0.0728)
[2025-08-07 21:13:51 train.log] INFO: Epoch: [23]  [Step 14400/14540]  lr: 0.000011  loss: 1.47764  detection_loss: 1.3959 (cls: 0.2933, box: 1.1025)  rpn_loss: 0.0818 (cls: 0.0424, box: 0.0394)
[2025-08-07 21:13:56 train.log] INFO: Epoch: [23]  [Step 14500/14540]  lr: 0.000011  loss: 0.85415  detection_loss: 0.8110 (cls: 0.1499, box: 0.6611)  rpn_loss: 0.0432 (cls: 0.0190, box: 0.0242)
[2025-08-07 21:17:15 train.log] INFO: Epoch: [24]  [Step 100/14540]  lr: 0.000008  loss: 0.88279  detection_loss: 0.7596 (cls: 0.1721, box: 0.5875)  rpn_loss: 0.1232 (cls: 0.0511, box: 0.0721)
[2025-08-07 21:17:21 train.log] INFO: Epoch: [24]  [Step 200/14540]  lr: 0.000008  loss: 0.50107  detection_loss: 0.4500 (cls: 0.1362, box: 0.3138)  rpn_loss: 0.0510 (cls: 0.0273, box: 0.0238)
[2025-08-07 21:17:27 train.log] INFO: Epoch: [24]  [Step 300/14540]  lr: 0.000008  loss: 1.08000  detection_loss: 0.9947 (cls: 0.2538, box: 0.7409)  rpn_loss: 0.0853 (cls: 0.0566, box: 0.0287)
[2025-08-07 21:17:32 train.log] INFO: Epoch: [24]  [Step 400/14540]  lr: 0.000008  loss: 0.47212  detection_loss: 0.4150 (cls: 0.0884, box: 0.3266)  rpn_loss: 0.0571 (cls: 0.0353, box: 0.0218)
[2025-08-07 21:17:38 train.log] INFO: Epoch: [24]  [Step 500/14540]  lr: 0.000008  loss: 1.00815  detection_loss: 0.8169 (cls: 0.2019, box: 0.6150)  rpn_loss: 0.1913 (cls: 0.0420, box: 0.1493)
[2025-08-07 21:17:43 train.log] INFO: Epoch: [24]  [Step 600/14540]  lr: 0.000008  loss: 1.01580  detection_loss: 0.8684 (cls: 0.2518, box: 0.6166)  rpn_loss: 0.1474 (cls: 0.1232, box: 0.0243)
[2025-08-07 21:17:49 train.log] INFO: Epoch: [24]  [Step 700/14540]  lr: 0.000008  loss: 1.29358  detection_loss: 1.1346 (cls: 0.2505, box: 0.8840)  rpn_loss: 0.1590 (cls: 0.0528, box: 0.1062)
[2025-08-07 21:17:54 train.log] INFO: Epoch: [24]  [Step 800/14540]  lr: 0.000008  loss: 0.37012  detection_loss: 0.3302 (cls: 0.0935, box: 0.2366)  rpn_loss: 0.0399 (cls: 0.0154, box: 0.0245)
[2025-08-07 21:18:00 train.log] INFO: Epoch: [24]  [Step 900/14540]  lr: 0.000008  loss: 1.06150  detection_loss: 0.9547 (cls: 0.1896, box: 0.7651)  rpn_loss: 0.1068 (cls: 0.0793, box: 0.0275)
[2025-08-07 21:18:06 train.log] INFO: Epoch: [24]  [Step 1000/14540]  lr: 0.000008  loss: 1.25255  detection_loss: 1.1509 (cls: 0.2932, box: 0.8577)  rpn_loss: 0.1016 (cls: 0.0686, box: 0.0331)
[2025-08-07 21:18:12 train.log] INFO: Epoch: [24]  [Step 1100/14540]  lr: 0.000008  loss: 0.98766  detection_loss: 0.8582 (cls: 0.2534, box: 0.6048)  rpn_loss: 0.1295 (cls: 0.0399, box: 0.0896)
[2025-08-07 21:18:17 train.log] INFO: Epoch: [24]  [Step 1200/14540]  lr: 0.000008  loss: 0.90879  detection_loss: 0.8408 (cls: 0.2319, box: 0.6089)  rpn_loss: 0.0680 (cls: 0.0358, box: 0.0322)
[2025-08-07 21:18:23 train.log] INFO: Epoch: [24]  [Step 1300/14540]  lr: 0.000008  loss: 1.21438  detection_loss: 1.0621 (cls: 0.2615, box: 0.8006)  rpn_loss: 0.1523 (cls: 0.0764, box: 0.0758)
[2025-08-07 21:18:29 train.log] INFO: Epoch: [24]  [Step 1400/14540]  lr: 0.000008  loss: 0.72814  detection_loss: 0.6180 (cls: 0.1964, box: 0.4217)  rpn_loss: 0.1101 (cls: 0.0929, box: 0.0173)
[2025-08-07 21:18:34 train.log] INFO: Epoch: [24]  [Step 1500/14540]  lr: 0.000008  loss: 1.08075  detection_loss: 0.9751 (cls: 0.2226, box: 0.7524)  rpn_loss: 0.1057 (cls: 0.0661, box: 0.0396)
[2025-08-07 21:18:40 train.log] INFO: Epoch: [24]  [Step 1600/14540]  lr: 0.000008  loss: 0.94556  detection_loss: 0.8711 (cls: 0.1727, box: 0.6984)  rpn_loss: 0.0745 (cls: 0.0351, box: 0.0393)
[2025-08-07 21:18:45 train.log] INFO: Epoch: [24]  [Step 1700/14540]  lr: 0.000008  loss: 0.79339  detection_loss: 0.6452 (cls: 0.2247, box: 0.4205)  rpn_loss: 0.1482 (cls: 0.0629, box: 0.0853)
[2025-08-07 21:18:51 train.log] INFO: Epoch: [24]  [Step 1800/14540]  lr: 0.000008  loss: 0.74409  detection_loss: 0.6409 (cls: 0.3084, box: 0.3326)  rpn_loss: 0.1031 (cls: 0.0381, box: 0.0651)
[2025-08-07 21:18:57 train.log] INFO: Epoch: [24]  [Step 1900/14540]  lr: 0.000008  loss: 0.74782  detection_loss: 0.6592 (cls: 0.1669, box: 0.4923)  rpn_loss: 0.0886 (cls: 0.0362, box: 0.0524)
[2025-08-07 21:19:02 train.log] INFO: Epoch: [24]  [Step 2000/14540]  lr: 0.000008  loss: 0.61548  detection_loss: 0.5392 (cls: 0.1393, box: 0.3998)  rpn_loss: 0.0763 (cls: 0.0159, box: 0.0604)
[2025-08-07 21:19:08 train.log] INFO: Epoch: [24]  [Step 2100/14540]  lr: 0.000008  loss: 0.75986  detection_loss: 0.6456 (cls: 0.1427, box: 0.5028)  rpn_loss: 0.1143 (cls: 0.0708, box: 0.0435)
[2025-08-07 21:19:14 train.log] INFO: Epoch: [24]  [Step 2200/14540]  lr: 0.000008  loss: 1.48634  detection_loss: 1.2839 (cls: 0.3679, box: 0.9160)  rpn_loss: 0.2024 (cls: 0.1594, box: 0.0430)
[2025-08-07 21:19:19 train.log] INFO: Epoch: [24]  [Step 2300/14540]  lr: 0.000008  loss: 0.66607  detection_loss: 0.5247 (cls: 0.1184, box: 0.4063)  rpn_loss: 0.1414 (cls: 0.0968, box: 0.0446)
[2025-08-07 21:19:25 train.log] INFO: Epoch: [24]  [Step 2400/14540]  lr: 0.000008  loss: 1.12724  detection_loss: 1.0239 (cls: 0.3359, box: 0.6880)  rpn_loss: 0.1033 (cls: 0.0742, box: 0.0291)
[2025-08-07 21:19:31 train.log] INFO: Epoch: [24]  [Step 2500/14540]  lr: 0.000008  loss: 0.90649  detection_loss: 0.7799 (cls: 0.1394, box: 0.6405)  rpn_loss: 0.1266 (cls: 0.0328, box: 0.0939)
[2025-08-07 21:19:36 train.log] INFO: Epoch: [24]  [Step 2600/14540]  lr: 0.000008  loss: 0.54859  detection_loss: 0.4787 (cls: 0.1160, box: 0.3627)  rpn_loss: 0.0699 (cls: 0.0425, box: 0.0274)
[2025-08-07 21:19:42 train.log] INFO: Epoch: [24]  [Step 2700/14540]  lr: 0.000008  loss: 0.59162  detection_loss: 0.5408 (cls: 0.1049, box: 0.4359)  rpn_loss: 0.0509 (cls: 0.0367, box: 0.0141)
[2025-08-07 21:19:48 train.log] INFO: Epoch: [24]  [Step 2800/14540]  lr: 0.000008  loss: 0.57329  detection_loss: 0.5254 (cls: 0.1111, box: 0.4143)  rpn_loss: 0.0479 (cls: 0.0240, box: 0.0239)
[2025-08-07 21:19:53 train.log] INFO: Epoch: [24]  [Step 2900/14540]  lr: 0.000008  loss: 0.92432  detection_loss: 0.8697 (cls: 0.1995, box: 0.6703)  rpn_loss: 0.0546 (cls: 0.0373, box: 0.0173)
[2025-08-07 21:19:59 train.log] INFO: Epoch: [24]  [Step 3000/14540]  lr: 0.000008  loss: 1.00288  detection_loss: 0.8925 (cls: 0.2815, box: 0.6110)  rpn_loss: 0.1104 (cls: 0.0689, box: 0.0415)
[2025-08-07 21:20:04 train.log] INFO: Epoch: [24]  [Step 3100/14540]  lr: 0.000008  loss: 1.13290  detection_loss: 1.0094 (cls: 0.2560, box: 0.7534)  rpn_loss: 0.1235 (cls: 0.0508, box: 0.0727)
[2025-08-07 21:20:10 train.log] INFO: Epoch: [24]  [Step 3200/14540]  lr: 0.000008  loss: 0.50666  detection_loss: 0.4669 (cls: 0.1047, box: 0.3622)  rpn_loss: 0.0398 (cls: 0.0220, box: 0.0178)
[2025-08-07 21:20:15 train.log] INFO: Epoch: [24]  [Step 3300/14540]  lr: 0.000008  loss: 1.18770  detection_loss: 1.0734 (cls: 0.2043, box: 0.8691)  rpn_loss: 0.1143 (cls: 0.0510, box: 0.0633)
[2025-08-07 21:20:21 train.log] INFO: Epoch: [24]  [Step 3400/14540]  lr: 0.000008  loss: 1.18175  detection_loss: 1.0983 (cls: 0.4064, box: 0.6919)  rpn_loss: 0.0834 (cls: 0.0490, box: 0.0344)
[2025-08-07 21:20:27 train.log] INFO: Epoch: [24]  [Step 3500/14540]  lr: 0.000008  loss: 0.88409  detection_loss: 0.7943 (cls: 0.2095, box: 0.5848)  rpn_loss: 0.0898 (cls: 0.0529, box: 0.0369)
[2025-08-07 21:20:32 train.log] INFO: Epoch: [24]  [Step 3600/14540]  lr: 0.000008  loss: 0.86802  detection_loss: 0.7747 (cls: 0.1440, box: 0.6307)  rpn_loss: 0.0934 (cls: 0.0360, box: 0.0573)
[2025-08-07 21:20:34 train.log] INFO: Epoch: [24]  [Step 3635/14540]  lr: 0.000008  loss: 1.32716  detection_loss: 1.2132 (cls: 0.3515, box: 0.8617)  rpn_loss: 0.1140 (cls: 0.0827, box: 0.0313)
[2025-08-07 21:20:38 train.log] INFO: Epoch: [24]  [Step 3700/14540]  lr: 0.000008  loss: 0.77858  detection_loss: 0.6513 (cls: 0.1809, box: 0.4704)  rpn_loss: 0.1273 (cls: 0.0434, box: 0.0839)
[2025-08-07 21:20:43 train.log] INFO: Epoch: [24]  [Step 3800/14540]  lr: 0.000008  loss: 0.62524  detection_loss: 0.5316 (cls: 0.1921, box: 0.3395)  rpn_loss: 0.0936 (cls: 0.0694, box: 0.0242)
[2025-08-07 21:20:49 train.log] INFO: Epoch: [24]  [Step 3900/14540]  lr: 0.000008  loss: 1.02003  detection_loss: 0.9375 (cls: 0.1749, box: 0.7626)  rpn_loss: 0.0825 (cls: 0.0366, box: 0.0459)
[2025-08-07 21:20:54 train.log] INFO: Epoch: [24]  [Step 4000/14540]  lr: 0.000008  loss: 1.00747  detection_loss: 0.9476 (cls: 0.1681, box: 0.7796)  rpn_loss: 0.0598 (cls: 0.0371, box: 0.0228)
[2025-08-07 21:21:00 train.log] INFO: Epoch: [24]  [Step 4100/14540]  lr: 0.000008  loss: 0.64598  detection_loss: 0.5835 (cls: 0.2148, box: 0.3686)  rpn_loss: 0.0625 (cls: 0.0233, box: 0.0392)
[2025-08-07 21:21:06 train.log] INFO: Epoch: [24]  [Step 4200/14540]  lr: 0.000008  loss: 0.61254  detection_loss: 0.5270 (cls: 0.0924, box: 0.4345)  rpn_loss: 0.0856 (cls: 0.0391, box: 0.0465)
[2025-08-07 21:21:11 train.log] INFO: Epoch: [24]  [Step 4300/14540]  lr: 0.000008  loss: 1.05740  detection_loss: 0.9957 (cls: 0.2675, box: 0.7282)  rpn_loss: 0.0617 (cls: 0.0236, box: 0.0380)
[2025-08-07 21:21:17 train.log] INFO: Epoch: [24]  [Step 4400/14540]  lr: 0.000008  loss: 0.86630  detection_loss: 0.7517 (cls: 0.2598, box: 0.4919)  rpn_loss: 0.1145 (cls: 0.0718, box: 0.0428)
[2025-08-07 21:21:22 train.log] INFO: Epoch: [24]  [Step 4500/14540]  lr: 0.000008  loss: 0.59328  detection_loss: 0.5325 (cls: 0.1346, box: 0.3979)  rpn_loss: 0.0608 (cls: 0.0226, box: 0.0381)
[2025-08-07 21:21:28 train.log] INFO: Epoch: [24]  [Step 4600/14540]  lr: 0.000008  loss: 0.69797  detection_loss: 0.5800 (cls: 0.1532, box: 0.4269)  rpn_loss: 0.1179 (cls: 0.0432, box: 0.0748)
[2025-08-07 21:21:34 train.log] INFO: Epoch: [24]  [Step 4700/14540]  lr: 0.000008  loss: 0.79242  detection_loss: 0.6697 (cls: 0.1528, box: 0.5169)  rpn_loss: 0.1227 (cls: 0.0317, box: 0.0911)
[2025-08-07 21:21:39 train.log] INFO: Epoch: [24]  [Step 4800/14540]  lr: 0.000008  loss: 0.62162  detection_loss: 0.4232 (cls: 0.0654, box: 0.3578)  rpn_loss: 0.1984 (cls: 0.0239, box: 0.1745)
[2025-08-07 21:21:45 train.log] INFO: Epoch: [24]  [Step 4900/14540]  lr: 0.000008  loss: 0.99669  detection_loss: 0.9306 (cls: 0.2363, box: 0.6943)  rpn_loss: 0.0661 (cls: 0.0522, box: 0.0139)
[2025-08-07 21:21:51 train.log] INFO: Epoch: [24]  [Step 5000/14540]  lr: 0.000008  loss: 0.81060  detection_loss: 0.7415 (cls: 0.1178, box: 0.6237)  rpn_loss: 0.0691 (cls: 0.0483, box: 0.0208)
[2025-08-07 21:21:56 train.log] INFO: Epoch: [24]  [Step 5100/14540]  lr: 0.000008  loss: 0.54676  detection_loss: 0.4615 (cls: 0.1012, box: 0.3603)  rpn_loss: 0.0852 (cls: 0.0431, box: 0.0421)
[2025-08-07 21:22:02 train.log] INFO: Epoch: [24]  [Step 5200/14540]  lr: 0.000008  loss: 0.73864  detection_loss: 0.6423 (cls: 0.1819, box: 0.4603)  rpn_loss: 0.0964 (cls: 0.0581, box: 0.0382)
[2025-08-07 21:22:08 train.log] INFO: Epoch: [24]  [Step 5300/14540]  lr: 0.000008  loss: 0.63356  detection_loss: 0.5919 (cls: 0.1064, box: 0.4855)  rpn_loss: 0.0417 (cls: 0.0195, box: 0.0222)
[2025-08-07 21:22:13 train.log] INFO: Epoch: [24]  [Step 5400/14540]  lr: 0.000008  loss: 0.98077  detection_loss: 0.8664 (cls: 0.2386, box: 0.6278)  rpn_loss: 0.1144 (cls: 0.0795, box: 0.0348)
[2025-08-07 21:22:19 train.log] INFO: Epoch: [24]  [Step 5500/14540]  lr: 0.000008  loss: 0.53834  detection_loss: 0.4942 (cls: 0.0677, box: 0.4265)  rpn_loss: 0.0442 (cls: 0.0136, box: 0.0306)
[2025-08-07 21:22:25 train.log] INFO: Epoch: [24]  [Step 5600/14540]  lr: 0.000008  loss: 0.77421  detection_loss: 0.5135 (cls: 0.1198, box: 0.3937)  rpn_loss: 0.2607 (cls: 0.0642, box: 0.1965)
[2025-08-07 21:22:30 train.log] INFO: Epoch: [24]  [Step 5700/14540]  lr: 0.000008  loss: 0.80861  detection_loss: 0.7391 (cls: 0.0918, box: 0.6473)  rpn_loss: 0.0695 (cls: 0.0333, box: 0.0363)
[2025-08-07 21:22:36 train.log] INFO: Epoch: [24]  [Step 5800/14540]  lr: 0.000008  loss: 1.17360  detection_loss: 0.9377 (cls: 0.1516, box: 0.7860)  rpn_loss: 0.2359 (cls: 0.0261, box: 0.2098)
[2025-08-07 21:22:42 train.log] INFO: Epoch: [24]  [Step 5900/14540]  lr: 0.000008  loss: 0.58533  detection_loss: 0.5410 (cls: 0.1251, box: 0.4159)  rpn_loss: 0.0443 (cls: 0.0242, box: 0.0201)
[2025-08-07 21:22:47 train.log] INFO: Epoch: [24]  [Step 6000/14540]  lr: 0.000008  loss: 0.44334  detection_loss: 0.4009 (cls: 0.0809, box: 0.3199)  rpn_loss: 0.0425 (cls: 0.0176, box: 0.0249)
[2025-08-07 21:22:53 train.log] INFO: Epoch: [24]  [Step 6100/14540]  lr: 0.000008  loss: 0.72969  detection_loss: 0.6481 (cls: 0.1810, box: 0.4671)  rpn_loss: 0.0816 (cls: 0.0520, box: 0.0296)
[2025-08-07 21:22:59 train.log] INFO: Epoch: [24]  [Step 6200/14540]  lr: 0.000008  loss: 1.27688  detection_loss: 1.1429 (cls: 0.4621, box: 0.6808)  rpn_loss: 0.1340 (cls: 0.0505, box: 0.0835)
[2025-08-07 21:23:04 train.log] INFO: Epoch: [24]  [Step 6300/14540]  lr: 0.000008  loss: 1.35056  detection_loss: 1.2421 (cls: 0.4050, box: 0.8371)  rpn_loss: 0.1084 (cls: 0.0350, box: 0.0735)
[2025-08-07 21:23:10 train.log] INFO: Epoch: [24]  [Step 6400/14540]  lr: 0.000008  loss: 0.83991  detection_loss: 0.7567 (cls: 0.1138, box: 0.6429)  rpn_loss: 0.0832 (cls: 0.0157, box: 0.0675)
[2025-08-07 21:23:16 train.log] INFO: Epoch: [24]  [Step 6500/14540]  lr: 0.000008  loss: 0.71509  detection_loss: 0.6499 (cls: 0.1715, box: 0.4784)  rpn_loss: 0.0652 (cls: 0.0373, box: 0.0279)
[2025-08-07 21:23:21 train.log] INFO: Epoch: [24]  [Step 6600/14540]  lr: 0.000008  loss: 0.79033  detection_loss: 0.6936 (cls: 0.2004, box: 0.4932)  rpn_loss: 0.0967 (cls: 0.0648, box: 0.0320)
[2025-08-07 21:23:27 train.log] INFO: Epoch: [24]  [Step 6700/14540]  lr: 0.000008  loss: 0.85329  detection_loss: 0.6917 (cls: 0.1418, box: 0.5499)  rpn_loss: 0.1616 (cls: 0.0652, box: 0.0964)
[2025-08-07 21:23:32 train.log] INFO: Epoch: [24]  [Step 6800/14540]  lr: 0.000008  loss: 0.79858  detection_loss: 0.7554 (cls: 0.1663, box: 0.5891)  rpn_loss: 0.0431 (cls: 0.0245, box: 0.0186)
[2025-08-07 21:23:38 train.log] INFO: Epoch: [24]  [Step 6900/14540]  lr: 0.000008  loss: 0.83535  detection_loss: 0.6981 (cls: 0.1402, box: 0.5579)  rpn_loss: 0.1372 (cls: 0.0713, box: 0.0660)
[2025-08-07 21:23:44 train.log] INFO: Epoch: [24]  [Step 7000/14540]  lr: 0.000008  loss: 0.70234  detection_loss: 0.6355 (cls: 0.2119, box: 0.4236)  rpn_loss: 0.0668 (cls: 0.0432, box: 0.0236)
[2025-08-07 21:23:50 train.log] INFO: Epoch: [24]  [Step 7100/14540]  lr: 0.000008  loss: 0.85197  detection_loss: 0.7562 (cls: 0.2035, box: 0.5527)  rpn_loss: 0.0958 (cls: 0.0280, box: 0.0678)
[2025-08-07 21:23:55 train.log] INFO: Epoch: [24]  [Step 7200/14540]  lr: 0.000008  loss: 0.96853  detection_loss: 0.7730 (cls: 0.1908, box: 0.5823)  rpn_loss: 0.1955 (cls: 0.0512, box: 0.1443)
[2025-08-07 21:24:01 train.log] INFO: Epoch: [24]  [Step 7300/14540]  lr: 0.000008  loss: 0.37513  detection_loss: 0.2981 (cls: 0.0887, box: 0.2094)  rpn_loss: 0.0771 (cls: 0.0257, box: 0.0514)
[2025-08-07 21:24:07 train.log] INFO: Epoch: [24]  [Step 7400/14540]  lr: 0.000008  loss: 0.84212  detection_loss: 0.7530 (cls: 0.1958, box: 0.5572)  rpn_loss: 0.0891 (cls: 0.0337, box: 0.0554)
[2025-08-07 21:24:12 train.log] INFO: Epoch: [24]  [Step 7500/14540]  lr: 0.000008  loss: 0.77014  detection_loss: 0.5776 (cls: 0.1454, box: 0.4322)  rpn_loss: 0.1926 (cls: 0.0418, box: 0.1508)
[2025-08-07 21:24:18 train.log] INFO: Epoch: [24]  [Step 7600/14540]  lr: 0.000008  loss: 1.12558  detection_loss: 1.0375 (cls: 0.1887, box: 0.8488)  rpn_loss: 0.0881 (cls: 0.0618, box: 0.0262)
[2025-08-07 21:24:23 train.log] INFO: Epoch: [24]  [Step 7700/14540]  lr: 0.000008  loss: 0.90581  detection_loss: 0.8564 (cls: 0.2501, box: 0.6063)  rpn_loss: 0.0494 (cls: 0.0239, box: 0.0255)
[2025-08-07 21:24:29 train.log] INFO: Epoch: [24]  [Step 7800/14540]  lr: 0.000008  loss: 0.74123  detection_loss: 0.6787 (cls: 0.1952, box: 0.4835)  rpn_loss: 0.0625 (cls: 0.0417, box: 0.0208)
[2025-08-07 21:24:34 train.log] INFO: Epoch: [24]  [Step 7900/14540]  lr: 0.000008  loss: 0.75041  detection_loss: 0.6811 (cls: 0.0848, box: 0.5963)  rpn_loss: 0.0693 (cls: 0.0065, box: 0.0629)
[2025-08-07 21:24:40 train.log] INFO: Epoch: [24]  [Step 8000/14540]  lr: 0.000008  loss: 0.56952  detection_loss: 0.3451 (cls: 0.0795, box: 0.2656)  rpn_loss: 0.2245 (cls: 0.0102, box: 0.2143)
[2025-08-07 21:24:46 train.log] INFO: Epoch: [24]  [Step 8100/14540]  lr: 0.000008  loss: 1.04163  detection_loss: 0.9275 (cls: 0.2602, box: 0.6673)  rpn_loss: 0.1141 (cls: 0.0936, box: 0.0205)
[2025-08-07 21:24:51 train.log] INFO: Epoch: [24]  [Step 8200/14540]  lr: 0.000008  loss: 0.75047  detection_loss: 0.5283 (cls: 0.1119, box: 0.4164)  rpn_loss: 0.2221 (cls: 0.0335, box: 0.1886)
[2025-08-07 21:24:57 train.log] INFO: Epoch: [24]  [Step 8300/14540]  lr: 0.000008  loss: 0.88627  detection_loss: 0.6152 (cls: 0.1340, box: 0.4812)  rpn_loss: 0.2711 (cls: 0.0255, box: 0.2456)
[2025-08-07 21:25:02 train.log] INFO: Epoch: [24]  [Step 8400/14540]  lr: 0.000008  loss: 0.99274  detection_loss: 0.9320 (cls: 0.2708, box: 0.6612)  rpn_loss: 0.0607 (cls: 0.0283, box: 0.0324)
[2025-08-07 21:25:08 train.log] INFO: Epoch: [24]  [Step 8500/14540]  lr: 0.000008  loss: 1.01496  detection_loss: 0.9060 (cls: 0.1981, box: 0.7078)  rpn_loss: 0.1090 (cls: 0.0237, box: 0.0853)
[2025-08-07 21:25:14 train.log] INFO: Epoch: [24]  [Step 8600/14540]  lr: 0.000008  loss: 0.81175  detection_loss: 0.7788 (cls: 0.1273, box: 0.6515)  rpn_loss: 0.0329 (cls: 0.0151, box: 0.0179)
[2025-08-07 21:25:19 train.log] INFO: Epoch: [24]  [Step 8700/14540]  lr: 0.000008  loss: 1.27961  detection_loss: 1.1526 (cls: 0.4073, box: 0.7453)  rpn_loss: 0.1270 (cls: 0.0982, box: 0.0288)
[2025-08-07 21:25:25 train.log] INFO: Epoch: [24]  [Step 8800/14540]  lr: 0.000008  loss: 0.79524  detection_loss: 0.7253 (cls: 0.0914, box: 0.6339)  rpn_loss: 0.0699 (cls: 0.0449, box: 0.0250)
[2025-08-07 21:25:30 train.log] INFO: Epoch: [24]  [Step 8900/14540]  lr: 0.000008  loss: 0.88768  detection_loss: 0.8235 (cls: 0.0994, box: 0.7241)  rpn_loss: 0.0641 (cls: 0.0413, box: 0.0229)
[2025-08-07 21:25:36 train.log] INFO: Epoch: [24]  [Step 9000/14540]  lr: 0.000008  loss: 1.40614  detection_loss: 1.2275 (cls: 0.3386, box: 0.8889)  rpn_loss: 0.1787 (cls: 0.1216, box: 0.0571)
[2025-08-07 21:25:41 train.log] INFO: Epoch: [24]  [Step 9100/14540]  lr: 0.000008  loss: 1.27779  detection_loss: 1.1797 (cls: 0.3402, box: 0.8395)  rpn_loss: 0.0981 (cls: 0.0490, box: 0.0491)
[2025-08-07 21:25:47 train.log] INFO: Epoch: [24]  [Step 9200/14540]  lr: 0.000008  loss: 0.68648  detection_loss: 0.6408 (cls: 0.2204, box: 0.4204)  rpn_loss: 0.0457 (cls: 0.0318, box: 0.0139)
[2025-08-07 21:25:52 train.log] INFO: Epoch: [24]  [Step 9300/14540]  lr: 0.000008  loss: 0.96539  detection_loss: 0.8280 (cls: 0.1056, box: 0.7224)  rpn_loss: 0.1374 (cls: 0.0722, box: 0.0652)
[2025-08-07 21:25:58 train.log] INFO: Epoch: [24]  [Step 9400/14540]  lr: 0.000008  loss: 0.90664  detection_loss: 0.7763 (cls: 0.2339, box: 0.5423)  rpn_loss: 0.1304 (cls: 0.0535, box: 0.0768)
[2025-08-07 21:26:03 train.log] INFO: Epoch: [24]  [Step 9500/14540]  lr: 0.000008  loss: 0.97442  detection_loss: 0.8542 (cls: 0.1985, box: 0.6557)  rpn_loss: 0.1202 (cls: 0.0345, box: 0.0857)
[2025-08-07 21:26:09 train.log] INFO: Epoch: [24]  [Step 9600/14540]  lr: 0.000008  loss: 0.63359  detection_loss: 0.5520 (cls: 0.1524, box: 0.3996)  rpn_loss: 0.0816 (cls: 0.0631, box: 0.0185)
[2025-08-07 21:26:14 train.log] INFO: Epoch: [24]  [Step 9700/14540]  lr: 0.000008  loss: 0.56393  detection_loss: 0.5114 (cls: 0.1334, box: 0.3780)  rpn_loss: 0.0525 (cls: 0.0368, box: 0.0157)
[2025-08-07 21:26:20 train.log] INFO: Epoch: [24]  [Step 9800/14540]  lr: 0.000008  loss: 1.03503  detection_loss: 0.8891 (cls: 0.3299, box: 0.5592)  rpn_loss: 0.1459 (cls: 0.1175, box: 0.0284)
[2025-08-07 21:26:25 train.log] INFO: Epoch: [24]  [Step 9900/14540]  lr: 0.000008  loss: 0.78728  detection_loss: 0.6926 (cls: 0.1124, box: 0.5803)  rpn_loss: 0.0946 (cls: 0.0607, box: 0.0339)
[2025-08-07 21:26:31 train.log] INFO: Epoch: [24]  [Step 10000/14540]  lr: 0.000008  loss: 1.08706  detection_loss: 0.9083 (cls: 0.2018, box: 0.7066)  rpn_loss: 0.1787 (cls: 0.0343, box: 0.1445)
[2025-08-07 21:26:36 train.log] INFO: Epoch: [24]  [Step 10100/14540]  lr: 0.000008  loss: 0.67472  detection_loss: 0.6231 (cls: 0.2555, box: 0.3676)  rpn_loss: 0.0516 (cls: 0.0330, box: 0.0186)
[2025-08-07 21:26:42 train.log] INFO: Epoch: [24]  [Step 10200/14540]  lr: 0.000008  loss: 1.04873  detection_loss: 0.8620 (cls: 0.2159, box: 0.6461)  rpn_loss: 0.1867 (cls: 0.1339, box: 0.0529)
[2025-08-07 21:26:47 train.log] INFO: Epoch: [24]  [Step 10300/14540]  lr: 0.000008  loss: 1.15308  detection_loss: 1.0272 (cls: 0.2346, box: 0.7926)  rpn_loss: 0.1259 (cls: 0.0518, box: 0.0741)
[2025-08-07 21:26:53 train.log] INFO: Epoch: [24]  [Step 10400/14540]  lr: 0.000008  loss: 0.76732  detection_loss: 0.6631 (cls: 0.1336, box: 0.5294)  rpn_loss: 0.1042 (cls: 0.0932, box: 0.0110)
[2025-08-07 21:26:58 train.log] INFO: Epoch: [24]  [Step 10500/14540]  lr: 0.000008  loss: 0.91529  detection_loss: 0.8429 (cls: 0.2406, box: 0.6023)  rpn_loss: 0.0724 (cls: 0.0434, box: 0.0290)
[2025-08-07 21:27:04 train.log] INFO: Epoch: [24]  [Step 10600/14540]  lr: 0.000008  loss: 0.84811  detection_loss: 0.7802 (cls: 0.2182, box: 0.5620)  rpn_loss: 0.0679 (cls: 0.0367, box: 0.0312)
[2025-08-07 21:27:09 train.log] INFO: Epoch: [24]  [Step 10700/14540]  lr: 0.000008  loss: 0.84832  detection_loss: 0.7839 (cls: 0.1902, box: 0.5936)  rpn_loss: 0.0644 (cls: 0.0404, box: 0.0240)
[2025-08-07 21:27:15 train.log] INFO: Epoch: [24]  [Step 10800/14540]  lr: 0.000008  loss: 1.02287  detection_loss: 0.7938 (cls: 0.1582, box: 0.6355)  rpn_loss: 0.2291 (cls: 0.0588, box: 0.1703)
[2025-08-07 21:27:20 train.log] INFO: Epoch: [24]  [Step 10900/14540]  lr: 0.000008  loss: 0.98242  detection_loss: 0.8583 (cls: 0.2682, box: 0.5901)  rpn_loss: 0.1241 (cls: 0.0678, box: 0.0563)
[2025-08-07 21:27:26 train.log] INFO: Epoch: [24]  [Step 11000/14540]  lr: 0.000008  loss: 0.98162  detection_loss: 0.8932 (cls: 0.1526, box: 0.7406)  rpn_loss: 0.0884 (cls: 0.0486, box: 0.0398)
[2025-08-07 21:27:31 train.log] INFO: Epoch: [24]  [Step 11100/14540]  lr: 0.000008  loss: 0.64516  detection_loss: 0.5737 (cls: 0.1417, box: 0.4320)  rpn_loss: 0.0714 (cls: 0.0431, box: 0.0283)
[2025-08-07 21:27:37 train.log] INFO: Epoch: [24]  [Step 11200/14540]  lr: 0.000008  loss: 0.80314  detection_loss: 0.7386 (cls: 0.1392, box: 0.5993)  rpn_loss: 0.0646 (cls: 0.0287, box: 0.0359)
[2025-08-07 21:27:42 train.log] INFO: Epoch: [24]  [Step 11300/14540]  lr: 0.000008  loss: 1.16099  detection_loss: 0.9237 (cls: 0.2662, box: 0.6575)  rpn_loss: 0.2372 (cls: 0.0892, box: 0.1480)
[2025-08-07 21:27:48 train.log] INFO: Epoch: [24]  [Step 11400/14540]  lr: 0.000008  loss: 1.05925  detection_loss: 0.9956 (cls: 0.2634, box: 0.7322)  rpn_loss: 0.0636 (cls: 0.0289, box: 0.0347)
[2025-08-07 21:27:53 train.log] INFO: Epoch: [24]  [Step 11500/14540]  lr: 0.000008  loss: 0.80614  detection_loss: 0.7047 (cls: 0.3676, box: 0.3371)  rpn_loss: 0.1014 (cls: 0.0457, box: 0.0557)
[2025-08-07 21:27:59 train.log] INFO: Epoch: [24]  [Step 11600/14540]  lr: 0.000008  loss: 1.25719  detection_loss: 1.1026 (cls: 0.3355, box: 0.7671)  rpn_loss: 0.1546 (cls: 0.1149, box: 0.0396)
[2025-08-07 21:28:04 train.log] INFO: Epoch: [24]  [Step 11700/14540]  lr: 0.000008  loss: 0.75380  detection_loss: 0.7286 (cls: 0.1048, box: 0.6238)  rpn_loss: 0.0252 (cls: 0.0091, box: 0.0161)
[2025-08-07 21:28:10 train.log] INFO: Epoch: [24]  [Step 11800/14540]  lr: 0.000008  loss: 0.78191  detection_loss: 0.7181 (cls: 0.1724, box: 0.5458)  rpn_loss: 0.0638 (cls: 0.0379, box: 0.0259)
[2025-08-07 21:28:16 train.log] INFO: Epoch: [24]  [Step 11900/14540]  lr: 0.000008  loss: 0.98551  detection_loss: 0.9232 (cls: 0.1833, box: 0.7399)  rpn_loss: 0.0623 (cls: 0.0277, box: 0.0346)
[2025-08-07 21:28:21 train.log] INFO: Epoch: [24]  [Step 12000/14540]  lr: 0.000008  loss: 0.91435  detection_loss: 0.8094 (cls: 0.1454, box: 0.6641)  rpn_loss: 0.1049 (cls: 0.0879, box: 0.0170)
[2025-08-07 21:28:26 train.log] INFO: Epoch: [24]  [Step 12100/14540]  lr: 0.000008  loss: 0.84153  detection_loss: 0.8116 (cls: 0.1527, box: 0.6590)  rpn_loss: 0.0299 (cls: 0.0172, box: 0.0127)
[2025-08-07 21:28:32 train.log] INFO: Epoch: [24]  [Step 12200/14540]  lr: 0.000008  loss: 0.79332  detection_loss: 0.7416 (cls: 0.1888, box: 0.5528)  rpn_loss: 0.0517 (cls: 0.0287, box: 0.0231)
[2025-08-07 21:28:38 train.log] INFO: Epoch: [24]  [Step 12300/14540]  lr: 0.000008  loss: 0.64338  detection_loss: 0.5931 (cls: 0.1971, box: 0.3960)  rpn_loss: 0.0503 (cls: 0.0162, box: 0.0341)
[2025-08-07 21:28:43 train.log] INFO: Epoch: [24]  [Step 12400/14540]  lr: 0.000008  loss: 0.78894  detection_loss: 0.7419 (cls: 0.1520, box: 0.5899)  rpn_loss: 0.0471 (cls: 0.0181, box: 0.0290)
[2025-08-07 21:28:49 train.log] INFO: Epoch: [24]  [Step 12500/14540]  lr: 0.000008  loss: 0.82217  detection_loss: 0.6712 (cls: 0.1693, box: 0.5019)  rpn_loss: 0.1510 (cls: 0.0239, box: 0.1271)
[2025-08-07 21:28:54 train.log] INFO: Epoch: [24]  [Step 12600/14540]  lr: 0.000008  loss: 0.79132  detection_loss: 0.6978 (cls: 0.1480, box: 0.5498)  rpn_loss: 0.0935 (cls: 0.0628, box: 0.0307)
[2025-08-07 21:28:59 train.log] INFO: Epoch: [24]  [Step 12700/14540]  lr: 0.000008  loss: 0.46212  detection_loss: 0.3615 (cls: 0.0674, box: 0.2941)  rpn_loss: 0.1006 (cls: 0.0895, box: 0.0111)
[2025-08-07 21:29:05 train.log] INFO: Epoch: [24]  [Step 12800/14540]  lr: 0.000008  loss: 1.15398  detection_loss: 1.0456 (cls: 0.2988, box: 0.7469)  rpn_loss: 0.1083 (cls: 0.0329, box: 0.0755)
[2025-08-07 21:29:11 train.log] INFO: Epoch: [24]  [Step 12900/14540]  lr: 0.000008  loss: 1.13479  detection_loss: 1.0016 (cls: 0.3620, box: 0.6395)  rpn_loss: 0.1332 (cls: 0.1071, box: 0.0261)
[2025-08-07 21:29:16 train.log] INFO: Epoch: [24]  [Step 13000/14540]  lr: 0.000008  loss: 0.77214  detection_loss: 0.7452 (cls: 0.1457, box: 0.5995)  rpn_loss: 0.0270 (cls: 0.0111, box: 0.0159)
[2025-08-07 21:29:22 train.log] INFO: Epoch: [24]  [Step 13100/14540]  lr: 0.000008  loss: 0.99178  detection_loss: 0.9027 (cls: 0.2623, box: 0.6404)  rpn_loss: 0.0891 (cls: 0.0686, box: 0.0204)
[2025-08-07 21:29:27 train.log] INFO: Epoch: [24]  [Step 13200/14540]  lr: 0.000008  loss: 0.36475  detection_loss: 0.3135 (cls: 0.1046, box: 0.2090)  rpn_loss: 0.0513 (cls: 0.0354, box: 0.0158)
[2025-08-07 21:29:33 train.log] INFO: Epoch: [24]  [Step 13300/14540]  lr: 0.000008  loss: 1.16340  detection_loss: 0.9423 (cls: 0.3158, box: 0.6265)  rpn_loss: 0.2211 (cls: 0.1748, box: 0.0464)
[2025-08-07 21:29:38 train.log] INFO: Epoch: [24]  [Step 13400/14540]  lr: 0.000008  loss: 1.12947  detection_loss: 1.0575 (cls: 0.1722, box: 0.8853)  rpn_loss: 0.0720 (cls: 0.0243, box: 0.0477)
[2025-08-07 21:29:44 train.log] INFO: Epoch: [24]  [Step 13500/14540]  lr: 0.000008  loss: 1.20326  detection_loss: 1.0793 (cls: 0.2490, box: 0.8303)  rpn_loss: 0.1239 (cls: 0.0985, box: 0.0254)
[2025-08-07 21:29:49 train.log] INFO: Epoch: [24]  [Step 13600/14540]  lr: 0.000008  loss: 1.14072  detection_loss: 0.9085 (cls: 0.2898, box: 0.6187)  rpn_loss: 0.2322 (cls: 0.0463, box: 0.1859)
[2025-08-07 21:29:55 train.log] INFO: Epoch: [24]  [Step 13700/14540]  lr: 0.000008  loss: 0.63512  detection_loss: 0.5694 (cls: 0.2000, box: 0.3694)  rpn_loss: 0.0657 (cls: 0.0470, box: 0.0187)
[2025-08-07 21:30:00 train.log] INFO: Epoch: [24]  [Step 13800/14540]  lr: 0.000008  loss: 0.96150  detection_loss: 0.8444 (cls: 0.3449, box: 0.4994)  rpn_loss: 0.1171 (cls: 0.0451, box: 0.0720)
[2025-08-07 21:30:06 train.log] INFO: Epoch: [24]  [Step 13900/14540]  lr: 0.000008  loss: 0.77827  detection_loss: 0.6890 (cls: 0.1730, box: 0.5161)  rpn_loss: 0.0892 (cls: 0.0669, box: 0.0223)
[2025-08-07 21:30:12 train.log] INFO: Epoch: [24]  [Step 14000/14540]  lr: 0.000008  loss: 1.15762  detection_loss: 1.0248 (cls: 0.1766, box: 0.8481)  rpn_loss: 0.1329 (cls: 0.0868, box: 0.0460)
[2025-08-07 21:30:17 train.log] INFO: Epoch: [24]  [Step 14100/14540]  lr: 0.000008  loss: 0.67017  detection_loss: 0.5889 (cls: 0.1211, box: 0.4679)  rpn_loss: 0.0812 (cls: 0.0219, box: 0.0594)
[2025-08-07 21:30:23 train.log] INFO: Epoch: [24]  [Step 14200/14540]  lr: 0.000008  loss: 1.17033  detection_loss: 1.0895 (cls: 0.1568, box: 0.9327)  rpn_loss: 0.0808 (cls: 0.0382, box: 0.0426)
[2025-08-07 21:30:28 train.log] INFO: Epoch: [24]  [Step 14300/14540]  lr: 0.000008  loss: 0.85217  detection_loss: 0.7449 (cls: 0.1589, box: 0.5860)  rpn_loss: 0.1073 (cls: 0.0117, box: 0.0956)
[2025-08-07 21:30:34 train.log] INFO: Epoch: [24]  [Step 14400/14540]  lr: 0.000008  loss: 0.86429  detection_loss: 0.7359 (cls: 0.1894, box: 0.5465)  rpn_loss: 0.1284 (cls: 0.1004, box: 0.0279)
[2025-08-07 21:30:39 train.log] INFO: Epoch: [24]  [Step 14500/14540]  lr: 0.000008  loss: 1.22018  detection_loss: 1.0656 (cls: 0.2742, box: 0.7914)  rpn_loss: 0.1545 (cls: 0.1263, box: 0.0282)
[2025-08-07 21:34:09 train.log] INFO: Epoch: [25]  [Step 100/14540]  lr: 0.000005  loss: 0.97574  detection_loss: 0.7198 (cls: 0.0971, box: 0.6227)  rpn_loss: 0.2560 (cls: 0.0314, box: 0.2245)
[2025-08-07 21:34:15 train.log] INFO: Epoch: [25]  [Step 200/14540]  lr: 0.000005  loss: 0.79357  detection_loss: 0.7034 (cls: 0.1788, box: 0.5245)  rpn_loss: 0.0902 (cls: 0.0577, box: 0.0325)
[2025-08-07 21:34:21 train.log] INFO: Epoch: [25]  [Step 300/14540]  lr: 0.000005  loss: 1.28839  detection_loss: 1.0901 (cls: 0.2375, box: 0.8526)  rpn_loss: 0.1983 (cls: 0.1166, box: 0.0816)
[2025-08-07 21:34:27 train.log] INFO: Epoch: [25]  [Step 400/14540]  lr: 0.000005  loss: 0.79960  detection_loss: 0.7199 (cls: 0.1594, box: 0.5605)  rpn_loss: 0.0797 (cls: 0.0357, box: 0.0441)
[2025-08-07 21:34:33 train.log] INFO: Epoch: [25]  [Step 500/14540]  lr: 0.000005  loss: 0.76344  detection_loss: 0.6421 (cls: 0.1714, box: 0.4707)  rpn_loss: 0.1214 (cls: 0.0643, box: 0.0570)
[2025-08-07 21:34:39 train.log] INFO: Epoch: [25]  [Step 600/14540]  lr: 0.000005  loss: 0.85779  detection_loss: 0.7499 (cls: 0.2743, box: 0.4756)  rpn_loss: 0.1079 (cls: 0.0751, box: 0.0328)
[2025-08-07 21:34:45 train.log] INFO: Epoch: [25]  [Step 700/14540]  lr: 0.000005  loss: 0.99823  detection_loss: 0.9191 (cls: 0.2504, box: 0.6686)  rpn_loss: 0.0792 (cls: 0.0438, box: 0.0354)
[2025-08-07 21:34:51 train.log] INFO: Epoch: [25]  [Step 800/14540]  lr: 0.000005  loss: 1.04786  detection_loss: 0.8586 (cls: 0.2284, box: 0.6302)  rpn_loss: 0.1892 (cls: 0.1433, box: 0.0459)
[2025-08-07 21:34:56 train.log] INFO: Epoch: [25]  [Step 900/14540]  lr: 0.000005  loss: 0.78709  detection_loss: 0.7172 (cls: 0.1292, box: 0.5880)  rpn_loss: 0.0699 (cls: 0.0369, box: 0.0330)
[2025-08-07 21:35:02 train.log] INFO: Epoch: [25]  [Step 1000/14540]  lr: 0.000005  loss: 1.62537  detection_loss: 1.4874 (cls: 0.3528, box: 1.1347)  rpn_loss: 0.1380 (cls: 0.0828, box: 0.0551)
[2025-08-07 21:35:07 train.log] INFO: Epoch: [25]  [Step 1100/14540]  lr: 0.000005  loss: 0.85292  detection_loss: 0.7708 (cls: 0.2091, box: 0.5617)  rpn_loss: 0.0822 (cls: 0.0486, box: 0.0335)
[2025-08-07 21:35:13 train.log] INFO: Epoch: [25]  [Step 1200/14540]  lr: 0.000005  loss: 0.96580  detection_loss: 0.8475 (cls: 0.3033, box: 0.5442)  rpn_loss: 0.1183 (cls: 0.0341, box: 0.0842)
[2025-08-07 21:35:19 train.log] INFO: Epoch: [25]  [Step 1300/14540]  lr: 0.000005  loss: 0.55498  detection_loss: 0.5349 (cls: 0.0997, box: 0.4352)  rpn_loss: 0.0201 (cls: 0.0155, box: 0.0046)
[2025-08-07 21:35:24 train.log] INFO: Epoch: [25]  [Step 1400/14540]  lr: 0.000005  loss: 1.16553  detection_loss: 0.8476 (cls: 0.2346, box: 0.6130)  rpn_loss: 0.3179 (cls: 0.0200, box: 0.2979)
[2025-08-07 21:35:30 train.log] INFO: Epoch: [25]  [Step 1500/14540]  lr: 0.000005  loss: 0.49603  detection_loss: 0.4665 (cls: 0.1326, box: 0.3340)  rpn_loss: 0.0295 (cls: 0.0089, box: 0.0206)
[2025-08-07 21:35:35 train.log] INFO: Epoch: [25]  [Step 1600/14540]  lr: 0.000005  loss: 0.68194  detection_loss: 0.6219 (cls: 0.1778, box: 0.4441)  rpn_loss: 0.0601 (cls: 0.0429, box: 0.0171)
[2025-08-07 21:35:41 train.log] INFO: Epoch: [25]  [Step 1700/14540]  lr: 0.000005  loss: 0.98498  detection_loss: 0.8821 (cls: 0.1742, box: 0.7079)  rpn_loss: 0.1029 (cls: 0.0719, box: 0.0310)
[2025-08-07 21:35:47 train.log] INFO: Epoch: [25]  [Step 1800/14540]  lr: 0.000005  loss: 0.87029  detection_loss: 0.7815 (cls: 0.2159, box: 0.5656)  rpn_loss: 0.0888 (cls: 0.0363, box: 0.0525)
[2025-08-07 21:35:52 train.log] INFO: Epoch: [25]  [Step 1900/14540]  lr: 0.000005  loss: 0.90092  detection_loss: 0.8514 (cls: 0.1556, box: 0.6957)  rpn_loss: 0.0495 (cls: 0.0279, box: 0.0217)
[2025-08-07 21:35:58 train.log] INFO: Epoch: [25]  [Step 2000/14540]  lr: 0.000005  loss: 0.69318  detection_loss: 0.4981 (cls: 0.1454, box: 0.3527)  rpn_loss: 0.1951 (cls: 0.0328, box: 0.1622)
[2025-08-07 21:36:03 train.log] INFO: Epoch: [25]  [Step 2100/14540]  lr: 0.000005  loss: 0.67615  detection_loss: 0.6489 (cls: 0.1532, box: 0.4957)  rpn_loss: 0.0272 (cls: 0.0109, box: 0.0163)
[2025-08-07 21:36:09 train.log] INFO: Epoch: [25]  [Step 2200/14540]  lr: 0.000005  loss: 0.63122  detection_loss: 0.5962 (cls: 0.1373, box: 0.4589)  rpn_loss: 0.0350 (cls: 0.0226, box: 0.0123)
[2025-08-07 21:36:14 train.log] INFO: Epoch: [25]  [Step 2300/14540]  lr: 0.000005  loss: 0.71478  detection_loss: 0.5936 (cls: 0.1526, box: 0.4410)  rpn_loss: 0.1212 (cls: 0.0643, box: 0.0569)
[2025-08-07 21:36:20 train.log] INFO: Epoch: [25]  [Step 2400/14540]  lr: 0.000005  loss: 0.47302  detection_loss: 0.4076 (cls: 0.1139, box: 0.2936)  rpn_loss: 0.0655 (cls: 0.0300, box: 0.0355)
[2025-08-07 21:36:26 train.log] INFO: Epoch: [25]  [Step 2500/14540]  lr: 0.000005  loss: 1.06763  detection_loss: 0.8108 (cls: 0.1704, box: 0.6403)  rpn_loss: 0.2569 (cls: 0.2188, box: 0.0380)
[2025-08-07 21:36:31 train.log] INFO: Epoch: [25]  [Step 2600/14540]  lr: 0.000005  loss: 0.65905  detection_loss: 0.6055 (cls: 0.1872, box: 0.4183)  rpn_loss: 0.0535 (cls: 0.0321, box: 0.0214)
[2025-08-07 21:36:37 train.log] INFO: Epoch: [25]  [Step 2700/14540]  lr: 0.000005  loss: 1.07286  detection_loss: 0.7554 (cls: 0.1807, box: 0.5747)  rpn_loss: 0.3174 (cls: 0.1671, box: 0.1504)
[2025-08-07 21:36:43 train.log] INFO: Epoch: [25]  [Step 2800/14540]  lr: 0.000005  loss: 1.23987  detection_loss: 1.0926 (cls: 0.1570, box: 0.9356)  rpn_loss: 0.1473 (cls: 0.0853, box: 0.0619)
[2025-08-07 21:36:48 train.log] INFO: Epoch: [25]  [Step 2900/14540]  lr: 0.000005  loss: 0.70726  detection_loss: 0.6620 (cls: 0.1144, box: 0.5476)  rpn_loss: 0.0452 (cls: 0.0199, box: 0.0254)
[2025-08-07 21:36:54 train.log] INFO: Epoch: [25]  [Step 3000/14540]  lr: 0.000005  loss: 0.60773  detection_loss: 0.5363 (cls: 0.1872, box: 0.3491)  rpn_loss: 0.0714 (cls: 0.0334, box: 0.0380)
[2025-08-07 21:37:00 train.log] INFO: Epoch: [25]  [Step 3100/14540]  lr: 0.000005  loss: 0.83015  detection_loss: 0.7742 (cls: 0.1733, box: 0.6009)  rpn_loss: 0.0560 (cls: 0.0237, box: 0.0323)
[2025-08-07 21:37:06 train.log] INFO: Epoch: [25]  [Step 3200/14540]  lr: 0.000005  loss: 0.82956  detection_loss: 0.6376 (cls: 0.1872, box: 0.4504)  rpn_loss: 0.1919 (cls: 0.0774, box: 0.1145)
[2025-08-07 21:37:12 train.log] INFO: Epoch: [25]  [Step 3300/14540]  lr: 0.000005  loss: 1.33789  detection_loss: 1.2261 (cls: 0.3149, box: 0.9112)  rpn_loss: 0.1118 (cls: 0.0369, box: 0.0749)
[2025-08-07 21:37:17 train.log] INFO: Epoch: [25]  [Step 3400/14540]  lr: 0.000005  loss: 1.04376  detection_loss: 0.9327 (cls: 0.2406, box: 0.6921)  rpn_loss: 0.1111 (cls: 0.0334, box: 0.0778)
[2025-08-07 21:37:23 train.log] INFO: Epoch: [25]  [Step 3500/14540]  lr: 0.000005  loss: 0.80746  detection_loss: 0.7462 (cls: 0.1881, box: 0.5581)  rpn_loss: 0.0613 (cls: 0.0429, box: 0.0183)
[2025-08-07 21:37:29 train.log] INFO: Epoch: [25]  [Step 3600/14540]  lr: 0.000005  loss: 0.63409  detection_loss: 0.5112 (cls: 0.1291, box: 0.3822)  rpn_loss: 0.1229 (cls: 0.0894, box: 0.0334)
[2025-08-07 21:37:31 train.log] INFO: Epoch: [25]  [Step 3635/14540]  lr: 0.000005  loss: 0.76574  detection_loss: 0.6660 (cls: 0.2560, box: 0.4100)  rpn_loss: 0.0998 (cls: 0.0629, box: 0.0369)
[2025-08-07 21:37:34 train.log] INFO: Epoch: [25]  [Step 3700/14540]  lr: 0.000005  loss: 0.85065  detection_loss: 0.7637 (cls: 0.1779, box: 0.5857)  rpn_loss: 0.0870 (cls: 0.0306, box: 0.0564)
[2025-08-07 21:37:40 train.log] INFO: Epoch: [25]  [Step 3800/14540]  lr: 0.000005  loss: 0.65032  detection_loss: 0.5743 (cls: 0.1613, box: 0.4130)  rpn_loss: 0.0760 (cls: 0.0532, box: 0.0229)
[2025-08-07 21:37:46 train.log] INFO: Epoch: [25]  [Step 3900/14540]  lr: 0.000005  loss: 0.68487  detection_loss: 0.5524 (cls: 0.1328, box: 0.4196)  rpn_loss: 0.1325 (cls: 0.0583, box: 0.0741)
[2025-08-07 21:37:52 train.log] INFO: Epoch: [25]  [Step 4000/14540]  lr: 0.000005  loss: 0.96046  detection_loss: 0.8442 (cls: 0.2600, box: 0.5842)  rpn_loss: 0.1163 (cls: 0.0361, box: 0.0802)
[2025-08-07 21:37:57 train.log] INFO: Epoch: [25]  [Step 4100/14540]  lr: 0.000005  loss: 1.06164  detection_loss: 0.9880 (cls: 0.2462, box: 0.7418)  rpn_loss: 0.0736 (cls: 0.0631, box: 0.0105)
[2025-08-07 21:38:03 train.log] INFO: Epoch: [25]  [Step 4200/14540]  lr: 0.000005  loss: 1.05163  detection_loss: 0.9864 (cls: 0.3155, box: 0.6709)  rpn_loss: 0.0653 (cls: 0.0445, box: 0.0208)
[2025-08-07 21:38:09 train.log] INFO: Epoch: [25]  [Step 4300/14540]  lr: 0.000005  loss: 0.76759  detection_loss: 0.7085 (cls: 0.1166, box: 0.5919)  rpn_loss: 0.0591 (cls: 0.0352, box: 0.0238)
[2025-08-07 21:38:14 train.log] INFO: Epoch: [25]  [Step 4400/14540]  lr: 0.000005  loss: 1.30857  detection_loss: 1.1915 (cls: 0.2810, box: 0.9105)  rpn_loss: 0.1171 (cls: 0.0450, box: 0.0721)
[2025-08-07 21:38:20 train.log] INFO: Epoch: [25]  [Step 4500/14540]  lr: 0.000005  loss: 0.91898  detection_loss: 0.8455 (cls: 0.1770, box: 0.6685)  rpn_loss: 0.0735 (cls: 0.0332, box: 0.0403)
[2025-08-07 21:38:26 train.log] INFO: Epoch: [25]  [Step 4600/14540]  lr: 0.000005  loss: 0.52353  detection_loss: 0.4853 (cls: 0.1120, box: 0.3733)  rpn_loss: 0.0382 (cls: 0.0194, box: 0.0189)
[2025-08-07 21:38:32 train.log] INFO: Epoch: [25]  [Step 4700/14540]  lr: 0.000005  loss: 0.71708  detection_loss: 0.5201 (cls: 0.1655, box: 0.3546)  rpn_loss: 0.1970 (cls: 0.0633, box: 0.1337)
[2025-08-07 21:38:38 train.log] INFO: Epoch: [25]  [Step 4800/14540]  lr: 0.000005  loss: 0.76653  detection_loss: 0.7129 (cls: 0.2098, box: 0.5031)  rpn_loss: 0.0536 (cls: 0.0341, box: 0.0196)
[2025-08-07 21:38:44 train.log] INFO: Epoch: [25]  [Step 4900/14540]  lr: 0.000005  loss: 0.83253  detection_loss: 0.7679 (cls: 0.0800, box: 0.6879)  rpn_loss: 0.0646 (cls: 0.0386, box: 0.0260)
[2025-08-07 21:38:50 train.log] INFO: Epoch: [25]  [Step 5000/14540]  lr: 0.000005  loss: 0.64576  detection_loss: 0.5619 (cls: 0.1368, box: 0.4251)  rpn_loss: 0.0839 (cls: 0.0221, box: 0.0618)
[2025-08-07 21:38:56 train.log] INFO: Epoch: [25]  [Step 5100/14540]  lr: 0.000005  loss: 1.10103  detection_loss: 0.9580 (cls: 0.2449, box: 0.7131)  rpn_loss: 0.1431 (cls: 0.1140, box: 0.0290)
[2025-08-07 21:39:02 train.log] INFO: Epoch: [25]  [Step 5200/14540]  lr: 0.000005  loss: 0.76074  detection_loss: 0.6954 (cls: 0.1990, box: 0.4964)  rpn_loss: 0.0654 (cls: 0.0281, box: 0.0372)
[2025-08-07 21:39:07 train.log] INFO: Epoch: [25]  [Step 5300/14540]  lr: 0.000005  loss: 0.75417  detection_loss: 0.6446 (cls: 0.1349, box: 0.5096)  rpn_loss: 0.1096 (cls: 0.0766, box: 0.0330)
[2025-08-07 21:39:13 train.log] INFO: Epoch: [25]  [Step 5400/14540]  lr: 0.000005  loss: 1.13709  detection_loss: 1.0303 (cls: 0.2920, box: 0.7384)  rpn_loss: 0.1068 (cls: 0.0698, box: 0.0370)
[2025-08-07 21:39:19 train.log] INFO: Epoch: [25]  [Step 5500/14540]  lr: 0.000005  loss: 0.58997  detection_loss: 0.5242 (cls: 0.1214, box: 0.4028)  rpn_loss: 0.0657 (cls: 0.0332, box: 0.0325)
[2025-08-07 21:39:25 train.log] INFO: Epoch: [25]  [Step 5600/14540]  lr: 0.000005  loss: 0.77031  detection_loss: 0.6914 (cls: 0.1653, box: 0.5261)  rpn_loss: 0.0789 (cls: 0.0534, box: 0.0255)
[2025-08-07 21:39:30 train.log] INFO: Epoch: [25]  [Step 5700/14540]  lr: 0.000005  loss: 0.99626  detection_loss: 0.9226 (cls: 0.2685, box: 0.6541)  rpn_loss: 0.0737 (cls: 0.0443, box: 0.0294)
[2025-08-07 21:39:36 train.log] INFO: Epoch: [25]  [Step 5800/14540]  lr: 0.000005  loss: 1.07958  detection_loss: 0.9181 (cls: 0.2714, box: 0.6467)  rpn_loss: 0.1615 (cls: 0.0911, box: 0.0703)
[2025-08-07 21:39:42 train.log] INFO: Epoch: [25]  [Step 5900/14540]  lr: 0.000005  loss: 1.22115  detection_loss: 0.9880 (cls: 0.1814, box: 0.8066)  rpn_loss: 0.2331 (cls: 0.1754, box: 0.0578)
[2025-08-07 21:39:47 train.log] INFO: Epoch: [25]  [Step 6000/14540]  lr: 0.000005  loss: 1.00328  detection_loss: 0.9236 (cls: 0.2337, box: 0.6899)  rpn_loss: 0.0797 (cls: 0.0611, box: 0.0186)
[2025-08-07 21:39:53 train.log] INFO: Epoch: [25]  [Step 6100/14540]  lr: 0.000005  loss: 1.68748  detection_loss: 1.5760 (cls: 0.4540, box: 1.1220)  rpn_loss: 0.1114 (cls: 0.0512, box: 0.0602)
[2025-08-07 21:39:58 train.log] INFO: Epoch: [25]  [Step 6200/14540]  lr: 0.000005  loss: 0.73447  detection_loss: 0.6463 (cls: 0.2071, box: 0.4392)  rpn_loss: 0.0882 (cls: 0.0510, box: 0.0371)
[2025-08-07 21:40:04 train.log] INFO: Epoch: [25]  [Step 6300/14540]  lr: 0.000005  loss: 0.99629  detection_loss: 0.8991 (cls: 0.2681, box: 0.6311)  rpn_loss: 0.0971 (cls: 0.0348, box: 0.0624)
[2025-08-07 21:40:10 train.log] INFO: Epoch: [25]  [Step 6400/14540]  lr: 0.000005  loss: 1.20782  detection_loss: 1.1273 (cls: 0.2771, box: 0.8503)  rpn_loss: 0.0805 (cls: 0.0456, box: 0.0349)
[2025-08-07 21:40:15 train.log] INFO: Epoch: [25]  [Step 6500/14540]  lr: 0.000005  loss: 0.53418  detection_loss: 0.4239 (cls: 0.1055, box: 0.3185)  rpn_loss: 0.1103 (cls: 0.0579, box: 0.0524)
[2025-08-07 21:40:21 train.log] INFO: Epoch: [25]  [Step 6600/14540]  lr: 0.000005  loss: 1.02404  detection_loss: 0.8999 (cls: 0.2408, box: 0.6592)  rpn_loss: 0.1241 (cls: 0.0806, box: 0.0435)
[2025-08-07 21:40:27 train.log] INFO: Epoch: [25]  [Step 6700/14540]  lr: 0.000005  loss: 1.35269  detection_loss: 0.9800 (cls: 0.2583, box: 0.7217)  rpn_loss: 0.3727 (cls: 0.0358, box: 0.3368)
[2025-08-07 21:40:33 train.log] INFO: Epoch: [25]  [Step 6800/14540]  lr: 0.000005  loss: 0.55285  detection_loss: 0.4781 (cls: 0.1185, box: 0.3596)  rpn_loss: 0.0748 (cls: 0.0425, box: 0.0322)
[2025-08-07 21:40:38 train.log] INFO: Epoch: [25]  [Step 6900/14540]  lr: 0.000005  loss: 1.13163  detection_loss: 0.9960 (cls: 0.2653, box: 0.7307)  rpn_loss: 0.1357 (cls: 0.0959, box: 0.0397)
[2025-08-07 21:40:44 train.log] INFO: Epoch: [25]  [Step 7000/14540]  lr: 0.000005  loss: 0.87386  detection_loss: 0.7826 (cls: 0.1843, box: 0.5983)  rpn_loss: 0.0913 (cls: 0.0188, box: 0.0725)
[2025-08-07 21:40:49 train.log] INFO: Epoch: [25]  [Step 7100/14540]  lr: 0.000005  loss: 0.61919  detection_loss: 0.5818 (cls: 0.1626, box: 0.4191)  rpn_loss: 0.0374 (cls: 0.0156, box: 0.0218)
[2025-08-07 21:40:55 train.log] INFO: Epoch: [25]  [Step 7200/14540]  lr: 0.000005  loss: 1.15643  detection_loss: 0.9846 (cls: 0.3152, box: 0.6695)  rpn_loss: 0.1718 (cls: 0.0975, box: 0.0743)
[2025-08-07 21:41:01 train.log] INFO: Epoch: [25]  [Step 7300/14540]  lr: 0.000005  loss: 0.63845  detection_loss: 0.5280 (cls: 0.0948, box: 0.4332)  rpn_loss: 0.1104 (cls: 0.0989, box: 0.0116)
[2025-08-07 21:41:07 train.log] INFO: Epoch: [25]  [Step 7400/14540]  lr: 0.000005  loss: 1.20966  detection_loss: 1.0940 (cls: 0.1642, box: 0.9298)  rpn_loss: 0.1157 (cls: 0.0234, box: 0.0923)
[2025-08-07 21:41:12 train.log] INFO: Epoch: [25]  [Step 7500/14540]  lr: 0.000005  loss: 0.57523  detection_loss: 0.5061 (cls: 0.1946, box: 0.3115)  rpn_loss: 0.0692 (cls: 0.0241, box: 0.0451)
[2025-08-07 21:41:18 train.log] INFO: Epoch: [25]  [Step 7600/14540]  lr: 0.000005  loss: 1.03346  detection_loss: 0.8566 (cls: 0.3065, box: 0.5501)  rpn_loss: 0.1769 (cls: 0.0584, box: 0.1185)
[2025-08-07 21:41:24 train.log] INFO: Epoch: [25]  [Step 7700/14540]  lr: 0.000005  loss: 0.58980  detection_loss: 0.4840 (cls: 0.1141, box: 0.3699)  rpn_loss: 0.1058 (cls: 0.0771, box: 0.0287)
[2025-08-07 21:41:29 train.log] INFO: Epoch: [25]  [Step 7800/14540]  lr: 0.000005  loss: 0.57877  detection_loss: 0.5050 (cls: 0.1276, box: 0.3774)  rpn_loss: 0.0738 (cls: 0.0287, box: 0.0450)
[2025-08-07 21:41:35 train.log] INFO: Epoch: [25]  [Step 7900/14540]  lr: 0.000005  loss: 1.23008  detection_loss: 1.1673 (cls: 0.2794, box: 0.8879)  rpn_loss: 0.0628 (cls: 0.0261, box: 0.0367)
[2025-08-07 21:41:41 train.log] INFO: Epoch: [25]  [Step 8000/14540]  lr: 0.000005  loss: 1.13047  detection_loss: 1.0479 (cls: 0.2150, box: 0.8329)  rpn_loss: 0.0825 (cls: 0.0312, box: 0.0513)
[2025-08-07 21:41:46 train.log] INFO: Epoch: [25]  [Step 8100/14540]  lr: 0.000005  loss: 1.03291  detection_loss: 0.8822 (cls: 0.2223, box: 0.6599)  rpn_loss: 0.1507 (cls: 0.1205, box: 0.0302)
[2025-08-07 21:41:52 train.log] INFO: Epoch: [25]  [Step 8200/14540]  lr: 0.000005  loss: 0.85187  detection_loss: 0.7725 (cls: 0.2080, box: 0.5645)  rpn_loss: 0.0793 (cls: 0.0336, box: 0.0458)
[2025-08-07 21:41:57 train.log] INFO: Epoch: [25]  [Step 8300/14540]  lr: 0.000005  loss: 1.04681  detection_loss: 0.9661 (cls: 0.2195, box: 0.7467)  rpn_loss: 0.0807 (cls: 0.0203, box: 0.0604)
[2025-08-07 21:42:03 train.log] INFO: Epoch: [25]  [Step 8400/14540]  lr: 0.000005  loss: 1.23521  detection_loss: 1.1103 (cls: 0.3132, box: 0.7970)  rpn_loss: 0.1250 (cls: 0.0745, box: 0.0505)
[2025-08-07 21:42:09 train.log] INFO: Epoch: [25]  [Step 8500/14540]  lr: 0.000005  loss: 1.23306  detection_loss: 1.1201 (cls: 0.2710, box: 0.8491)  rpn_loss: 0.1130 (cls: 0.0426, box: 0.0703)
[2025-08-07 21:42:14 train.log] INFO: Epoch: [25]  [Step 8600/14540]  lr: 0.000005  loss: 1.03674  detection_loss: 0.9695 (cls: 0.2040, box: 0.7655)  rpn_loss: 0.0672 (cls: 0.0271, box: 0.0401)
[2025-08-07 21:42:20 train.log] INFO: Epoch: [25]  [Step 8700/14540]  lr: 0.000005  loss: 0.74432  detection_loss: 0.6484 (cls: 0.1744, box: 0.4740)  rpn_loss: 0.0959 (cls: 0.0362, box: 0.0597)
[2025-08-07 21:42:26 train.log] INFO: Epoch: [25]  [Step 8800/14540]  lr: 0.000005  loss: 1.02226  detection_loss: 0.8456 (cls: 0.1664, box: 0.6792)  rpn_loss: 0.1767 (cls: 0.0840, box: 0.0927)
[2025-08-07 21:42:31 train.log] INFO: Epoch: [25]  [Step 8900/14540]  lr: 0.000005  loss: 0.83574  detection_loss: 0.7405 (cls: 0.2364, box: 0.5040)  rpn_loss: 0.0953 (cls: 0.0621, box: 0.0332)
[2025-08-07 21:42:37 train.log] INFO: Epoch: [25]  [Step 9000/14540]  lr: 0.000005  loss: 0.62660  detection_loss: 0.5704 (cls: 0.0949, box: 0.4756)  rpn_loss: 0.0562 (cls: 0.0201, box: 0.0360)
[2025-08-07 21:42:43 train.log] INFO: Epoch: [25]  [Step 9100/14540]  lr: 0.000005  loss: 0.66988  detection_loss: 0.6154 (cls: 0.1453, box: 0.4701)  rpn_loss: 0.0545 (cls: 0.0130, box: 0.0414)
[2025-08-07 21:42:48 train.log] INFO: Epoch: [25]  [Step 9200/14540]  lr: 0.000005  loss: 0.59771  detection_loss: 0.5098 (cls: 0.1261, box: 0.3837)  rpn_loss: 0.0879 (cls: 0.0555, box: 0.0324)
[2025-08-07 21:42:54 train.log] INFO: Epoch: [25]  [Step 9300/14540]  lr: 0.000005  loss: 1.07298  detection_loss: 0.9391 (cls: 0.1715, box: 0.7676)  rpn_loss: 0.1339 (cls: 0.0294, box: 0.1045)
[2025-08-07 21:43:00 train.log] INFO: Epoch: [25]  [Step 9400/14540]  lr: 0.000005  loss: 1.07721  detection_loss: 0.9727 (cls: 0.1735, box: 0.7992)  rpn_loss: 0.1045 (cls: 0.0848, box: 0.0197)
[2025-08-07 21:43:05 train.log] INFO: Epoch: [25]  [Step 9500/14540]  lr: 0.000005  loss: 1.25448  detection_loss: 1.1528 (cls: 0.3457, box: 0.8071)  rpn_loss: 0.1017 (cls: 0.0612, box: 0.0404)
[2025-08-07 21:43:11 train.log] INFO: Epoch: [25]  [Step 9600/14540]  lr: 0.000005  loss: 1.49869  detection_loss: 1.3288 (cls: 0.2507, box: 1.0780)  rpn_loss: 0.1699 (cls: 0.0508, box: 0.1191)
[2025-08-07 21:43:16 train.log] INFO: Epoch: [25]  [Step 9700/14540]  lr: 0.000005  loss: 0.77600  detection_loss: 0.6654 (cls: 0.1408, box: 0.5247)  rpn_loss: 0.1106 (cls: 0.0521, box: 0.0584)
[2025-08-07 21:43:22 train.log] INFO: Epoch: [25]  [Step 9800/14540]  lr: 0.000005  loss: 0.39058  detection_loss: 0.3266 (cls: 0.1085, box: 0.2181)  rpn_loss: 0.0640 (cls: 0.0337, box: 0.0303)
[2025-08-07 21:43:28 train.log] INFO: Epoch: [25]  [Step 9900/14540]  lr: 0.000005  loss: 0.71409  detection_loss: 0.6221 (cls: 0.2241, box: 0.3980)  rpn_loss: 0.0920 (cls: 0.0631, box: 0.0289)
[2025-08-07 21:43:33 train.log] INFO: Epoch: [25]  [Step 10000/14540]  lr: 0.000005  loss: 0.52220  detection_loss: 0.4509 (cls: 0.1459, box: 0.3051)  rpn_loss: 0.0713 (cls: 0.0548, box: 0.0165)
[2025-08-07 21:43:39 train.log] INFO: Epoch: [25]  [Step 10100/14540]  lr: 0.000005  loss: 1.23563  detection_loss: 1.0444 (cls: 0.2635, box: 0.7810)  rpn_loss: 0.1912 (cls: 0.0301, box: 0.1611)
[2025-08-07 21:43:45 train.log] INFO: Epoch: [25]  [Step 10200/14540]  lr: 0.000005  loss: 0.82530  detection_loss: 0.7489 (cls: 0.1929, box: 0.5561)  rpn_loss: 0.0764 (cls: 0.0412, box: 0.0352)
[2025-08-07 21:43:50 train.log] INFO: Epoch: [25]  [Step 10300/14540]  lr: 0.000005  loss: 1.51758  detection_loss: 1.2130 (cls: 0.4857, box: 0.7273)  rpn_loss: 0.3046 (cls: 0.0755, box: 0.2291)
[2025-08-07 21:43:56 train.log] INFO: Epoch: [25]  [Step 10400/14540]  lr: 0.000005  loss: 1.27765  detection_loss: 1.2076 (cls: 0.2711, box: 0.9365)  rpn_loss: 0.0701 (cls: 0.0266, box: 0.0434)
[2025-08-07 21:44:02 train.log] INFO: Epoch: [25]  [Step 10500/14540]  lr: 0.000005  loss: 0.89358  detection_loss: 0.6821 (cls: 0.1682, box: 0.5139)  rpn_loss: 0.2115 (cls: 0.0434, box: 0.1681)
[2025-08-07 21:44:07 train.log] INFO: Epoch: [25]  [Step 10600/14540]  lr: 0.000005  loss: 1.05503  detection_loss: 0.9336 (cls: 0.1944, box: 0.7392)  rpn_loss: 0.1215 (cls: 0.0359, box: 0.0855)
[2025-08-07 21:44:13 train.log] INFO: Epoch: [25]  [Step 10700/14540]  lr: 0.000005  loss: 1.21235  detection_loss: 1.1063 (cls: 0.1816, box: 0.9247)  rpn_loss: 0.1061 (cls: 0.0224, box: 0.0837)
[2025-08-07 21:44:19 train.log] INFO: Epoch: [25]  [Step 10800/14540]  lr: 0.000005  loss: 0.49577  detection_loss: 0.4369 (cls: 0.1563, box: 0.2806)  rpn_loss: 0.0589 (cls: 0.0164, box: 0.0425)
[2025-08-07 21:44:24 train.log] INFO: Epoch: [25]  [Step 10900/14540]  lr: 0.000005  loss: 0.76955  detection_loss: 0.6622 (cls: 0.1614, box: 0.5008)  rpn_loss: 0.1073 (cls: 0.0416, box: 0.0657)
[2025-08-07 21:44:30 train.log] INFO: Epoch: [25]  [Step 11000/14540]  lr: 0.000005  loss: 1.47925  detection_loss: 1.3133 (cls: 0.3677, box: 0.9456)  rpn_loss: 0.1659 (cls: 0.1260, box: 0.0399)
[2025-08-07 21:44:36 train.log] INFO: Epoch: [25]  [Step 11100/14540]  lr: 0.000005  loss: 0.77035  detection_loss: 0.6787 (cls: 0.1768, box: 0.5019)  rpn_loss: 0.0916 (cls: 0.0319, box: 0.0597)
[2025-08-07 21:44:41 train.log] INFO: Epoch: [25]  [Step 11200/14540]  lr: 0.000005  loss: 1.24490  detection_loss: 1.1464 (cls: 0.2103, box: 0.9361)  rpn_loss: 0.0985 (cls: 0.0450, box: 0.0535)
[2025-08-07 21:44:47 train.log] INFO: Epoch: [25]  [Step 11300/14540]  lr: 0.000005  loss: 1.44348  detection_loss: 1.2438 (cls: 0.2044, box: 1.0394)  rpn_loss: 0.1997 (cls: 0.0343, box: 0.1654)
[2025-08-07 21:44:53 train.log] INFO: Epoch: [25]  [Step 11400/14540]  lr: 0.000005  loss: 1.53964  detection_loss: 1.4532 (cls: 0.2524, box: 1.2008)  rpn_loss: 0.0864 (cls: 0.0464, box: 0.0400)
[2025-08-07 21:44:58 train.log] INFO: Epoch: [25]  [Step 11500/14540]  lr: 0.000005  loss: 0.66720  detection_loss: 0.5752 (cls: 0.1075, box: 0.4677)  rpn_loss: 0.0920 (cls: 0.0314, box: 0.0606)
[2025-08-07 21:45:04 train.log] INFO: Epoch: [25]  [Step 11600/14540]  lr: 0.000005  loss: 1.39603  detection_loss: 0.9709 (cls: 0.2214, box: 0.7495)  rpn_loss: 0.4251 (cls: 0.0845, box: 0.3406)
[2025-08-07 21:45:09 train.log] INFO: Epoch: [25]  [Step 11700/14540]  lr: 0.000005  loss: 0.87551  detection_loss: 0.8016 (cls: 0.2054, box: 0.5962)  rpn_loss: 0.0740 (cls: 0.0456, box: 0.0283)
[2025-08-07 21:45:15 train.log] INFO: Epoch: [25]  [Step 11800/14540]  lr: 0.000005  loss: 0.91416  detection_loss: 0.8262 (cls: 0.2615, box: 0.5647)  rpn_loss: 0.0880 (cls: 0.0439, box: 0.0441)
[2025-08-07 21:45:21 train.log] INFO: Epoch: [25]  [Step 11900/14540]  lr: 0.000005  loss: 0.63650  detection_loss: 0.5804 (cls: 0.2234, box: 0.3570)  rpn_loss: 0.0561 (cls: 0.0365, box: 0.0196)
[2025-08-07 21:45:26 train.log] INFO: Epoch: [25]  [Step 12000/14540]  lr: 0.000005  loss: 0.58683  detection_loss: 0.5379 (cls: 0.1630, box: 0.3749)  rpn_loss: 0.0490 (cls: 0.0271, box: 0.0219)
[2025-08-07 21:45:32 train.log] INFO: Epoch: [25]  [Step 12100/14540]  lr: 0.000005  loss: 0.66628  detection_loss: 0.6289 (cls: 0.1061, box: 0.5228)  rpn_loss: 0.0374 (cls: 0.0218, box: 0.0156)
[2025-08-07 21:45:37 train.log] INFO: Epoch: [25]  [Step 12200/14540]  lr: 0.000005  loss: 0.69789  detection_loss: 0.6358 (cls: 0.2693, box: 0.3665)  rpn_loss: 0.0621 (cls: 0.0119, box: 0.0502)
[2025-08-07 21:45:43 train.log] INFO: Epoch: [25]  [Step 12300/14540]  lr: 0.000005  loss: 0.98526  detection_loss: 0.8916 (cls: 0.2211, box: 0.6704)  rpn_loss: 0.0937 (cls: 0.0443, box: 0.0494)
[2025-08-07 21:45:49 train.log] INFO: Epoch: [25]  [Step 12400/14540]  lr: 0.000005  loss: 0.75963  detection_loss: 0.6947 (cls: 0.1822, box: 0.5125)  rpn_loss: 0.0650 (cls: 0.0294, box: 0.0355)
[2025-08-07 21:45:54 train.log] INFO: Epoch: [25]  [Step 12500/14540]  lr: 0.000005  loss: 0.80619  detection_loss: 0.7120 (cls: 0.2004, box: 0.5117)  rpn_loss: 0.0942 (cls: 0.0680, box: 0.0261)
[2025-08-07 21:46:00 train.log] INFO: Epoch: [25]  [Step 12600/14540]  lr: 0.000005  loss: 1.20855  detection_loss: 1.1073 (cls: 0.3210, box: 0.7863)  rpn_loss: 0.1013 (cls: 0.0542, box: 0.0471)
[2025-08-07 21:46:06 train.log] INFO: Epoch: [25]  [Step 12700/14540]  lr: 0.000005  loss: 0.69155  detection_loss: 0.6476 (cls: 0.1082, box: 0.5393)  rpn_loss: 0.0440 (cls: 0.0287, box: 0.0153)
[2025-08-07 21:46:11 train.log] INFO: Epoch: [25]  [Step 12800/14540]  lr: 0.000005  loss: 1.16617  detection_loss: 1.0289 (cls: 0.1934, box: 0.8355)  rpn_loss: 0.1373 (cls: 0.0279, box: 0.1094)
[2025-08-07 21:46:17 train.log] INFO: Epoch: [25]  [Step 12900/14540]  lr: 0.000005  loss: 0.67608  detection_loss: 0.3748 (cls: 0.1062, box: 0.2687)  rpn_loss: 0.3013 (cls: 0.0135, box: 0.2878)
[2025-08-07 21:46:23 train.log] INFO: Epoch: [25]  [Step 13000/14540]  lr: 0.000005  loss: 0.95617  detection_loss: 0.8665 (cls: 0.1988, box: 0.6677)  rpn_loss: 0.0897 (cls: 0.0486, box: 0.0411)
[2025-08-07 21:46:28 train.log] INFO: Epoch: [25]  [Step 13100/14540]  lr: 0.000005  loss: 0.89888  detection_loss: 0.7398 (cls: 0.2081, box: 0.5316)  rpn_loss: 0.1591 (cls: 0.1132, box: 0.0459)
[2025-08-07 21:46:34 train.log] INFO: Epoch: [25]  [Step 13200/14540]  lr: 0.000005  loss: 0.47039  detection_loss: 0.4194 (cls: 0.1195, box: 0.2999)  rpn_loss: 0.0510 (cls: 0.0323, box: 0.0186)
[2025-08-07 21:46:40 train.log] INFO: Epoch: [25]  [Step 13300/14540]  lr: 0.000005  loss: 1.07791  detection_loss: 0.9045 (cls: 0.2293, box: 0.6752)  rpn_loss: 0.1734 (cls: 0.0413, box: 0.1320)
[2025-08-07 21:46:46 train.log] INFO: Epoch: [25]  [Step 13400/14540]  lr: 0.000005  loss: 0.91135  detection_loss: 0.8474 (cls: 0.1576, box: 0.6898)  rpn_loss: 0.0640 (cls: 0.0414, box: 0.0226)
[2025-08-07 21:46:52 train.log] INFO: Epoch: [25]  [Step 13500/14540]  lr: 0.000005  loss: 0.80663  detection_loss: 0.6807 (cls: 0.2203, box: 0.4603)  rpn_loss: 0.1260 (cls: 0.0586, box: 0.0674)
[2025-08-07 21:46:57 train.log] INFO: Epoch: [25]  [Step 13600/14540]  lr: 0.000005  loss: 0.31409  detection_loss: 0.2798 (cls: 0.0763, box: 0.2035)  rpn_loss: 0.0343 (cls: 0.0214, box: 0.0129)
[2025-08-07 21:47:03 train.log] INFO: Epoch: [25]  [Step 13700/14540]  lr: 0.000005  loss: 0.82144  detection_loss: 0.7326 (cls: 0.1331, box: 0.5995)  rpn_loss: 0.0888 (cls: 0.0391, box: 0.0497)
[2025-08-07 21:47:09 train.log] INFO: Epoch: [25]  [Step 13800/14540]  lr: 0.000005  loss: 1.46555  detection_loss: 1.3203 (cls: 0.4081, box: 0.9122)  rpn_loss: 0.1452 (cls: 0.1035, box: 0.0417)
[2025-08-07 21:47:14 train.log] INFO: Epoch: [25]  [Step 13900/14540]  lr: 0.000005  loss: 1.26113  detection_loss: 1.0850 (cls: 0.2875, box: 0.7975)  rpn_loss: 0.1762 (cls: 0.0906, box: 0.0856)
[2025-08-07 21:47:20 train.log] INFO: Epoch: [25]  [Step 14000/14540]  lr: 0.000005  loss: 0.62500  detection_loss: 0.4655 (cls: 0.1173, box: 0.3482)  rpn_loss: 0.1595 (cls: 0.1376, box: 0.0219)
[2025-08-07 21:47:26 train.log] INFO: Epoch: [25]  [Step 14100/14540]  lr: 0.000005  loss: 0.99789  detection_loss: 0.8791 (cls: 0.2117, box: 0.6674)  rpn_loss: 0.1188 (cls: 0.0708, box: 0.0480)
[2025-08-07 21:47:31 train.log] INFO: Epoch: [25]  [Step 14200/14540]  lr: 0.000005  loss: 1.15705  detection_loss: 1.0364 (cls: 0.3804, box: 0.6560)  rpn_loss: 0.1207 (cls: 0.0551, box: 0.0656)
[2025-08-07 21:47:37 train.log] INFO: Epoch: [25]  [Step 14300/14540]  lr: 0.000005  loss: 0.71928  detection_loss: 0.6476 (cls: 0.1981, box: 0.4495)  rpn_loss: 0.0717 (cls: 0.0147, box: 0.0570)
[2025-08-07 21:47:43 train.log] INFO: Epoch: [25]  [Step 14400/14540]  lr: 0.000005  loss: 1.00960  detection_loss: 0.8749 (cls: 0.2152, box: 0.6597)  rpn_loss: 0.1347 (cls: 0.0776, box: 0.0571)
[2025-08-07 21:47:48 train.log] INFO: Epoch: [25]  [Step 14500/14540]  lr: 0.000005  loss: 0.80400  detection_loss: 0.7245 (cls: 0.2068, box: 0.5177)  rpn_loss: 0.0795 (cls: 0.0161, box: 0.0634)
[2025-08-07 21:51:15 train.log] INFO: Epoch: [26]  [Step 100/14540]  lr: 0.000003  loss: 0.80734  detection_loss: 0.5983 (cls: 0.2254, box: 0.3729)  rpn_loss: 0.2091 (cls: 0.0628, box: 0.1463)
[2025-08-07 21:51:21 train.log] INFO: Epoch: [26]  [Step 200/14540]  lr: 0.000003  loss: 1.46189  detection_loss: 1.3553 (cls: 0.2564, box: 1.0990)  rpn_loss: 0.1066 (cls: 0.0514, box: 0.0551)
[2025-08-07 21:51:27 train.log] INFO: Epoch: [26]  [Step 300/14540]  lr: 0.000003  loss: 1.16619  detection_loss: 1.0424 (cls: 0.1545, box: 0.8880)  rpn_loss: 0.1238 (cls: 0.0192, box: 0.1046)
[2025-08-07 21:51:33 train.log] INFO: Epoch: [26]  [Step 400/14540]  lr: 0.000003  loss: 1.34285  detection_loss: 1.2160 (cls: 0.2200, box: 0.9960)  rpn_loss: 0.1269 (cls: 0.0854, box: 0.0415)
[2025-08-07 21:51:40 train.log] INFO: Epoch: [26]  [Step 500/14540]  lr: 0.000003  loss: 0.75592  detection_loss: 0.6781 (cls: 0.2064, box: 0.4717)  rpn_loss: 0.0778 (cls: 0.0364, box: 0.0414)
[2025-08-07 21:51:45 train.log] INFO: Epoch: [26]  [Step 600/14540]  lr: 0.000003  loss: 0.90671  detection_loss: 0.7730 (cls: 0.1614, box: 0.6115)  rpn_loss: 0.1337 (cls: 0.0400, box: 0.0937)
[2025-08-07 21:51:51 train.log] INFO: Epoch: [26]  [Step 700/14540]  lr: 0.000003  loss: 1.59423  detection_loss: 1.4783 (cls: 0.3098, box: 1.1685)  rpn_loss: 0.1159 (cls: 0.0428, box: 0.0732)
[2025-08-07 21:51:57 train.log] INFO: Epoch: [26]  [Step 800/14540]  lr: 0.000003  loss: 1.19924  detection_loss: 1.0526 (cls: 0.2258, box: 0.8268)  rpn_loss: 0.1467 (cls: 0.1257, box: 0.0210)
[2025-08-07 21:52:03 train.log] INFO: Epoch: [26]  [Step 900/14540]  lr: 0.000003  loss: 0.87983  detection_loss: 0.7981 (cls: 0.1924, box: 0.6057)  rpn_loss: 0.0817 (cls: 0.0293, box: 0.0524)
[2025-08-07 21:52:08 train.log] INFO: Epoch: [26]  [Step 1000/14540]  lr: 0.000003  loss: 1.17210  detection_loss: 1.0524 (cls: 0.3155, box: 0.7369)  rpn_loss: 0.1197 (cls: 0.0777, box: 0.0420)
[2025-08-07 21:52:14 train.log] INFO: Epoch: [26]  [Step 1100/14540]  lr: 0.000003  loss: 0.78852  detection_loss: 0.7105 (cls: 0.1742, box: 0.5364)  rpn_loss: 0.0780 (cls: 0.0392, box: 0.0387)
[2025-08-07 21:52:19 train.log] INFO: Epoch: [26]  [Step 1200/14540]  lr: 0.000003  loss: 1.03741  detection_loss: 0.8887 (cls: 0.3104, box: 0.5784)  rpn_loss: 0.1487 (cls: 0.1146, box: 0.0341)
[2025-08-07 21:52:25 train.log] INFO: Epoch: [26]  [Step 1300/14540]  lr: 0.000003  loss: 0.76844  detection_loss: 0.6505 (cls: 0.1972, box: 0.4533)  rpn_loss: 0.1180 (cls: 0.0974, box: 0.0205)
[2025-08-07 21:52:31 train.log] INFO: Epoch: [26]  [Step 1400/14540]  lr: 0.000003  loss: 0.64567  detection_loss: 0.5827 (cls: 0.1708, box: 0.4119)  rpn_loss: 0.0630 (cls: 0.0241, box: 0.0389)
[2025-08-07 21:52:37 train.log] INFO: Epoch: [26]  [Step 1500/14540]  lr: 0.000003  loss: 1.14529  detection_loss: 1.0573 (cls: 0.2849, box: 0.7724)  rpn_loss: 0.0880 (cls: 0.0381, box: 0.0499)
[2025-08-07 21:52:42 train.log] INFO: Epoch: [26]  [Step 1600/14540]  lr: 0.000003  loss: 0.69037  detection_loss: 0.6428 (cls: 0.1421, box: 0.5007)  rpn_loss: 0.0476 (cls: 0.0202, box: 0.0274)
[2025-08-07 21:52:48 train.log] INFO: Epoch: [26]  [Step 1700/14540]  lr: 0.000003  loss: 0.87670  detection_loss: 0.7375 (cls: 0.1923, box: 0.5453)  rpn_loss: 0.1392 (cls: 0.0529, box: 0.0862)
[2025-08-07 21:52:54 train.log] INFO: Epoch: [26]  [Step 1800/14540]  lr: 0.000003  loss: 1.09897  detection_loss: 0.9643 (cls: 0.3002, box: 0.6641)  rpn_loss: 0.1347 (cls: 0.0875, box: 0.0472)
[2025-08-07 21:52:59 train.log] INFO: Epoch: [26]  [Step 1900/14540]  lr: 0.000003  loss: 0.94524  detection_loss: 0.8017 (cls: 0.2608, box: 0.5408)  rpn_loss: 0.1436 (cls: 0.1011, box: 0.0425)
[2025-08-07 21:53:05 train.log] INFO: Epoch: [26]  [Step 2000/14540]  lr: 0.000003  loss: 0.79473  detection_loss: 0.6778 (cls: 0.1527, box: 0.5251)  rpn_loss: 0.1169 (cls: 0.0667, box: 0.0503)
[2025-08-07 21:53:11 train.log] INFO: Epoch: [26]  [Step 2100/14540]  lr: 0.000003  loss: 0.49208  detection_loss: 0.3938 (cls: 0.0560, box: 0.3378)  rpn_loss: 0.0983 (cls: 0.0130, box: 0.0852)
[2025-08-07 21:53:16 train.log] INFO: Epoch: [26]  [Step 2200/14540]  lr: 0.000003  loss: 0.92309  detection_loss: 0.8605 (cls: 0.2543, box: 0.6062)  rpn_loss: 0.0626 (cls: 0.0451, box: 0.0175)
[2025-08-07 21:53:22 train.log] INFO: Epoch: [26]  [Step 2300/14540]  lr: 0.000003  loss: 1.79536  detection_loss: 1.6425 (cls: 0.6113, box: 1.0312)  rpn_loss: 0.1529 (cls: 0.0920, box: 0.0608)
[2025-08-07 21:53:28 train.log] INFO: Epoch: [26]  [Step 2400/14540]  lr: 0.000003  loss: 0.84500  detection_loss: 0.7755 (cls: 0.1998, box: 0.5757)  rpn_loss: 0.0695 (cls: 0.0452, box: 0.0243)
[2025-08-07 21:53:33 train.log] INFO: Epoch: [26]  [Step 2500/14540]  lr: 0.000003  loss: 0.75711  detection_loss: 0.6647 (cls: 0.1818, box: 0.4829)  rpn_loss: 0.0924 (cls: 0.0546, box: 0.0378)
[2025-08-07 21:53:39 train.log] INFO: Epoch: [26]  [Step 2600/14540]  lr: 0.000003  loss: 1.25155  detection_loss: 1.1201 (cls: 0.3203, box: 0.7998)  rpn_loss: 0.1314 (cls: 0.0928, box: 0.0386)
[2025-08-07 21:53:45 train.log] INFO: Epoch: [26]  [Step 2700/14540]  lr: 0.000003  loss: 0.99357  detection_loss: 0.8187 (cls: 0.2000, box: 0.6187)  rpn_loss: 0.1749 (cls: 0.0974, box: 0.0775)
[2025-08-07 21:53:50 train.log] INFO: Epoch: [26]  [Step 2800/14540]  lr: 0.000003  loss: 0.55553  detection_loss: 0.4874 (cls: 0.0701, box: 0.4173)  rpn_loss: 0.0681 (cls: 0.0277, box: 0.0404)
[2025-08-07 21:53:56 train.log] INFO: Epoch: [26]  [Step 2900/14540]  lr: 0.000003  loss: 0.88790  detection_loss: 0.8158 (cls: 0.2165, box: 0.5993)  rpn_loss: 0.0721 (cls: 0.0391, box: 0.0330)
[2025-08-07 21:54:02 train.log] INFO: Epoch: [26]  [Step 3000/14540]  lr: 0.000003  loss: 0.94526  detection_loss: 0.8935 (cls: 0.2093, box: 0.6842)  rpn_loss: 0.0518 (cls: 0.0273, box: 0.0245)
[2025-08-07 21:54:07 train.log] INFO: Epoch: [26]  [Step 3100/14540]  lr: 0.000003  loss: 1.10277  detection_loss: 1.0057 (cls: 0.2757, box: 0.7300)  rpn_loss: 0.0971 (cls: 0.0379, box: 0.0592)
[2025-08-07 21:54:13 train.log] INFO: Epoch: [26]  [Step 3200/14540]  lr: 0.000003  loss: 0.92110  detection_loss: 0.7845 (cls: 0.1826, box: 0.6019)  rpn_loss: 0.1366 (cls: 0.0837, box: 0.0529)
[2025-08-07 21:54:19 train.log] INFO: Epoch: [26]  [Step 3300/14540]  lr: 0.000003  loss: 1.53729  detection_loss: 1.2824 (cls: 0.4367, box: 0.8457)  rpn_loss: 0.2549 (cls: 0.0883, box: 0.1666)
[2025-08-07 21:54:24 train.log] INFO: Epoch: [26]  [Step 3400/14540]  lr: 0.000003  loss: 0.89424  detection_loss: 0.7590 (cls: 0.1917, box: 0.5673)  rpn_loss: 0.1353 (cls: 0.0586, box: 0.0767)
[2025-08-07 21:54:30 train.log] INFO: Epoch: [26]  [Step 3500/14540]  lr: 0.000003  loss: 1.25584  detection_loss: 1.1198 (cls: 0.2052, box: 0.9146)  rpn_loss: 0.1361 (cls: 0.0279, box: 0.1082)
[2025-08-07 21:54:36 train.log] INFO: Epoch: [26]  [Step 3600/14540]  lr: 0.000003  loss: 0.78832  detection_loss: 0.7127 (cls: 0.1446, box: 0.5681)  rpn_loss: 0.0756 (cls: 0.0297, box: 0.0459)
[2025-08-07 21:54:38 train.log] INFO: Epoch: [26]  [Step 3635/14540]  lr: 0.000003  loss: 1.28075  detection_loss: 1.1765 (cls: 0.2732, box: 0.9033)  rpn_loss: 0.1043 (cls: 0.0475, box: 0.0568)
[2025-08-07 21:54:41 train.log] INFO: Epoch: [26]  [Step 3700/14540]  lr: 0.000003  loss: 0.83793  detection_loss: 0.7397 (cls: 0.1314, box: 0.6083)  rpn_loss: 0.0983 (cls: 0.0488, box: 0.0494)
[2025-08-07 21:54:47 train.log] INFO: Epoch: [26]  [Step 3800/14540]  lr: 0.000003  loss: 0.99702  detection_loss: 0.8017 (cls: 0.2528, box: 0.5489)  rpn_loss: 0.1954 (cls: 0.1204, box: 0.0750)
[2025-08-07 21:54:53 train.log] INFO: Epoch: [26]  [Step 3900/14540]  lr: 0.000003  loss: 1.22755  detection_loss: 1.1301 (cls: 0.2701, box: 0.8600)  rpn_loss: 0.0974 (cls: 0.0352, box: 0.0622)
[2025-08-07 21:54:58 train.log] INFO: Epoch: [26]  [Step 4000/14540]  lr: 0.000003  loss: 0.63433  detection_loss: 0.5857 (cls: 0.1254, box: 0.4603)  rpn_loss: 0.0486 (cls: 0.0198, box: 0.0288)
[2025-08-07 21:55:03 train.log] INFO: Epoch: [26]  [Step 4100/14540]  lr: 0.000003  loss: 0.95496  detection_loss: 0.7634 (cls: 0.1541, box: 0.6093)  rpn_loss: 0.1916 (cls: 0.0270, box: 0.1646)
[2025-08-07 21:55:09 train.log] INFO: Epoch: [26]  [Step 4200/14540]  lr: 0.000003  loss: 0.84019  detection_loss: 0.7901 (cls: 0.2234, box: 0.5667)  rpn_loss: 0.0501 (cls: 0.0246, box: 0.0255)
[2025-08-07 21:55:15 train.log] INFO: Epoch: [26]  [Step 4300/14540]  lr: 0.000003  loss: 0.87813  detection_loss: 0.7166 (cls: 0.2287, box: 0.4879)  rpn_loss: 0.1615 (cls: 0.0577, box: 0.1038)
[2025-08-07 21:55:20 train.log] INFO: Epoch: [26]  [Step 4400/14540]  lr: 0.000003  loss: 0.63799  detection_loss: 0.5567 (cls: 0.1828, box: 0.3739)  rpn_loss: 0.0813 (cls: 0.0592, box: 0.0221)
[2025-08-07 21:55:26 train.log] INFO: Epoch: [26]  [Step 4500/14540]  lr: 0.000003  loss: 0.72168  detection_loss: 0.6565 (cls: 0.0543, box: 0.6022)  rpn_loss: 0.0652 (cls: 0.0170, box: 0.0482)
[2025-08-07 21:55:31 train.log] INFO: Epoch: [26]  [Step 4600/14540]  lr: 0.000003  loss: 0.94473  detection_loss: 0.8289 (cls: 0.2838, box: 0.5451)  rpn_loss: 0.1158 (cls: 0.0871, box: 0.0287)
[2025-08-07 21:55:37 train.log] INFO: Epoch: [26]  [Step 4700/14540]  lr: 0.000003  loss: 1.31835  detection_loss: 1.2533 (cls: 0.2981, box: 0.9552)  rpn_loss: 0.0650 (cls: 0.0343, box: 0.0308)
[2025-08-07 21:55:42 train.log] INFO: Epoch: [26]  [Step 4800/14540]  lr: 0.000003  loss: 0.76057  detection_loss: 0.6926 (cls: 0.1169, box: 0.5757)  rpn_loss: 0.0680 (cls: 0.0232, box: 0.0448)
[2025-08-07 21:55:48 train.log] INFO: Epoch: [26]  [Step 4900/14540]  lr: 0.000003  loss: 0.82427  detection_loss: 0.6826 (cls: 0.2070, box: 0.4755)  rpn_loss: 0.1417 (cls: 0.1054, box: 0.0363)
[2025-08-07 21:55:53 train.log] INFO: Epoch: [26]  [Step 5000/14540]  lr: 0.000003  loss: 0.94750  detection_loss: 0.8020 (cls: 0.2138, box: 0.5882)  rpn_loss: 0.1455 (cls: 0.0785, box: 0.0670)
[2025-08-07 21:55:59 train.log] INFO: Epoch: [26]  [Step 5100/14540]  lr: 0.000003  loss: 1.10978  detection_loss: 0.9803 (cls: 0.2025, box: 0.7778)  rpn_loss: 0.1295 (cls: 0.0902, box: 0.0393)
[2025-08-07 21:56:04 train.log] INFO: Epoch: [26]  [Step 5200/14540]  lr: 0.000003  loss: 0.77145  detection_loss: 0.6436 (cls: 0.1242, box: 0.5194)  rpn_loss: 0.1279 (cls: 0.1097, box: 0.0181)
[2025-08-07 21:56:10 train.log] INFO: Epoch: [26]  [Step 5300/14540]  lr: 0.000003  loss: 0.73952  detection_loss: 0.6477 (cls: 0.1525, box: 0.4952)  rpn_loss: 0.0918 (cls: 0.0580, box: 0.0338)
[2025-08-07 21:56:16 train.log] INFO: Epoch: [26]  [Step 5400/14540]  lr: 0.000003  loss: 0.58402  detection_loss: 0.5185 (cls: 0.2431, box: 0.2753)  rpn_loss: 0.0655 (cls: 0.0340, box: 0.0315)
[2025-08-07 21:56:21 train.log] INFO: Epoch: [26]  [Step 5500/14540]  lr: 0.000003  loss: 0.69543  detection_loss: 0.6165 (cls: 0.1729, box: 0.4436)  rpn_loss: 0.0789 (cls: 0.0576, box: 0.0213)
[2025-08-07 21:56:27 train.log] INFO: Epoch: [26]  [Step 5600/14540]  lr: 0.000003  loss: 0.79402  detection_loss: 0.6776 (cls: 0.1407, box: 0.5369)  rpn_loss: 0.1164 (cls: 0.0517, box: 0.0647)
[2025-08-07 21:56:33 train.log] INFO: Epoch: [26]  [Step 5700/14540]  lr: 0.000003  loss: 1.42263  detection_loss: 1.2539 (cls: 0.1814, box: 1.0725)  rpn_loss: 0.1688 (cls: 0.1067, box: 0.0621)
[2025-08-07 21:56:38 train.log] INFO: Epoch: [26]  [Step 5800/14540]  lr: 0.000003  loss: 0.93946  detection_loss: 0.8164 (cls: 0.2670, box: 0.5494)  rpn_loss: 0.1231 (cls: 0.0516, box: 0.0714)
[2025-08-07 21:56:44 train.log] INFO: Epoch: [26]  [Step 5900/14540]  lr: 0.000003  loss: 0.69031  detection_loss: 0.6232 (cls: 0.1776, box: 0.4457)  rpn_loss: 0.0671 (cls: 0.0396, box: 0.0275)
[2025-08-07 21:56:49 train.log] INFO: Epoch: [26]  [Step 6000/14540]  lr: 0.000003  loss: 1.05363  detection_loss: 0.8327 (cls: 0.2335, box: 0.5992)  rpn_loss: 0.2209 (cls: 0.1190, box: 0.1019)
[2025-08-07 21:56:55 train.log] INFO: Epoch: [26]  [Step 6100/14540]  lr: 0.000003  loss: 1.11283  detection_loss: 0.8241 (cls: 0.1283, box: 0.6959)  rpn_loss: 0.2887 (cls: 0.0810, box: 0.2077)
[2025-08-07 21:57:00 train.log] INFO: Epoch: [26]  [Step 6200/14540]  lr: 0.000003  loss: 1.40427  detection_loss: 1.2624 (cls: 0.2309, box: 1.0315)  rpn_loss: 0.1419 (cls: 0.1032, box: 0.0386)
[2025-08-07 21:57:06 train.log] INFO: Epoch: [26]  [Step 6300/14540]  lr: 0.000003  loss: 0.94204  detection_loss: 0.8268 (cls: 0.2916, box: 0.5351)  rpn_loss: 0.1153 (cls: 0.0536, box: 0.0617)
[2025-08-07 21:57:12 train.log] INFO: Epoch: [26]  [Step 6400/14540]  lr: 0.000003  loss: 0.90524  detection_loss: 0.6334 (cls: 0.1576, box: 0.4758)  rpn_loss: 0.2718 (cls: 0.0485, box: 0.2233)
[2025-08-07 21:57:17 train.log] INFO: Epoch: [26]  [Step 6500/14540]  lr: 0.000003  loss: 1.11113  detection_loss: 1.0371 (cls: 0.2246, box: 0.8125)  rpn_loss: 0.0740 (cls: 0.0356, box: 0.0385)
[2025-08-07 21:57:23 train.log] INFO: Epoch: [26]  [Step 6600/14540]  lr: 0.000003  loss: 1.14830  detection_loss: 1.0258 (cls: 0.1587, box: 0.8671)  rpn_loss: 0.1225 (cls: 0.0791, box: 0.0434)
[2025-08-07 21:57:29 train.log] INFO: Epoch: [26]  [Step 6700/14540]  lr: 0.000003  loss: 0.55918  detection_loss: 0.4596 (cls: 0.0753, box: 0.3842)  rpn_loss: 0.0996 (cls: 0.0707, box: 0.0290)
[2025-08-07 21:57:35 train.log] INFO: Epoch: [26]  [Step 6800/14540]  lr: 0.000003  loss: 0.96807  detection_loss: 0.7775 (cls: 0.1939, box: 0.5836)  rpn_loss: 0.1905 (cls: 0.1577, box: 0.0328)
[2025-08-07 21:57:40 train.log] INFO: Epoch: [26]  [Step 6900/14540]  lr: 0.000003  loss: 0.87430  detection_loss: 0.6735 (cls: 0.1826, box: 0.4908)  rpn_loss: 0.2008 (cls: 0.0479, box: 0.1530)
[2025-08-07 21:57:46 train.log] INFO: Epoch: [26]  [Step 7000/14540]  lr: 0.000003  loss: 0.71533  detection_loss: 0.6548 (cls: 0.1088, box: 0.5460)  rpn_loss: 0.0605 (cls: 0.0281, box: 0.0324)
[2025-08-07 21:57:52 train.log] INFO: Epoch: [26]  [Step 7100/14540]  lr: 0.000003  loss: 0.82801  detection_loss: 0.7319 (cls: 0.2064, box: 0.5255)  rpn_loss: 0.0961 (cls: 0.0718, box: 0.0243)
[2025-08-07 21:57:58 train.log] INFO: Epoch: [26]  [Step 7200/14540]  lr: 0.000003  loss: 0.67656  detection_loss: 0.4770 (cls: 0.1128, box: 0.3642)  rpn_loss: 0.1996 (cls: 0.0341, box: 0.1654)
[2025-08-07 21:58:04 train.log] INFO: Epoch: [26]  [Step 7300/14540]  lr: 0.000003  loss: 0.55587  detection_loss: 0.5247 (cls: 0.1298, box: 0.3950)  rpn_loss: 0.0312 (cls: 0.0188, box: 0.0124)
[2025-08-07 21:58:10 train.log] INFO: Epoch: [26]  [Step 7400/14540]  lr: 0.000003  loss: 1.31205  detection_loss: 1.1588 (cls: 0.2838, box: 0.8750)  rpn_loss: 0.1533 (cls: 0.0657, box: 0.0876)
[2025-08-07 21:58:15 train.log] INFO: Epoch: [26]  [Step 7500/14540]  lr: 0.000003  loss: 0.37731  detection_loss: 0.2734 (cls: 0.0850, box: 0.1884)  rpn_loss: 0.1039 (cls: 0.0331, box: 0.0708)
[2025-08-07 21:58:21 train.log] INFO: Epoch: [26]  [Step 7600/14540]  lr: 0.000003  loss: 0.66458  detection_loss: 0.5993 (cls: 0.1372, box: 0.4621)  rpn_loss: 0.0653 (cls: 0.0425, box: 0.0229)
[2025-08-07 21:58:27 train.log] INFO: Epoch: [26]  [Step 7700/14540]  lr: 0.000003  loss: 0.64557  detection_loss: 0.5661 (cls: 0.1663, box: 0.3999)  rpn_loss: 0.0794 (cls: 0.0292, box: 0.0502)
[2025-08-07 21:58:33 train.log] INFO: Epoch: [26]  [Step 7800/14540]  lr: 0.000003  loss: 0.89667  detection_loss: 0.7809 (cls: 0.1522, box: 0.6288)  rpn_loss: 0.1157 (cls: 0.0793, box: 0.0365)
[2025-08-07 21:58:38 train.log] INFO: Epoch: [26]  [Step 7900/14540]  lr: 0.000003  loss: 0.96296  detection_loss: 0.9274 (cls: 0.1232, box: 0.8042)  rpn_loss: 0.0356 (cls: 0.0116, box: 0.0240)
[2025-08-07 21:58:44 train.log] INFO: Epoch: [26]  [Step 8000/14540]  lr: 0.000003  loss: 0.90765  detection_loss: 0.8281 (cls: 0.2317, box: 0.5964)  rpn_loss: 0.0795 (cls: 0.0388, box: 0.0408)
[2025-08-07 21:58:50 train.log] INFO: Epoch: [26]  [Step 8100/14540]  lr: 0.000003  loss: 0.85203  detection_loss: 0.7004 (cls: 0.1919, box: 0.5085)  rpn_loss: 0.1516 (cls: 0.0265, box: 0.1251)
[2025-08-07 21:58:55 train.log] INFO: Epoch: [26]  [Step 8200/14540]  lr: 0.000003  loss: 0.58108  detection_loss: 0.5185 (cls: 0.1434, box: 0.3751)  rpn_loss: 0.0626 (cls: 0.0225, box: 0.0401)
[2025-08-07 21:59:01 train.log] INFO: Epoch: [26]  [Step 8300/14540]  lr: 0.000003  loss: 0.51148  detection_loss: 0.3662 (cls: 0.0850, box: 0.2812)  rpn_loss: 0.1453 (cls: 0.0991, box: 0.0462)
[2025-08-07 21:59:07 train.log] INFO: Epoch: [26]  [Step 8400/14540]  lr: 0.000003  loss: 0.71197  detection_loss: 0.6046 (cls: 0.1488, box: 0.4557)  rpn_loss: 0.1074 (cls: 0.0915, box: 0.0159)
[2025-08-07 21:59:12 train.log] INFO: Epoch: [26]  [Step 8500/14540]  lr: 0.000003  loss: 0.89461  detection_loss: 0.7754 (cls: 0.1517, box: 0.6237)  rpn_loss: 0.1192 (cls: 0.0111, box: 0.1081)
[2025-08-07 21:59:18 train.log] INFO: Epoch: [26]  [Step 8600/14540]  lr: 0.000003  loss: 1.26070  detection_loss: 1.1392 (cls: 0.2274, box: 0.9118)  rpn_loss: 0.1215 (cls: 0.0849, box: 0.0366)
[2025-08-07 21:59:24 train.log] INFO: Epoch: [26]  [Step 8700/14540]  lr: 0.000003  loss: 0.80923  detection_loss: 0.7549 (cls: 0.1873, box: 0.5676)  rpn_loss: 0.0543 (cls: 0.0312, box: 0.0231)
[2025-08-07 21:59:29 train.log] INFO: Epoch: [26]  [Step 8800/14540]  lr: 0.000003  loss: 0.96098  detection_loss: 0.8610 (cls: 0.1859, box: 0.6751)  rpn_loss: 0.1000 (cls: 0.0630, box: 0.0370)
[2025-08-07 21:59:35 train.log] INFO: Epoch: [26]  [Step 8900/14540]  lr: 0.000003  loss: 1.25134  detection_loss: 1.1227 (cls: 0.2346, box: 0.8881)  rpn_loss: 0.1286 (cls: 0.0850, box: 0.0436)
[2025-08-07 21:59:41 train.log] INFO: Epoch: [26]  [Step 9000/14540]  lr: 0.000003  loss: 0.85034  detection_loss: 0.7252 (cls: 0.1687, box: 0.5565)  rpn_loss: 0.1251 (cls: 0.0429, box: 0.0822)
[2025-08-07 21:59:46 train.log] INFO: Epoch: [26]  [Step 9100/14540]  lr: 0.000003  loss: 0.56569  detection_loss: 0.5157 (cls: 0.1473, box: 0.3683)  rpn_loss: 0.0500 (cls: 0.0280, box: 0.0220)
[2025-08-07 21:59:52 train.log] INFO: Epoch: [26]  [Step 9200/14540]  lr: 0.000003  loss: 0.92423  detection_loss: 0.7583 (cls: 0.1558, box: 0.6025)  rpn_loss: 0.1659 (cls: 0.0394, box: 0.1266)
[2025-08-07 21:59:58 train.log] INFO: Epoch: [26]  [Step 9300/14540]  lr: 0.000003  loss: 0.78612  detection_loss: 0.7279 (cls: 0.2989, box: 0.4290)  rpn_loss: 0.0582 (cls: 0.0221, box: 0.0361)
[2025-08-07 22:00:03 train.log] INFO: Epoch: [26]  [Step 9400/14540]  lr: 0.000003  loss: 1.09673  detection_loss: 1.0233 (cls: 0.1607, box: 0.8626)  rpn_loss: 0.0735 (cls: 0.0374, box: 0.0360)
[2025-08-07 22:00:09 train.log] INFO: Epoch: [26]  [Step 9500/14540]  lr: 0.000003  loss: 0.88041  detection_loss: 0.8075 (cls: 0.2237, box: 0.5838)  rpn_loss: 0.0730 (cls: 0.0338, box: 0.0392)
[2025-08-07 22:00:15 train.log] INFO: Epoch: [26]  [Step 9600/14540]  lr: 0.000003  loss: 0.59004  detection_loss: 0.5099 (cls: 0.1376, box: 0.3723)  rpn_loss: 0.0801 (cls: 0.0664, box: 0.0137)
[2025-08-07 22:00:20 train.log] INFO: Epoch: [26]  [Step 9700/14540]  lr: 0.000003  loss: 1.45263  detection_loss: 1.3725 (cls: 0.3854, box: 0.9870)  rpn_loss: 0.0802 (cls: 0.0369, box: 0.0433)
[2025-08-07 22:00:26 train.log] INFO: Epoch: [26]  [Step 9800/14540]  lr: 0.000003  loss: 0.90278  detection_loss: 0.8266 (cls: 0.1404, box: 0.6862)  rpn_loss: 0.0762 (cls: 0.0317, box: 0.0446)
[2025-08-07 22:00:31 train.log] INFO: Epoch: [26]  [Step 9900/14540]  lr: 0.000003  loss: 0.55790  detection_loss: 0.4983 (cls: 0.1528, box: 0.3455)  rpn_loss: 0.0596 (cls: 0.0295, box: 0.0301)
[2025-08-07 22:00:37 train.log] INFO: Epoch: [26]  [Step 10000/14540]  lr: 0.000003  loss: 0.52472  detection_loss: 0.4418 (cls: 0.0945, box: 0.3473)  rpn_loss: 0.0829 (cls: 0.0647, box: 0.0182)
[2025-08-07 22:00:43 train.log] INFO: Epoch: [26]  [Step 10100/14540]  lr: 0.000003  loss: 0.60299  detection_loss: 0.5613 (cls: 0.1604, box: 0.4008)  rpn_loss: 0.0417 (cls: 0.0337, box: 0.0081)
[2025-08-07 22:00:48 train.log] INFO: Epoch: [26]  [Step 10200/14540]  lr: 0.000003  loss: 0.61331  detection_loss: 0.5502 (cls: 0.1866, box: 0.3636)  rpn_loss: 0.0631 (cls: 0.0311, box: 0.0320)
[2025-08-07 22:00:54 train.log] INFO: Epoch: [26]  [Step 10300/14540]  lr: 0.000003  loss: 0.94262  detection_loss: 0.7972 (cls: 0.1403, box: 0.6569)  rpn_loss: 0.1454 (cls: 0.0904, box: 0.0550)
[2025-08-07 22:01:00 train.log] INFO: Epoch: [26]  [Step 10400/14540]  lr: 0.000003  loss: 0.81921  detection_loss: 0.7122 (cls: 0.2115, box: 0.5006)  rpn_loss: 0.1070 (cls: 0.0663, box: 0.0407)
[2025-08-07 22:01:05 train.log] INFO: Epoch: [26]  [Step 10500/14540]  lr: 0.000003  loss: 1.24563  detection_loss: 1.1639 (cls: 0.1855, box: 0.9784)  rpn_loss: 0.0817 (cls: 0.0264, box: 0.0553)
[2025-08-07 22:01:11 train.log] INFO: Epoch: [26]  [Step 10600/14540]  lr: 0.000003  loss: 0.85327  detection_loss: 0.7606 (cls: 0.2044, box: 0.5562)  rpn_loss: 0.0927 (cls: 0.0406, box: 0.0521)
[2025-08-07 22:01:17 train.log] INFO: Epoch: [26]  [Step 10700/14540]  lr: 0.000003  loss: 0.58070  detection_loss: 0.5380 (cls: 0.1163, box: 0.4218)  rpn_loss: 0.0427 (cls: 0.0237, box: 0.0190)
[2025-08-07 22:01:23 train.log] INFO: Epoch: [26]  [Step 10800/14540]  lr: 0.000003  loss: 0.93596  detection_loss: 0.8777 (cls: 0.1879, box: 0.6898)  rpn_loss: 0.0583 (cls: 0.0343, box: 0.0240)
[2025-08-07 22:01:28 train.log] INFO: Epoch: [26]  [Step 10900/14540]  lr: 0.000003  loss: 0.96035  detection_loss: 0.8868 (cls: 0.2309, box: 0.6558)  rpn_loss: 0.0736 (cls: 0.0456, box: 0.0280)
[2025-08-07 22:01:34 train.log] INFO: Epoch: [26]  [Step 11000/14540]  lr: 0.000003  loss: 0.78585  detection_loss: 0.6736 (cls: 0.1706, box: 0.5030)  rpn_loss: 0.1122 (cls: 0.0141, box: 0.0982)
[2025-08-07 22:01:39 train.log] INFO: Epoch: [26]  [Step 11100/14540]  lr: 0.000003  loss: 0.93421  detection_loss: 0.8045 (cls: 0.1833, box: 0.6212)  rpn_loss: 0.1297 (cls: 0.0900, box: 0.0397)
[2025-08-07 22:01:45 train.log] INFO: Epoch: [26]  [Step 11200/14540]  lr: 0.000003  loss: 1.04107  detection_loss: 0.9690 (cls: 0.2531, box: 0.7159)  rpn_loss: 0.0720 (cls: 0.0332, box: 0.0388)
[2025-08-07 22:01:51 train.log] INFO: Epoch: [26]  [Step 11300/14540]  lr: 0.000003  loss: 0.94315  detection_loss: 0.8036 (cls: 0.1720, box: 0.6315)  rpn_loss: 0.1396 (cls: 0.0259, box: 0.1137)
[2025-08-07 22:01:56 train.log] INFO: Epoch: [26]  [Step 11400/14540]  lr: 0.000003  loss: 0.93702  detection_loss: 0.8669 (cls: 0.2522, box: 0.6147)  rpn_loss: 0.0701 (cls: 0.0349, box: 0.0352)
[2025-08-07 22:02:02 train.log] INFO: Epoch: [26]  [Step 11500/14540]  lr: 0.000003  loss: 1.14636  detection_loss: 1.0452 (cls: 0.3290, box: 0.7161)  rpn_loss: 0.1012 (cls: 0.0625, box: 0.0387)
[2025-08-07 22:02:08 train.log] INFO: Epoch: [26]  [Step 11600/14540]  lr: 0.000003  loss: 1.02982  detection_loss: 0.9037 (cls: 0.2664, box: 0.6373)  rpn_loss: 0.1262 (cls: 0.0567, box: 0.0694)
[2025-08-07 22:02:13 train.log] INFO: Epoch: [26]  [Step 11700/14540]  lr: 0.000003  loss: 1.02102  detection_loss: 0.9448 (cls: 0.2337, box: 0.7111)  rpn_loss: 0.0762 (cls: 0.0291, box: 0.0471)
[2025-08-07 22:02:19 train.log] INFO: Epoch: [26]  [Step 11800/14540]  lr: 0.000003  loss: 1.29271  detection_loss: 1.1410 (cls: 0.3308, box: 0.8103)  rpn_loss: 0.1517 (cls: 0.1132, box: 0.0384)
[2025-08-07 22:02:24 train.log] INFO: Epoch: [26]  [Step 11900/14540]  lr: 0.000003  loss: 0.57499  detection_loss: 0.5240 (cls: 0.0933, box: 0.4307)  rpn_loss: 0.0510 (cls: 0.0222, box: 0.0288)
[2025-08-07 22:02:30 train.log] INFO: Epoch: [26]  [Step 12000/14540]  lr: 0.000003  loss: 1.14287  detection_loss: 1.0255 (cls: 0.2955, box: 0.7300)  rpn_loss: 0.1174 (cls: 0.0591, box: 0.0583)
[2025-08-07 22:02:36 train.log] INFO: Epoch: [26]  [Step 12100/14540]  lr: 0.000003  loss: 1.60924  detection_loss: 1.4598 (cls: 0.2552, box: 1.2047)  rpn_loss: 0.1494 (cls: 0.0970, box: 0.0524)
[2025-08-07 22:02:41 train.log] INFO: Epoch: [26]  [Step 12200/14540]  lr: 0.000003  loss: 0.61697  detection_loss: 0.5685 (cls: 0.1112, box: 0.4572)  rpn_loss: 0.0485 (cls: 0.0152, box: 0.0333)
[2025-08-07 22:02:47 train.log] INFO: Epoch: [26]  [Step 12300/14540]  lr: 0.000003  loss: 0.45046  detection_loss: 0.3709 (cls: 0.1070, box: 0.2640)  rpn_loss: 0.0795 (cls: 0.0343, box: 0.0453)
[2025-08-07 22:02:53 train.log] INFO: Epoch: [26]  [Step 12400/14540]  lr: 0.000003  loss: 0.97275  detection_loss: 0.8254 (cls: 0.3101, box: 0.5152)  rpn_loss: 0.1474 (cls: 0.1142, box: 0.0332)
[2025-08-07 22:02:59 train.log] INFO: Epoch: [26]  [Step 12500/14540]  lr: 0.000003  loss: 0.84457  detection_loss: 0.7531 (cls: 0.1692, box: 0.5839)  rpn_loss: 0.0914 (cls: 0.0519, box: 0.0396)
[2025-08-07 22:03:04 train.log] INFO: Epoch: [26]  [Step 12600/14540]  lr: 0.000003  loss: 0.91417  detection_loss: 0.7643 (cls: 0.2076, box: 0.5567)  rpn_loss: 0.1499 (cls: 0.1293, box: 0.0205)
[2025-08-07 22:03:10 train.log] INFO: Epoch: [26]  [Step 12700/14540]  lr: 0.000003  loss: 0.72362  detection_loss: 0.6391 (cls: 0.0903, box: 0.5488)  rpn_loss: 0.0845 (cls: 0.0152, box: 0.0693)
[2025-08-07 22:03:16 train.log] INFO: Epoch: [26]  [Step 12800/14540]  lr: 0.000003  loss: 1.32045  detection_loss: 1.1322 (cls: 0.3314, box: 0.8009)  rpn_loss: 0.1882 (cls: 0.1065, box: 0.0817)
[2025-08-07 22:03:22 train.log] INFO: Epoch: [26]  [Step 12900/14540]  lr: 0.000003  loss: 0.73388  detection_loss: 0.6485 (cls: 0.1320, box: 0.5166)  rpn_loss: 0.0853 (cls: 0.0667, box: 0.0186)
[2025-08-07 22:03:28 train.log] INFO: Epoch: [26]  [Step 13000/14540]  lr: 0.000003  loss: 0.90500  detection_loss: 0.7213 (cls: 0.0934, box: 0.6279)  rpn_loss: 0.1837 (cls: 0.0374, box: 0.1463)
[2025-08-07 22:03:33 train.log] INFO: Epoch: [26]  [Step 13100/14540]  lr: 0.000003  loss: 1.03910  detection_loss: 0.9627 (cls: 0.2756, box: 0.6872)  rpn_loss: 0.0764 (cls: 0.0308, box: 0.0456)
[2025-08-07 22:03:39 train.log] INFO: Epoch: [26]  [Step 13200/14540]  lr: 0.000003  loss: 0.39380  detection_loss: 0.3079 (cls: 0.1027, box: 0.2052)  rpn_loss: 0.0859 (cls: 0.0477, box: 0.0382)
[2025-08-07 22:03:45 train.log] INFO: Epoch: [26]  [Step 13300/14540]  lr: 0.000003  loss: 0.56983  detection_loss: 0.4918 (cls: 0.1477, box: 0.3441)  rpn_loss: 0.0781 (cls: 0.0647, box: 0.0134)
[2025-08-07 22:03:50 train.log] INFO: Epoch: [26]  [Step 13400/14540]  lr: 0.000003  loss: 0.83279  detection_loss: 0.6098 (cls: 0.1813, box: 0.4284)  rpn_loss: 0.2230 (cls: 0.1149, box: 0.1081)
[2025-08-07 22:03:56 train.log] INFO: Epoch: [26]  [Step 13500/14540]  lr: 0.000003  loss: 0.57901  detection_loss: 0.5305 (cls: 0.1512, box: 0.3793)  rpn_loss: 0.0485 (cls: 0.0300, box: 0.0185)
[2025-08-07 22:04:02 train.log] INFO: Epoch: [26]  [Step 13600/14540]  lr: 0.000003  loss: 0.65633  detection_loss: 0.4970 (cls: 0.0996, box: 0.3974)  rpn_loss: 0.1594 (cls: 0.0216, box: 0.1378)
[2025-08-07 22:04:07 train.log] INFO: Epoch: [26]  [Step 13700/14540]  lr: 0.000003  loss: 0.78531  detection_loss: 0.7018 (cls: 0.1312, box: 0.5706)  rpn_loss: 0.0835 (cls: 0.0464, box: 0.0371)
[2025-08-07 22:04:14 train.log] INFO: Epoch: [26]  [Step 13800/14540]  lr: 0.000003  loss: 0.87136  detection_loss: 0.7610 (cls: 0.3123, box: 0.4487)  rpn_loss: 0.1104 (cls: 0.0791, box: 0.0313)
[2025-08-07 22:04:19 train.log] INFO: Epoch: [26]  [Step 13900/14540]  lr: 0.000003  loss: 1.31568  detection_loss: 1.1698 (cls: 0.2394, box: 0.9304)  rpn_loss: 0.1459 (cls: 0.0767, box: 0.0692)
[2025-08-07 22:04:25 train.log] INFO: Epoch: [26]  [Step 14000/14540]  lr: 0.000003  loss: 1.35026  detection_loss: 1.2642 (cls: 0.3640, box: 0.9002)  rpn_loss: 0.0861 (cls: 0.0396, box: 0.0465)
[2025-08-07 22:04:31 train.log] INFO: Epoch: [26]  [Step 14100/14540]  lr: 0.000003  loss: 1.06583  detection_loss: 0.9379 (cls: 0.2374, box: 0.7005)  rpn_loss: 0.1280 (cls: 0.0950, box: 0.0329)
[2025-08-07 22:04:37 train.log] INFO: Epoch: [26]  [Step 14200/14540]  lr: 0.000003  loss: 0.72628  detection_loss: 0.6574 (cls: 0.1976, box: 0.4598)  rpn_loss: 0.0689 (cls: 0.0257, box: 0.0432)
[2025-08-07 22:04:42 train.log] INFO: Epoch: [26]  [Step 14300/14540]  lr: 0.000003  loss: 1.00196  detection_loss: 0.8626 (cls: 0.2821, box: 0.5805)  rpn_loss: 0.1393 (cls: 0.0428, box: 0.0965)
[2025-08-07 22:04:48 train.log] INFO: Epoch: [26]  [Step 14400/14540]  lr: 0.000003  loss: 0.79084  detection_loss: 0.7083 (cls: 0.2601, box: 0.4483)  rpn_loss: 0.0825 (cls: 0.0399, box: 0.0426)
[2025-08-07 22:04:54 train.log] INFO: Epoch: [26]  [Step 14500/14540]  lr: 0.000003  loss: 0.69996  detection_loss: 0.6337 (cls: 0.2304, box: 0.4033)  rpn_loss: 0.0662 (cls: 0.0333, box: 0.0329)
[2025-08-07 22:08:23 train.log] INFO: Epoch: [27]  [Step 100/14540]  lr: 0.000002  loss: 0.44871  detection_loss: 0.4261 (cls: 0.0820, box: 0.3441)  rpn_loss: 0.0226 (cls: 0.0131, box: 0.0095)
[2025-08-07 22:08:29 train.log] INFO: Epoch: [27]  [Step 200/14540]  lr: 0.000002  loss: 0.88019  detection_loss: 0.7726 (cls: 0.1983, box: 0.5743)  rpn_loss: 0.1076 (cls: 0.0555, box: 0.0522)
[2025-08-07 22:08:35 train.log] INFO: Epoch: [27]  [Step 300/14540]  lr: 0.000002  loss: 1.10064  detection_loss: 0.9965 (cls: 0.2911, box: 0.7054)  rpn_loss: 0.1041 (cls: 0.0378, box: 0.0663)
[2025-08-07 22:08:40 train.log] INFO: Epoch: [27]  [Step 400/14540]  lr: 0.000002  loss: 1.26953  detection_loss: 1.0955 (cls: 0.2433, box: 0.8522)  rpn_loss: 0.1740 (cls: 0.0344, box: 0.1396)
[2025-08-07 22:08:46 train.log] INFO: Epoch: [27]  [Step 500/14540]  lr: 0.000002  loss: 0.51562  detection_loss: 0.4690 (cls: 0.1225, box: 0.3465)  rpn_loss: 0.0466 (cls: 0.0167, box: 0.0299)
[2025-08-07 22:08:52 train.log] INFO: Epoch: [27]  [Step 600/14540]  lr: 0.000002  loss: 0.85637  detection_loss: 0.7689 (cls: 0.1627, box: 0.6062)  rpn_loss: 0.0875 (cls: 0.0427, box: 0.0448)
[2025-08-07 22:08:58 train.log] INFO: Epoch: [27]  [Step 700/14540]  lr: 0.000002  loss: 0.68077  detection_loss: 0.6192 (cls: 0.1314, box: 0.4878)  rpn_loss: 0.0615 (cls: 0.0217, box: 0.0399)
[2025-08-07 22:09:03 train.log] INFO: Epoch: [27]  [Step 800/14540]  lr: 0.000002  loss: 0.80160  detection_loss: 0.6843 (cls: 0.1429, box: 0.5414)  rpn_loss: 0.1173 (cls: 0.0635, box: 0.0537)
[2025-08-07 22:09:09 train.log] INFO: Epoch: [27]  [Step 900/14540]  lr: 0.000002  loss: 0.74423  detection_loss: 0.6727 (cls: 0.1781, box: 0.4946)  rpn_loss: 0.0715 (cls: 0.0286, box: 0.0430)
[2025-08-07 22:09:15 train.log] INFO: Epoch: [27]  [Step 1000/14540]  lr: 0.000002  loss: 0.86279  detection_loss: 0.7369 (cls: 0.2511, box: 0.4858)  rpn_loss: 0.1259 (cls: 0.0424, box: 0.0835)
[2025-08-07 22:09:21 train.log] INFO: Epoch: [27]  [Step 1100/14540]  lr: 0.000002  loss: 0.82925  detection_loss: 0.7605 (cls: 0.1262, box: 0.6343)  rpn_loss: 0.0688 (cls: 0.0473, box: 0.0214)
[2025-08-07 22:09:26 train.log] INFO: Epoch: [27]  [Step 1200/14540]  lr: 0.000002  loss: 0.60178  detection_loss: 0.5521 (cls: 0.1268, box: 0.4252)  rpn_loss: 0.0497 (cls: 0.0368, box: 0.0129)
[2025-08-07 22:09:32 train.log] INFO: Epoch: [27]  [Step 1300/14540]  lr: 0.000002  loss: 0.61528  detection_loss: 0.5417 (cls: 0.1766, box: 0.3651)  rpn_loss: 0.0736 (cls: 0.0361, box: 0.0375)
[2025-08-07 22:09:38 train.log] INFO: Epoch: [27]  [Step 1400/14540]  lr: 0.000002  loss: 1.38146  detection_loss: 1.2323 (cls: 0.4769, box: 0.7554)  rpn_loss: 0.1492 (cls: 0.1110, box: 0.0381)
[2025-08-07 22:09:44 train.log] INFO: Epoch: [27]  [Step 1500/14540]  lr: 0.000002  loss: 0.57388  detection_loss: 0.5411 (cls: 0.1143, box: 0.4267)  rpn_loss: 0.0328 (cls: 0.0185, box: 0.0143)
[2025-08-07 22:09:53 train.log] INFO: Epoch: [27]  [Step 1600/14540]  lr: 0.000002  loss: 0.50448  detection_loss: 0.4641 (cls: 0.1328, box: 0.3313)  rpn_loss: 0.0404 (cls: 0.0242, box: 0.0162)
[2025-08-07 22:10:01 train.log] INFO: Epoch: [27]  [Step 1700/14540]  lr: 0.000002  loss: 0.65011  detection_loss: 0.5023 (cls: 0.1733, box: 0.3290)  rpn_loss: 0.1478 (cls: 0.1093, box: 0.0385)
[2025-08-07 22:10:07 train.log] INFO: Epoch: [27]  [Step 1800/14540]  lr: 0.000002  loss: 0.93044  detection_loss: 0.8365 (cls: 0.1565, box: 0.6800)  rpn_loss: 0.0939 (cls: 0.0716, box: 0.0223)
[2025-08-07 22:10:13 train.log] INFO: Epoch: [27]  [Step 1900/14540]  lr: 0.000002  loss: 0.96888  detection_loss: 0.8691 (cls: 0.2451, box: 0.6239)  rpn_loss: 0.0998 (cls: 0.0653, box: 0.0346)
[2025-08-07 22:10:18 train.log] INFO: Epoch: [27]  [Step 2000/14540]  lr: 0.000002  loss: 0.72975  detection_loss: 0.6711 (cls: 0.1916, box: 0.4796)  rpn_loss: 0.0586 (cls: 0.0287, box: 0.0299)
[2025-08-07 22:10:24 train.log] INFO: Epoch: [27]  [Step 2100/14540]  lr: 0.000002  loss: 0.85616  detection_loss: 0.7203 (cls: 0.1813, box: 0.5390)  rpn_loss: 0.1358 (cls: 0.0526, box: 0.0832)
[2025-08-07 22:10:29 train.log] INFO: Epoch: [27]  [Step 2200/14540]  lr: 0.000002  loss: 0.72290  detection_loss: 0.6440 (cls: 0.1655, box: 0.4785)  rpn_loss: 0.0789 (cls: 0.0397, box: 0.0392)
[2025-08-07 22:10:35 train.log] INFO: Epoch: [27]  [Step 2300/14540]  lr: 0.000002  loss: 0.93740  detection_loss: 0.8288 (cls: 0.2514, box: 0.5774)  rpn_loss: 0.1086 (cls: 0.0671, box: 0.0414)
[2025-08-07 22:10:41 train.log] INFO: Epoch: [27]  [Step 2400/14540]  lr: 0.000002  loss: 0.59902  detection_loss: 0.5297 (cls: 0.1726, box: 0.3571)  rpn_loss: 0.0694 (cls: 0.0415, box: 0.0279)
[2025-08-07 22:10:46 train.log] INFO: Epoch: [27]  [Step 2500/14540]  lr: 0.000002  loss: 0.99015  detection_loss: 0.8725 (cls: 0.2294, box: 0.6432)  rpn_loss: 0.1176 (cls: 0.0773, box: 0.0403)
[2025-08-07 22:10:53 train.log] INFO: Epoch: [27]  [Step 2600/14540]  lr: 0.000002  loss: 0.86950  detection_loss: 0.7499 (cls: 0.2138, box: 0.5360)  rpn_loss: 0.1196 (cls: 0.0421, box: 0.0775)
[2025-08-07 22:10:58 train.log] INFO: Epoch: [27]  [Step 2700/14540]  lr: 0.000002  loss: 0.59146  detection_loss: 0.5490 (cls: 0.1775, box: 0.3715)  rpn_loss: 0.0425 (cls: 0.0263, box: 0.0161)
[2025-08-07 22:11:04 train.log] INFO: Epoch: [27]  [Step 2800/14540]  lr: 0.000002  loss: 0.65304  detection_loss: 0.5457 (cls: 0.1358, box: 0.4099)  rpn_loss: 0.1074 (cls: 0.0517, box: 0.0557)
[2025-08-07 22:11:09 train.log] INFO: Epoch: [27]  [Step 2900/14540]  lr: 0.000002  loss: 0.50642  detection_loss: 0.3839 (cls: 0.1339, box: 0.2500)  rpn_loss: 0.1225 (cls: 0.0702, box: 0.0523)
[2025-08-07 22:11:15 train.log] INFO: Epoch: [27]  [Step 3000/14540]  lr: 0.000002  loss: 0.56564  detection_loss: 0.5110 (cls: 0.1472, box: 0.3638)  rpn_loss: 0.0546 (cls: 0.0394, box: 0.0152)
[2025-08-07 22:11:21 train.log] INFO: Epoch: [27]  [Step 3100/14540]  lr: 0.000002  loss: 0.83296  detection_loss: 0.7168 (cls: 0.1486, box: 0.5681)  rpn_loss: 0.1162 (cls: 0.0846, box: 0.0315)
[2025-08-07 22:11:26 train.log] INFO: Epoch: [27]  [Step 3200/14540]  lr: 0.000002  loss: 0.74523  detection_loss: 0.6460 (cls: 0.1327, box: 0.5133)  rpn_loss: 0.0992 (cls: 0.0819, box: 0.0174)
[2025-08-07 22:11:32 train.log] INFO: Epoch: [27]  [Step 3300/14540]  lr: 0.000002  loss: 0.82462  detection_loss: 0.6718 (cls: 0.1804, box: 0.4913)  rpn_loss: 0.1528 (cls: 0.0417, box: 0.1111)
[2025-08-07 22:11:38 train.log] INFO: Epoch: [27]  [Step 3400/14540]  lr: 0.000002  loss: 0.95846  detection_loss: 0.8547 (cls: 0.0868, box: 0.7679)  rpn_loss: 0.1037 (cls: 0.0205, box: 0.0833)
[2025-08-07 22:11:43 train.log] INFO: Epoch: [27]  [Step 3500/14540]  lr: 0.000002  loss: 0.76632  detection_loss: 0.7095 (cls: 0.2539, box: 0.4556)  rpn_loss: 0.0568 (cls: 0.0304, box: 0.0265)
[2025-08-07 22:11:49 train.log] INFO: Epoch: [27]  [Step 3600/14540]  lr: 0.000002  loss: 0.77571  detection_loss: 0.6864 (cls: 0.1424, box: 0.5440)  rpn_loss: 0.0893 (cls: 0.0544, box: 0.0349)
[2025-08-07 22:11:51 train.log] INFO: Epoch: [27]  [Step 3635/14540]  lr: 0.000002  loss: 0.98511  detection_loss: 0.9055 (cls: 0.1715, box: 0.7340)  rpn_loss: 0.0796 (cls: 0.0279, box: 0.0518)
[2025-08-07 22:11:54 train.log] INFO: Epoch: [27]  [Step 3700/14540]  lr: 0.000002  loss: 0.58508  detection_loss: 0.5442 (cls: 0.1371, box: 0.4071)  rpn_loss: 0.0409 (cls: 0.0191, box: 0.0218)
[2025-08-07 22:12:00 train.log] INFO: Epoch: [27]  [Step 3800/14540]  lr: 0.000002  loss: 1.04800  detection_loss: 0.9790 (cls: 0.2487, box: 0.7303)  rpn_loss: 0.0690 (cls: 0.0375, box: 0.0315)
[2025-08-07 22:12:05 train.log] INFO: Epoch: [27]  [Step 3900/14540]  lr: 0.000002  loss: 0.61414  detection_loss: 0.5258 (cls: 0.1380, box: 0.3877)  rpn_loss: 0.0884 (cls: 0.0645, box: 0.0238)
[2025-08-07 22:12:11 train.log] INFO: Epoch: [27]  [Step 4000/14540]  lr: 0.000002  loss: 0.93168  detection_loss: 0.8261 (cls: 0.1397, box: 0.6864)  rpn_loss: 0.1056 (cls: 0.0517, box: 0.0539)
[2025-08-07 22:12:16 train.log] INFO: Epoch: [27]  [Step 4100/14540]  lr: 0.000002  loss: 1.10065  detection_loss: 0.8967 (cls: 0.1326, box: 0.7641)  rpn_loss: 0.2039 (cls: 0.0258, box: 0.1781)
[2025-08-07 22:12:22 train.log] INFO: Epoch: [27]  [Step 4200/14540]  lr: 0.000002  loss: 0.77665  detection_loss: 0.7006 (cls: 0.2251, box: 0.4755)  rpn_loss: 0.0761 (cls: 0.0318, box: 0.0443)
[2025-08-07 22:12:28 train.log] INFO: Epoch: [27]  [Step 4300/14540]  lr: 0.000002  loss: 0.98162  detection_loss: 0.9234 (cls: 0.2632, box: 0.6602)  rpn_loss: 0.0582 (cls: 0.0248, box: 0.0335)
[2025-08-07 22:12:33 train.log] INFO: Epoch: [27]  [Step 4400/14540]  lr: 0.000002  loss: 1.05935  detection_loss: 0.9376 (cls: 0.2588, box: 0.6788)  rpn_loss: 0.1218 (cls: 0.0728, box: 0.0490)
[2025-08-07 22:12:39 train.log] INFO: Epoch: [27]  [Step 4500/14540]  lr: 0.000002  loss: 0.67740  detection_loss: 0.5953 (cls: 0.1800, box: 0.4152)  rpn_loss: 0.0821 (cls: 0.0216, box: 0.0605)
[2025-08-07 22:12:45 train.log] INFO: Epoch: [27]  [Step 4600/14540]  lr: 0.000002  loss: 1.41978  detection_loss: 1.2348 (cls: 0.3532, box: 0.8817)  rpn_loss: 0.1849 (cls: 0.1303, box: 0.0546)
[2025-08-07 22:12:50 train.log] INFO: Epoch: [27]  [Step 4700/14540]  lr: 0.000002  loss: 0.58171  detection_loss: 0.5447 (cls: 0.1003, box: 0.4443)  rpn_loss: 0.0370 (cls: 0.0202, box: 0.0169)
[2025-08-07 22:12:56 train.log] INFO: Epoch: [27]  [Step 4800/14540]  lr: 0.000002  loss: 0.82433  detection_loss: 0.7092 (cls: 0.2108, box: 0.4985)  rpn_loss: 0.1151 (cls: 0.0230, box: 0.0921)
[2025-08-07 22:13:01 train.log] INFO: Epoch: [27]  [Step 4900/14540]  lr: 0.000002  loss: 0.63541  detection_loss: 0.5567 (cls: 0.0974, box: 0.4593)  rpn_loss: 0.0787 (cls: 0.0394, box: 0.0393)
[2025-08-07 22:13:07 train.log] INFO: Epoch: [27]  [Step 5000/14540]  lr: 0.000002  loss: 0.46106  detection_loss: 0.4246 (cls: 0.1259, box: 0.2987)  rpn_loss: 0.0365 (cls: 0.0211, box: 0.0153)
[2025-08-07 22:13:12 train.log] INFO: Epoch: [27]  [Step 5100/14540]  lr: 0.000002  loss: 1.25594  detection_loss: 1.1111 (cls: 0.2339, box: 0.8772)  rpn_loss: 0.1449 (cls: 0.0973, box: 0.0476)
[2025-08-07 22:13:18 train.log] INFO: Epoch: [27]  [Step 5200/14540]  lr: 0.000002  loss: 1.08784  detection_loss: 0.9162 (cls: 0.2075, box: 0.7087)  rpn_loss: 0.1717 (cls: 0.0277, box: 0.1440)
[2025-08-07 22:13:24 train.log] INFO: Epoch: [27]  [Step 5300/14540]  lr: 0.000002  loss: 0.58671  detection_loss: 0.5175 (cls: 0.1591, box: 0.3584)  rpn_loss: 0.0692 (cls: 0.0257, box: 0.0436)
[2025-08-07 22:13:30 train.log] INFO: Epoch: [27]  [Step 5400/14540]  lr: 0.000002  loss: 0.87012  detection_loss: 0.7827 (cls: 0.1984, box: 0.5842)  rpn_loss: 0.0874 (cls: 0.0714, box: 0.0160)
[2025-08-07 22:13:36 train.log] INFO: Epoch: [27]  [Step 5500/14540]  lr: 0.000002  loss: 0.77387  detection_loss: 0.7078 (cls: 0.2107, box: 0.4971)  rpn_loss: 0.0660 (cls: 0.0272, box: 0.0389)
[2025-08-07 22:13:42 train.log] INFO: Epoch: [27]  [Step 5600/14540]  lr: 0.000002  loss: 0.78444  detection_loss: 0.6632 (cls: 0.2101, box: 0.4531)  rpn_loss: 0.1212 (cls: 0.1020, box: 0.0193)
[2025-08-07 22:13:47 train.log] INFO: Epoch: [27]  [Step 5700/14540]  lr: 0.000002  loss: 0.94246  detection_loss: 0.7620 (cls: 0.1753, box: 0.5867)  rpn_loss: 0.1804 (cls: 0.0759, box: 0.1046)
[2025-08-07 22:13:53 train.log] INFO: Epoch: [27]  [Step 5800/14540]  lr: 0.000002  loss: 0.84472  detection_loss: 0.7610 (cls: 0.1913, box: 0.5697)  rpn_loss: 0.0837 (cls: 0.0667, box: 0.0170)
[2025-08-07 22:13:59 train.log] INFO: Epoch: [27]  [Step 5900/14540]  lr: 0.000002  loss: 1.02295  detection_loss: 0.9156 (cls: 0.1999, box: 0.7157)  rpn_loss: 0.1073 (cls: 0.0705, box: 0.0369)
[2025-08-07 22:14:05 train.log] INFO: Epoch: [27]  [Step 6000/14540]  lr: 0.000002  loss: 0.76125  detection_loss: 0.6666 (cls: 0.1742, box: 0.4925)  rpn_loss: 0.0946 (cls: 0.0442, box: 0.0504)
[2025-08-07 22:14:11 train.log] INFO: Epoch: [27]  [Step 6100/14540]  lr: 0.000002  loss: 0.68496  detection_loss: 0.6493 (cls: 0.1970, box: 0.4523)  rpn_loss: 0.0357 (cls: 0.0214, box: 0.0143)
[2025-08-07 22:14:17 train.log] INFO: Epoch: [27]  [Step 6200/14540]  lr: 0.000002  loss: 0.98113  detection_loss: 0.8896 (cls: 0.1724, box: 0.7172)  rpn_loss: 0.0916 (cls: 0.0370, box: 0.0546)
[2025-08-07 22:14:22 train.log] INFO: Epoch: [27]  [Step 6300/14540]  lr: 0.000002  loss: 0.90797  detection_loss: 0.8141 (cls: 0.1825, box: 0.6317)  rpn_loss: 0.0938 (cls: 0.0479, box: 0.0460)
[2025-08-07 22:14:28 train.log] INFO: Epoch: [27]  [Step 6400/14540]  lr: 0.000002  loss: 0.74555  detection_loss: 0.6453 (cls: 0.1512, box: 0.4941)  rpn_loss: 0.1003 (cls: 0.0486, box: 0.0516)
[2025-08-07 22:14:34 train.log] INFO: Epoch: [27]  [Step 6500/14540]  lr: 0.000002  loss: 0.60952  detection_loss: 0.5462 (cls: 0.1302, box: 0.4160)  rpn_loss: 0.0633 (cls: 0.0342, box: 0.0291)
[2025-08-07 22:14:40 train.log] INFO: Epoch: [27]  [Step 6600/14540]  lr: 0.000002  loss: 0.95958  detection_loss: 0.8865 (cls: 0.2464, box: 0.6401)  rpn_loss: 0.0731 (cls: 0.0426, box: 0.0305)
[2025-08-07 22:14:45 train.log] INFO: Epoch: [27]  [Step 6700/14540]  lr: 0.000002  loss: 0.32030  detection_loss: 0.2706 (cls: 0.0874, box: 0.1832)  rpn_loss: 0.0497 (cls: 0.0106, box: 0.0391)
[2025-08-07 22:14:51 train.log] INFO: Epoch: [27]  [Step 6800/14540]  lr: 0.000002  loss: 0.53683  detection_loss: 0.4602 (cls: 0.1088, box: 0.3514)  rpn_loss: 0.0767 (cls: 0.0351, box: 0.0415)
[2025-08-07 22:14:57 train.log] INFO: Epoch: [27]  [Step 6900/14540]  lr: 0.000002  loss: 1.13754  detection_loss: 0.9609 (cls: 0.2160, box: 0.7449)  rpn_loss: 0.1767 (cls: 0.0909, box: 0.0858)
[2025-08-07 22:15:02 train.log] INFO: Epoch: [27]  [Step 7000/14540]  lr: 0.000002  loss: 1.14102  detection_loss: 0.9008 (cls: 0.1455, box: 0.7554)  rpn_loss: 0.2402 (cls: 0.0520, box: 0.1882)
[2025-08-07 22:15:08 train.log] INFO: Epoch: [27]  [Step 7100/14540]  lr: 0.000002  loss: 1.12099  detection_loss: 1.0051 (cls: 0.2153, box: 0.7898)  rpn_loss: 0.1158 (cls: 0.0449, box: 0.0709)
[2025-08-07 22:15:13 train.log] INFO: Epoch: [27]  [Step 7200/14540]  lr: 0.000002  loss: 1.03166  detection_loss: 0.9438 (cls: 0.2332, box: 0.7106)  rpn_loss: 0.0878 (cls: 0.0391, box: 0.0488)
[2025-08-07 22:15:19 train.log] INFO: Epoch: [27]  [Step 7300/14540]  lr: 0.000002  loss: 0.50675  detection_loss: 0.4378 (cls: 0.1755, box: 0.2622)  rpn_loss: 0.0690 (cls: 0.0252, box: 0.0438)
[2025-08-07 22:15:24 train.log] INFO: Epoch: [27]  [Step 7400/14540]  lr: 0.000002  loss: 0.89210  detection_loss: 0.7787 (cls: 0.1911, box: 0.5876)  rpn_loss: 0.1134 (cls: 0.0744, box: 0.0390)
[2025-08-07 22:15:30 train.log] INFO: Epoch: [27]  [Step 7500/14540]  lr: 0.000002  loss: 1.10617  detection_loss: 1.0566 (cls: 0.2425, box: 0.8141)  rpn_loss: 0.0496 (cls: 0.0211, box: 0.0284)
[2025-08-07 22:15:35 train.log] INFO: Epoch: [27]  [Step 7600/14540]  lr: 0.000002  loss: 0.97842  detection_loss: 0.7513 (cls: 0.1738, box: 0.5775)  rpn_loss: 0.2271 (cls: 0.0527, box: 0.1744)
[2025-08-07 22:15:41 train.log] INFO: Epoch: [27]  [Step 7700/14540]  lr: 0.000002  loss: 0.78887  detection_loss: 0.6912 (cls: 0.1910, box: 0.5003)  rpn_loss: 0.0976 (cls: 0.0593, box: 0.0383)
[2025-08-07 22:15:46 train.log] INFO: Epoch: [27]  [Step 7800/14540]  lr: 0.000002  loss: 0.79868  detection_loss: 0.6179 (cls: 0.2456, box: 0.3722)  rpn_loss: 0.1808 (cls: 0.0247, box: 0.1561)
[2025-08-07 22:15:52 train.log] INFO: Epoch: [27]  [Step 7900/14540]  lr: 0.000002  loss: 1.25365  detection_loss: 0.9082 (cls: 0.1948, box: 0.7134)  rpn_loss: 0.3455 (cls: 0.0611, box: 0.2844)
[2025-08-07 22:15:58 train.log] INFO: Epoch: [27]  [Step 8000/14540]  lr: 0.000002  loss: 0.76385  detection_loss: 0.7148 (cls: 0.1315, box: 0.5832)  rpn_loss: 0.0491 (cls: 0.0311, box: 0.0180)
[2025-08-07 22:16:03 train.log] INFO: Epoch: [27]  [Step 8100/14540]  lr: 0.000002  loss: 0.87891  detection_loss: 0.7914 (cls: 0.1938, box: 0.5976)  rpn_loss: 0.0875 (cls: 0.0513, box: 0.0362)
[2025-08-07 22:16:09 train.log] INFO: Epoch: [27]  [Step 8200/14540]  lr: 0.000002  loss: 0.48788  detection_loss: 0.4177 (cls: 0.1403, box: 0.2774)  rpn_loss: 0.0702 (cls: 0.0311, box: 0.0391)
[2025-08-07 22:16:15 train.log] INFO: Epoch: [27]  [Step 8300/14540]  lr: 0.000002  loss: 1.04455  detection_loss: 0.9887 (cls: 0.1406, box: 0.8481)  rpn_loss: 0.0559 (cls: 0.0282, box: 0.0277)
[2025-08-07 22:16:20 train.log] INFO: Epoch: [27]  [Step 8400/14540]  lr: 0.000002  loss: 0.40436  detection_loss: 0.3748 (cls: 0.1562, box: 0.2186)  rpn_loss: 0.0296 (cls: 0.0150, box: 0.0146)
[2025-08-07 22:16:26 train.log] INFO: Epoch: [27]  [Step 8500/14540]  lr: 0.000002  loss: 0.93523  detection_loss: 0.8257 (cls: 0.1772, box: 0.6486)  rpn_loss: 0.1095 (cls: 0.0795, box: 0.0299)
[2025-08-07 22:16:32 train.log] INFO: Epoch: [27]  [Step 8600/14540]  lr: 0.000002  loss: 0.72573  detection_loss: 0.6477 (cls: 0.1725, box: 0.4752)  rpn_loss: 0.0780 (cls: 0.0281, box: 0.0499)
[2025-08-07 22:16:37 train.log] INFO: Epoch: [27]  [Step 8700/14540]  lr: 0.000002  loss: 0.83130  detection_loss: 0.7057 (cls: 0.2501, box: 0.4556)  rpn_loss: 0.1256 (cls: 0.0484, box: 0.0772)
[2025-08-07 22:16:42 train.log] INFO: Epoch: [27]  [Step 8800/14540]  lr: 0.000002  loss: 1.08609  detection_loss: 0.9542 (cls: 0.2041, box: 0.7501)  rpn_loss: 0.1319 (cls: 0.0400, box: 0.0919)
[2025-08-07 22:16:48 train.log] INFO: Epoch: [27]  [Step 8900/14540]  lr: 0.000002  loss: 1.10441  detection_loss: 0.9562 (cls: 0.1189, box: 0.8374)  rpn_loss: 0.1482 (cls: 0.0221, box: 0.1261)
[2025-08-07 22:16:54 train.log] INFO: Epoch: [27]  [Step 9000/14540]  lr: 0.000002  loss: 0.85382  detection_loss: 0.7230 (cls: 0.1344, box: 0.5886)  rpn_loss: 0.1308 (cls: 0.0198, box: 0.1110)
[2025-08-07 22:16:59 train.log] INFO: Epoch: [27]  [Step 9100/14540]  lr: 0.000002  loss: 0.63328  detection_loss: 0.5827 (cls: 0.0999, box: 0.4827)  rpn_loss: 0.0506 (cls: 0.0334, box: 0.0172)
[2025-08-07 22:17:05 train.log] INFO: Epoch: [27]  [Step 9200/14540]  lr: 0.000002  loss: 0.56934  detection_loss: 0.4963 (cls: 0.1203, box: 0.3760)  rpn_loss: 0.0731 (cls: 0.0388, box: 0.0342)
[2025-08-07 22:17:11 train.log] INFO: Epoch: [27]  [Step 9300/14540]  lr: 0.000002  loss: 0.67838  detection_loss: 0.6355 (cls: 0.1785, box: 0.4570)  rpn_loss: 0.0429 (cls: 0.0224, box: 0.0205)
[2025-08-07 22:17:17 train.log] INFO: Epoch: [27]  [Step 9400/14540]  lr: 0.000002  loss: 0.79565  detection_loss: 0.7215 (cls: 0.2659, box: 0.4556)  rpn_loss: 0.0741 (cls: 0.0519, box: 0.0223)
[2025-08-07 22:17:22 train.log] INFO: Epoch: [27]  [Step 9500/14540]  lr: 0.000002  loss: 0.74019  detection_loss: 0.5607 (cls: 0.1550, box: 0.4057)  rpn_loss: 0.1795 (cls: 0.0250, box: 0.1545)
[2025-08-07 22:17:28 train.log] INFO: Epoch: [27]  [Step 9600/14540]  lr: 0.000002  loss: 1.38965  detection_loss: 1.2279 (cls: 0.5747, box: 0.6532)  rpn_loss: 0.1617 (cls: 0.0811, box: 0.0806)
[2025-08-07 22:17:35 train.log] INFO: Epoch: [27]  [Step 9700/14540]  lr: 0.000002  loss: 0.46261  detection_loss: 0.4174 (cls: 0.0910, box: 0.3264)  rpn_loss: 0.0453 (cls: 0.0305, box: 0.0148)
[2025-08-07 22:17:41 train.log] INFO: Epoch: [27]  [Step 9800/14540]  lr: 0.000002  loss: 1.21708  detection_loss: 1.0451 (cls: 0.2820, box: 0.7631)  rpn_loss: 0.1719 (cls: 0.0810, box: 0.0909)
[2025-08-07 22:17:46 train.log] INFO: Epoch: [27]  [Step 9900/14540]  lr: 0.000002  loss: 0.80493  detection_loss: 0.7704 (cls: 0.1268, box: 0.6436)  rpn_loss: 0.0345 (cls: 0.0086, box: 0.0260)
[2025-08-07 22:17:52 train.log] INFO: Epoch: [27]  [Step 10000/14540]  lr: 0.000002  loss: 0.84217  detection_loss: 0.7913 (cls: 0.1407, box: 0.6507)  rpn_loss: 0.0508 (cls: 0.0317, box: 0.0191)
[2025-08-07 22:17:58 train.log] INFO: Epoch: [27]  [Step 10100/14540]  lr: 0.000002  loss: 0.29031  detection_loss: 0.2722 (cls: 0.0625, box: 0.2097)  rpn_loss: 0.0181 (cls: 0.0043, box: 0.0138)
[2025-08-07 22:18:04 train.log] INFO: Epoch: [27]  [Step 10200/14540]  lr: 0.000002  loss: 0.95723  detection_loss: 0.7862 (cls: 0.2129, box: 0.5733)  rpn_loss: 0.1710 (cls: 0.0746, box: 0.0964)
[2025-08-07 22:18:10 train.log] INFO: Epoch: [27]  [Step 10300/14540]  lr: 0.000002  loss: 1.53186  detection_loss: 1.4353 (cls: 0.2653, box: 1.1700)  rpn_loss: 0.0966 (cls: 0.0638, box: 0.0328)
[2025-08-07 22:18:15 train.log] INFO: Epoch: [27]  [Step 10400/14540]  lr: 0.000002  loss: 0.69798  detection_loss: 0.6306 (cls: 0.1222, box: 0.5084)  rpn_loss: 0.0674 (cls: 0.0250, box: 0.0424)
[2025-08-07 22:18:21 train.log] INFO: Epoch: [27]  [Step 10500/14540]  lr: 0.000002  loss: 1.25485  detection_loss: 1.0893 (cls: 0.2342, box: 0.8552)  rpn_loss: 0.1655 (cls: 0.0135, box: 0.1520)
[2025-08-07 22:18:27 train.log] INFO: Epoch: [27]  [Step 10600/14540]  lr: 0.000002  loss: 0.69556  detection_loss: 0.6161 (cls: 0.1253, box: 0.4909)  rpn_loss: 0.0794 (cls: 0.0450, box: 0.0344)
[2025-08-07 22:18:32 train.log] INFO: Epoch: [27]  [Step 10700/14540]  lr: 0.000002  loss: 0.60704  detection_loss: 0.5374 (cls: 0.2029, box: 0.3345)  rpn_loss: 0.0697 (cls: 0.0441, box: 0.0255)
[2025-08-07 22:18:38 train.log] INFO: Epoch: [27]  [Step 10800/14540]  lr: 0.000002  loss: 0.82961  detection_loss: 0.6708 (cls: 0.1601, box: 0.5106)  rpn_loss: 0.1588 (cls: 0.0373, box: 0.1215)
[2025-08-07 22:18:43 train.log] INFO: Epoch: [27]  [Step 10900/14540]  lr: 0.000002  loss: 0.78216  detection_loss: 0.5689 (cls: 0.1916, box: 0.3773)  rpn_loss: 0.2132 (cls: 0.0609, box: 0.1523)
[2025-08-07 22:18:49 train.log] INFO: Epoch: [27]  [Step 11000/14540]  lr: 0.000002  loss: 0.80654  detection_loss: 0.7071 (cls: 0.1558, box: 0.5514)  rpn_loss: 0.0994 (cls: 0.0107, box: 0.0887)
[2025-08-07 22:18:54 train.log] INFO: Epoch: [27]  [Step 11100/14540]  lr: 0.000002  loss: 0.95649  detection_loss: 0.7826 (cls: 0.2233, box: 0.5592)  rpn_loss: 0.1739 (cls: 0.0904, box: 0.0835)
[2025-08-07 22:19:00 train.log] INFO: Epoch: [27]  [Step 11200/14540]  lr: 0.000002  loss: 0.80074  detection_loss: 0.6818 (cls: 0.1661, box: 0.5157)  rpn_loss: 0.1189 (cls: 0.0572, box: 0.0617)
[2025-08-07 22:19:06 train.log] INFO: Epoch: [27]  [Step 11300/14540]  lr: 0.000002  loss: 0.45945  detection_loss: 0.4070 (cls: 0.0853, box: 0.3216)  rpn_loss: 0.0525 (cls: 0.0187, box: 0.0338)
[2025-08-07 22:19:12 train.log] INFO: Epoch: [27]  [Step 11400/14540]  lr: 0.000002  loss: 0.46923  detection_loss: 0.4273 (cls: 0.1240, box: 0.3033)  rpn_loss: 0.0419 (cls: 0.0300, box: 0.0119)
[2025-08-07 22:19:17 train.log] INFO: Epoch: [27]  [Step 11500/14540]  lr: 0.000002  loss: 1.18567  detection_loss: 1.1004 (cls: 0.2868, box: 0.8136)  rpn_loss: 0.0852 (cls: 0.0587, box: 0.0265)
[2025-08-07 22:19:23 train.log] INFO: Epoch: [27]  [Step 11600/14540]  lr: 0.000002  loss: 0.72338  detection_loss: 0.6330 (cls: 0.1188, box: 0.5142)  rpn_loss: 0.0904 (cls: 0.0595, box: 0.0309)
[2025-08-07 22:19:28 train.log] INFO: Epoch: [27]  [Step 11700/14540]  lr: 0.000002  loss: 0.75618  detection_loss: 0.6486 (cls: 0.1571, box: 0.4915)  rpn_loss: 0.1076 (cls: 0.0710, box: 0.0366)
[2025-08-07 22:19:34 train.log] INFO: Epoch: [27]  [Step 11800/14540]  lr: 0.000002  loss: 0.88179  detection_loss: 0.8157 (cls: 0.3468, box: 0.4688)  rpn_loss: 0.0661 (cls: 0.0538, box: 0.0123)
[2025-08-07 22:19:39 train.log] INFO: Epoch: [27]  [Step 11900/14540]  lr: 0.000002  loss: 0.65274  detection_loss: 0.5622 (cls: 0.1779, box: 0.3843)  rpn_loss: 0.0905 (cls: 0.0711, box: 0.0195)
[2025-08-07 22:19:45 train.log] INFO: Epoch: [27]  [Step 12000/14540]  lr: 0.000002  loss: 0.79353  detection_loss: 0.6978 (cls: 0.1840, box: 0.5138)  rpn_loss: 0.0957 (cls: 0.0509, box: 0.0448)
[2025-08-07 22:19:51 train.log] INFO: Epoch: [27]  [Step 12100/14540]  lr: 0.000002  loss: 0.64112  detection_loss: 0.5905 (cls: 0.1479, box: 0.4427)  rpn_loss: 0.0506 (cls: 0.0381, box: 0.0124)
[2025-08-07 22:19:56 train.log] INFO: Epoch: [27]  [Step 12200/14540]  lr: 0.000002  loss: 0.87440  detection_loss: 0.7672 (cls: 0.1999, box: 0.5673)  rpn_loss: 0.1072 (cls: 0.0439, box: 0.0633)
[2025-08-07 22:20:02 train.log] INFO: Epoch: [27]  [Step 12300/14540]  lr: 0.000002  loss: 0.56501  detection_loss: 0.4447 (cls: 0.0917, box: 0.3530)  rpn_loss: 0.1203 (cls: 0.0967, box: 0.0237)
[2025-08-07 22:20:08 train.log] INFO: Epoch: [27]  [Step 12400/14540]  lr: 0.000002  loss: 1.35071  detection_loss: 0.7410 (cls: 0.1623, box: 0.5787)  rpn_loss: 0.6097 (cls: 0.0402, box: 0.5695)
[2025-08-07 22:20:13 train.log] INFO: Epoch: [27]  [Step 12500/14540]  lr: 0.000002  loss: 0.49569  detection_loss: 0.4589 (cls: 0.1130, box: 0.3459)  rpn_loss: 0.0368 (cls: 0.0226, box: 0.0143)
[2025-08-07 22:20:19 train.log] INFO: Epoch: [27]  [Step 12600/14540]  lr: 0.000002  loss: 0.61486  detection_loss: 0.5159 (cls: 0.1279, box: 0.3880)  rpn_loss: 0.0990 (cls: 0.0437, box: 0.0553)
[2025-08-07 22:20:25 train.log] INFO: Epoch: [27]  [Step 12700/14540]  lr: 0.000002  loss: 0.76027  detection_loss: 0.6958 (cls: 0.1564, box: 0.5393)  rpn_loss: 0.0645 (cls: 0.0451, box: 0.0195)
[2025-08-07 22:20:30 train.log] INFO: Epoch: [27]  [Step 12800/14540]  lr: 0.000002  loss: 1.13062  detection_loss: 0.9566 (cls: 0.2420, box: 0.7146)  rpn_loss: 0.1740 (cls: 0.1249, box: 0.0491)
[2025-08-07 22:20:36 train.log] INFO: Epoch: [27]  [Step 12900/14540]  lr: 0.000002  loss: 0.60361  detection_loss: 0.5228 (cls: 0.0820, box: 0.4408)  rpn_loss: 0.0809 (cls: 0.0596, box: 0.0213)
[2025-08-07 22:20:41 train.log] INFO: Epoch: [27]  [Step 13000/14540]  lr: 0.000002  loss: 1.20991  detection_loss: 1.0520 (cls: 0.2275, box: 0.8246)  rpn_loss: 0.1579 (cls: 0.0725, box: 0.0854)
[2025-08-07 22:20:47 train.log] INFO: Epoch: [27]  [Step 13100/14540]  lr: 0.000002  loss: 0.59632  detection_loss: 0.5474 (cls: 0.1071, box: 0.4402)  rpn_loss: 0.0489 (cls: 0.0301, box: 0.0189)
[2025-08-07 22:20:53 train.log] INFO: Epoch: [27]  [Step 13200/14540]  lr: 0.000002  loss: 1.29206  detection_loss: 1.1039 (cls: 0.1888, box: 0.9150)  rpn_loss: 0.1882 (cls: 0.0317, box: 0.1564)
[2025-08-07 22:20:58 train.log] INFO: Epoch: [27]  [Step 13300/14540]  lr: 0.000002  loss: 0.68632  detection_loss: 0.6173 (cls: 0.1837, box: 0.4336)  rpn_loss: 0.0690 (cls: 0.0503, box: 0.0187)
[2025-08-07 22:21:04 train.log] INFO: Epoch: [27]  [Step 13400/14540]  lr: 0.000002  loss: 0.71737  detection_loss: 0.6340 (cls: 0.2086, box: 0.4254)  rpn_loss: 0.0833 (cls: 0.0530, box: 0.0303)
[2025-08-07 22:21:09 train.log] INFO: Epoch: [27]  [Step 13500/14540]  lr: 0.000002  loss: 1.22304  detection_loss: 1.0568 (cls: 0.1838, box: 0.8730)  rpn_loss: 0.1662 (cls: 0.0683, box: 0.0979)
[2025-08-07 22:21:15 train.log] INFO: Epoch: [27]  [Step 13600/14540]  lr: 0.000002  loss: 0.76345  detection_loss: 0.6514 (cls: 0.1474, box: 0.5039)  rpn_loss: 0.1121 (cls: 0.0573, box: 0.0548)
[2025-08-07 22:21:20 train.log] INFO: Epoch: [27]  [Step 13700/14540]  lr: 0.000002  loss: 0.63085  detection_loss: 0.5473 (cls: 0.1713, box: 0.3760)  rpn_loss: 0.0835 (cls: 0.0397, box: 0.0438)
[2025-08-07 22:21:26 train.log] INFO: Epoch: [27]  [Step 13800/14540]  lr: 0.000002  loss: 0.61439  detection_loss: 0.5614 (cls: 0.1818, box: 0.3796)  rpn_loss: 0.0530 (cls: 0.0194, box: 0.0336)
[2025-08-07 22:21:31 train.log] INFO: Epoch: [27]  [Step 13900/14540]  lr: 0.000002  loss: 0.98420  detection_loss: 0.8724 (cls: 0.2543, box: 0.6181)  rpn_loss: 0.1118 (cls: 0.0484, box: 0.0634)
[2025-08-07 22:21:37 train.log] INFO: Epoch: [27]  [Step 14000/14540]  lr: 0.000002  loss: 0.64091  detection_loss: 0.5492 (cls: 0.1013, box: 0.4479)  rpn_loss: 0.0917 (cls: 0.0527, box: 0.0390)
[2025-08-07 22:21:42 train.log] INFO: Epoch: [27]  [Step 14100/14540]  lr: 0.000002  loss: 0.44706  detection_loss: 0.3955 (cls: 0.0943, box: 0.3012)  rpn_loss: 0.0516 (cls: 0.0364, box: 0.0152)
[2025-08-07 22:21:48 train.log] INFO: Epoch: [27]  [Step 14200/14540]  lr: 0.000002  loss: 0.59512  detection_loss: 0.5275 (cls: 0.1786, box: 0.3489)  rpn_loss: 0.0676 (cls: 0.0301, box: 0.0375)
[2025-08-07 22:21:54 train.log] INFO: Epoch: [27]  [Step 14300/14540]  lr: 0.000002  loss: 1.04676  detection_loss: 0.9816 (cls: 0.2896, box: 0.6919)  rpn_loss: 0.0652 (cls: 0.0408, box: 0.0244)
[2025-08-07 22:21:59 train.log] INFO: Epoch: [27]  [Step 14400/14540]  lr: 0.000002  loss: 0.45687  detection_loss: 0.4243 (cls: 0.0790, box: 0.3453)  rpn_loss: 0.0326 (cls: 0.0167, box: 0.0159)
[2025-08-07 22:22:05 train.log] INFO: Epoch: [27]  [Step 14500/14540]  lr: 0.000002  loss: 0.64463  detection_loss: 0.5397 (cls: 0.1080, box: 0.4316)  rpn_loss: 0.1050 (cls: 0.0539, box: 0.0510)
[2025-08-07 22:25:27 train.log] INFO: Epoch: [28]  [Step 100/14540]  lr: 0.000001  loss: 0.62372  detection_loss: 0.5447 (cls: 0.1804, box: 0.3644)  rpn_loss: 0.0790 (cls: 0.0486, box: 0.0304)
[2025-08-07 22:25:34 train.log] INFO: Epoch: [28]  [Step 200/14540]  lr: 0.000001  loss: 1.22841  detection_loss: 1.1140 (cls: 0.3176, box: 0.7963)  rpn_loss: 0.1144 (cls: 0.0375, box: 0.0769)
[2025-08-07 22:25:39 train.log] INFO: Epoch: [28]  [Step 300/14540]  lr: 0.000001  loss: 0.67864  detection_loss: 0.6186 (cls: 0.1370, box: 0.4816)  rpn_loss: 0.0600 (cls: 0.0294, box: 0.0306)
[2025-08-07 22:25:45 train.log] INFO: Epoch: [28]  [Step 400/14540]  lr: 0.000001  loss: 0.89133  detection_loss: 0.7846 (cls: 0.1972, box: 0.5874)  rpn_loss: 0.1068 (cls: 0.0621, box: 0.0447)
[2025-08-07 22:25:50 train.log] INFO: Epoch: [28]  [Step 500/14540]  lr: 0.000001  loss: 1.18315  detection_loss: 1.1086 (cls: 0.1811, box: 0.9275)  rpn_loss: 0.0745 (cls: 0.0231, box: 0.0515)
[2025-08-07 22:25:56 train.log] INFO: Epoch: [28]  [Step 600/14540]  lr: 0.000001  loss: 0.46389  detection_loss: 0.4251 (cls: 0.1720, box: 0.2531)  rpn_loss: 0.0388 (cls: 0.0167, box: 0.0221)
[2025-08-07 22:26:01 train.log] INFO: Epoch: [28]  [Step 700/14540]  lr: 0.000001  loss: 1.00813  detection_loss: 0.9087 (cls: 0.2938, box: 0.6148)  rpn_loss: 0.0995 (cls: 0.0537, box: 0.0457)
[2025-08-07 22:26:07 train.log] INFO: Epoch: [28]  [Step 800/14540]  lr: 0.000001  loss: 0.61480  detection_loss: 0.5341 (cls: 0.1838, box: 0.3504)  rpn_loss: 0.0807 (cls: 0.0603, box: 0.0204)
[2025-08-07 22:26:13 train.log] INFO: Epoch: [28]  [Step 900/14540]  lr: 0.000001  loss: 1.17050  detection_loss: 1.0762 (cls: 0.2022, box: 0.8741)  rpn_loss: 0.0943 (cls: 0.0431, box: 0.0512)
[2025-08-07 22:26:18 train.log] INFO: Epoch: [28]  [Step 1000/14540]  lr: 0.000001  loss: 1.80406  detection_loss: 1.6517 (cls: 0.2544, box: 1.3973)  rpn_loss: 0.1524 (cls: 0.0940, box: 0.0584)
[2025-08-07 22:26:24 train.log] INFO: Epoch: [28]  [Step 1100/14540]  lr: 0.000001  loss: 1.07282  detection_loss: 0.9957 (cls: 0.1479, box: 0.8478)  rpn_loss: 0.0772 (cls: 0.0412, box: 0.0360)
[2025-08-07 22:26:29 train.log] INFO: Epoch: [28]  [Step 1200/14540]  lr: 0.000001  loss: 0.62940  detection_loss: 0.5825 (cls: 0.1226, box: 0.4599)  rpn_loss: 0.0469 (cls: 0.0319, box: 0.0150)
[2025-08-07 22:26:35 train.log] INFO: Epoch: [28]  [Step 1300/14540]  lr: 0.000001  loss: 1.15146  detection_loss: 1.0412 (cls: 0.3077, box: 0.7334)  rpn_loss: 0.1103 (cls: 0.0646, box: 0.0457)
[2025-08-07 22:26:41 train.log] INFO: Epoch: [28]  [Step 1400/14540]  lr: 0.000001  loss: 1.17190  detection_loss: 1.0687 (cls: 0.2575, box: 0.8111)  rpn_loss: 0.1032 (cls: 0.0694, box: 0.0338)
[2025-08-07 22:26:46 train.log] INFO: Epoch: [28]  [Step 1500/14540]  lr: 0.000001  loss: 1.03623  detection_loss: 0.9079 (cls: 0.1638, box: 0.7442)  rpn_loss: 0.1283 (cls: 0.0932, box: 0.0351)
[2025-08-07 22:26:52 train.log] INFO: Epoch: [28]  [Step 1600/14540]  lr: 0.000001  loss: 1.00958  detection_loss: 0.9085 (cls: 0.1746, box: 0.7340)  rpn_loss: 0.1011 (cls: 0.0314, box: 0.0696)
[2025-08-07 22:26:57 train.log] INFO: Epoch: [28]  [Step 1700/14540]  lr: 0.000001  loss: 1.24607  detection_loss: 1.1133 (cls: 0.1947, box: 0.9185)  rpn_loss: 0.1328 (cls: 0.0655, box: 0.0673)
[2025-08-07 22:27:03 train.log] INFO: Epoch: [28]  [Step 1800/14540]  lr: 0.000001  loss: 0.90875  detection_loss: 0.6796 (cls: 0.1808, box: 0.4988)  rpn_loss: 0.2292 (cls: 0.0181, box: 0.2111)
[2025-08-07 22:27:08 train.log] INFO: Epoch: [28]  [Step 1900/14540]  lr: 0.000001  loss: 0.97537  detection_loss: 0.9063 (cls: 0.1827, box: 0.7236)  rpn_loss: 0.0691 (cls: 0.0363, box: 0.0328)
[2025-08-07 22:27:14 train.log] INFO: Epoch: [28]  [Step 2000/14540]  lr: 0.000001  loss: 0.55392  detection_loss: 0.4791 (cls: 0.0845, box: 0.3946)  rpn_loss: 0.0748 (cls: 0.0397, box: 0.0351)
[2025-08-07 22:27:20 train.log] INFO: Epoch: [28]  [Step 2100/14540]  lr: 0.000001  loss: 0.66300  detection_loss: 0.6096 (cls: 0.1720, box: 0.4376)  rpn_loss: 0.0534 (cls: 0.0230, box: 0.0304)
[2025-08-07 22:27:25 train.log] INFO: Epoch: [28]  [Step 2200/14540]  lr: 0.000001  loss: 1.59062  detection_loss: 1.4453 (cls: 0.4683, box: 0.9770)  rpn_loss: 0.1453 (cls: 0.1076, box: 0.0377)
[2025-08-07 22:27:31 train.log] INFO: Epoch: [28]  [Step 2300/14540]  lr: 0.000001  loss: 0.62621  detection_loss: 0.5800 (cls: 0.1719, box: 0.4081)  rpn_loss: 0.0462 (cls: 0.0153, box: 0.0309)
[2025-08-07 22:27:37 train.log] INFO: Epoch: [28]  [Step 2400/14540]  lr: 0.000001  loss: 0.54045  detection_loss: 0.4918 (cls: 0.2031, box: 0.2888)  rpn_loss: 0.0486 (cls: 0.0270, box: 0.0216)
[2025-08-07 22:27:42 train.log] INFO: Epoch: [28]  [Step 2500/14540]  lr: 0.000001  loss: 0.54798  detection_loss: 0.5082 (cls: 0.1246, box: 0.3836)  rpn_loss: 0.0397 (cls: 0.0144, box: 0.0253)
[2025-08-07 22:27:48 train.log] INFO: Epoch: [28]  [Step 2600/14540]  lr: 0.000001  loss: 0.81303  detection_loss: 0.7347 (cls: 0.1692, box: 0.5655)  rpn_loss: 0.0784 (cls: 0.0238, box: 0.0545)
[2025-08-07 22:27:54 train.log] INFO: Epoch: [28]  [Step 2700/14540]  lr: 0.000001  loss: 0.96368  detection_loss: 0.8702 (cls: 0.0981, box: 0.7720)  rpn_loss: 0.0935 (cls: 0.0250, box: 0.0685)
[2025-08-07 22:28:00 train.log] INFO: Epoch: [28]  [Step 2800/14540]  lr: 0.000001  loss: 0.67979  detection_loss: 0.5628 (cls: 0.1645, box: 0.3982)  rpn_loss: 0.1170 (cls: 0.0924, box: 0.0247)
[2025-08-07 22:28:05 train.log] INFO: Epoch: [28]  [Step 2900/14540]  lr: 0.000001  loss: 0.75918  detection_loss: 0.6828 (cls: 0.1509, box: 0.5319)  rpn_loss: 0.0764 (cls: 0.0222, box: 0.0543)
[2025-08-07 22:28:11 train.log] INFO: Epoch: [28]  [Step 3000/14540]  lr: 0.000001  loss: 0.80237  detection_loss: 0.5446 (cls: 0.1657, box: 0.3789)  rpn_loss: 0.2577 (cls: 0.0551, box: 0.2027)
[2025-08-07 22:28:16 train.log] INFO: Epoch: [28]  [Step 3100/14540]  lr: 0.000001  loss: 0.69711  detection_loss: 0.5943 (cls: 0.1466, box: 0.4477)  rpn_loss: 0.1028 (cls: 0.0763, box: 0.0265)
[2025-08-07 22:28:22 train.log] INFO: Epoch: [28]  [Step 3200/14540]  lr: 0.000001  loss: 1.03448  detection_loss: 0.8543 (cls: 0.1912, box: 0.6630)  rpn_loss: 0.1802 (cls: 0.1354, box: 0.0448)
[2025-08-07 22:28:27 train.log] INFO: Epoch: [28]  [Step 3300/14540]  lr: 0.000001  loss: 0.98495  detection_loss: 0.9275 (cls: 0.3134, box: 0.6141)  rpn_loss: 0.0574 (cls: 0.0167, box: 0.0407)
[2025-08-07 22:28:33 train.log] INFO: Epoch: [28]  [Step 3400/14540]  lr: 0.000001  loss: 0.79889  detection_loss: 0.7087 (cls: 0.1371, box: 0.5716)  rpn_loss: 0.0902 (cls: 0.0345, box: 0.0557)
[2025-08-07 22:28:39 train.log] INFO: Epoch: [28]  [Step 3500/14540]  lr: 0.000001  loss: 0.97463  detection_loss: 0.8658 (cls: 0.2140, box: 0.6518)  rpn_loss: 0.1088 (cls: 0.0448, box: 0.0640)
[2025-08-07 22:28:44 train.log] INFO: Epoch: [28]  [Step 3600/14540]  lr: 0.000001  loss: 0.58194  detection_loss: 0.4906 (cls: 0.1087, box: 0.3819)  rpn_loss: 0.0914 (cls: 0.0320, box: 0.0594)
[2025-08-07 22:28:46 train.log] INFO: Epoch: [28]  [Step 3635/14540]  lr: 0.000001  loss: 0.75221  detection_loss: 0.5962 (cls: 0.1471, box: 0.4491)  rpn_loss: 0.1560 (cls: 0.0105, box: 0.1455)
[2025-08-07 22:28:49 train.log] INFO: Epoch: [28]  [Step 3700/14540]  lr: 0.000001  loss: 0.73477  detection_loss: 0.6329 (cls: 0.1307, box: 0.5022)  rpn_loss: 0.1018 (cls: 0.0150, box: 0.0869)
[2025-08-07 22:28:55 train.log] INFO: Epoch: [28]  [Step 3800/14540]  lr: 0.000001  loss: 0.99842  detection_loss: 0.9004 (cls: 0.2523, box: 0.6480)  rpn_loss: 0.0981 (cls: 0.0605, box: 0.0375)
[2025-08-07 22:29:01 train.log] INFO: Epoch: [28]  [Step 3900/14540]  lr: 0.000001  loss: 0.55688  detection_loss: 0.4911 (cls: 0.1029, box: 0.3882)  rpn_loss: 0.0658 (cls: 0.0337, box: 0.0321)
[2025-08-07 22:29:06 train.log] INFO: Epoch: [28]  [Step 4000/14540]  lr: 0.000001  loss: 1.38664  detection_loss: 1.2976 (cls: 0.2246, box: 1.0730)  rpn_loss: 0.0891 (cls: 0.0428, box: 0.0463)
[2025-08-07 22:29:12 train.log] INFO: Epoch: [28]  [Step 4100/14540]  lr: 0.000001  loss: 1.36950  detection_loss: 1.1671 (cls: 0.4325, box: 0.7346)  rpn_loss: 0.2024 (cls: 0.1687, box: 0.0337)
[2025-08-07 22:29:17 train.log] INFO: Epoch: [28]  [Step 4200/14540]  lr: 0.000001  loss: 1.48448  detection_loss: 1.3788 (cls: 0.4408, box: 0.9380)  rpn_loss: 0.1057 (cls: 0.0642, box: 0.0414)
[2025-08-07 22:29:23 train.log] INFO: Epoch: [28]  [Step 4300/14540]  lr: 0.000001  loss: 0.75028  detection_loss: 0.6415 (cls: 0.1591, box: 0.4824)  rpn_loss: 0.1088 (cls: 0.0313, box: 0.0775)
[2025-08-07 22:29:28 train.log] INFO: Epoch: [28]  [Step 4400/14540]  lr: 0.000001  loss: 1.21561  detection_loss: 1.1036 (cls: 0.2725, box: 0.8310)  rpn_loss: 0.1120 (cls: 0.0783, box: 0.0337)
[2025-08-07 22:29:34 train.log] INFO: Epoch: [28]  [Step 4500/14540]  lr: 0.000001  loss: 0.96521  detection_loss: 0.7924 (cls: 0.1827, box: 0.6097)  rpn_loss: 0.1728 (cls: 0.1186, box: 0.0542)
[2025-08-07 22:29:39 train.log] INFO: Epoch: [28]  [Step 4600/14540]  lr: 0.000001  loss: 0.50022  detection_loss: 0.4408 (cls: 0.1093, box: 0.3316)  rpn_loss: 0.0594 (cls: 0.0369, box: 0.0225)
[2025-08-07 22:29:45 train.log] INFO: Epoch: [28]  [Step 4700/14540]  lr: 0.000001  loss: 1.24870  detection_loss: 1.1185 (cls: 0.3228, box: 0.7957)  rpn_loss: 0.1302 (cls: 0.0817, box: 0.0485)
[2025-08-07 22:29:50 train.log] INFO: Epoch: [28]  [Step 4800/14540]  lr: 0.000001  loss: 0.44211  detection_loss: 0.4203 (cls: 0.0845, box: 0.3358)  rpn_loss: 0.0218 (cls: 0.0062, box: 0.0155)
[2025-08-07 22:29:56 train.log] INFO: Epoch: [28]  [Step 4900/14540]  lr: 0.000001  loss: 0.55269  detection_loss: 0.4968 (cls: 0.1260, box: 0.3708)  rpn_loss: 0.0559 (cls: 0.0384, box: 0.0175)
[2025-08-07 22:30:02 train.log] INFO: Epoch: [28]  [Step 5000/14540]  lr: 0.000001  loss: 0.49623  detection_loss: 0.4664 (cls: 0.1318, box: 0.3346)  rpn_loss: 0.0298 (cls: 0.0163, box: 0.0135)
[2025-08-07 22:30:08 train.log] INFO: Epoch: [28]  [Step 5100/14540]  lr: 0.000001  loss: 1.23223  detection_loss: 1.1142 (cls: 0.3893, box: 0.7248)  rpn_loss: 0.1181 (cls: 0.0586, box: 0.0594)
[2025-08-07 22:30:13 train.log] INFO: Epoch: [28]  [Step 5200/14540]  lr: 0.000001  loss: 0.93489  detection_loss: 0.7867 (cls: 0.2379, box: 0.5488)  rpn_loss: 0.1482 (cls: 0.0706, box: 0.0775)
[2025-08-07 22:30:19 train.log] INFO: Epoch: [28]  [Step 5300/14540]  lr: 0.000001  loss: 0.99628  detection_loss: 0.8821 (cls: 0.2187, box: 0.6633)  rpn_loss: 0.1142 (cls: 0.0616, box: 0.0526)
[2025-08-07 22:30:24 train.log] INFO: Epoch: [28]  [Step 5400/14540]  lr: 0.000001  loss: 0.76386  detection_loss: 0.7152 (cls: 0.2433, box: 0.4719)  rpn_loss: 0.0486 (cls: 0.0227, box: 0.0259)
[2025-08-07 22:30:30 train.log] INFO: Epoch: [28]  [Step 5500/14540]  lr: 0.000001  loss: 0.69763  detection_loss: 0.6183 (cls: 0.1368, box: 0.4816)  rpn_loss: 0.0793 (cls: 0.0272, box: 0.0521)
[2025-08-07 22:30:36 train.log] INFO: Epoch: [28]  [Step 5600/14540]  lr: 0.000001  loss: 1.64572  detection_loss: 1.3601 (cls: 0.2320, box: 1.1281)  rpn_loss: 0.2856 (cls: 0.0445, box: 0.2411)
[2025-08-07 22:30:42 train.log] INFO: Epoch: [28]  [Step 5700/14540]  lr: 0.000001  loss: 0.57231  detection_loss: 0.4980 (cls: 0.1081, box: 0.3899)  rpn_loss: 0.0743 (cls: 0.0247, box: 0.0496)
[2025-08-07 22:30:47 train.log] INFO: Epoch: [28]  [Step 5800/14540]  lr: 0.000001  loss: 1.21531  detection_loss: 1.0643 (cls: 0.2459, box: 0.8184)  rpn_loss: 0.1510 (cls: 0.0589, box: 0.0921)
[2025-08-07 22:30:53 train.log] INFO: Epoch: [28]  [Step 5900/14540]  lr: 0.000001  loss: 0.65828  detection_loss: 0.5934 (cls: 0.1076, box: 0.4858)  rpn_loss: 0.0649 (cls: 0.0108, box: 0.0541)
[2025-08-07 22:30:58 train.log] INFO: Epoch: [28]  [Step 6000/14540]  lr: 0.000001  loss: 1.06575  detection_loss: 0.9454 (cls: 0.2668, box: 0.6786)  rpn_loss: 0.1204 (cls: 0.0906, box: 0.0298)
[2025-08-07 22:31:04 train.log] INFO: Epoch: [28]  [Step 6100/14540]  lr: 0.000001  loss: 0.49379  detection_loss: 0.3349 (cls: 0.0961, box: 0.2388)  rpn_loss: 0.1589 (cls: 0.0755, box: 0.0834)
[2025-08-07 22:31:10 train.log] INFO: Epoch: [28]  [Step 6200/14540]  lr: 0.000001  loss: 0.62834  detection_loss: 0.5402 (cls: 0.1926, box: 0.3476)  rpn_loss: 0.0881 (cls: 0.0530, box: 0.0351)
[2025-08-07 22:31:15 train.log] INFO: Epoch: [28]  [Step 6300/14540]  lr: 0.000001  loss: 1.36651  detection_loss: 1.1782 (cls: 0.3293, box: 0.8489)  rpn_loss: 0.1883 (cls: 0.1649, box: 0.0234)
[2025-08-07 22:31:21 train.log] INFO: Epoch: [28]  [Step 6400/14540]  lr: 0.000001  loss: 0.36179  detection_loss: 0.2712 (cls: 0.0915, box: 0.1797)  rpn_loss: 0.0906 (cls: 0.0727, box: 0.0179)
[2025-08-07 22:31:27 train.log] INFO: Epoch: [28]  [Step 6500/14540]  lr: 0.000001  loss: 0.81841  detection_loss: 0.6782 (cls: 0.1234, box: 0.5547)  rpn_loss: 0.1402 (cls: 0.1230, box: 0.0173)
[2025-08-07 22:31:32 train.log] INFO: Epoch: [28]  [Step 6600/14540]  lr: 0.000001  loss: 0.60462  detection_loss: 0.5216 (cls: 0.1333, box: 0.3884)  rpn_loss: 0.0830 (cls: 0.0591, box: 0.0239)
[2025-08-07 22:31:38 train.log] INFO: Epoch: [28]  [Step 6700/14540]  lr: 0.000001  loss: 0.67482  detection_loss: 0.6157 (cls: 0.1559, box: 0.4598)  rpn_loss: 0.0591 (cls: 0.0477, box: 0.0114)
[2025-08-07 22:31:43 train.log] INFO: Epoch: [28]  [Step 6800/14540]  lr: 0.000001  loss: 1.01220  detection_loss: 0.9438 (cls: 0.2518, box: 0.6920)  rpn_loss: 0.0684 (cls: 0.0358, box: 0.0326)
[2025-08-07 22:31:49 train.log] INFO: Epoch: [28]  [Step 6900/14540]  lr: 0.000001  loss: 0.48712  detection_loss: 0.4402 (cls: 0.1096, box: 0.3306)  rpn_loss: 0.0470 (cls: 0.0154, box: 0.0316)
[2025-08-07 22:31:54 train.log] INFO: Epoch: [28]  [Step 7000/14540]  lr: 0.000001  loss: 0.47686  detection_loss: 0.4276 (cls: 0.1086, box: 0.3191)  rpn_loss: 0.0492 (cls: 0.0291, box: 0.0201)
[2025-08-07 22:32:00 train.log] INFO: Epoch: [28]  [Step 7100/14540]  lr: 0.000001  loss: 1.12422  detection_loss: 1.0637 (cls: 0.2081, box: 0.8555)  rpn_loss: 0.0606 (cls: 0.0418, box: 0.0187)
[2025-08-07 22:32:05 train.log] INFO: Epoch: [28]  [Step 7200/14540]  lr: 0.000001  loss: 1.02563  detection_loss: 0.8723 (cls: 0.2284, box: 0.6439)  rpn_loss: 0.1533 (cls: 0.0839, box: 0.0693)
[2025-08-07 22:32:11 train.log] INFO: Epoch: [28]  [Step 7300/14540]  lr: 0.000001  loss: 0.55390  detection_loss: 0.4463 (cls: 0.1426, box: 0.3037)  rpn_loss: 0.1076 (cls: 0.0950, box: 0.0126)
[2025-08-07 22:32:17 train.log] INFO: Epoch: [28]  [Step 7400/14540]  lr: 0.000001  loss: 0.73808  detection_loss: 0.6569 (cls: 0.2115, box: 0.4454)  rpn_loss: 0.0812 (cls: 0.0692, box: 0.0120)
[2025-08-07 22:32:22 train.log] INFO: Epoch: [28]  [Step 7500/14540]  lr: 0.000001  loss: 0.79215  detection_loss: 0.7169 (cls: 0.1801, box: 0.5367)  rpn_loss: 0.0753 (cls: 0.0488, box: 0.0265)
[2025-08-07 22:32:28 train.log] INFO: Epoch: [28]  [Step 7600/14540]  lr: 0.000001  loss: 0.43991  detection_loss: 0.3915 (cls: 0.1025, box: 0.2889)  rpn_loss: 0.0484 (cls: 0.0277, box: 0.0208)
[2025-08-07 22:32:33 train.log] INFO: Epoch: [28]  [Step 7700/14540]  lr: 0.000001  loss: 0.89052  detection_loss: 0.7919 (cls: 0.2563, box: 0.5357)  rpn_loss: 0.0986 (cls: 0.0769, box: 0.0217)
[2025-08-07 22:32:39 train.log] INFO: Epoch: [28]  [Step 7800/14540]  lr: 0.000001  loss: 1.02013  detection_loss: 0.8131 (cls: 0.2156, box: 0.5974)  rpn_loss: 0.2071 (cls: 0.0560, box: 0.1511)
[2025-08-07 22:32:44 train.log] INFO: Epoch: [28]  [Step 7900/14540]  lr: 0.000001  loss: 1.29749  detection_loss: 1.1395 (cls: 0.3414, box: 0.7981)  rpn_loss: 0.1580 (cls: 0.1286, box: 0.0294)
[2025-08-07 22:32:50 train.log] INFO: Epoch: [28]  [Step 8000/14540]  lr: 0.000001  loss: 0.63248  detection_loss: 0.5504 (cls: 0.0886, box: 0.4618)  rpn_loss: 0.0821 (cls: 0.0337, box: 0.0484)
[2025-08-07 22:32:56 train.log] INFO: Epoch: [28]  [Step 8100/14540]  lr: 0.000001  loss: 0.85614  detection_loss: 0.7736 (cls: 0.2402, box: 0.5334)  rpn_loss: 0.0825 (cls: 0.0508, box: 0.0317)
[2025-08-07 22:33:01 train.log] INFO: Epoch: [28]  [Step 8200/14540]  lr: 0.000001  loss: 0.84097  detection_loss: 0.6162 (cls: 0.1569, box: 0.4593)  rpn_loss: 0.2247 (cls: 0.1628, box: 0.0619)
[2025-08-07 22:33:07 train.log] INFO: Epoch: [28]  [Step 8300/14540]  lr: 0.000001  loss: 0.86910  detection_loss: 0.7986 (cls: 0.2166, box: 0.5820)  rpn_loss: 0.0705 (cls: 0.0421, box: 0.0284)
[2025-08-07 22:33:13 train.log] INFO: Epoch: [28]  [Step 8400/14540]  lr: 0.000001  loss: 0.91354  detection_loss: 0.7939 (cls: 0.1567, box: 0.6372)  rpn_loss: 0.1196 (cls: 0.0182, box: 0.1015)
[2025-08-07 22:33:18 train.log] INFO: Epoch: [28]  [Step 8500/14540]  lr: 0.000001  loss: 0.83592  detection_loss: 0.6869 (cls: 0.1867, box: 0.5002)  rpn_loss: 0.1491 (cls: 0.0902, box: 0.0588)
[2025-08-07 22:33:24 train.log] INFO: Epoch: [28]  [Step 8600/14540]  lr: 0.000001  loss: 1.29884  detection_loss: 1.1937 (cls: 0.3465, box: 0.8472)  rpn_loss: 0.1052 (cls: 0.0597, box: 0.0455)
[2025-08-07 22:33:30 train.log] INFO: Epoch: [28]  [Step 8700/14540]  lr: 0.000001  loss: 0.79232  detection_loss: 0.7109 (cls: 0.1781, box: 0.5328)  rpn_loss: 0.0814 (cls: 0.0300, box: 0.0514)
[2025-08-07 22:33:35 train.log] INFO: Epoch: [28]  [Step 8800/14540]  lr: 0.000001  loss: 0.79186  detection_loss: 0.6787 (cls: 0.1162, box: 0.5625)  rpn_loss: 0.1132 (cls: 0.0238, box: 0.0894)
[2025-08-07 22:33:41 train.log] INFO: Epoch: [28]  [Step 8900/14540]  lr: 0.000001  loss: 0.66906  detection_loss: 0.6235 (cls: 0.1573, box: 0.4662)  rpn_loss: 0.0456 (cls: 0.0122, box: 0.0334)
[2025-08-07 22:33:46 train.log] INFO: Epoch: [28]  [Step 9000/14540]  lr: 0.000001  loss: 0.73455  detection_loss: 0.6872 (cls: 0.1267, box: 0.5605)  rpn_loss: 0.0474 (cls: 0.0307, box: 0.0167)
[2025-08-07 22:33:52 train.log] INFO: Epoch: [28]  [Step 9100/14540]  lr: 0.000001  loss: 0.51732  detection_loss: 0.4527 (cls: 0.1967, box: 0.2560)  rpn_loss: 0.0646 (cls: 0.0209, box: 0.0437)
[2025-08-07 22:33:57 train.log] INFO: Epoch: [28]  [Step 9200/14540]  lr: 0.000001  loss: 0.67600  detection_loss: 0.3919 (cls: 0.1125, box: 0.2794)  rpn_loss: 0.2841 (cls: 0.0440, box: 0.2401)
[2025-08-07 22:34:03 train.log] INFO: Epoch: [28]  [Step 9300/14540]  lr: 0.000001  loss: 0.61692  detection_loss: 0.5773 (cls: 0.0984, box: 0.4789)  rpn_loss: 0.0396 (cls: 0.0208, box: 0.0188)
[2025-08-07 22:34:08 train.log] INFO: Epoch: [28]  [Step 9400/14540]  lr: 0.000001  loss: 0.94343  detection_loss: 0.8975 (cls: 0.2721, box: 0.6254)  rpn_loss: 0.0459 (cls: 0.0322, box: 0.0137)
[2025-08-07 22:34:14 train.log] INFO: Epoch: [28]  [Step 9500/14540]  lr: 0.000001  loss: 1.07313  detection_loss: 0.9434 (cls: 0.1533, box: 0.7901)  rpn_loss: 0.1298 (cls: 0.0446, box: 0.0851)
[2025-08-07 22:34:20 train.log] INFO: Epoch: [28]  [Step 9600/14540]  lr: 0.000001  loss: 0.91717  detection_loss: 0.8341 (cls: 0.1927, box: 0.6415)  rpn_loss: 0.0830 (cls: 0.0574, box: 0.0256)
[2025-08-07 22:34:25 train.log] INFO: Epoch: [28]  [Step 9700/14540]  lr: 0.000001  loss: 0.58738  detection_loss: 0.5400 (cls: 0.1053, box: 0.4347)  rpn_loss: 0.0474 (cls: 0.0375, box: 0.0099)
[2025-08-07 22:34:31 train.log] INFO: Epoch: [28]  [Step 9800/14540]  lr: 0.000001  loss: 0.64919  detection_loss: 0.5889 (cls: 0.2034, box: 0.3855)  rpn_loss: 0.0603 (cls: 0.0246, box: 0.0358)
[2025-08-07 22:34:36 train.log] INFO: Epoch: [28]  [Step 9900/14540]  lr: 0.000001  loss: 1.43986  detection_loss: 1.3366 (cls: 0.3286, box: 1.0081)  rpn_loss: 0.1032 (cls: 0.0652, box: 0.0380)
[2025-08-07 22:34:42 train.log] INFO: Epoch: [28]  [Step 10000/14540]  lr: 0.000001  loss: 0.37918  detection_loss: 0.3243 (cls: 0.1067, box: 0.2177)  rpn_loss: 0.0548 (cls: 0.0323, box: 0.0225)
[2025-08-07 22:34:47 train.log] INFO: Epoch: [28]  [Step 10100/14540]  lr: 0.000001  loss: 0.49963  detection_loss: 0.4763 (cls: 0.0658, box: 0.4105)  rpn_loss: 0.0233 (cls: 0.0040, box: 0.0193)
[2025-08-07 22:34:53 train.log] INFO: Epoch: [28]  [Step 10200/14540]  lr: 0.000001  loss: 0.58052  detection_loss: 0.5343 (cls: 0.2081, box: 0.3262)  rpn_loss: 0.0462 (cls: 0.0334, box: 0.0129)
[2025-08-07 22:34:59 train.log] INFO: Epoch: [28]  [Step 10300/14540]  lr: 0.000001  loss: 0.69541  detection_loss: 0.6248 (cls: 0.2662, box: 0.3586)  rpn_loss: 0.0706 (cls: 0.0594, box: 0.0112)
[2025-08-07 22:35:05 train.log] INFO: Epoch: [28]  [Step 10400/14540]  lr: 0.000001  loss: 1.07609  detection_loss: 0.9626 (cls: 0.2378, box: 0.7248)  rpn_loss: 0.1135 (cls: 0.0485, box: 0.0650)
[2025-08-07 22:35:11 train.log] INFO: Epoch: [28]  [Step 10500/14540]  lr: 0.000001  loss: 0.60124  detection_loss: 0.5524 (cls: 0.1273, box: 0.4250)  rpn_loss: 0.0489 (cls: 0.0179, box: 0.0310)
[2025-08-07 22:35:16 train.log] INFO: Epoch: [28]  [Step 10600/14540]  lr: 0.000001  loss: 0.31458  detection_loss: 0.2788 (cls: 0.0659, box: 0.2129)  rpn_loss: 0.0358 (cls: 0.0201, box: 0.0157)
[2025-08-07 22:35:22 train.log] INFO: Epoch: [28]  [Step 10700/14540]  lr: 0.000001  loss: 0.62523  detection_loss: 0.5751 (cls: 0.1370, box: 0.4381)  rpn_loss: 0.0501 (cls: 0.0335, box: 0.0166)
[2025-08-07 22:35:27 train.log] INFO: Epoch: [28]  [Step 10800/14540]  lr: 0.000001  loss: 0.96592  detection_loss: 0.8678 (cls: 0.3031, box: 0.5647)  rpn_loss: 0.0981 (cls: 0.0642, box: 0.0339)
[2025-08-07 22:35:33 train.log] INFO: Epoch: [28]  [Step 10900/14540]  lr: 0.000001  loss: 0.45709  detection_loss: 0.3580 (cls: 0.1113, box: 0.2467)  rpn_loss: 0.0990 (cls: 0.0266, box: 0.0724)
[2025-08-07 22:35:38 train.log] INFO: Epoch: [28]  [Step 11000/14540]  lr: 0.000001  loss: 0.91760  detection_loss: 0.8091 (cls: 0.2483, box: 0.5608)  rpn_loss: 0.1085 (cls: 0.0681, box: 0.0405)
[2025-08-07 22:35:44 train.log] INFO: Epoch: [28]  [Step 11100/14540]  lr: 0.000001  loss: 0.52338  detection_loss: 0.4969 (cls: 0.1115, box: 0.3854)  rpn_loss: 0.0264 (cls: 0.0103, box: 0.0161)
[2025-08-07 22:35:50 train.log] INFO: Epoch: [28]  [Step 11200/14540]  lr: 0.000001  loss: 0.84079  detection_loss: 0.7354 (cls: 0.1517, box: 0.5837)  rpn_loss: 0.1054 (cls: 0.0410, box: 0.0643)
[2025-08-07 22:35:55 train.log] INFO: Epoch: [28]  [Step 11300/14540]  lr: 0.000001  loss: 1.21735  detection_loss: 1.0379 (cls: 0.1933, box: 0.8446)  rpn_loss: 0.1794 (cls: 0.0764, box: 0.1031)
[2025-08-07 22:36:01 train.log] INFO: Epoch: [28]  [Step 11400/14540]  lr: 0.000001  loss: 1.07597  detection_loss: 1.0266 (cls: 0.2256, box: 0.8009)  rpn_loss: 0.0494 (cls: 0.0320, box: 0.0174)
[2025-08-07 22:36:06 train.log] INFO: Epoch: [28]  [Step 11500/14540]  lr: 0.000001  loss: 1.47130  detection_loss: 1.2654 (cls: 0.1948, box: 1.0706)  rpn_loss: 0.2059 (cls: 0.0257, box: 0.1802)
[2025-08-07 22:36:12 train.log] INFO: Epoch: [28]  [Step 11600/14540]  lr: 0.000001  loss: 0.61336  detection_loss: 0.5564 (cls: 0.1824, box: 0.3740)  rpn_loss: 0.0570 (cls: 0.0295, box: 0.0275)
[2025-08-07 22:36:17 train.log] INFO: Epoch: [28]  [Step 11700/14540]  lr: 0.000001  loss: 1.46719  detection_loss: 1.0624 (cls: 0.2497, box: 0.8127)  rpn_loss: 0.4048 (cls: 0.0323, box: 0.3725)
[2025-08-07 22:36:23 train.log] INFO: Epoch: [28]  [Step 11800/14540]  lr: 0.000001  loss: 1.10259  detection_loss: 0.9679 (cls: 0.3179, box: 0.6500)  rpn_loss: 0.1347 (cls: 0.1026, box: 0.0321)
[2025-08-07 22:36:28 train.log] INFO: Epoch: [28]  [Step 11900/14540]  lr: 0.000001  loss: 0.56405  detection_loss: 0.4553 (cls: 0.0986, box: 0.3567)  rpn_loss: 0.1087 (cls: 0.0249, box: 0.0838)
[2025-08-07 22:36:34 train.log] INFO: Epoch: [28]  [Step 12000/14540]  lr: 0.000001  loss: 0.72763  detection_loss: 0.6107 (cls: 0.1797, box: 0.4311)  rpn_loss: 0.1169 (cls: 0.0824, box: 0.0345)
[2025-08-07 22:36:39 train.log] INFO: Epoch: [28]  [Step 12100/14540]  lr: 0.000001  loss: 0.85939  detection_loss: 0.7695 (cls: 0.1618, box: 0.6077)  rpn_loss: 0.0899 (cls: 0.0511, box: 0.0388)
[2025-08-07 22:36:45 train.log] INFO: Epoch: [28]  [Step 12200/14540]  lr: 0.000001  loss: 1.19795  detection_loss: 0.8615 (cls: 0.2445, box: 0.6170)  rpn_loss: 0.3365 (cls: 0.1703, box: 0.1662)
[2025-08-07 22:36:51 train.log] INFO: Epoch: [28]  [Step 12300/14540]  lr: 0.000001  loss: 0.97362  detection_loss: 0.8883 (cls: 0.2332, box: 0.6551)  rpn_loss: 0.0853 (cls: 0.0436, box: 0.0418)
[2025-08-07 22:36:56 train.log] INFO: Epoch: [28]  [Step 12400/14540]  lr: 0.000001  loss: 0.91044  detection_loss: 0.8760 (cls: 0.2892, box: 0.5868)  rpn_loss: 0.0345 (cls: 0.0224, box: 0.0121)
[2025-08-07 22:37:02 train.log] INFO: Epoch: [28]  [Step 12500/14540]  lr: 0.000001  loss: 1.35599  detection_loss: 1.1447 (cls: 0.4861, box: 0.6586)  rpn_loss: 0.2113 (cls: 0.1873, box: 0.0239)
[2025-08-07 22:37:07 train.log] INFO: Epoch: [28]  [Step 12600/14540]  lr: 0.000001  loss: 0.99906  detection_loss: 0.9104 (cls: 0.2215, box: 0.6889)  rpn_loss: 0.0887 (cls: 0.0674, box: 0.0212)
[2025-08-07 22:37:13 train.log] INFO: Epoch: [28]  [Step 12700/14540]  lr: 0.000001  loss: 0.90378  detection_loss: 0.7951 (cls: 0.2284, box: 0.5668)  rpn_loss: 0.1086 (cls: 0.0960, box: 0.0126)
[2025-08-07 22:37:18 train.log] INFO: Epoch: [28]  [Step 12800/14540]  lr: 0.000001  loss: 0.74763  detection_loss: 0.6745 (cls: 0.1999, box: 0.4745)  rpn_loss: 0.0732 (cls: 0.0310, box: 0.0421)
[2025-08-07 22:37:24 train.log] INFO: Epoch: [28]  [Step 12900/14540]  lr: 0.000001  loss: 0.69425  detection_loss: 0.5874 (cls: 0.2245, box: 0.3629)  rpn_loss: 0.1069 (cls: 0.0855, box: 0.0214)
[2025-08-07 22:37:30 train.log] INFO: Epoch: [28]  [Step 13000/14540]  lr: 0.000001  loss: 0.83442  detection_loss: 0.7384 (cls: 0.2462, box: 0.4923)  rpn_loss: 0.0960 (cls: 0.0843, box: 0.0117)
[2025-08-07 22:37:35 train.log] INFO: Epoch: [28]  [Step 13100/14540]  lr: 0.000001  loss: 0.74079  detection_loss: 0.6687 (cls: 0.1790, box: 0.4897)  rpn_loss: 0.0721 (cls: 0.0312, box: 0.0409)
[2025-08-07 22:37:41 train.log] INFO: Epoch: [28]  [Step 13200/14540]  lr: 0.000001  loss: 0.83323  detection_loss: 0.7456 (cls: 0.2422, box: 0.5034)  rpn_loss: 0.0877 (cls: 0.0389, box: 0.0488)
[2025-08-07 22:37:47 train.log] INFO: Epoch: [28]  [Step 13300/14540]  lr: 0.000001  loss: 0.86621  detection_loss: 0.7485 (cls: 0.1913, box: 0.5571)  rpn_loss: 0.1178 (cls: 0.0693, box: 0.0485)
[2025-08-07 22:37:52 train.log] INFO: Epoch: [28]  [Step 13400/14540]  lr: 0.000001  loss: 0.55863  detection_loss: 0.4857 (cls: 0.2177, box: 0.2680)  rpn_loss: 0.0729 (cls: 0.0581, box: 0.0148)
[2025-08-07 22:37:58 train.log] INFO: Epoch: [28]  [Step 13500/14540]  lr: 0.000001  loss: 0.84294  detection_loss: 0.6442 (cls: 0.1956, box: 0.4486)  rpn_loss: 0.1987 (cls: 0.1657, box: 0.0330)
[2025-08-07 22:38:03 train.log] INFO: Epoch: [28]  [Step 13600/14540]  lr: 0.000001  loss: 0.71718  detection_loss: 0.6606 (cls: 0.2085, box: 0.4521)  rpn_loss: 0.0566 (cls: 0.0356, box: 0.0210)
[2025-08-07 22:38:09 train.log] INFO: Epoch: [28]  [Step 13700/14540]  lr: 0.000001  loss: 1.21136  detection_loss: 1.1501 (cls: 0.2820, box: 0.8681)  rpn_loss: 0.0613 (cls: 0.0159, box: 0.0454)
[2025-08-07 22:38:15 train.log] INFO: Epoch: [28]  [Step 13800/14540]  lr: 0.000001  loss: 1.02771  detection_loss: 0.9162 (cls: 0.2800, box: 0.6362)  rpn_loss: 0.1115 (cls: 0.0829, box: 0.0285)
[2025-08-07 22:38:20 train.log] INFO: Epoch: [28]  [Step 13900/14540]  lr: 0.000001  loss: 0.88590  detection_loss: 0.8132 (cls: 0.2097, box: 0.6035)  rpn_loss: 0.0727 (cls: 0.0262, box: 0.0465)
[2025-08-07 22:38:26 train.log] INFO: Epoch: [28]  [Step 14000/14540]  lr: 0.000001  loss: 0.86734  detection_loss: 0.7438 (cls: 0.2087, box: 0.5351)  rpn_loss: 0.1236 (cls: 0.0358, box: 0.0878)
[2025-08-07 22:38:32 train.log] INFO: Epoch: [28]  [Step 14100/14540]  lr: 0.000001  loss: 0.63961  detection_loss: 0.5870 (cls: 0.0965, box: 0.4905)  rpn_loss: 0.0526 (cls: 0.0304, box: 0.0222)
[2025-08-07 22:38:37 train.log] INFO: Epoch: [28]  [Step 14200/14540]  lr: 0.000001  loss: 1.01909  detection_loss: 0.9380 (cls: 0.1875, box: 0.7505)  rpn_loss: 0.0811 (cls: 0.0579, box: 0.0232)
[2025-08-07 22:38:43 train.log] INFO: Epoch: [28]  [Step 14300/14540]  lr: 0.000001  loss: 1.65710  detection_loss: 1.4941 (cls: 0.3720, box: 1.1221)  rpn_loss: 0.1630 (cls: 0.0846, box: 0.0784)
[2025-08-07 22:38:48 train.log] INFO: Epoch: [28]  [Step 14400/14540]  lr: 0.000001  loss: 0.84582  detection_loss: 0.6908 (cls: 0.1916, box: 0.4992)  rpn_loss: 0.1550 (cls: 0.1308, box: 0.0242)
[2025-08-07 22:38:54 train.log] INFO: Epoch: [28]  [Step 14500/14540]  lr: 0.000001  loss: 0.90284  detection_loss: 0.8220 (cls: 0.2735, box: 0.5485)  rpn_loss: 0.0809 (cls: 0.0517, box: 0.0291)
[2025-08-07 22:42:17 train.log] INFO: Epoch: [29]  [Step 100/14540]  lr: 0.000001  loss: 1.13135  detection_loss: 0.9996 (cls: 0.2997, box: 0.7000)  rpn_loss: 0.1317 (cls: 0.1032, box: 0.0285)
[2025-08-07 22:42:23 train.log] INFO: Epoch: [29]  [Step 200/14540]  lr: 0.000001  loss: 0.76441  detection_loss: 0.6661 (cls: 0.1442, box: 0.5218)  rpn_loss: 0.0984 (cls: 0.0279, box: 0.0705)
[2025-08-07 22:42:29 train.log] INFO: Epoch: [29]  [Step 300/14540]  lr: 0.000001  loss: 0.37782  detection_loss: 0.3432 (cls: 0.0753, box: 0.2680)  rpn_loss: 0.0346 (cls: 0.0110, box: 0.0236)
[2025-08-07 22:42:35 train.log] INFO: Epoch: [29]  [Step 400/14540]  lr: 0.000001  loss: 1.24917  detection_loss: 1.1379 (cls: 0.2981, box: 0.8398)  rpn_loss: 0.1113 (cls: 0.0401, box: 0.0712)
[2025-08-07 22:42:40 train.log] INFO: Epoch: [29]  [Step 500/14540]  lr: 0.000001  loss: 1.03274  detection_loss: 0.8822 (cls: 0.1506, box: 0.7316)  rpn_loss: 0.1506 (cls: 0.0254, box: 0.1251)
[2025-08-07 22:42:46 train.log] INFO: Epoch: [29]  [Step 600/14540]  lr: 0.000001  loss: 0.77190  detection_loss: 0.6804 (cls: 0.1493, box: 0.5311)  rpn_loss: 0.0915 (cls: 0.0341, box: 0.0574)
[2025-08-07 22:42:51 train.log] INFO: Epoch: [29]  [Step 700/14540]  lr: 0.000001  loss: 0.93016  detection_loss: 0.6938 (cls: 0.1577, box: 0.5361)  rpn_loss: 0.2364 (cls: 0.0618, box: 0.1745)
[2025-08-07 22:42:57 train.log] INFO: Epoch: [29]  [Step 800/14540]  lr: 0.000001  loss: 0.69782  detection_loss: 0.6372 (cls: 0.1868, box: 0.4504)  rpn_loss: 0.0606 (cls: 0.0451, box: 0.0155)
[2025-08-07 22:43:02 train.log] INFO: Epoch: [29]  [Step 900/14540]  lr: 0.000001  loss: 1.16094  detection_loss: 1.0146 (cls: 0.3146, box: 0.7000)  rpn_loss: 0.1464 (cls: 0.0308, box: 0.1155)
[2025-08-07 22:43:08 train.log] INFO: Epoch: [29]  [Step 1000/14540]  lr: 0.000001  loss: 0.56604  detection_loss: 0.5323 (cls: 0.1651, box: 0.3672)  rpn_loss: 0.0337 (cls: 0.0102, box: 0.0236)
[2025-08-07 22:43:14 train.log] INFO: Epoch: [29]  [Step 1100/14540]  lr: 0.000001  loss: 0.94664  detection_loss: 0.8658 (cls: 0.1484, box: 0.7174)  rpn_loss: 0.0809 (cls: 0.0562, box: 0.0247)
[2025-08-07 22:43:20 train.log] INFO: Epoch: [29]  [Step 1200/14540]  lr: 0.000001  loss: 0.99365  detection_loss: 0.8718 (cls: 0.2309, box: 0.6409)  rpn_loss: 0.1219 (cls: 0.0875, box: 0.0344)
[2025-08-07 22:43:25 train.log] INFO: Epoch: [29]  [Step 1300/14540]  lr: 0.000001  loss: 1.19389  detection_loss: 1.0604 (cls: 0.2152, box: 0.8453)  rpn_loss: 0.1334 (cls: 0.0300, box: 0.1034)
[2025-08-07 22:43:31 train.log] INFO: Epoch: [29]  [Step 1400/14540]  lr: 0.000001  loss: 1.18559  detection_loss: 1.0484 (cls: 0.2775, box: 0.7709)  rpn_loss: 0.1371 (cls: 0.1039, box: 0.0333)
[2025-08-07 22:43:36 train.log] INFO: Epoch: [29]  [Step 1500/14540]  lr: 0.000001  loss: 0.75382  detection_loss: 0.6692 (cls: 0.1890, box: 0.4802)  rpn_loss: 0.0846 (cls: 0.0616, box: 0.0229)
[2025-08-07 22:43:42 train.log] INFO: Epoch: [29]  [Step 1600/14540]  lr: 0.000001  loss: 0.81179  detection_loss: 0.7776 (cls: 0.0959, box: 0.6817)  rpn_loss: 0.0342 (cls: 0.0125, box: 0.0216)
[2025-08-07 22:43:47 train.log] INFO: Epoch: [29]  [Step 1700/14540]  lr: 0.000001  loss: 0.88476  detection_loss: 0.8190 (cls: 0.1951, box: 0.6239)  rpn_loss: 0.0657 (cls: 0.0172, box: 0.0485)
[2025-08-07 22:43:53 train.log] INFO: Epoch: [29]  [Step 1800/14540]  lr: 0.000001  loss: 0.64583  detection_loss: 0.5690 (cls: 0.1987, box: 0.3704)  rpn_loss: 0.0768 (cls: 0.0475, box: 0.0293)
[2025-08-07 22:43:58 train.log] INFO: Epoch: [29]  [Step 1900/14540]  lr: 0.000001  loss: 0.87949  detection_loss: 0.8128 (cls: 0.1575, box: 0.6553)  rpn_loss: 0.0667 (cls: 0.0251, box: 0.0416)
[2025-08-07 22:44:04 train.log] INFO: Epoch: [29]  [Step 2000/14540]  lr: 0.000001  loss: 0.99127  detection_loss: 0.9159 (cls: 0.2667, box: 0.6492)  rpn_loss: 0.0754 (cls: 0.0424, box: 0.0329)
[2025-08-07 22:44:09 train.log] INFO: Epoch: [29]  [Step 2100/14540]  lr: 0.000001  loss: 0.69587  detection_loss: 0.6550 (cls: 0.1342, box: 0.5208)  rpn_loss: 0.0409 (cls: 0.0236, box: 0.0173)
[2025-08-07 22:44:15 train.log] INFO: Epoch: [29]  [Step 2200/14540]  lr: 0.000001  loss: 0.77438  detection_loss: 0.5590 (cls: 0.0898, box: 0.4691)  rpn_loss: 0.2154 (cls: 0.0540, box: 0.1615)
[2025-08-07 22:44:21 train.log] INFO: Epoch: [29]  [Step 2300/14540]  lr: 0.000001  loss: 0.52302  detection_loss: 0.4471 (cls: 0.1744, box: 0.2728)  rpn_loss: 0.0759 (cls: 0.0410, box: 0.0349)
[2025-08-07 22:44:26 train.log] INFO: Epoch: [29]  [Step 2400/14540]  lr: 0.000001  loss: 0.88401  detection_loss: 0.7817 (cls: 0.1592, box: 0.6225)  rpn_loss: 0.1023 (cls: 0.0621, box: 0.0402)
[2025-08-07 22:44:32 train.log] INFO: Epoch: [29]  [Step 2500/14540]  lr: 0.000001  loss: 1.02156  detection_loss: 0.8891 (cls: 0.1759, box: 0.7133)  rpn_loss: 0.1325 (cls: 0.0260, box: 0.1064)
[2025-08-07 22:44:37 train.log] INFO: Epoch: [29]  [Step 2600/14540]  lr: 0.000001  loss: 0.55112  detection_loss: 0.4701 (cls: 0.1510, box: 0.3192)  rpn_loss: 0.0810 (cls: 0.0487, box: 0.0323)
[2025-08-07 22:44:43 train.log] INFO: Epoch: [29]  [Step 2700/14540]  lr: 0.000001  loss: 0.70969  detection_loss: 0.6435 (cls: 0.1350, box: 0.5085)  rpn_loss: 0.0662 (cls: 0.0235, box: 0.0427)
[2025-08-07 22:44:49 train.log] INFO: Epoch: [29]  [Step 2800/14540]  lr: 0.000001  loss: 0.39875  detection_loss: 0.3452 (cls: 0.1377, box: 0.2076)  rpn_loss: 0.0535 (cls: 0.0440, box: 0.0095)
[2025-08-07 22:44:54 train.log] INFO: Epoch: [29]  [Step 2900/14540]  lr: 0.000001  loss: 1.26657  detection_loss: 1.1696 (cls: 0.2384, box: 0.9311)  rpn_loss: 0.0970 (cls: 0.0409, box: 0.0561)
[2025-08-07 22:45:00 train.log] INFO: Epoch: [29]  [Step 3000/14540]  lr: 0.000001  loss: 0.77243  detection_loss: 0.6455 (cls: 0.1838, box: 0.4617)  rpn_loss: 0.1269 (cls: 0.0767, box: 0.0503)
[2025-08-07 22:45:05 train.log] INFO: Epoch: [29]  [Step 3100/14540]  lr: 0.000001  loss: 0.73064  detection_loss: 0.6423 (cls: 0.1328, box: 0.5094)  rpn_loss: 0.0884 (cls: 0.0301, box: 0.0582)
[2025-08-07 22:45:11 train.log] INFO: Epoch: [29]  [Step 3200/14540]  lr: 0.000001  loss: 0.86257  detection_loss: 0.7271 (cls: 0.1374, box: 0.5896)  rpn_loss: 0.1355 (cls: 0.0304, box: 0.1051)
[2025-08-07 22:45:16 train.log] INFO: Epoch: [29]  [Step 3300/14540]  lr: 0.000001  loss: 1.01950  detection_loss: 0.9348 (cls: 0.1252, box: 0.8095)  rpn_loss: 0.0847 (cls: 0.0217, box: 0.0630)
[2025-08-07 22:45:22 train.log] INFO: Epoch: [29]  [Step 3400/14540]  lr: 0.000001  loss: 0.89249  detection_loss: 0.8153 (cls: 0.2700, box: 0.5453)  rpn_loss: 0.0772 (cls: 0.0546, box: 0.0226)
[2025-08-07 22:45:27 train.log] INFO: Epoch: [29]  [Step 3500/14540]  lr: 0.000001  loss: 0.42022  detection_loss: 0.3711 (cls: 0.0669, box: 0.3042)  rpn_loss: 0.0491 (cls: 0.0367, box: 0.0124)
[2025-08-07 22:45:33 train.log] INFO: Epoch: [29]  [Step 3600/14540]  lr: 0.000001  loss: 0.47359  detection_loss: 0.4009 (cls: 0.1433, box: 0.2576)  rpn_loss: 0.0727 (cls: 0.0553, box: 0.0174)
[2025-08-07 22:45:35 train.log] INFO: Epoch: [29]  [Step 3635/14540]  lr: 0.000001  loss: 0.41892  detection_loss: 0.3504 (cls: 0.1279, box: 0.2225)  rpn_loss: 0.0685 (cls: 0.0237, box: 0.0449)
[2025-08-07 22:45:38 train.log] INFO: Epoch: [29]  [Step 3700/14540]  lr: 0.000001  loss: 1.09389  detection_loss: 0.9152 (cls: 0.2764, box: 0.6388)  rpn_loss: 0.1787 (cls: 0.0626, box: 0.1161)
[2025-08-07 22:45:44 train.log] INFO: Epoch: [29]  [Step 3800/14540]  lr: 0.000001  loss: 1.21471  detection_loss: 1.1302 (cls: 0.1841, box: 0.9461)  rpn_loss: 0.0845 (cls: 0.0534, box: 0.0311)
[2025-08-07 22:45:50 train.log] INFO: Epoch: [29]  [Step 3900/14540]  lr: 0.000001  loss: 0.88706  detection_loss: 0.7971 (cls: 0.1936, box: 0.6035)  rpn_loss: 0.0900 (cls: 0.0702, box: 0.0198)
[2025-08-07 22:45:55 train.log] INFO: Epoch: [29]  [Step 4000/14540]  lr: 0.000001  loss: 1.24762  detection_loss: 1.0713 (cls: 0.3742, box: 0.6971)  rpn_loss: 0.1763 (cls: 0.0734, box: 0.1029)
[2025-08-07 22:46:00 train.log] INFO: Epoch: [29]  [Step 4100/14540]  lr: 0.000001  loss: 0.45040  detection_loss: 0.3730 (cls: 0.0895, box: 0.2835)  rpn_loss: 0.0774 (cls: 0.0577, box: 0.0197)
[2025-08-07 22:46:06 train.log] INFO: Epoch: [29]  [Step 4200/14540]  lr: 0.000001  loss: 0.65361  detection_loss: 0.6042 (cls: 0.1052, box: 0.4991)  rpn_loss: 0.0494 (cls: 0.0072, box: 0.0422)
[2025-08-07 22:46:11 train.log] INFO: Epoch: [29]  [Step 4300/14540]  lr: 0.000001  loss: 0.95766  detection_loss: 0.8604 (cls: 0.1374, box: 0.7229)  rpn_loss: 0.0973 (cls: 0.0811, box: 0.0161)
[2025-08-07 22:46:17 train.log] INFO: Epoch: [29]  [Step 4400/14540]  lr: 0.000001  loss: 1.20125  detection_loss: 1.0595 (cls: 0.3356, box: 0.7239)  rpn_loss: 0.1417 (cls: 0.1070, box: 0.0347)
[2025-08-07 22:46:23 train.log] INFO: Epoch: [29]  [Step 4500/14540]  lr: 0.000001  loss: 1.19449  detection_loss: 1.0216 (cls: 0.2716, box: 0.7500)  rpn_loss: 0.1728 (cls: 0.0685, box: 0.1044)
[2025-08-07 22:46:28 train.log] INFO: Epoch: [29]  [Step 4600/14540]  lr: 0.000001  loss: 0.92123  detection_loss: 0.7931 (cls: 0.1537, box: 0.6394)  rpn_loss: 0.1282 (cls: 0.0592, box: 0.0689)
[2025-08-07 22:46:34 train.log] INFO: Epoch: [29]  [Step 4700/14540]  lr: 0.000001  loss: 0.75244  detection_loss: 0.6370 (cls: 0.2098, box: 0.4272)  rpn_loss: 0.1154 (cls: 0.0734, box: 0.0420)
[2025-08-07 22:46:40 train.log] INFO: Epoch: [29]  [Step 4800/14540]  lr: 0.000001  loss: 0.74947  detection_loss: 0.7172 (cls: 0.0996, box: 0.6177)  rpn_loss: 0.0322 (cls: 0.0131, box: 0.0191)
[2025-08-07 22:46:45 train.log] INFO: Epoch: [29]  [Step 4900/14540]  lr: 0.000001  loss: 0.52383  detection_loss: 0.4969 (cls: 0.1059, box: 0.3909)  rpn_loss: 0.0270 (cls: 0.0071, box: 0.0199)
[2025-08-07 22:46:50 train.log] INFO: Epoch: [29]  [Step 5000/14540]  lr: 0.000001  loss: 0.88554  detection_loss: 0.8475 (cls: 0.1569, box: 0.6906)  rpn_loss: 0.0381 (cls: 0.0198, box: 0.0183)
[2025-08-07 22:46:56 train.log] INFO: Epoch: [29]  [Step 5100/14540]  lr: 0.000001  loss: 1.09944  detection_loss: 0.9882 (cls: 0.3021, box: 0.6861)  rpn_loss: 0.1112 (cls: 0.0779, box: 0.0333)
[2025-08-07 22:47:02 train.log] INFO: Epoch: [29]  [Step 5200/14540]  lr: 0.000001  loss: 0.62195  detection_loss: 0.4424 (cls: 0.1103, box: 0.3320)  rpn_loss: 0.1796 (cls: 0.1332, box: 0.0464)
[2025-08-07 22:47:07 train.log] INFO: Epoch: [29]  [Step 5300/14540]  lr: 0.000001  loss: 0.87987  detection_loss: 0.7455 (cls: 0.1836, box: 0.5619)  rpn_loss: 0.1344 (cls: 0.0571, box: 0.0773)
[2025-08-07 22:47:13 train.log] INFO: Epoch: [29]  [Step 5400/14540]  lr: 0.000001  loss: 1.32214  detection_loss: 1.2177 (cls: 0.3263, box: 0.8913)  rpn_loss: 0.1045 (cls: 0.0515, box: 0.0530)
[2025-08-07 22:47:19 train.log] INFO: Epoch: [29]  [Step 5500/14540]  lr: 0.000001  loss: 0.88834  detection_loss: 0.7952 (cls: 0.2430, box: 0.5522)  rpn_loss: 0.0931 (cls: 0.0689, box: 0.0242)
[2025-08-07 22:47:24 train.log] INFO: Epoch: [29]  [Step 5600/14540]  lr: 0.000001  loss: 0.51674  detection_loss: 0.4397 (cls: 0.1129, box: 0.3267)  rpn_loss: 0.0771 (cls: 0.0586, box: 0.0185)
[2025-08-07 22:47:30 train.log] INFO: Epoch: [29]  [Step 5700/14540]  lr: 0.000001  loss: 1.38029  detection_loss: 1.1722 (cls: 0.4189, box: 0.7533)  rpn_loss: 0.2081 (cls: 0.0908, box: 0.1172)
[2025-08-07 22:47:35 train.log] INFO: Epoch: [29]  [Step 5800/14540]  lr: 0.000001  loss: 0.84920  detection_loss: 0.7735 (cls: 0.2743, box: 0.4992)  rpn_loss: 0.0757 (cls: 0.0528, box: 0.0229)
[2025-08-07 22:47:41 train.log] INFO: Epoch: [29]  [Step 5900/14540]  lr: 0.000001  loss: 0.95697  detection_loss: 0.6909 (cls: 0.1848, box: 0.5061)  rpn_loss: 0.2661 (cls: 0.0122, box: 0.2539)
[2025-08-07 22:47:47 train.log] INFO: Epoch: [29]  [Step 6000/14540]  lr: 0.000001  loss: 1.10028  detection_loss: 0.9752 (cls: 0.2550, box: 0.7202)  rpn_loss: 0.1250 (cls: 0.0765, box: 0.0486)
[2025-08-07 22:47:52 train.log] INFO: Epoch: [29]  [Step 6100/14540]  lr: 0.000001  loss: 0.48533  detection_loss: 0.4236 (cls: 0.1616, box: 0.2620)  rpn_loss: 0.0617 (cls: 0.0314, box: 0.0304)
[2025-08-07 22:47:58 train.log] INFO: Epoch: [29]  [Step 6200/14540]  lr: 0.000001  loss: 1.03072  detection_loss: 0.9486 (cls: 0.2091, box: 0.7395)  rpn_loss: 0.0821 (cls: 0.0356, box: 0.0466)
[2025-08-07 22:48:03 train.log] INFO: Epoch: [29]  [Step 6300/14540]  lr: 0.000001  loss: 0.98793  detection_loss: 0.9420 (cls: 0.1056, box: 0.8363)  rpn_loss: 0.0459 (cls: 0.0126, box: 0.0334)
[2025-08-07 22:48:09 train.log] INFO: Epoch: [29]  [Step 6400/14540]  lr: 0.000001  loss: 0.80272  detection_loss: 0.6953 (cls: 0.1886, box: 0.5067)  rpn_loss: 0.1074 (cls: 0.0370, box: 0.0704)
[2025-08-07 22:48:15 train.log] INFO: Epoch: [29]  [Step 6500/14540]  lr: 0.000001  loss: 0.63044  detection_loss: 0.5504 (cls: 0.1042, box: 0.4462)  rpn_loss: 0.0800 (cls: 0.0346, box: 0.0454)
[2025-08-07 22:48:20 train.log] INFO: Epoch: [29]  [Step 6600/14540]  lr: 0.000001  loss: 0.76089  detection_loss: 0.6399 (cls: 0.1439, box: 0.4959)  rpn_loss: 0.1210 (cls: 0.0797, box: 0.0414)
[2025-08-07 22:48:26 train.log] INFO: Epoch: [29]  [Step 6700/14540]  lr: 0.000001  loss: 1.12059  detection_loss: 1.0050 (cls: 0.2405, box: 0.7645)  rpn_loss: 0.1156 (cls: 0.0965, box: 0.0191)
[2025-08-07 22:48:31 train.log] INFO: Epoch: [29]  [Step 6800/14540]  lr: 0.000001  loss: 1.03914  detection_loss: 0.9357 (cls: 0.3254, box: 0.6102)  rpn_loss: 0.1035 (cls: 0.0253, box: 0.0781)
[2025-08-07 22:48:37 train.log] INFO: Epoch: [29]  [Step 6900/14540]  lr: 0.000001  loss: 1.27483  detection_loss: 1.1650 (cls: 0.2074, box: 0.9576)  rpn_loss: 0.1098 (cls: 0.0452, box: 0.0647)
[2025-08-07 22:48:43 train.log] INFO: Epoch: [29]  [Step 7000/14540]  lr: 0.000001  loss: 1.06846  detection_loss: 1.0001 (cls: 0.1673, box: 0.8327)  rpn_loss: 0.0684 (cls: 0.0403, box: 0.0281)
[2025-08-07 22:48:48 train.log] INFO: Epoch: [29]  [Step 7100/14540]  lr: 0.000001  loss: 0.90160  detection_loss: 0.8132 (cls: 0.2360, box: 0.5772)  rpn_loss: 0.0884 (cls: 0.0529, box: 0.0356)
[2025-08-07 22:48:53 train.log] INFO: Epoch: [29]  [Step 7200/14540]  lr: 0.000001  loss: 0.86900  detection_loss: 0.7837 (cls: 0.2707, box: 0.5130)  rpn_loss: 0.0853 (cls: 0.0526, box: 0.0328)
[2025-08-07 22:48:59 train.log] INFO: Epoch: [29]  [Step 7300/14540]  lr: 0.000001  loss: 0.45086  detection_loss: 0.3848 (cls: 0.1524, box: 0.2323)  rpn_loss: 0.0661 (cls: 0.0325, box: 0.0336)
[2025-08-07 22:49:05 train.log] INFO: Epoch: [29]  [Step 7400/14540]  lr: 0.000001  loss: 0.69714  detection_loss: 0.5666 (cls: 0.1829, box: 0.3838)  rpn_loss: 0.1305 (cls: 0.1010, box: 0.0295)
[2025-08-07 22:49:10 train.log] INFO: Epoch: [29]  [Step 7500/14540]  lr: 0.000001  loss: 0.38579  detection_loss: 0.3505 (cls: 0.1240, box: 0.2265)  rpn_loss: 0.0353 (cls: 0.0140, box: 0.0213)
[2025-08-07 22:49:16 train.log] INFO: Epoch: [29]  [Step 7600/14540]  lr: 0.000001  loss: 1.04958  detection_loss: 0.8474 (cls: 0.2400, box: 0.6074)  rpn_loss: 0.2022 (cls: 0.1781, box: 0.0240)
[2025-08-07 22:49:21 train.log] INFO: Epoch: [29]  [Step 7700/14540]  lr: 0.000001  loss: 0.87879  detection_loss: 0.7977 (cls: 0.2064, box: 0.5913)  rpn_loss: 0.0811 (cls: 0.0324, box: 0.0486)
[2025-08-07 22:49:27 train.log] INFO: Epoch: [29]  [Step 7800/14540]  lr: 0.000001  loss: 0.74170  detection_loss: 0.6913 (cls: 0.2389, box: 0.4524)  rpn_loss: 0.0504 (cls: 0.0241, box: 0.0263)
[2025-08-07 22:49:33 train.log] INFO: Epoch: [29]  [Step 7900/14540]  lr: 0.000001  loss: 1.02468  detection_loss: 0.9629 (cls: 0.2446, box: 0.7183)  rpn_loss: 0.0618 (cls: 0.0410, box: 0.0209)
[2025-08-07 22:49:38 train.log] INFO: Epoch: [29]  [Step 8000/14540]  lr: 0.000001  loss: 0.67230  detection_loss: 0.6396 (cls: 0.0912, box: 0.5484)  rpn_loss: 0.0327 (cls: 0.0069, box: 0.0258)
[2025-08-07 22:49:44 train.log] INFO: Epoch: [29]  [Step 8100/14540]  lr: 0.000001  loss: 0.88129  detection_loss: 0.8028 (cls: 0.2097, box: 0.5931)  rpn_loss: 0.0785 (cls: 0.0384, box: 0.0400)
[2025-08-07 22:49:50 train.log] INFO: Epoch: [29]  [Step 8200/14540]  lr: 0.000001  loss: 1.00009  detection_loss: 0.8950 (cls: 0.2391, box: 0.6559)  rpn_loss: 0.1050 (cls: 0.0404, box: 0.0646)
[2025-08-07 22:49:55 train.log] INFO: Epoch: [29]  [Step 8300/14540]  lr: 0.000001  loss: 1.02384  detection_loss: 0.9451 (cls: 0.2019, box: 0.7432)  rpn_loss: 0.0787 (cls: 0.0560, box: 0.0227)
[2025-08-07 22:50:01 train.log] INFO: Epoch: [29]  [Step 8400/14540]  lr: 0.000001  loss: 0.76996  detection_loss: 0.5804 (cls: 0.1702, box: 0.4102)  rpn_loss: 0.1895 (cls: 0.0212, box: 0.1684)
[2025-08-07 22:50:06 train.log] INFO: Epoch: [29]  [Step 8500/14540]  lr: 0.000001  loss: 0.79291  detection_loss: 0.6411 (cls: 0.1298, box: 0.5113)  rpn_loss: 0.1518 (cls: 0.0177, box: 0.1341)
[2025-08-07 22:50:12 train.log] INFO: Epoch: [29]  [Step 8600/14540]  lr: 0.000001  loss: 0.85736  detection_loss: 0.7830 (cls: 0.1671, box: 0.6159)  rpn_loss: 0.0743 (cls: 0.0330, box: 0.0414)
[2025-08-07 22:50:17 train.log] INFO: Epoch: [29]  [Step 8700/14540]  lr: 0.000001  loss: 1.20575  detection_loss: 1.0318 (cls: 0.2966, box: 0.7352)  rpn_loss: 0.1740 (cls: 0.1469, box: 0.0271)
[2025-08-07 22:50:23 train.log] INFO: Epoch: [29]  [Step 8800/14540]  lr: 0.000001  loss: 0.58409  detection_loss: 0.4898 (cls: 0.1232, box: 0.3666)  rpn_loss: 0.0943 (cls: 0.0221, box: 0.0722)
[2025-08-07 22:50:28 train.log] INFO: Epoch: [29]  [Step 8900/14540]  lr: 0.000001  loss: 1.47553  detection_loss: 1.3615 (cls: 0.2498, box: 1.1117)  rpn_loss: 0.1140 (cls: 0.0781, box: 0.0358)
[2025-08-07 22:50:34 train.log] INFO: Epoch: [29]  [Step 9000/14540]  lr: 0.000001  loss: 1.07380  detection_loss: 0.9359 (cls: 0.1672, box: 0.7687)  rpn_loss: 0.1379 (cls: 0.0396, box: 0.0983)
[2025-08-07 22:50:40 train.log] INFO: Epoch: [29]  [Step 9100/14540]  lr: 0.000001  loss: 0.67153  detection_loss: 0.5954 (cls: 0.1760, box: 0.4194)  rpn_loss: 0.0762 (cls: 0.0234, box: 0.0528)
[2025-08-07 22:50:45 train.log] INFO: Epoch: [29]  [Step 9200/14540]  lr: 0.000001  loss: 0.65513  detection_loss: 0.6134 (cls: 0.1614, box: 0.4520)  rpn_loss: 0.0417 (cls: 0.0283, box: 0.0134)
[2025-08-07 22:50:51 train.log] INFO: Epoch: [29]  [Step 9300/14540]  lr: 0.000001  loss: 0.99345  detection_loss: 0.9227 (cls: 0.2424, box: 0.6803)  rpn_loss: 0.0707 (cls: 0.0488, box: 0.0219)
[2025-08-07 22:50:57 train.log] INFO: Epoch: [29]  [Step 9400/14540]  lr: 0.000001  loss: 1.17060  detection_loss: 1.0962 (cls: 0.1749, box: 0.9213)  rpn_loss: 0.0744 (cls: 0.0309, box: 0.0435)
[2025-08-07 22:51:02 train.log] INFO: Epoch: [29]  [Step 9500/14540]  lr: 0.000001  loss: 1.58236  detection_loss: 1.4577 (cls: 0.3969, box: 1.0608)  rpn_loss: 0.1247 (cls: 0.0676, box: 0.0570)
[2025-08-07 22:51:08 train.log] INFO: Epoch: [29]  [Step 9600/14540]  lr: 0.000001  loss: 1.10542  detection_loss: 0.9241 (cls: 0.2646, box: 0.6594)  rpn_loss: 0.1814 (cls: 0.1207, box: 0.0607)
[2025-08-07 22:51:14 train.log] INFO: Epoch: [29]  [Step 9700/14540]  lr: 0.000001  loss: 1.10406  detection_loss: 0.9843 (cls: 0.3499, box: 0.6344)  rpn_loss: 0.1198 (cls: 0.0903, box: 0.0295)
[2025-08-07 22:51:19 train.log] INFO: Epoch: [29]  [Step 9800/14540]  lr: 0.000001  loss: 0.45253  detection_loss: 0.3641 (cls: 0.1010, box: 0.2631)  rpn_loss: 0.0884 (cls: 0.0705, box: 0.0179)
[2025-08-07 22:51:25 train.log] INFO: Epoch: [29]  [Step 9900/14540]  lr: 0.000001  loss: 1.15798  detection_loss: 1.0479 (cls: 0.3053, box: 0.7426)  rpn_loss: 0.1100 (cls: 0.0870, box: 0.0230)
[2025-08-07 22:51:30 train.log] INFO: Epoch: [29]  [Step 10000/14540]  lr: 0.000001  loss: 0.68105  detection_loss: 0.6448 (cls: 0.0903, box: 0.5544)  rpn_loss: 0.0363 (cls: 0.0209, box: 0.0153)
[2025-08-07 22:51:36 train.log] INFO: Epoch: [29]  [Step 10100/14540]  lr: 0.000001  loss: 0.69435  detection_loss: 0.6071 (cls: 0.1784, box: 0.4287)  rpn_loss: 0.0873 (cls: 0.0121, box: 0.0751)
[2025-08-07 22:51:42 train.log] INFO: Epoch: [29]  [Step 10200/14540]  lr: 0.000001  loss: 0.58104  detection_loss: 0.5321 (cls: 0.1488, box: 0.3833)  rpn_loss: 0.0489 (cls: 0.0235, box: 0.0254)
[2025-08-07 22:51:48 train.log] INFO: Epoch: [29]  [Step 10300/14540]  lr: 0.000001  loss: 0.75405  detection_loss: 0.3786 (cls: 0.0844, box: 0.2942)  rpn_loss: 0.3754 (cls: 0.0552, box: 0.3202)
[2025-08-07 22:51:54 train.log] INFO: Epoch: [29]  [Step 10400/14540]  lr: 0.000001  loss: 0.94085  detection_loss: 0.8286 (cls: 0.2054, box: 0.6232)  rpn_loss: 0.1122 (cls: 0.0834, box: 0.0289)
[2025-08-07 22:51:59 train.log] INFO: Epoch: [29]  [Step 10500/14540]  lr: 0.000001  loss: 0.83716  detection_loss: 0.7107 (cls: 0.2452, box: 0.4655)  rpn_loss: 0.1264 (cls: 0.0647, box: 0.0617)
[2025-08-07 22:52:05 train.log] INFO: Epoch: [29]  [Step 10600/14540]  lr: 0.000001  loss: 1.08432  detection_loss: 0.9677 (cls: 0.1840, box: 0.7837)  rpn_loss: 0.1166 (cls: 0.0775, box: 0.0391)
[2025-08-07 22:52:11 train.log] INFO: Epoch: [29]  [Step 10700/14540]  lr: 0.000001  loss: 0.87957  detection_loss: 0.7320 (cls: 0.1711, box: 0.5610)  rpn_loss: 0.1475 (cls: 0.0254, box: 0.1221)
[2025-08-07 22:52:17 train.log] INFO: Epoch: [29]  [Step 10800/14540]  lr: 0.000001  loss: 0.54724  detection_loss: 0.4750 (cls: 0.1581, box: 0.3169)  rpn_loss: 0.0723 (cls: 0.0258, box: 0.0465)
[2025-08-07 22:52:23 train.log] INFO: Epoch: [29]  [Step 10900/14540]  lr: 0.000001  loss: 0.84630  detection_loss: 0.7544 (cls: 0.1992, box: 0.5552)  rpn_loss: 0.0919 (cls: 0.0417, box: 0.0502)
[2025-08-07 22:52:28 train.log] INFO: Epoch: [29]  [Step 11000/14540]  lr: 0.000001  loss: 0.92463  detection_loss: 0.8718 (cls: 0.2226, box: 0.6492)  rpn_loss: 0.0528 (cls: 0.0365, box: 0.0163)
[2025-08-07 22:52:34 train.log] INFO: Epoch: [29]  [Step 11100/14540]  lr: 0.000001  loss: 1.15372  detection_loss: 1.0995 (cls: 0.1818, box: 0.9177)  rpn_loss: 0.0542 (cls: 0.0119, box: 0.0422)
[2025-08-07 22:52:40 train.log] INFO: Epoch: [29]  [Step 11200/14540]  lr: 0.000001  loss: 0.96616  detection_loss: 0.8964 (cls: 0.3166, box: 0.5798)  rpn_loss: 0.0698 (cls: 0.0237, box: 0.0460)
[2025-08-07 22:52:46 train.log] INFO: Epoch: [29]  [Step 11300/14540]  lr: 0.000001  loss: 0.77404  detection_loss: 0.6662 (cls: 0.2437, box: 0.4225)  rpn_loss: 0.1079 (cls: 0.0703, box: 0.0376)
[2025-08-07 22:52:51 train.log] INFO: Epoch: [29]  [Step 11400/14540]  lr: 0.000001  loss: 1.00164  detection_loss: 0.8672 (cls: 0.2585, box: 0.6087)  rpn_loss: 0.1345 (cls: 0.1072, box: 0.0273)
[2025-08-07 22:52:57 train.log] INFO: Epoch: [29]  [Step 11500/14540]  lr: 0.000001  loss: 0.52783  detection_loss: 0.4667 (cls: 0.1070, box: 0.3597)  rpn_loss: 0.0611 (cls: 0.0245, box: 0.0366)
[2025-08-07 22:53:02 train.log] INFO: Epoch: [29]  [Step 11600/14540]  lr: 0.000001  loss: 0.83573  detection_loss: 0.7693 (cls: 0.1639, box: 0.6053)  rpn_loss: 0.0664 (cls: 0.0444, box: 0.0220)
[2025-08-07 22:53:08 train.log] INFO: Epoch: [29]  [Step 11700/14540]  lr: 0.000001  loss: 0.93579  detection_loss: 0.8429 (cls: 0.2541, box: 0.5889)  rpn_loss: 0.0929 (cls: 0.0674, box: 0.0254)
[2025-08-07 22:53:14 train.log] INFO: Epoch: [29]  [Step 11800/14540]  lr: 0.000001  loss: 0.68041  detection_loss: 0.6208 (cls: 0.1748, box: 0.4461)  rpn_loss: 0.0596 (cls: 0.0251, box: 0.0345)
[2025-08-07 22:53:19 train.log] INFO: Epoch: [29]  [Step 11900/14540]  lr: 0.000001  loss: 0.85369  detection_loss: 0.7915 (cls: 0.2101, box: 0.5814)  rpn_loss: 0.0622 (cls: 0.0342, box: 0.0280)
[2025-08-07 22:53:25 train.log] INFO: Epoch: [29]  [Step 12000/14540]  lr: 0.000001  loss: 0.55383  detection_loss: 0.5087 (cls: 0.1715, box: 0.3372)  rpn_loss: 0.0452 (cls: 0.0280, box: 0.0171)
[2025-08-07 22:53:30 train.log] INFO: Epoch: [29]  [Step 12100/14540]  lr: 0.000001  loss: 0.62168  detection_loss: 0.5722 (cls: 0.1113, box: 0.4609)  rpn_loss: 0.0495 (cls: 0.0361, box: 0.0134)
[2025-08-07 22:53:36 train.log] INFO: Epoch: [29]  [Step 12200/14540]  lr: 0.000001  loss: 0.82060  detection_loss: 0.7187 (cls: 0.2357, box: 0.4829)  rpn_loss: 0.1019 (cls: 0.0379, box: 0.0641)
[2025-08-07 22:53:41 train.log] INFO: Epoch: [29]  [Step 12300/14540]  lr: 0.000001  loss: 1.20721  detection_loss: 0.6328 (cls: 0.1316, box: 0.5012)  rpn_loss: 0.5744 (cls: 0.0385, box: 0.5359)
[2025-08-07 22:53:47 train.log] INFO: Epoch: [29]  [Step 12400/14540]  lr: 0.000001  loss: 0.78406  detection_loss: 0.6888 (cls: 0.1317, box: 0.5571)  rpn_loss: 0.0953 (cls: 0.0396, box: 0.0557)
[2025-08-07 22:53:52 train.log] INFO: Epoch: [29]  [Step 12500/14540]  lr: 0.000001  loss: 1.12326  detection_loss: 1.0561 (cls: 0.3154, box: 0.7407)  rpn_loss: 0.0672 (cls: 0.0402, box: 0.0270)
[2025-08-07 22:53:58 train.log] INFO: Epoch: [29]  [Step 12600/14540]  lr: 0.000001  loss: 1.12623  detection_loss: 1.0225 (cls: 0.3263, box: 0.6961)  rpn_loss: 0.1038 (cls: 0.0350, box: 0.0687)
[2025-08-07 22:54:03 train.log] INFO: Epoch: [29]  [Step 12700/14540]  lr: 0.000001  loss: 1.04748  detection_loss: 0.9365 (cls: 0.3372, box: 0.5993)  rpn_loss: 0.1110 (cls: 0.0368, box: 0.0742)
[2025-08-07 22:54:09 train.log] INFO: Epoch: [29]  [Step 12800/14540]  lr: 0.000001  loss: 0.66808  detection_loss: 0.5853 (cls: 0.1409, box: 0.4444)  rpn_loss: 0.0828 (cls: 0.0418, box: 0.0410)
[2025-08-07 22:54:14 train.log] INFO: Epoch: [29]  [Step 12900/14540]  lr: 0.000001  loss: 1.22478  detection_loss: 1.0922 (cls: 0.2281, box: 0.8641)  rpn_loss: 0.1326 (cls: 0.0497, box: 0.0829)
[2025-08-07 22:54:20 train.log] INFO: Epoch: [29]  [Step 13000/14540]  lr: 0.000001  loss: 1.13908  detection_loss: 1.0209 (cls: 0.2194, box: 0.8015)  rpn_loss: 0.1182 (cls: 0.0575, box: 0.0607)
[2025-08-07 22:54:25 train.log] INFO: Epoch: [29]  [Step 13100/14540]  lr: 0.000001  loss: 0.59454  detection_loss: 0.5293 (cls: 0.1281, box: 0.4013)  rpn_loss: 0.0652 (cls: 0.0359, box: 0.0293)
[2025-08-07 22:54:31 train.log] INFO: Epoch: [29]  [Step 13200/14540]  lr: 0.000001  loss: 0.79856  detection_loss: 0.7169 (cls: 0.1919, box: 0.5250)  rpn_loss: 0.0817 (cls: 0.0263, box: 0.0554)
[2025-08-07 22:54:36 train.log] INFO: Epoch: [29]  [Step 13300/14540]  lr: 0.000001  loss: 0.45747  detection_loss: 0.3925 (cls: 0.0739, box: 0.3185)  rpn_loss: 0.0650 (cls: 0.0287, box: 0.0363)
[2025-08-07 22:54:42 train.log] INFO: Epoch: [29]  [Step 13400/14540]  lr: 0.000001  loss: 0.52303  detection_loss: 0.4932 (cls: 0.0807, box: 0.4125)  rpn_loss: 0.0298 (cls: 0.0132, box: 0.0166)
[2025-08-07 22:54:47 train.log] INFO: Epoch: [29]  [Step 13500/14540]  lr: 0.000001  loss: 0.99088  detection_loss: 0.8848 (cls: 0.2418, box: 0.6430)  rpn_loss: 0.1060 (cls: 0.0410, box: 0.0650)
[2025-08-07 22:54:53 train.log] INFO: Epoch: [29]  [Step 13600/14540]  lr: 0.000001  loss: 0.65807  detection_loss: 0.4773 (cls: 0.0633, box: 0.4140)  rpn_loss: 0.1808 (cls: 0.0197, box: 0.1611)
[2025-08-07 22:54:59 train.log] INFO: Epoch: [29]  [Step 13700/14540]  lr: 0.000001  loss: 0.75778  detection_loss: 0.6379 (cls: 0.2319, box: 0.4061)  rpn_loss: 0.1199 (cls: 0.0925, box: 0.0273)
[2025-08-07 22:55:04 train.log] INFO: Epoch: [29]  [Step 13800/14540]  lr: 0.000001  loss: 1.08025  detection_loss: 0.9731 (cls: 0.1714, box: 0.8018)  rpn_loss: 0.1071 (cls: 0.0593, box: 0.0478)
[2025-08-07 22:55:10 train.log] INFO: Epoch: [29]  [Step 13900/14540]  lr: 0.000001  loss: 0.83302  detection_loss: 0.7531 (cls: 0.2426, box: 0.5105)  rpn_loss: 0.0799 (cls: 0.0294, box: 0.0505)
[2025-08-07 22:55:15 train.log] INFO: Epoch: [29]  [Step 14000/14540]  lr: 0.000001  loss: 1.05238  detection_loss: 0.9069 (cls: 0.2747, box: 0.6322)  rpn_loss: 0.1455 (cls: 0.0412, box: 0.1043)
[2025-08-07 22:55:21 train.log] INFO: Epoch: [29]  [Step 14100/14540]  lr: 0.000001  loss: 0.64045  detection_loss: 0.5884 (cls: 0.0915, box: 0.4969)  rpn_loss: 0.0520 (cls: 0.0303, box: 0.0217)
[2025-08-07 22:55:26 train.log] INFO: Epoch: [29]  [Step 14200/14540]  lr: 0.000001  loss: 0.90312  detection_loss: 0.8293 (cls: 0.1402, box: 0.6892)  rpn_loss: 0.0738 (cls: 0.0292, box: 0.0446)
[2025-08-07 22:55:32 train.log] INFO: Epoch: [29]  [Step 14300/14540]  lr: 0.000001  loss: 0.86833  detection_loss: 0.8114 (cls: 0.1708, box: 0.6406)  rpn_loss: 0.0570 (cls: 0.0357, box: 0.0213)
[2025-08-07 22:55:37 train.log] INFO: Epoch: [29]  [Step 14400/14540]  lr: 0.000001  loss: 1.13416  detection_loss: 0.8528 (cls: 0.1681, box: 0.6846)  rpn_loss: 0.2814 (cls: 0.0579, box: 0.2235)
[2025-08-07 22:55:43 train.log] INFO: Epoch: [29]  [Step 14500/14540]  lr: 0.000001  loss: 0.71615  detection_loss: 0.6473 (cls: 0.1352, box: 0.5120)  rpn_loss: 0.0689 (cls: 0.0441, box: 0.0247)
